#+LATEX_CLASS: book-noparts
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage{shellesc}
#+LATEX_HEADER: \usepackage{booktabs}
#+LaTeX_HEADER: \usepackage{pdfpages}
# #+LaTeX_HEADER: \usepackage{tikz}

# 'externalize' all TikZ plots, i.e. cache them
# #+LaTeX_HEADER: \usepackage{pgfplots}
# #+LaTeX_HEADER: \usepgfplotslibrary{external} 
# #+LaTeX_HEADER: \tikzexternalize[prefix=cache/]

#+LATEX_HEADER: % main document, called main.tex
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{external}
#+LATEX_HEADER: \tikzexternalize[prefix=cache/] % activate!

# got an error suddenly with the 'externalize' section above
# https://tex.stackexchange.com/questions/365777/cannot-run-tikz-externalize-with-lualatex-but-it-used-to-work

# for mini table of contents for each chapter
#+LATEX_HEADER: \usepackage{minitoc}

#+LATEX_HEADER: \usepackage{siunitx}
#+LATEX_HEADER: \sisetup{mode=text,range-phrase = {\text{~to~}}}

# font handling

# font handling
#+LATEX_HEADER: \usepackage{fontspec,minted}
#+LATEX_HEADER: \setmonofont{Fira Code} % suports all unicode we care about in code
#+LATEX_HEADER: \setmainfont{DejaVu Serif} % supports all unicode we care about as serif font

# STIX looks nice, but we have to set up the other versions (bold
# etc.) and decide on a good line spacing.
# #+LATEX_HEADER: \setmainfont[Path = "/usr/share/fonts/stix/static_otf/", Extension = ".otf"]{"STIXTwoText-Regular"}
# #+LATEX_HEADER:   #UprightFont    =  ,
# #+LATEX_HEADER:   #BoldFont       = *-Bold ,
# #+LATEX_HEADER:   #ItalicFont     = *-Italic ,
# #+LATEX_HEADER:   #BoldItalicFont = *-BoldItalic
# #+LATEX_HEADER: ]{"STIXTwoText-Regular"}


# The following is the approach using `ucharclasses` but that ruins
# code blocks of minted...
#   #+LATEX_HEADER: \usepackage{fontspec}
#   #+LATEX_HEADER: \usepackage[Latin,Mathematics,Punctuation,Symbols]{ucharclasses}
#
#   #+LATEX_HEADER: \newfontfamily{\mydefaultfont}{DejaVuSans}
#   #+LATEX_HEADER: \newfontfamily{\mymainfont}{CMU Serif}
#
#   #+LATEX_HEADER: \setTransitionsForPunctuation{\mymainfont}{\mydefaultfont}
#   #+LATEX_HEADER: \setTransitionsForLatin{\mymainfont}{\mydefaultfont}
#   #+LATEX_HEADER: \setTransitionsForSymbols{\mydefaultfont}{\mymainfont}
#   #+LATEX_HEADER: \setTransitionsForMathematics{\mydefaultfont}{\mymainfont}

# package that allows inserting unicode characters in math environment
#+LATEX_HEADER: \usepackage{unicode-math}

#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{mhchem}
#+LATEX_HEADER: \usepackage{subcaption}

# make the margin on the sides smaller
#+LATEX_HEADER: \usepackage[margin=2.5cm]{geometry}

# ##############################
# change output of code blocks to use monokai
# ##############################
#+LaTeX_HEADER: \usemintedstyle{monokai}

#+LATEX_HEADER: \definecolor{monokai_bg}{RGB}{39, 40, 34}
#+LATEX_HEADER: \definecolor{monokai_fg}{RGB}{241, 235, 235}
#+LATEX_HEADER: \definecolor{monokai_0}{RGB}{72,72,62}
#+LATEX_HEADER: \definecolor{monokai_1}{RGB}{220,37,102}
#+LATEX_HEADER: \definecolor{monokai_3}{RGB}{212,201,110}
#+LATEX_HEADER: \definecolor{monokai_4}{RGB}{85,188,206}

# color commands
#+LATEX_HEADER: \definecolor{monokai_orange}{RGB}{253, 151, 31}
#+LATEX_HEADER: \newcommand{\orange}{\textcolor{monokai_orange}}
#+LATEX_HEADER: \newcommand{\green}{\textcolor{green}}
#+LATEX_HEADER: \newcommand{\red}{\textcolor{red}}
#+LATEX_HEADER: \DeclareSIUnit\year{yr}

# custom commands for convenience
#+LATEX_HEADER: \newcommand{\ccsini}{$\mathrm{Si}₃\mathrm{N}₄$}
# \def\si3n4{$\mathrm{Si}₃\mathrm{N}₄$}

#+LATEX_HEADER: \usepackage[backend=biber]{biblatex}
#+LATEX_HEADER: \addbibresource{references.bib}


# With Dejavu Serif a linespacing of 1.2 is too tight. 1.5 looks nice,
# maybe 1.4 is optimal? 
#+LATEX_HEADER: \linespread{1.5} % change line spacing to be a bit larger. TODO: find good value!

# HTML Export
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="nimdoc.css" />
#+OPTIONS: html-style:nil

#+OPTIONS: toc:nil # turn off Table of Contents here and place it elsewhere

#+LATEX: \dominitoc % initialize the package

#+EXCLUDE_TAGS: noexport


\begin{titlepage}

\begin{center}
  \huge Search for solar axions using a 7-GridPix IAXO prototype detector at CAST

  \vspace{2cm}
  \Large Sebastian Michael Schmidt
\end{center}

place funny logos and stuff

Doktorgrad
erworben 2021
Solingen


\end{titlepage}

#+TOC: headlines 2


# Part 0: Introduction

* Compile                                                          :noexport:

Compilation at the moment is still a bit broken due to =biber=.

We need to generate the TeX file from Org =C-c C-e l l= to generate
the TeX file.

Then in terminal:
#+begin_src sh
lualatex --shell-escape thesis.tex
biber thesis
lualatex --shell-escape thesis.tex
#+end_src

Or better yet, let =latexmk= take care of it:
#+begin_src
latexmk -pvc -pdf -view=none -shell-escape -pdflatex=lualatex thesis.tex
#+end_src

it watches the file and automatically recompiles if the file changed
on disc.

* Start me                                                         :noexport:

#+begin_src emacs-lisp
(add-to-list 'org-latex-classes
             '("book-noparts"
               "\\documentclass{book}"
               ("\\chapter{%s}" . "\\chapter*{%s}")
               ("\\section{%s}" . "\\section*{%s}")
               ("\\subsection{%s}" . "\\subsection*{%s}")
               ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
               ("\\paragraph{%s}" . "\\paragraph*{%s}")
               ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+end_src


* Introduction                                                        :Intro:

Bla..


After a short side note about this thesis as a document in chapter
[[About this thesis (structure)]], we introduce the theoretical foundation
of axion physics in chapter [[Theory of axions]]. From a historical
standpoint as to why axions were invented in the first place to the
avenues of detection and related the expected solar axion fluxes.

This leads to chapter [[Axion helioscopes]], which introduces the concept
of an axion helioscope as a way to potentially detect axions of a
solar origin. Other possible approaches will be shortly mentioned.

With an understanding of possible detection mechanisms for axions, we
will focus next on the required hardware to actually measure axions
indirectly, i.e. via gaseous detectors for X-ray detection in chapter
[[Gaseous detectors principles]].

As we finally wish to compute a limit on different axion coupling
constants, an understanding of basic statistics for limit calculations
is required. This we will cover in chapter [[Statistics & limit
calculations]].

Next we introduce our detector, the Septemboard based GridPix
detector, in chapter [[Septemboard detector]]. Here we will discuss both
the motivation behind why such a detector was built, the different
features of the detector and basic calibration principles as well as
covering the setup and software used to run the detector.

Stopping at the software running the detector, we will then transfer
over to the software suite built to analyze the data in chapter
[[Software]].

A further chapter about the analysis principles follows, which
explains the ideas of how the data reconstruction works, what kind of
calibrations are applied to the data and how it all fits together to
compute a background rate and limit. This is chapter [[Chapter about
analysis principle]].

Raytracing chapter will be moved somehow.

What follows in chapter [[Detector preparation / study /
characterization etc.]] is the explanation of all characterization
measurements, an introduction to the $^55\text{Fe}$ calibration
measurements and how the energy calibration works.

From there we go to the actual deployment of the detector at CAST in
chapter [[Detector installation at CAST & data taking]], in which we
describe the physical setup and give an overview over the different
data taking periods.

With the description of the data periods out of the way, we can make
use of the data to compute the background rate of the detector for
different cases in chapter [[Background rate computation]].

These background rates are combined with the expected signals from
chapter *TODO which one Raytracing + theory?* and the measured
candidates during tracking time to compute a limit in chapter [[Limit
calculation]].

As a final part we will give an outlook of what a future Timepix3
based detector might achieve in chapter [[Outlook]].

Afterwards we finally conclude in chapter [[Summary & conclusion]].

* About this thesis (structure)                                       :Intro:

*TODO:* (maybe) insert the essay written on my phone one night here
(into the full version of the thesis at least) 

Explanation about the thesis structure and introduction of the "full
thesis document".

The thesis you are reading right now is a shortened version of the
full document it is part of. To conform to the expectations of a PhD
thesis many parts are removed that are irrelevant for the basic
presentation of the work done during the thesis.

However, a fellow researcher who wishes to understand all the details,
in particular in terms of reproducibility of the results, the full
document should be read instead. If possible a PhD thesis should be a
tome of knowledge about the topic that allows the interested reader to
absorb as much of the authors knowledge as possible to help with the
continuation of the research.

Furthermore, every thesis, especially those relying on large pieces of
software, contains mistakes, bugs, wrong assumptions and more. Most of
these are not known to the researcher, possibly due to lack of
knowledge in a specific topic. Other times shortcomings _are_ known,
but left out for convenience. This thesis is about one thing:
*transparency*. There are bugs in the referenced code that I'm not
aware of, bad assumptions about certain things, etc. Where I *am*
aware of sketchy choices, I will highlight them honestly. 

The full document is found at:

*TODO*: insert link, probably to GitHub as well as some other source

The main difference between the regular thesis document and the
extended version are the following. The extended version contains:
- either inline code or links to the code that produces *every plot*
  (that is created by me); inline code is used if the required code to
  generate the plot is less than a certain amount of lines.
  For non-inlined code the used code is referenced (link to the code +
  correct git commit)
- access to *all* raw and reconstructed data to reproduce the results
- additional chapters that were not relevant enough / polished enough
  for inclusion into the thesis. This includes additional plots,
  investigations of detector behavior etc., theoretical calculations
  and more.

In essence the idea is to provide a fully reproducible thesis. The
extended version should ideally be read as a mix of the generated PDF
and the real Org file behind it.

The extended version includes many source code blocks that can be
extracted using [[https://github.com/OrgTangle/ntangle][ntangle]]:
#+begin_src sh
ntangle thesis.org
#+end_src

Ideally, all results can be reproduced with a single:
#+begin_src sh
./generateResults.sh
#+end_src
call (we'll see how that will work out).

The package versions for the code used in the extended version will be
frozen at a specific time. The list of version numbers will be found
below.

*TODO*: Add version numbers of all packages used for final plots.

*TODO*: Have specific marking in (sub)sections if they contain more
information in extended version?

*TODO*: It would be sick if we could do something like
#+begin_src sh
curl -s <backblaze link> | sh foo.sh
#+end_src
to download and generate everything in one go. Seems a bit insane
though. But who knows.

*TODO*: In =noexport= sections, possibly have a "Skip this section
if:" introduction? So that readers know exactly why a certain section
might be of interest to them.


Further, this thesis does not attempt to cover *every* aspect of the
theoretical foundation required to understand every part. For example
we will not introduce the Standard Model or explain certain detector
features, if they are not of importance for the understanding of our
data.
Good references, if available, will however be given for an interested
reader / a reader attempting to fill in gaps in knowledge.

* TODO List of todos [0/9]                                   :Intro:noexport:

** TODO Have reference to Firmware used at CAST in each run

** TODO Run list (appendix)

** TODO Include exact results from Geometer measurements

Find in EDH and include, even if we don't use it. Referenced in X-ray
finger measurements.


** TODO fix up schematic of V6 Septemboard connections
** TODO fix up schematic of MM working principle

The existing schematic is not very clear. Change the drift gap
behavior and amplification gap one by reversing their drawing
style. Add some alpha to different regions to highlight amount of
electrons drifting. Add a text label with O(magnitude)

** TODO insert the first LaTeX + Vega-lite based plot

This gives us an idea of how this will work. For a start I'd say base
the Vega-lite plots on Github gists. That allows for easy replacement
for the time being.

** TODO implement nothing ⇒ background rate as reproducible build

This one will be a bit ambitious, but maybe it's a day of work.

*If* we get this working we're at a point where generating other plots
is just a simple shell command (call script X with args Y), as we will
have all =Calibration/DataRunsX_Y.h5= files ready somewhere.

Steps:
*** Setup Nim + all packages of fixed versions (take versions from a TOML file)
*** Have config file storing paths of raw data + output paths
*** run raw data, reco, ...
*** generate CDL datasets
*** compute logL files
*** plot background

** TODO find way to host the raw data

Can also just use Zenodo https://zenodo.org


B2 maybe as an alternative?

We could start by a simple Backblaze B2 hosting.

Pricing is competitive:
Hosting: 0.005 $/Month/GB
Download: 0.01 $/GB
https://www.backblaze.com/b2/cloud-storage-pricing.html

Which is 1.5$ for 300 GB and 3$ to download it. Certainly cheap enough
to try!

Data to store
*** All 2017/18 data runs
**** Run 2
**** Run 3
*** Detector calibration files for Run 2, Run 3
*** FADC pedestal run
*** X-ray finger runs
*** All our notes + thesis
*** Nim code?                                                     :pending:

** TODO use some package for abbreviations

** Points of contention

At the moment <2021-07-31 Sat 11:36> my biggest point of uncertainty
is the whole detector calibration part + how this plays into a
software framework.

Difficult to come up with good layout at this point. Will be easier
once more notes are added in each part I think.

** Structure

I'm very lost <2022-08-22 Mon 13:53> about how to structure the thesis
at this point. :(

Maybe it's easier to think of the ingredients for the limit
calculation as tips of strands. Follow each back to its
introduction. But: should each of these simply be its own chapter?

E.g. axion image:
- raytracing
- solar axion flux
- axion models

So therefore have a chapter "Deriving the expected axion image" that
starts from:
- pick a solar model & axion model
- compute expected flux
- use raytracing, explain, to compute the image?
- but: needs average absorption depth to know at what point to even
  compute something!
  Well, this _can_ work, as long as the setup & detector are explained
  _before_ this chapter.

However: none of that makes any sense without the context of the
limit calculation! Why else would one need to compute such an image
etc?

Instead could also start part 2 (or whatever) of the thesis as "limit
calculation" and have this be a huge part that first introduces the
math of what & how to compute a limit, and *then* introduces how one
ends up at the necessary inputs?

If I do it this way, then the first part of the thesis is purely:
- axion theory generically
- axion helioscopes  
- gaseous detector physics & micromegas
- the septemboard detector
- deployment at CAST
- data analysis to an extent? to what extent though?

Part 2:
limit calculation
- how to compute limit, method
- ingredients, show them.
- then: each ingredient, how to derive it
- finally:
  - put all ingredients together, short overview
  - compute
  
  

* Theory of axions                                                   :Theory:
#+LATEX: \minitoc

*ADD SENTENCE ABOUT CPT INVARIANCE OF SM*

The standard model of particle physics at low energies can be
described by a combination of three different forces, the
electromagnetic, the weak and the strong force. These can be
represented mathematically by an internal group structure of
$\mathrm{U}(1) \times \mathrm{SU}(2) \times \mathrm{SU}(3)$,
respectively. [fn:groups] The weak force, represented by
$\mathrm{SU}(2)$, has long since been known to exhibit a
$CP$-violation [fn:cp_violation] *CITE REFERENCE WEAK CP PROBLEM*. Due
to the similar structure between the weak and the strong force
($\mathrm{SU}(2)$ vs. $\mathrm{SU}(3)$) many parallels exist between
the mathematical descriptions of the two forces in the standard
model. *CITE t'HOOFT QCD VACUUM STRUCTURE* In particular the
Lagrangian term giving rise to the weak $CP$-violation can be written
down equivalently for the strong force, implying an expected
$CP$-violation in the strong force. Peculiarly, any effect expected
from this has still _not_ been observed. One such effect is for
example an expected electric dipole moment of the neutron
\cite{CREWTHER_NEDM, CREWTHER_NEDM_ERRATA, Baluni_NEDM}. Such a dipole
moment may naively be expected plainly from the fact that the
constituent quarks of a neutron are charged after all. However, very
stringent limits place an extremely low upper bound on it at
\cite{NEDM_Limit, Revised_NEDM_Limit}

*SHOW WEAK CP VIOLATING TERM*
*GET BEST CURRENT LIMIT ON NEDM*
*WRITE THETA TERM HERE TO REFERENCE IT IN QUINN PECCEI*

\[
d_{\text{NEDM}} \leq \SI{3e-26}{\elementarycharge \cm},
\]

where $e$ is the electron charge. Nature's deviation from our
expectation in this context is coined the _strong $CP$-problem_ of
particle physics. While it is possible that our universe is simply one
in which the effect of the strong $CP$-violation is suppressed (or
even exactly zero) "by chance", Helen Quinn and Roberto Peccei
realized in 1977 \cite{PecceiQuinn1977_1, PecceiQuinn1977_2} that this
behavior can be explained in the presence of an additional scalar
field. Shortly after both Weinberg and Wilczek \cite{AxionWeinberg,
AxionWilczek} realized the implication of such an additional field,
namely a pseudo Nambu-Goldstone boson, which *WILCZEK OR WEINBERG??*
named the _axion_, after a washing detergent, as it washes the
standard model clean of the strong $CP$-problem. While the most
straight forward axion model based on the work by Wilczek and Weinberg
yields a coupling of the axion to matter that is already excluded
*CITE SEE LANDSCAPE*, models for an 'invisible axion' manage to unify
the solution to the strong $CP$-problem with the current lack of
experimental evidence for an axion-like particle. There are two main
models for the invisible axion, the KSVZ
(Kim-Shifman-Vainshtein-Zakharov) and the DFSZ
(Dine-Fischler-Srednicki-Zhitnitskii) models.

For the most comprehensive overview of the theory of axions, overview
of models, best bounds on different axion models and general axion
reference, make sure to look into the aptly named "landscape of QCD
axions" \cite{DILUZIO20201}!

*LANDSCAPE OF QCD AXION* shows nice explanation of visible vs
invisible models.

*FIND REFERENCE TO ORIGINAL AXION BEING VISIBLE*
*FIND REFERENCE TO INVISIBLE AXION*

*ADD REMARKS ABOUT*:
- theta term
- axion mass
- axion coupling constants    

[fn:groups] $\mathrm{U}(1)$ refers to the "circle group", i.e. the
group that describes rotations on a unit circle (consider a phase
shift on the complex plane). The group operation as such can be
considered as multiplication by a complex phase. $\mathrm{SU}(n)$ is
the special unitary group, which means the group of unitary matrices
of rank $n$ with determinant 1, where the group operation is matrix
multiplication of these matrices (for $\mathrm{SU}(2)$ the Pauli
matrices multiplied by $\frac{i}{2}$ are a possible set of
infinitesimal generators for example).

[fn:cp_violation] $C$ refers to the discrete transformation of charge
conjugation and $P$ for parity transformation. Both refer to the
idea of studying a physical system with either (or both) of these
transformations applied. A $CP$ conserving theory (or system) would
behave exactly the same under the combined transformation. The
standard model is mathematically $CPT$ invariant ($T$ being time
reversal). As such, if a system exhibits different behavior under time
reversal it implies a violation of $CP$ to achieve a combined $CPT$
invariance.



From a historical standpoint including the strong CP problem, we go
over to the Peccei-Quinn solution. Another way to look at it is from a
modern standpoint asking why does the neutron not have a dipole
moment?

*Take a look at lectures for Axion School*
*QCD AXION LANDSCAPE PAPER*
*PAPER RINGWALD LIKED SO MUCH*


[fn:axion_overview] To be brutally honest, as a combination of the
significant growth of the axion community (both experimentally and
theoretically) and my lack of theory work in the last years, I cannot
do an overview of axion theory justice. Fortunately, there are a huge
number of amazing reviews of the current axion landscape out there! In
particular "landscape of QCD axion models".


*NOTE*: I think after introducing the axion the way I've done up there
now, maybe it's a good idea to just review the relevant parts that
will show up in the thesis? Mass, coupling, etc?

** Historical origins

From electroweak theory we know about CP violation. Standard model for
strong force is just SU(3) vs. SU(2) for electroweak.

Lagrangian allows mostly the same terms for both forces. This implies
there should be a strong CP violation. This isn't observed and even
today theh neutron electric dipole moment is restricted to values
smaller $d_N \leq 1e-26 \text{? some units}$.

Merge the next section into this one and change title?

** Strong CP problem

Use the schematic I created for Hendrik's presentation?

** Peccei-Quinn solution

Main Peccei-Quinn paper citation.

Solution by introducing another global U(1) symmetry that is
spontaneously broken below some energy scale. 

** The axion

Leads to a pseudo Nambu-Goldstone boson that Wilzcek named the Axion
(ref a pic of axion detergent), as it washes the standard model clean
of an ugly stain.

** DFSZ & KSVZ axion models

Further developments lead to more complex axion models that better fit
with our understanding.

Two main types of models emerged.

** Implications for axion interactions

Axions are apparently not interacting a whole lot, otherwise we'd know
about them already. Very weak interaction

Main interaction arises due to anomalies in standard model that allow
for a Fermion loop diagram. That allows for coupling to
gluons. Effective photon coupling is the result, equivalent to
Primakoff effect for pions (also an effective coupling!).

Write down effective Lagrangian.

*COHERENCE CONDITION*
*VACUMM VS GAS*

** Solar axion flux

Important for us? How do we detect them.

Have a simple derivation from KG equation? Take a look at Biljana &
Kreso for simple overview and simplify.

Take KG equation and derive interaction.

Interaction tells us conversion is proportional to B and L. Where are
strong Bs for long Ls? Solar core.
Take modern solar model to plot the density profile & especially
temperature. Density + temperature allows us to compute:
- number of photons
- at various photon energies

By wrapping blackbody radiation (ref, 3 sentences about it) present in
solar core with Primakoff coupling, we get an effective axion flux
equivalent to:

$dΦ/dE ∝ g_{aγ}² · \text{black body radiation}$

*CHECK CAST PHASE I RESULT PAPER FOR OVERVIEW* (contains physics +
integration over solar model!)
Refer to that paper in particular to answer the question: "do axions
escape from the sun?"

*BIBBER* \cite{PhysRevD.39.2089} contains derivation of axion flux based
on black body radiation. First CAST paper bases their flux on this,
with a modification from some other paper & a newer solar model from
2001 ("reference" 15 in that CAST paper). This reference *also*
contains a derivation of axion equations of motion etc. via KG equation.

*** Primakoff flux

Including analytical equation for flux... :)

#+begin_src nim :tangle /tmp/solar_axion_flux.nim :results silent
import unchained, ggplotnim, math, chroma, ginger
defUnit(keV⁻¹•m⁻²•yr⁻¹)
defUnit(keV⁻¹•cm⁻²•s⁻¹)
defUnit(GeV⁻¹)

proc axionFluxPrimakoff(E_a: keV, g_aγ: GeV⁻¹): keV⁻¹•cm⁻²•s⁻¹ =
  ## dΦ_a/dE taken from paper about first CAST results \cite{PhysRevLett.94.121301}
  let g₁₀ = g_aγ / 1e-10.GeV⁻¹ # * 10e10.GeV¹ #
  result = g₁₀^2 * 3.821e10.cm⁻²•s⁻¹•keV⁻¹ * (E_a / 1.keV)^3 / (exp(E_a / (1.103.keV)) - 1)

proc axFluxPerYear(E_a: keV, g_aγ: GeV⁻¹): keV⁻¹•m⁻²•yr⁻¹ =
  result = axionFluxPrimakoff(E_a, g_aγ).to(keV⁻¹•m⁻²•yr⁻¹)

proc axionFluxPrimakoffMasterThesis(ω: keV, g_ay: GeV⁻¹): keV⁻¹•m⁻²•yr⁻¹ =
  # axion flux produced by the Primakoff effect
  # in units of m^(-2) year^(-1) keV^(-1)
  result = 2.0 * 1e18.keV⁻¹•m⁻²•yr⁻¹ * (g_ay / 1e-12.GeV⁻¹)^2 * pow(ω / 1.keV, 2.450) * exp(-0.829 * ω / 1.keV)

let E = linspace(1e-3, 14.0, 1000)
let df = seqsToDf(E)
  .mutate(f{float: "Flux" ~ axionFluxPrimakoff(`E`.keV, 1e-11.GeV⁻¹).float})
  .mutate(f{float: "FluxYr" ~ axFluxPerYear(`E`.keV, 1e-11.GeV⁻¹).float})
  .mutate(f{float: "FluxMSc" ~ axionFluxPrimakoffMasterThesis(`E`.keV, 1e-11.GeV⁻¹).float})    
ggplot(df, aes("E", "Flux")) +
  geom_line() +
  #geom_line(aes = aes(y = "FluxMSc"), color = some(parseHex("0000FF"))) + 
  ggtitle("Solar axion flux due to Primakoff production, g_aγ = 10⁻¹¹·GeV⁻¹") +
  xlab("Energy [keV]") +
  #ylab("Axion flux [keV⁻¹·cm⁻²·s⁻¹]") +
  ylab("Axion flux [keV⁻¹·m⁻²·yr⁻¹]") +  
  ggsave("/tmp/primakoff_axion_flux.pdf")

ggplot(df.mutate(f{"Flux" ~ `Flux` / 1e8}), aes("E", "Flux")) +
  geom_line() +
  #xlab("Energy [keV]", tickFont = font(12.0), margin = 1.5) +
  xlab(r"\fontfamily{lmss}\selectfont Energy [$\si{\keV}$]", margin = 2.0, font = font(16.0),
       tickFont = font(16.0)) +
  xlim(0, 14) + 
  #ylab("Axion flux [10¹⁰ keV⁻¹·cm⁻²·s⁻¹]", margin = 1.5) +
  ylab(r"\fontfamily{lmss}\selectfont Axion flux [\SI[print-unity-mantissa=false]{1e11}{\keV^{-1} \cm^{-2} \second^{-1}}]",
       margin = 2.0,
       font = font(16.0)) + 
  #     tickFont = font(12.0)) +
  #ggtitle(r"Expected solar axion flux, g_aγ = 10⁻¹⁰ GeV⁻¹", titleFont = font(12.0)) +
  annotate(r"\fontfamily{lmss}\selectfont Expected solar axion flux" &
    r"\\$g_{aγ} = \SI[print-unity-mantissa=false]{1e-11}{\GeV^{-1}}$", #10⁻¹⁰ GeV⁻¹",
           x = 6.2, y = 6.2, 
           font = font(16.0),
           backgroundColor = transparent) +
  #ggtitle(r"Expected solar axion flux, $g_{aγ} = \SI{1e-11}{\GeV^{-1}}$", titleFont = font(12.0)) + 
  #ggsave("/tmp/cristina_primakoff_axion_flux.pdf", width = 400, height = 300) #, useTeX = true, standalone = true)
  ggsave("/tmp/cristina_primakoff_axion_flux.pdf", useTeX = true, standalone = true)
  

defUnit(m⁻²•yr⁻¹)  
echo 1.cm⁻²•s⁻¹.to(m⁻²•yr⁻¹)
#+end_src

There are different analytical expressions for the solar axion flux
for Primakoff production. These stem from the fact that a solar model
is used to model the internal density, temperature, etc. in the Sun to
compute the photon distribution (essentially the blackbody radiation)
near the core. From it (after converting via the Primakoff effect) we
get the axion flux.

Different solar models result in different expressions for the
flux. The first one uses an older model, while the latter ones use
newer models.

*** Axion-electron flux

*citations*: Redondo 2013, maybe (Johanna + Sebastian Hoof something?)
*Keep in mind errors in Redondo 2013*! *possibly write a mail to Sebastian Hoof*

Expected axion flux combined.

Reference to file storing the results for specific coupling constants.

Much more complicated.

ABC components.

B and C can be expressed analytically.

A cannot, needs opacity project.

Show plot of differential axion flux.

For a derivation of this, consider section about ray tracing. Custom
computation of A done by Johanna in code developed by her & me in
*LINK*.

** TODO possibly add chameleons?

?? will depend on whether we do a chameleon limit (which we should, as
our detector is much better here!)

Should be easy after all, as everything is the same as for axions,
except different flux, raytracing and thus limit calc (from a number
perspective; concept is the same).

** Current bounds on axion couplings

The field of axion searches is expanding rapidly in recent years,
especially in haloscope experiments.

A haloscope is a type of axion experiment consisting of a (typically
microwave) cavity placed in a magnetic field. It intends to detect
axions of the dark matter halo of our galaxy. Axions that are part of
the dark matter component are necessarily very low energy as they
decoupled long ago and underwent cooling ever since. Thus, their
energies are in the microwave range. If a cavity has a resonance
frequency matching the axion mass (the kinetic energy is negligible,
so the majority of the energy is in the mass), the conversion probability is
enhanced by the quality factor $Q$ of the cavity (effectively the
number of reflections in the cavity). The upside of such experiments
are the strong enhancements possible, which allow to reach very low
coupling constants. However, a cavity has a single resonance
frequency, limiting the mass range to be studied to a very narrow
range. Most experiments use cavities that can be tuned to expand the
mass range. At each tuned frequency data is taken for a fixed amount
of time to reach a certain coupling constant. As such a tunable cavity
experiment can scan a narrow band of axion masses over the course of
its data taking campaign. Due to the simplicity of the setup these
type of experiments are very popular nowadays.

Astronomical axion bounds.

Cavity bounds.

Helioscope bounds.

(what else?)

*TODO*: include newest Chandra results for coupling constant

*TODO*: include Xenon-1T results 

* Axion helioscopes                                                  :Theory:
#+LATEX: \minitoc
Introduce axion helioscopes as one of the types of experiments
proposed by Sikivie in his paper. *CITE SIKIVIE*

Maybe shortly mention other experiments.

As discussed in the previous chapter in section [[Solar axion flux]],
stars are expected to produce significant excess of axions. In 1983
Pierre Sikivie proposed multiple methods to potentially detect
axions, one of these making use of this solar axion production. 

From the theory on axions (ref. section [[Implications for axion
interactions]]) we know there is an effective coupling to the photon
$g_{aγ}$. This coupling is an equivalent to the Primakoff effect,
which describes a resonant production of mesons via a Fermion loop in
strong electromagnetic fields when interacting with a nucleus. In the
Primakoff effect two photons are present, an incoming real photon and
a virtual photon of the electromagnetic interaction of the
nucleus. Axions can take the place of the physical photon, either in
the initial state or in the final state. In the former case we have an
axion to photon conversion and in the latter a photon to axion
conversion.

*DIFFERENTIATE BETWEEN PRIMAKOFF AND INVERSE PRIMAKOFF*

*PUT PRIMAKOFF FEYNMAN DIAGRAM*
*POSSIBLY MOVE TO THEORY ITSELF AND REFERENCE*

As it turns out, the relevant aspect for the Primakoff effect is not
the presence of a nucleus, but simply the fact that the nucleus
provides an electromagnetic field. This means the nucleus can also be
replaced by - for example - a transverse, constant magnetic field.

*EXPLAIN WHY TRANSVERSE MAGNETIC FIELD IN THEORY*

This fact is the foundation of the helioscope idea. By pointing a
magnet at the Sun one expects a small fraction of the axions produced
in the Sun to reconvert to photons in the presence of the magnetic
field via the inverse Primakoff effect. These photons will carry the
energy of the original photons that produced the axions, namely the
energy of photons in the solar core. Essentially black body radiation
of $\sim\mathcal{O}(\SI{15}{\mega\kelvin}$.

*INSERT FIG BLACKBODY HERE OR IN SOLAR AXION FLUX SECTION*

This means the reconverted photons are mostly in the soft X-ray range
between \SIrange{1}{7}{\keV}. The first implementation of the
helioscope idea was the Rochester-Brookhaven-Florida experment *CITE
2*. It was followed by the SUMICO experiment in Tokyo *CITE 3*. The
third and only still running helioscope is the CERN Axion Solar
Telescope (CAST), which we will present in more detail in section [[CERN
Axion Solar Telescope (CAST)]]. In the final section we will introduce
the next generation of axion helioscopes, the International AXion
Observatory (IAXO), section [[International AXion Observatory (IAXO)]].

** Black body radiation in solar core                             :noexport:

Let's compute the black body radiation for the solar core and see if
it matches the energy spectrum we expect for axions.

Planck's law is defined as *CITE SOMETHING*:

\[
B_ν(ν, T) = \frac{2hν³}{c²} \frac{1}{e^{hν/kT} - 1}
\]

where $ν$ is the frequency of the photon and $T$ the temperature in
Kelvin. $k$ is of course the Boltzmann constant and $h$ the Planck
constant. Let's see what this looks like for $T =
\SI{15}{\mega\kelvin}$.

#+begin_src nim :tangle /home/basti/phd/code/black_body_sun_core.nim
import ggplotnim, unchained, sequtils

#defUnit(s⁻¹)
#defUnit(μs⁻¹)
defUnit(Watt•Steradian⁻¹•Meter⁻²•NanoMeter⁻¹)
defUnit(Joule•Meter⁻²•Steradian⁻¹)

let T_sun = 15.MegaKelvin.to(Kelvin)

proc blackBody(ν: s⁻¹, T: Kelvin): Joule•Meter⁻²•Steradian⁻¹ =
  result = (2 * hp * ν^3 / c^2 / (exp(hp * ν / (k_B * T)) - 1)).to(Joule•Meter⁻²•Steradian⁻¹)

proc xrayEnergyToFreq(E: keV): s⁻¹ = 
  ## converts the input energy in keV to a correct frequency
  result = E.to(Joule) / hp
echo 1.keV.xrayEnergyToFreq

echo blackBody(1.μHz.to(Hz), T_sun)
echo blackBody(1.keV.xrayEnergyToFreq, T_sun)

let energies = linspace(0.01, 16.0, 1000)
let radiance = energies.mapIt(blackBody(it.keV.xrayEnergyToFreq, T_sun).float)
let df = seqsToDf(energies, radiance)
ggplot(df, aes("energies", "radiance")) + 
  geom_line() + 
  ggtitle("Black body radiation @ T = 15 Mio. K") +
  xlab("Energy [keV]") + ylab("Radiance [J•m⁻²•sr⁻¹]") + 
  ggsave("/tmp/blackbody_sun.pdf")
#+end_src

#+RESULTS:


** TODO small section about other kinds of experiment?

** CERN Axion Solar Telescope (CAST)

The CERN Axion Solar Telescope (CAST) was proposed in 1999
\cite{ZIOUTAS1999480} and started data taking in 2003
\cite{PhysRevLett.94.121301}. 

*PICTURE OF CAST*

Using a \SI{9.26}{m} long LHC dipole magnet that was available from
the developments for the LHC, CAST features a \SI{9}{\tesla} strong
transverse magnetic field for axion-photon conversion produced by a
current of \SI{13}{\kilo\ampere} in the superconducting wires
*MATERIAL EXPLICIT* at \SI{1.8}{\kelvin}. It is placed on a movable
platform that allows for solar tracking both during sunrise as well as
sunset. The vertical range of movement is in principle
$\sim\pm\ang{8}$, but is slightly reduced in the last years of data
taking since 2019 (*CHECK NUMBER ASK THEODOROS*). This range of motion
allows for solar tracking of approximately \SI{90}{\minute} each day,
the exact duration depending on time of the year. Due to their
incredibly feeble interactions solar tracking can already start before
sunrise / stop after sunset as axions easily traverse through large
distances of Earth's mantle.

*NAME SUPERCONDUCTING MATERIAL OF THESE MAGNETS*

*CROSS SECTION OF LHC DIPOLE MAGNET*

An LHC dipole magnet has two bores for the two proton beams running in
reverse order. Being a prototype magnet it is *not* bent to the
curvature required by the LHC. A cross section can be seen in
fig. *INSERT ME*. These two bores have a diameter of \SI{4.3}{cm}
*CITE NUMBER* \cite{ZIOUTAS1999480} *SAYS 42.5mm*. In total then two
bores on each side allow for 4 experiments to be installed at CAST,
two for data taking during sunrise and two during sunset. 
#+begin_export latex
\footnote{There is some confusion about the diameter and length of the
magnet. The original CAST proposal \cite{ZIOUTAS1999480} talks about
the prototype dipole magnets as having a bore diameter of
\SI{42.5}{mm} and a length of \SI{9.25}{m}. However, ever CAST
publication afterwards uses the numbers \SI{43}{mm} and
\SI{9.26}{m}. Digging into references about the prototype dipole
magnets is inconclusive. For better compatibility with all other CAST
related publications, we will use the same \SI{43}{mm} and
\SI{9.26}{m} values in this thesis.}
#+end_export

The first data taking period (often referred to as 'phase I') took
place in 2003 for 6 months between May and November and was a pure
vacuum run with 3 different detectors. On the side observing during
sunset was a Time Projection Chamber (TPC) that covered both bores. On
the 'sunrise' side a Micromegas (Micromesh Gaseous Detector) detector
and a Charged Coupled Device (CCD) detector were installed. The CCD
was further behind a still in place X-ray telescope originally
designed for the ABRIXAS X-ray space telescope
\cite{ABRIXAS}. \cite{PhysRevLett.94.121301}

The full first phase I data taking period comprises of data taken in
2003 and 2004 and achieved a best limit of $g_{aγ} <
\SI{8.8e-11}{\GeV^{-1}}$ \cite{Andriamonje_2007}.

In what is typically referred to as 'phase II' of the CAST data
taking, the magnet was filled with helium as a buffer gas. First
between late 2005 and early 2007 with $^4\text{He}$. From March 2008 a
run with $^3\text{He}$ was started, which ran until 2011
\cite{Arik_2009, PhysRevD.92.021101}. In 2012 another $^4\text{He}$
data run took place \cite{PhysRevD.92.021101}. 

From 2013 on the CAST experiment has only taken data using vacuum
\cite{cast_nature}. Further, the physics scope has been extended
to include searches for chameleons *CITE CHRISTOPH, SDD, KWISP*, and
axions in the galactic halo via cavity experiments *CITE SERGIO,
CAPP*. 

In addition, with the MicroMegas dataset taken in *CHECK EXACT* phase I a
limit on the axion electron coupling was computed *CITE 2013*.

*160 STEPS WERE PERFORMED WITH BUFFER GAS* \cite{Arik_2009}

*BETTER SEPARATE X-ray OPTICS*

*MENTION COHERENCE CONDITION* (here or in theory?)

*2 ANNOTATED PICTURES OF CAST W/ HIGHLIGHT OF SUNRISE, SUNSET,
AIRPORT, JURA* 
*INTRODUCE THESE IN TEXT*

*CAST PROPOSAL MENTIONS 9.25m and 42.5mm DIAMETER!! CHECK*

Basic data.

Data taking periods.

*INSERT VIDEO IN FOOTNOTE*

*** CAST X-ray optics

The first X-ray telescope used at CAST as a focusing optics for the
expected axion induced X-ray flux was a Wolter I type X-ray telescope
\cite{wolter_1_type} originally built for a proposed German space
based X-ray telescope mission, ABRIXAS \cite{ABRIXAS}. The telescope
consists of 27 gold coated parabolic and hyperbolic shells and has a
focal length of \SI{1.6}{m}. Due to the small size of the dipole
magnet's bores of only \SI{42.5}{mm} only a single section of the
telescope can be exposed. The telescope is thus placed off-axis from
the magnet bore to expose a single mirror section. An image of the
mirror system with a rough indication of the exposed section is shown
in fig. [[CAST_abrixas_mirror_system]]. 

The telescope is owned by the Max Planck Institut für
extraterrestrische Physik in Garching. For that reason it will often
be referred to as the 'MPE telescope' in the rest of the thesis.

The efficiency of the telescope reaches about \SI{48}{\%} as the peak
at around \SI{1.5}{\keV}, drops sharply at around \SI{2.3}{\keV} to
only about \SI{30}{\%} up to about \SI{7}{\keV}. From there it
continues to drop until about \SI{5}{\%} efficiency at
\SI{10}{\keV}. The efficiency is shown in a comparison with the LLNL
telescope in the next section [[Lawrence Livermore National Laboratory
(LLNL) telescope]] in fig. [[telescope_efficiency_comparison_mpe_llnl]].

A picture of the telescope installed at CAST behind the magnet on the
'sunrise' side of the magnet is shown in fig. [[CAST_abrixas_telescope_installed]]. 

This telescope was used for the data taking campaign in 2014 and 2015 using a GridPix
based detector discussed in \cite{krieger2018search} and serves as a
comparison for certain aspects in this thesis.

#+begin_center
#+CAPTION: Image of the CAST Abrixas installed at CAST on the sunrise side.
#+CAPTION: The image is taken from \cite{CAST_telescope_ccd} as it provides a 
#+CAPTION: relatively clear image of the telescope, which is hard to take nowadays.
#+NAME: CAST_abrixas_telescope_installed
[[~/org/Figs/thesis/CAST/cast_abrixas_telescope_image_clear.png]]
#+end_center

#+begin_center
#+CAPTION: Image of the CAST Abrixas telescope mirror system. The different shells of the 
#+CAPTION: Wolter I type telescope system are visible. One section is exposed to the 
#+CAPTION: magnet bore, the white line indicating roughly the extent of the bore. The 
#+CAPTION: sproke like structure is the support for the mirror shells.
#+CAPTION: Image taken from \cite{CAST_telescope_ccd}.
#+NAME: CAST_abrixas_mirror_system
[[~/org/Figs/thesis/CAST/abrixas_cast_telescope_system.png]]
#+end_center

*** Lawrence Livermore National Laboratory (LLNL) telescope
:PROPERTIES:
:CUSTOM_ID: sec:cast:llnl_telescope
:END:

Up to 2014 there was only a single X-ray telescope in use at CAST. In
August 2014 a second X-ray optics was installed on the second bore
next to the ABRIXAS telescope. This telescope using technologies
originally developed for the space based NuSTAR telescope by NASA
\cite{Harrison_2013, Harrison2006, nustar_design_performance, nustar_fabrication, nustar_overview_status}, 
but purpose built for
axion searches and in particular the CAST experiment. Contrary to the
ABRIXAS telescope only a single telescope section of the Wolter I type
geometry was built as the small bore cannot expose more area. It
consists of 13 platinum / carbon coated glass shells in sections for a
total of 26 mirrors. Further the focal length was shortened to
\SI{1.5}{m} and the focal point is slightly angled away from the
straight continuation of the bore to make more room for the
installation of the detectors. This can be seen in the render of the
2017/18 detector setup in
fig. [[llnl_telescope_setup_2017_render]]. \cite{llnl_telescope_first_cast_results}

*BETTER INTRODUCE 2 LENGTH WISE SECTION THING OF WOLTER TELESCOPES*

#+begin_center
#+CAPTION: Render of the setup of the GridPix septemboard detector in 2017/18 showing the 
#+CAPTION: LLNL telescope on the left side. The diversion away from the extension of the
#+CAPTION: bore is visible, to have more space for detector installation, in particular the
#+CAPTION: lead shielding that is not shown in the render.
#+CAPTION: *ANNOTATE THE RENDER*
#+NAME: llnl_telescope_setup_2017_render
[[~/org/Figs/rayTracing/llnl_cast_gridpix_render_small.png]]
#+end_center

Part of the master thesis of Johanna von Oy in this group was a ray
tracing simulation for this optics. A comparison of the ray tracing
simulation is part of a more detailed introduction to the ray tracing
in chapter [[Raytracing - where does this belong?]]. *CITE JOHANNA*

#+begin_center
#+CAPTION: Comparison of the efficiency between the two telescopes, the MPE (ABRIXAS) as the 
#+CAPTION: original CAST telescope and the LLNL telescope purpose built for axion searches.
#+CAPTION: The LLNL telescope has superior efficiency in the energy range where the axion
#+CAPTION: flux is assumed to dominate, but falls off sharper at high energies.
#+CAPTION: The data for the LLNL telescope is extracted from fig. 3 in \cite{llnl_telescope_first_cast_results},
#+CAPTION: whereas for the ABRIXAS telescope it is extracted from the red line in fig. 4
#+CAPTION: of \cite{CAST_telescope_ccd}.
#+CAPTION: *FIX ME (REPLACE BY DATA FROM 0 TO 10 AND THINK ABOUT TRANSMISSION VS EFFICIENCY*
#+NAME: telescope_efficiency_comparison_mpe_llnl
[[~/org/Figs/statusAndProgress/llnl_mpe_transmission_comparison.pdf]]
#+end_center

#+begin_comment
Note: Refer to DTU thesis
[[/home/basti/org/Papers/llnl_telescope_optimizations_phdthesis_for_DTU_orbit.pdf]]
around page 65 (and shortly before for effective area definition; and
another eff area def on page 7). 
#+end_comment

*** Best limits

In the many years of data taking and countless detectors taking data
at the CAST experiment, it has put the most stringent limits on
different coupling constants over the years.

Specifically, CAST sets the current best limits on the:
- Axion-photon coupling $g_{aγ}$
- Axion-electron coupling $g_{ae}$
- Chameleon-photon coupling $β_γ$

For the axion-photon coupling the best limit is from
\cite{cast_nature} in 2017 based on the full MicroMegas dataset
including the data behind the LLNL telescope and constricts the coupling to $g_{aγ} <
\SI{6.6e-11}{\GeV^{-1}}$. 

For the axion-photon coupling the best limit is still from 2013 in
\cite{Barth_2013} using the theoretical calculations for an expected
solar axion flux done by J. Redondo in \cite{Redondo_2013} for a limit
on the product of the axion-electron and axion-photon coupling of
$g_{ae} g_{aγ} < \SI{8.1e-23}{\GeV^{-1}}$. The limit calculation was
based on data taken in CAST phase I in 2003 - 2005 with a pn-CCD
detector behind the MPE telescope.

For the chameleon search the best current limit on the
chameleon-photon coupling is based on a single GridPix based detector
with data taken in 2014 and 2015 by C. Krieger in
\cite{krieger2018search}, limiting the coupling to $β_γ <
\num{5.74e10}$, which is the first limit below the solar luminosity
bound. *CHECK CORRECT TERM*.

*Mention the limit method with foreshadowing to statistics chapter
that we will use the same?*

*** Subsection about gaseous phase, affecting conversion :noexport:

Extract parts of the axionMass.org file and place it here. Essentially
the:
- conversion probability in gas
- how to compute that
- one step showing conversion prob outside coherent condition

** International AXion Observatory (IAXO)

Barring a revolution in detector development or a lucky find of a non
QCD axion, the CAST experiment was unlikely to detect any signals. A
fourth generation axion helioscope to possibly reach towards the QCD
band in the mass-coupling constant phase space is a natural idea.

The first proposal for a next generation axion helioscope was
published in 2011 \cite{Irastorza_2011}, with the name International AXion
Observatory (IAXO) first appearing in 2013 \cite{vogel2013iaxo}. A
conceptual design report was further published in 2014
\cite{Armengaud_2014}. 

The proposed experiment is supposed to have a total magnet length of \SI{25}{m}
length with \num{8} \SI{60}{\cm} bores with an average transverse
magnetic field of \SI{2.5}{\tesla}. With a cryostat and magnet design
specifically built for the experiment, much larger tilting angles of
the magnet of about $\pm\ang{25}$ are proposed to allow for solar
tracking for \SI{12}{\hour} per day for a 1:1 data split between
tracking and background data. \cite{Armengaud_2014}

A schematic of the proposed design can be seen in fig. *IAXO FIG*.

Given the comparatively large budget requirements for such an
experiment, a compromise was envisioned to prove the required
technologies. This intermediate experiment called BabyIAXO will be
discussed in the next section, [[BabyIAXO]].

Make use of PRC (?) mainly for data, citation both that and first
proposal.

*MAYBE PICTURE OF IAXO LEFT, BABYIAXO RIGHT*

*** BabyIAXO

The major difference between full grown IAXO and BabyIAXO is
restricting the setup to 2 bores instead of 8 with a magnet length of
only \SI{10}{\m} to prove the magnet design works, before building a
larger version of said design.

Since the first conceptual design of IAXO \cite{Armengaud_2014} the
bore diameter for the two bores of BabyIAXO has increased from
\SI{60}{\cm} to \SI{70}{\cm}. \cite{abeln2021conceptual}

The BabyIAXO design was approved by the Deutsches
Elektronen-Synchrotron (DESY) for construction onsite, possibly
starting 2022 *CHECK*. As of writing the thesis the final construction
site is still undecided.
*WHEN CONSTRUCTION START UNCLEAR, WHAT TO WRITE HERE*

A schematic of the BabyIAXO design can be seen in fig. *BABYIAXO*.

*FIGURE OF MERIT*

*EXPECTED LIMIT for IAXO / BabyIAXO*


* Gaseous detectors principles                                       :Theory:

#+LATEX: \minitoc

Gaseous detectors, keep a bit short. Before writing properly read
Lucian. Best if read Lucian and then write a couple of weeks later.

This chapter will be kept reasonably short. Instead of introducing all
physics relevant for gaseous detectors, we will focus on the things
that are relevant for the understanding in the context of the
thesis. For better general overview of the physics of gaseous
detectors, read some of the following references: *Lucian, Markus MSc;
Lupberger, Krieger PhD, Elisa PhD, PDG, some book?...*

*Highlight which reference for what*

The theory sections covered in the following parts all have in common
that their understanding is required to make certain assumptions in
the data analysis or *???* 

It should be noted though that no part will be thorough enough to
stand on its own. Further reading is required in many places. This
theory section is supposed to serve as a reference for the later parts
of the thesis.

Of particular interest are all sections that give the theoretical
foundation for different kinds of background we might measure or the
understanding of our calibration data.

** Particle interactions with matter

We will now describe a few of the laws governing how particles
interact with matter, to the extent as it will be useful in the
context of the rest of this thesis.

*WRITE SUMMARY*

On the one hand we will discuss how X-rays interact with matter. Both
in terms of solids as well as gases, focused on their attenuation,
because this is required to describe signal attenuation due to a
detector window of a gaseous detector as well as for the absorption of
X-rays in the detector gas. In addition, X-ray reflectivity will be
discussed briefly as it is of interest for the behavior of X-ray
telescopes.

On the other hand the interaction of highly energetic charged
particles with matter will be discussed, its relation to cosmic
radiation as a source of background for an axion helioscope.

Finally, X-ray fluorescence will be covered as it is another major
source of background in an axion helioscope experiment, in particular
for gaseous detectors.

*** X-rays through matter & gases
:PROPERTIES:
:CUSTOM_ID: sec:theory:xray_matter_gas
:END:


*FIND REFERENCE TO MODERN LAW IN SOMETHING LIKE DEMTRÖDER*

Lambert-Beer's law \cite{bouguer1729essai, lambert1760photometria, beer1852bestimmung}

\[
I(z) = I_0 e^{-μz},
\]

gives the intensity of radiation $I(z)$ after traversing through a
medium with constant attenuation $μ$ of length $z$, given a starting
intensity of $I_0$. Directly related is of course the absorption
length $l_{\text{abs}} = 1/μ$ (or mean free path), which is a useful
property when considering typical absorption depths.

This law is of vital importance for the behavior of X-rays traversing
through matter, which is needed to compute the efficiency of a gaseous
detector with an entrance window.

In addition it is also related to the mean free path of X-rays in a
gas, which is an important parameter in gaseous detectors to
understand the absorption efficiency of X-rays of different energies
and the resulting expected diffusion.

For a more detailed overview of the remaining section, see the X-ray data
booklet \cite{williams2001x}.

In the context of X-rays the factor $μ$ is typically rewritten via the
'mass attenuation coefficient' $μ_m = μ · ρ$ with $ρ$ the density of
the material, commonly in \si{g cm^{-3}}. $μ_m$ is then defined by

\[
μ_m = \frac{N_A}{M} σ_A,
\]

where $N_A$ is Avogadro's number, $M$ the molar mass of the medium in
units of \si{g\per\mol} and $σ_A$ is the photoabsorption cross section
in units of \si{cm^2}. Thus, the mass attenuation coefficient is
usually given in $\si{cm^2 g^{-1}}$ such that $μ = μ_m · ρ$ is of inverse length
as expected. Further, the photoabsorption cross section can be
described via the scattering factor $f₂$

\[
σ_A = 2 r_e λ f₂,
\]

where $r_e$ is the classical electron radius and $λ$ the wavelength of
the X-ray. $f₂$ is the imaginary part of the forward scattering factor
$f$

\[
f = f₁ - i f₂
\]

which itself is the simplification of the general atomic scattering
factor that describes the atom specific part of the scattering cross
section.

This way of expressing it has the nice property of relying on a well
tabulated parameter $f₂$. Together with $f₁$ these tabulated values
can be used to compute everything from the refractive index at a
specific X-ray energy of a compound to the attenuation coefficient and
even reflectivity of a multi layer substrate.

It generalizes from single element to compounds easily by

\[
μ_m = \frac{N_A}{M_c} \sum_i n_i σ_{A,i},
\]

with $M_c$ the molar weight of the compound and $n_i$ the number of
atoms of kind $i$.

There is an online calculator for calculations of X-ray transmission
found under [fn:henke_gov] \cite{henke1993x}, as well as a library
implementation developed during the course of this thesis
under [fn:scinim_xrayAttenuation] \cite{Schmidt_xrayAttenuation_2022}. 

[fn:henke_gov] https://henke.lbl.gov/optical_constants/ 

[fn:scinim_xrayAttenuation] https://github.com/SciNim/xrayAttenuation



Fig. [[fig:theory:trasmission_examples]] shows an example of X-ray
transmission through a \SI{300}{nm} thick layer of \ccsini as well as
transmission through \SI{3}{cm} of argon at \SI{1}{atm}. All
information about the absorption lines and general transmission is
encoded in $f₂$.

#+CAPTION: X-ray transmission through a \SI{300}{nm} thick layer of \ccsini
#+CAPTION: and \SI{3}{cm} of argon calculated with \cite{Schmidt_xrayAttenuation_2022}. 
#+CAPTION: Calculation of the transmission based on tabulated scattering form factors.
#+NAME: fig:theory:transmission_examples
[[~/phd/Figs/theory/transmission_example.pdf]]

Mean free path of photons in gas. (for point of absorption in
detector + diffusion distance)

*EXAMPLE of ?*

**** Generation of \ccsini transmission figure                 :noexport:

Let's compute an example transmission plot using the Lambert-Beer law
as presented above based on =xrayAttenuation= now, on the one hand for
\ccsini as well as argon (common detector gas).

*TODO*: update ginger to use =-output-directory= to put the plot in
the right path & turn it into a TikZ plot.

#+begin_src nim :tangle /home/basti/phd/code/transmission_example.nim
import std / strutils
import xrayAttenuation, ggplotnim
# generate a compound of silicon and nitrogen with correct number of atoms
let Si₃N₄ = compound((Si, 3), (N, 4))
# instantiate an Argon instance
let ar = Argon.init()
# compute the density using ideal gas law at 1 atm
let ρ_Ar = density(1013.mbar.to(Pascal), 293.K, ar.molarMass)

# define energies in which to compute the transmission
# (we don't start at 0, as at 0 energy the parameters are not well defined)
let energies = linspace(1e-2, 10.0, 1000)

proc compTrans[T: AnyCompound](el: T, ρ: g•cm⁻³, length: Meter): DataFrame =
  result = toDf({ "Energy [keV]" : energies })
    .mutate(f{float: "μ" ~ el.attenuationCoefficient(idx("Energy [keV]").keV).float},
            f{float: "Trans" ~ transmission(`μ`.cm²•g⁻¹, ρ, length).float},
            f{"Compound" <- el.name})
var df = newDataFrame()
# compute transmission for Si₃N₄ (known density and desired length)
df.add Si₃N₄.compTrans(3.44.g•cm⁻³, 300.nm.to(Meter))
# and for argon 
df.add ar.compTrans(ρ_Ar, 3.cm.to(Meter))
# create a plot for the transmissions
echo df
let dS = pretty(300.nm, 3, short = true)
let dA = pretty(3.cm, 1, short = true)
let si = r"$\mathrm{Si}₃\mathrm{N}₄$"
ggplot(df, aes("Energy [keV]", "Trans", color = "Compound")) +
  geom_line() +
  xlab("Energy [keV]") + ylab("Transmission") +
  ggtitle("Transmission examples of $# $# and $# Argon" % [dS, si, dA]) +
  ggsave("/home/basti/phd/Figs/theory/transmission_example.pdf",
         #width = 800, height = 600,
         useTex = true, standalone = true) 
#+end_src

#+RESULTS:

*** X-ray reflectivity & scattering

The same atomic scattering factors $f₁$ and $f₂$ introduced in section
[[#sec:theory:xray_matter_gas]] for the attenuation can also be used to
compute the reflectivity of X-rays under shallow angles.

By defining the combined scattering factor

\[
f(E) = f₁(E) + i f₂(E)
\]

at energy $E$, the refractive index $n$ of a medium can be computed using

\[
n(E) = 1 - r_e \frac{λ²}{2π} \sum_i n_{ai} f_i(E)
\]

where $n_{ai}$ is the number density of the $i$-th compound of the
medium.

Then, in what is essentially an application of Snell's law, the
reflectivity can be expressed as

*TODO: FIX THIS UP LIKELY TO INCLUDE SURFACE ROUGHNESS. ALSO LOOK AT
XRAY DATA BOOKLET FOR IT AGAIN*

\[
R = \left| \frac{k_m - k_p}{k_m + k_p} \right|²
\]

where $k_m$ and $k_p$ are

\[
k_m = \sqrt{k² - (k \cos{θ})²}
\]

and

\[
k_p = \sqrt{ k² n² - (k \cos{θ})² }
\]

defined via the wave number $k$, which itself is computed via

\[
k = 2π \sin{θ} / λ.
\]

This can be generalized to multiple layers of material on a substrate
and including a surface roughness. Combined these provide the essence
for a realistic computation of the efficiency of an X-ray telescope
mirror shell.

This is also implemented in [fn:scinim_xrayAttenuation]
\cite{Schmidt_xrayAttenuation_2022} and [fn:henke_gov]
\cite{henke1993x} also provides an online calculator for such
reflectivities. 


[fn:henke_gov] https://henke.lbl.gov/optical_constants/ 

[fn:scinim_xrayAttenuation] https://github.com/SciNim/xrayAttenuation
Note: at the time of writing this, multi layers are not yet
implemented and the reflectivity code still has to be cleaned up.


*** Bethe-Bloch equation
:PROPERTIES:
:CUSTOM_ID: sec:theory:bethe_bloch
:END:

Another relevant aspect for gaseous detectors is the energy deposition
of charged particles. In particular for experiments that sit near the
surface, a major source of background is due to cosmic radiation, with
cosmic muons making up more than \SI{95}{\percent} \cite{Zyla:2020zbs}
of radiation (aside from neutrinos) at the surface, see
sec. [[#sec:theory:cosmic_radiation]].

These muons lose energy according to the Bethe-Bloch equation, which
describes the average energy loss per distance for a charged particle
with charge $z$ in a homogeneous medium with charge carriers $Z$. \cite{Zyla:2020zbs}

\begin{equation}
  \label{eq:theory:bethe_bloch_eq}
  \left\langle -\frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle = 
    K z² \frac{Z}{A} \frac{1}{β²} \left[ 
      \frac{1}{2} \ln\frac{2m_e c² β² γ² W_{\text{max}}}{I²} - β² - \frac{δ(βγ)}{2} 
    \right]
\end{equation}
where the different variables are as follows: 
*TURN INTO TABLE?*
- $K = 4π N_A r_e² m_e c² = \SI{0.307075}{\MeV \mol^{-1} \cm²}$
- $N_A = \SI{6.022 140 857(74)e23}{\mol^{-1}}$: Avogadro's number
- $r_e = e² / 4π ε_0 m_e c² = \SI{2.817 940 3227(19)}{fm}$: classical
  electron radius
- $m_e = \SI{9.1093837015(28)e-31}{\kg}$: electron mass
- $c = \SI{299792458}{\meter\per\second}$: speed of light in vacuum
- $z$: charge number of incident particle
- $Z$: atomic number of absorber material
- $A$: atomic mass of absorber material
- $β = \frac{v}{c}$: speed of incident particle
- $γ = \frac{1}{\sqrt{1 - β²}}$: Lorentz factor
- $W_{\text{max}}$: Maximum possible energy transfer to an electron in
  a single interaction
- $I$: mean excitation energy of the absorber material in \si{\eV}
- $δ(βγ)$: density-effect correction to energy loss

This interaction behavior of muons leads to a specific, expected
energy loss per distance. For argon gas at normal conditions (1 bar,
20°C, ...) this is shown in
fig. *FIG BETHE*. 

*CITE PDG*
There are multiple different representations of the Bethe-Bloch
equation mention multiple different ways to write formula.

As the Bethe formula was derived from quantum mechanical perturbation
theory, higher order corrections can be computed. For our purposes
here the leading order is enough. The next corrections proportional to
$Z³$ and $Z⁴$ are called /??/ and /shell correction/ respectively. 
At higher energies also the density correction by Fermi *CITE* needs
to be accounted for. These higher order corrections are mainly
relevant for very low energies. *SEE PDG "Energy loss at low energies" section*
*SHOW WITH OR WITHOUT. EQUATION WITH, BUT DROP IN CALCS*

It is important to keep in mind that the Bethe-Bloch equation gives
the *mean energy* per distance. When considering short distances as
typically encountered in particle detectors, this mean is skewed by
rare interactions that deposit large amounts of energy (towards
$W_{\text{max}}$). The energy deposition along short distances is
typically described by a Landau-Vavilov distribution (similar, but
different from a normal Landau distribution) \cite{Zyla:2020zbs,
BICHSEL2006154}. The most probable energy loss is often a more
appropriate number to look at. It can be expressed as

\begin{equation}
\label{eq:theory:most_probable_loss}
Δ_p = ξ \left[ \ln{ \frac{2 m_e c² β² γ²}{I}} + \ln{\frac{ξ}{I}} + j -
β² - δ(βγ) \right],
\end{equation}

where $ξ$ is

\[
ξ = \frac{1}{2} K z² \left\langle \frac{Z}{A} \right\rangle
\frac{x}{β²} \, \si{MeV},
\]

for a detector in which the material column the particle
travels through is expressed as $x = d · ρ$ of a distance $d$ in \si{g
cm^{-2}}. $j = \num{0.200}$ is an empirical constant
\cite{Zyla:2020zbs, bichsel1988straggling}. Further, $\langle Z / A
\rangle$ is simply the average $Z/A$ for a material compound $\langle
Z/A \rangle = \sum_i w_i Z_i / A_i$. 

The large difference typically encountered between the most probable
and the mean value for the energy loss in particle detectors, makes
studying the expected signals a complicated topic. For a detailed
description relevant for thin gaseous detectors, see especially
\cite{BICHSEL2006154}. 

Fig. [[fig:theory:muon_argon_3cm_bethe_loss]] shows the comparison of the
most probable energy loss via equation [[eq:theory:most_probable_loss]]
and the mean energy loss via the Bethe-Bloch equation
[[eq:theory:bethe_bloch_eq]] for muons of different energies traversing
$\SI{3}{cm}$ of argon gas.

*TODO: ADD MOST PROBABLE LOSS TO PLOT BELOW!*

*REPHRASE* instead focus on fact that they lose > 2 GeV instead of
talking about typical muon energies.

Muons arriving at the surface have energies typically above
\SI{100}{\MeV}. For that reason the higher order corrections are not
of importance for the study of muons in gaseous detectors.

At each point the formula gives the *expectation value* for the energy
loss after a distance large enough to include many interactions. In
each interaction the particle loses energy according to a Landau
distribution *CITE WHAT*, shown in fig. *LANDAU PLOT*. 
*EXPLANATION NOT QUITE CORRECT*

*MOVE FOLLOWING TO SEPARATE SECTION LATER (noexport about muon studies?)*
By taking into account the Bethe formula and a Landau distribution for
each point, we can compute an expectation for the energy loss for
muons under typical conditions met in a gaseous detector.

Landau distribution!

Also check out this $f$ function that is mentioned here:
https://doi.org/10.1016/j.nima.2006.03.009

as a better way to compute the actual energy loss per distance?

Also: read again PDG part about PDG and later in chapter the average
energy loss. Of course cannot take the mean of the Landau distribution
due to the long tail. We don't really do that in our muon simulation
though. 

\input{~/phd/Figs/muonStudies/ar_energy_loss_cast.tex}

**** Bethe equation for muons traversing \SI{3}{\cm} of argon gas :noexport:

We will now compute the energy loss for muons traversing the
\SI{3}{\cm} of argon gas that are seen by a muon traversing
orthogonally to the readout plane (i.e. such that it may look like a
photon).

#+begin_src nim :results silent :tangle /home/basti/phd/code/bethe_bloch.nim
import math, macros, unchained, ggplotnim, sequtils, strformat, strutils
import thesisHelpers
import ggplotnim / ggplot_vegatex

let K = 4 * π * N_A * r_e^2 * m_e * c^2 # usually in: [MeV mol⁻¹ cm²]

defUnit(cm³•g⁻¹)
defUnit(J•m⁻¹)
defUnit(cm⁻³)
defUnit(g•mol⁻¹)
defUnit(MeV•g⁻¹•cm²)
defUnit(mol⁻¹)
defUnit(keV•cm⁻¹)
defUnit(g•cm⁻³)
defUnit(g•cm⁻²)

proc I[T](z: float): T =
  ## use Bloch approximation for all but Argon (better use tabulated values!)
  result = if z == 18.0: 188.0.eV.to(T) 
           else: (10.eV * z).to(T)

proc calcβ(γ: UnitLess): UnitLess =
  result = sqrt(1.0 - 1.0 / (γ^2))

proc betheBloch(z, Z: UnitLess, A: g•mol⁻¹, γ: UnitLess, M: kg): MeV•g⁻¹•cm² =
  ## result in MeV cm² g⁻¹ (normalized by density)
  ## z: charge of particle
  ## Z: charge of particles making up medium
  ## A: atomic mass of particles making up medium
  ## γ: Lorentz factor of particle
  ## M: mass of particle in MeV (or same mass as `m_e` defined as)
  let β = calcβ(γ)
  let W_max = 2 * m_e * c^2 * β^2 * γ^2 / (1 + 2 * γ * m_e / M + (m_e / M)^2)
  let lnArg = 2 * m_e * c^2 * β^2 * γ^2 * W_max / (I[Joule](Z)^2)
  result = (K * z^2 * Z / A * 1.0 / (β^2) * (
   0.5 * ln(lnArg) - β^2
  )).to(MeV•g⁻¹•cm²)

proc mostProbableLoss(z, Z: UnitLess, A: g•mol⁻¹, γ: UnitLess,
                      x: g•cm⁻²): keV =
  ## Computes the most probable value, corresponding to the peak of the Landau
  ## distribution, that gives rise to the Bethe-Bloch formula.
  ##
  ## Taken from PDG chapter 'Passage of particles through matter' equation
  ## `34.12` in 'Fluctuations in energy loss', version 2020).
  ##
  ## `x` is the "thickness". Density times length, `x = ρ * d`. The other parameters
  ## are as in `betheBloch` above.
  let β = calcβ(γ)
  let ξ = K / 2.0 * Z / A * z*z * (x / (β*β))
  const j = 0.200
  let I = I[Joule](Z)
  result = (ξ * ( ln((2 * m_e * c^2 * β^2 * γ^2).to(Joule) / I) + ln(ξ.to(Joule) / I) + j - β^2)).to(keV) # - δ*(β*γ)

proc density(p: mbar, M: g•mol⁻¹, temp: Kelvin): g•cm⁻³ =
  ## returns the density of the gas for the given pressure.
  ## The pressure is assumed in `mbar` and the temperature (in `K`).
  ## The default temperature corresponds to BabyIAXO aim.
  ## Returns the density in `g / cm^3`
  let gasConstant = 8.314.J•K⁻¹•mol⁻¹ # joule K^-1 mol^-1
  let pressure = p.to(Pa) # pressure in Pa
  result = (pressure * M / (gasConstant * temp)).to(g•cm⁻³)

proc E_to_γ(E: GeV): UnitLess =
  result = E.to(Joule) / (m_μ * c^2) + 1

type
  Element = object
    name: string
    Z: UnitLess
    M: g•mol⁻¹
    A: UnitLess # numerically same as `M`
    ρ: g•cm⁻³

proc initElement(name: string, Z: UnitLess, M: g•mol⁻¹, ρ: g•cm⁻³): Element =
  Element(name: name, Z: Z, M: M, A: M.UnitLess, ρ: ρ)

let M_Ar = 39.95.g•mol⁻¹ # molar mass. Numerically same as relative atomic mass
#let ρAr = density(1050.mbar, M_Ar, temp = 293.15.K)
let ρAr = density(1013.mbar, M_Ar, temp = 293.15.K)
let Argon = initElement("ar", 18.0.UnitLess, 39.95.g•mol⁻¹, ρAr)

proc intBethe(e: Element, d_total: cm, E0: eV, dx = 1.μm): eV =
  ## integrated energy loss of bethe formula after `d` cm of matter
  ## and returns the energy remaining
  var γ: UnitLess = E_to_γ(E0.to(GeV))
  var d: cm
  result = E0
  var totalLoss = 0.eV
  while d < d_total and result > 0.eV:
    let E_loss: MeV = betheBloch(-1, e.Z, e.M, γ, m_μ) * e.ρ * dx
    result = result - E_loss.to(eV)
    γ = E_to_γ(result.to(GeV))
    d = d + dx.to(cm)
    totalLoss = totalLoss + E_loss.to(eV)
  result = max(0.float, result.float).eV

func argonLabel(): string = "fig:theory:muon_argon_3cm_bethe_loss"

## TODO: add in the most probable value calc!  
func argonCaption(): string = 
  result = r"Mean energy loss via Bethe-Bloch (red) equation of muons in \SI{3}{\cm} of argon at " &
    r"conditions in use in GridPix detector at CAST. \SI{1050}{mbar} of chamber pressure at room " &
    r"temperature. Note that the mean is skewed by events that transfer a large amount of energy, " &
    r"but are very rare! As such care must be taken interpreting the numbers. Blue shows the most " &
    r"probable energy loss, based on the peak of the Landau-Vavilov distribution underlying the " &
    r"Bethe-Bloch mean value." &
    interactiveVega(argonLabel())

proc plotDetectorAbsorption(element: Element) =
  let E_float = logspace(-2, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  let E_loss = energies.mapIt((it.to(eV) - intBethe(element, 3.cm, it.to(eV))).to(keV).float)
  let E_lossMP = energies.mapIt(mostProbableLoss(-1, element.Z, element.M, E_to_γ(it), ρ_Ar * 3.cm).float)
  let df = seqsToDf({E_float, "Bethe-Bloch (BB)" : E_loss, "Most probable (MP)" : E_lossMP})
    .gather(["Bethe-Bloch (BB)", "Most probable (MP)"], "Type", "Value")
  ggplot(df, aes("E_float", "Value", color = "Type")) +
    geom_line() +
    #xlab(r"μ Energy [\si{\GeV}]") + ylab(r"$-\left\langle \frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle$ [\si{\keV}]") +
    xlab(r"μ Energy [\si{\GeV}]") +
    ylab(r"$-\left\langle \frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle$ (BB), $Δ_p$ (MP) [\si{\keV}]") +
    scale_x_log10() + scale_y_log10() +
    theme_latex() + 
    ggtitle(r"Energy loss of Muons in \SI{3}{\cm} " & &"{element.name.capitalizeAscii} at CAST conditions") +
    #ggsave(&"/home/basti/phd/Figs/muonStudies/{element.name}_energy_loss_cast.pdf", useTeX = true, standalone = true)
    ggvegatex(&"/home/basti/phd/Figs/muonStudies/{element.name}_energy_loss_cast",
              caption = argonCaption(),
              label = argonLabel())
plotDetectorAbsorption(Argon)

proc plotMostProbable(e: Element) =
  let E_float = logspace(-1.5, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  let E_loss = energies.mapIt(mostProbableLoss(-1, e.Z, e.M, E_to_γ(it), ρ_Ar * 3.cm))
  let df = toDf({"E_loss" : E_loss.mapIt(it.float), E_float})
  ggplot(df, aes("E_float", "E_loss")) +
    geom_line() +
    scale_x_log10() + 
    xlab("Energy [GeV]") + ylab("Most probable loss [keV]") +
    ggsave("/tmp/most_probable_loss.pdf")
plotMostProbable(Argon)
#+end_src

*** X-ray fluorescence
:PROPERTIES:
:CUSTOM_ID: sec:theory:xray_fluorescence
:END:

Cosmic muons in their interactions with matter can ionize atoms,
leading to the possible emission of X-rays if the removed electron is
part of an inner shell, mostly K (and some L) shell electrons. This
leads to a form of background based on real X-rays and thus represents
a kind of background that is impossible to distinguish from any kind
of axion signal unless external scintillator based vetoes are used.
*TOO MUCH DETAIL HERE?* *CHECK THE SHELL STUFF, GIVE A MINI TABLE OF
IMPORTANT ATOMIC LINES!*

Important for our 3 keV Argon line + 8 keV copper line mainly.

Different lines of different materials are listed in
tab. [[tab_all_xray_fluorescence]], with a focus on elements that are
likely to be present in or around a detector.

Of course to be relevant as a form of detector background the material
must be close to the detector, as the X-rays will otherwise be
absorbed. This makes the detector material, the gas itself and all
material in the direction of the detectors' sensitivity a candidate
for X-ray fluorescence background.

Tab. *TABLE INSERT* contains the different lines of plausible
materials used for detector construction / etc. *...*
*ASK TOBI IF TO ADD SOME MATERIAL*

- [ ] *HOW DOES THIS CORRESPOND TO AUGER ELECTRONS?*

- [ ] *ADD RELEVANT TABLE FOR BINDING ENERGY AS WELL!*  
- [ ] *TODO: REMOVE UNNECESSARY LINES*

#+NAME: tab_all_xray_fluorescence
#+CAPTION: Photon energies of K, L and M emission lines for different elements in \si{eV}. 
#+CAPTION: Taken from \cite{williams2001x}, specifically https://xdb.lbl.gov/Section1/Table_1-2.pdf.
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  3 | Li      | 54.3      |           |          |          |           |          |          |          |         |
|  4 | Be      | 108.5     |           |          |          |           |          |          |          |         |
|  5 | B       | 183.3     |           |          |          |           |          |          |          |         |
|  6 | C       | 277       |           |          |          |           |          |          |          |         |
|  7 | N       | 392.4     |           |          |          |           |          |          |          |         |
|  8 | O       | 524.9     |           |          |          |           |          |          |          |         |
|  9 | F       | 676.8     |           |          |          |           |          |          |          |         |
| 10 | Ne      | 848.6     | 848.6     |          |          |           |          |          |          |         |
| 11 | Na      | 1,040.98  | 1,040.98  | 1,071.1  |          |           |          |          |          |         |
| 12 | Mg      | 1,253.60  | 1,253.60  | 1,302.2  |          |           |          |          |          |         |
| 13 | Al      | 1,486.70  | 1,486.27  | 1,557.45 |          |           |          |          |          |         |
| 14 | Si      | 1,739.98  | 1,739.38  | 1,835.94 |          |           |          |          |          |         |
| 15 | P       | 2,013.7   | 2,012.7   | 2,139.1  |          |           |          |          |          |         |
| 16 | S       | 2,307.84  | 2,306.64  | 2,464.04 |          |           |          |          |          |         |
| 17 | Cl      | 2,622.39  | 2,620.78  | 2,815.6  |          |           |          |          |          |         |
| 18 | Ar      | 2,957.70  | 2,955.63  | 3,190.5  |          |           |          |          |          |         |
| 19 | K       | 3,313.8   | 3,311.1   | 3,589.6  |          |           |          |          |          |         |
| 20 | Ca      | 3,691.68  | 3,688.09  | 4,012.7  | 341.3    | 341.3     | 344.9    |          |          |         |
| 21 | Sc      | 4,090.6   | 4,086.1   | 4,460.5  | 395.4    | 395.4     | 399.6    |          |          |         |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
| 22 | Ti      | 4,510.84  | 4,504.86  | 4,931.81 | 452.2    | 452.2     | 458.4    |          |          |         |
| 23 | V       | 4,952.20  | 4,944.64  | 5,427.29 | 511.3    | 511.3     | 519.2    |          |          |         |
| 24 | Cr      | 5,414.72  | 5,405.509 | 5,946.71 | 572.8    | 572.8     | 582.8    |          |          |         |
| 25 | Mn      | 5,898.75  | 5,887.65  | 6,490.45 | 637.4    | 637.4     | 648.8    |          |          |         |
| 26 | Fe      | 6,403.84  | 6,390.84  | 7,057.98 | 705.0    | 705.0     | 718.5    |          |          |         |
| 27 | Co      | 6,930.32  | 6,915.30  | 7,649.43 | 776.2    | 776.2     | 791.4    |          |          |         |
| 28 | Ni      | 7,478.15  | 7,460.89  | 8,264.66 | 851.5    | 851.5     | 868.8    |          |          |         |
| 29 | Cu      | 8,047.78  | 8,027.83  | 8,905.29 | 929.7    | 929.7     | 949.8    |          |          |         |
| 30 | Zn      | 8,638.86  | 8,615.78  | 9,572.0  | 1,011.7  | 1,011.7   | 1,034.7  |          |          |         |
| 31 | Ga      | 9,251.74  | 9,224.82  | 10,264.2 | 1,097.92 | 1,097.92  | 1,124.8  |          |          |         |
| 32 | Ge      | 9,886.42  | 9,855.32  | 10,982.1 | 1,188.00 | 1,188.00  | 1,218.5  |          |          |         |
| 33 | As      | 10,543.72 | 10,507.99 | 11,726.2 | 1,282.0  | 1,282.0   | 1,317.0  |          |          |         |
| 34 | Se      | 11,222.4  | 11,181.4  | 12,495.9 | 1,379.10 | 1,379.10  | 1,419.23 |          |          |         |
| 35 | Br      | 11,924.2  | 11,877.6  | 13,291.4 | 1,480.43 | 1,480.43  | 1,525.90 |          |          |         |
| 36 | Kr      | 12,649    | 12,598    | 14,112   | 1,586.0  | 1,586.0   | 1,636.6  |          |          |         |
| 37 | Rb      | 13,395.3  | 13,335.8  | 14,961.3 | 1,694.13 | 1,692.56  | 1,752.17 |          |          |         |
| 38 | Sr      | 14,165    | 14,097.9  | 15,835.7 | 1,806.56 | 1,804.74  | 1,871.72 |          |          |         |
| 39 | Y       | 14,958.4  | 14,882.9  | 16,737.8 | 1,922.56 | 1,920.47  | 1,995.84 |          |          |         |
| 40 | Zr      | 15,775.1  | 15,690.9  | 17,667.8 | 2,042.36 | 2,039.9   | 2,124.4  | 2,219.4  | 2,302.7  |         |
| 41 | Nb      | 16,615.1  | 16,521.0  | 18,622.5 | 2,165.89 | 2,163.0   | 2,257.4  | 2,367.0  | 2,461.8  |         |
| 42 | Mo      | 17,479.34 | 17,374.3  | 19,608.3 | 2,293.16 | 2,289.85  | 2,394.81 | 2,518.3  | 2,623.5  |         |
| 43 | Tc      | 18,367.1  | 18,250.8  | 20,619   | 2,424    | 2,420     | 2,538    | 2,674    | 2,792    |         |
| 44 | Ru      | 19,279.2  | 19,150.4  | 21,656.8 | 2,558.55 | 2,554.31  | 2,683.23 | 2,836.0  | 2,964.5  |         |
| 45 | Rh      | 20,216.1  | 20,073.7  | 22,723.6 | 2,696.74 | 2,692.05  | 2,834.41 | 3,001.3  | 3,143.8  |         |
| 46 | Pd      | 21,177.1  | 21,020.1  | 23,818.7 | 2,838.61 | 2,833.29  | 2,990.22 | 3,171.79 | 3,328.7  |         |
| 47 | Ag      | 22,162.92 | 21,990.3  | 24,942.4 | 2,984.31 | 2,978.21  | 3,150.94 | 3,347.81 | 3,519.59 |         |
| 48 | Cd      | 23,173.6  | 22,984.1  | 26,095.5 | 3,133.73 | 3,126.91  | 3,316.57 | 3,528.12 | 3,716.86 |         |
| 49 | In      | 24,209.7  | 24,002.0  | 27,275.9 | 3,286.94 | 3,279.29  | 3,487.21 | 3,713.81 | 3,920.81 |         |
| 50 | Sn      | 25,271.3  | 25,044.0  | 28,486.0 | 3,443.98 | 3,435.42  | 3,662.80 | 3,904.86 | 4,131.12 |         |
| 51 | Sb      | 26,359.1  | 26,110.8  | 29,725.6 | 3,604.72 | 3,595.32  | 3,843.57 | 4,100.78 | 4,347.79 |         |
| 52 | Te      | 27,472.3  | 27,201.7  | 30,995.7 | 3,769.33 | 3,758.8   | 4,029.58 | 4,301.7  | 4,570.9  |         |
| 53 | I       | 28,612.0  | 28,317.2  | 32,294.7 | 3,937.65 | 3,926.04  | 4,220.72 | 4,507.5  | 4,800.9  |         |
| 54 | Xe      | 29,779    | 29,458    | 33,624   | 4,109.9  | —         | —        | —        | —        |         |
| 55 | Cs      | 30,972.8  | 30,625.1  | 34,986.9 | 4,286.5  | 4,272.2   | 4,619.8  | 4,935.9  | 5,280.4  |         |
| 56 | Ba      | 32,193.6  | 31,817.1  | 36,378.2 | 4,466.26 | 4,450.90  | 4,827.53 | 5,156.5  | 5,531.1  |         |
| 57 | La      | 33,441.8  | 33,034.1  | 37,801.0 | 4,650.97 | 4,634.23  | 5,042.1  | 5,383.5  | 5,788.5  | 833     |
| 58 | Ce      | 34,719.7  | 34,278.9  | 39,257.3 | 4,840.2  | 4,823.0   | 5,262.2  | 5,613.4  | 6,052    | 883     |
| 59 | Pr      | 36,026.3  | 35,550.2  | 40,748.2 | 5,033.7  | 5,013.5   | 5,488.9  | 5,850    | 6,322.1  | 929     |
| 60 | Nd      | 37,361.0  | 36,847.4  | 42,271.3 | 5,230.4  | 5,207.7   | 5,721.6  | 6,089.4  | 6,602.1  | 978     |
| 61 | Pm      | 38,724.7  | 38,171.2  | 43,826   | 5,432.5  | 5,407.8   | 5,961    | 6,339    | 6,892    | —       |
| 62 | Sm      | 40,118.1  | 39,522.4  | 45,413   | 5,636.1  | 5,609.0   | 6,205.1  | 6,586    | 7,178    | 1,081   |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
| 63 | Eu      | 41,542.2  | 40,901.9  | 47,037.9 | 5,845.7  | 5,816.6   | 6,456.4  | 6,843.2  | 7,480.3  | 1,131   |
| 64 | Gd      | 42,996.2  | 42,308.9  | 48,697   | 6,057.2  | 6,025.0   | 6,713.2  | 7,102.8  | 7,785.8  | 1,185   |
| 65 | Tb      | 44,481.6  | 43,744.1  | 50,382   | 6,272.8  | 6,238.0   | 6,978    | 7,366.7  | 8,102    | 1,240   |
| 66 | Dy      | 45,998.4  | 45,207.8  | 52,119   | 6,495.2  | 6,457.7   | 7,247.7  | 7,635.7  | 8,418.8  | 1,293   |
| 67 | Ho      | 47,546.7  | 46,699.7  | 53,877   | 6,719.8  | 6,679.5   | 7,525.3  | 7,911    | 8,747    | 1,348   |
| 68 | Er      | 49,127.7  | 48,221.1  | 55,681   | 6,948.7  | 6,905.0   | 7,810.9  | 8,189.0  | 9,089    | 1,406   |
| 69 | Tm      | 50,741.6  | 49,772.6  | 57,517   | 7,179.9  | 7,133.1   | 8,101    | 8,468    | 9,426    | 1,462   |
| 70 | Yb      | 52,388.9  | 51,354.0  | 59,370   | 7,415.6  | 7,367.3   | 8,401.8  | 8,758.8  | 9,780.1  | 1,521.4 |
| 71 | Lu      | 54,069.8  | 52,965.0  | 61,283   | 7,655.5  | 7,604.9   | 8,709.0  | 9,048.9  | 10,143.4 | 1,581.3 |
| 72 | Hf      | 55,790.2  | 54,611.4  | 63,234   | 7,899.0  | 7,844.6   | 9,022.7  | 9,347.3  | 10,515.8 | 1,644.6 |
| 73 | Ta      | 57,532    | 56,277    | 65,223   | 8,146.1  | 8,087.9   | 9,343.1  | 9,651.8  | 10,895.2 | 1,710   |
| 74 | W       | 59,318.24 | 57,981.7  | 67,244.3 | 8,397.6  | 8,335.2   | 9,672.35 | 9,961.5  | 11,285.9 | 1,775.4 |
| 75 | Re      | 61,140.3  | 59,717.9  | 69,310   | 8,652.5  | 8,586.2   | 10,010.0 | 10,275.2 | 11,685.4 | 1,842.5 |
| 76 | Os      | 63,000.5  | 61,486.7  | 71,413   | 8,911.7  | 8,841.0   | 10,355.3 | 10,598.5 | 12,095.3 | 1,910.2 |
| 77 | Ir      | 64,895.6  | 63,286.7  | 73,560.8 | 9,175.1  | 9,099.5   | 10,708.3 | 10,920.3 | 12,512.6 | 1,979.9 |
| 78 | Pt      | 66,832    | 65,112    | 75,748   | 9,442.3  | 9,361.8   | 11,070.7 | 11,250.5 | 12,942.0 | 2,050.5 |
| 79 | Au      | 68,803.7  | 66,989.5  | 77,984   | 9,713.3  | 9,628.0   | 11,442.3 | 11,584.7 | 13,381.7 | 2,122.9 |
| 80 | Hg      | 70,819    | 68,895    | 80,253   | 9,988.8  | 9,897.6   | 11,822.6 | 11,924.1 | 13,830.1 | 2,195.3 |
| 81 | Tl      | 72,871.5  | 70,831.9  | 82,576   | 10,268.5 | 10,172.8  | 12,213.3 | 12,271.5 | 14,291.5 | 2,270.6 |
| 82 | Pb      | 74,969.4  | 72,804.2  | 84,936   | 10,551.5 | 10,449.5  | 12,613.7 | 12,622.6 | 14,764.4 | 2,345.5 |
| 83 | Bi      | 77,107.9  | 74,814.8  | 87,343   | 10,838.8 | 10,730.91 | 13,023.5 | 12,979.9 | 15,247.7 | 2,422.6 |
| 84 | Po      | 79,290    | 76,862    | 89,800   | 11,130.8 | 11,015.8  | 13,447   | 13,340.4 | 15,744   | —       |
| 85 | At      | 81,520    | 78,950    | 92,300   | 11,426.8 | 11,304.8  | 13,876   | —        | 16,251   | —       |
| 86 | Rn      | 83,780    | 81,070    | 94,870   | 11,727.0 | 11,597.9  | 14,316   | —        | 16,770   | —       |
| 87 | Fr      | 86,100    | 83,230    | 97,470   | 12,031.3 | 11,895.0  | 14,770   | 14,450   | 17,303   | —       |
| 88 | Ra      | 88,470    | 85,430    | 100,130  | 12,339.7 | 12,196.2  | 15,235.8 | 14,841.4 | 17,849   | —       |
| 89 | Ac      | 90,884    | 87,670    | 102,850  | 12,652.0 | 12,500.8  | 15,713   | —        | 18,408   | —       |
| 90 | Th      | 93,350    | 89,953    | 105,609  | 12,968.7 | 12,809.6  | 16,202.2 | 15,623.7 | 18,982.5 | 2,996.1 |
| 91 | Pa      | 95,868    | 92,287    | 108,427  | 13,290.7 | 13,122.2  | 16,702   | 16,024   | 19,568   | 3,082.3 |
| 92 | U       | 98,439    | 94,665    | 111,300  | 13,614.7 | 13,438.8  | 17,220.0 | 16,428.3 | 20,167.1 | 3,170.8 |
| 93 | Np      | —         | —         | —        | 13,944.1 | 13,759.7  | 17,750.2 | 16,840.0 | 20,784.8 | —       |
| 94 | Pu      | —         | —         | —        | 14,278.6 | 14,084.2  | 18,293.7 | 17,255.3 | 21,417.3 | —       |
| 95 | Am      | —         | —         | —        | 14,617.2 | 14,411.9  | 18,852.0 | 17,676.5 | 22,065.2 | —       |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|

X-Ray Data Booklet Table 1-1. Electron binding energies, in electron
volts, for the elements in their natural forms.  
https://xdb.lbl.gov/Section1/Table_1-1.pdf

#+CAPTION: Electron binding energies of all elements up to uranium in \si{eV}.
#+CAPTION: Taken from the X-ray data book \cite{williams2001x},
#+CAPTION: specifically https://xdb.lbl.gov/Section1/Table_1-1.pdf.
#+NAME: tab_all_atomic_binding_energies
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element |     K 1s | L1 2s    | L2 2p1/2 | L3 2p3/2 | M1 3s   | M2 3p1/2 | M3 3p3/2 | M4 3d3/2 | M5 3d5/2 | N1 4s  | N2 4p1/2 | N3 4p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  1 | H       |     13.6 |          |          |          |         |          |          |          |          |        |          |          |
|  2 | He      |    24.6* |          |          |          |         |          |          |          |          |        |          |          |
|  3 | Li      |    54.7* |          |          |          |         |          |          |          |          |        |          |          |
|  4 | Be      |   111.5* |          |          |          |         |          |          |          |          |        |          |          |
|  5 | B       |     188* |          |          |          |         |          |          |          |          |        |          |          |
|  6 | C       |   284.2* |          |          |          |         |          |          |          |          |        |          |          |
|  7 | N       |   409.9* | 37.3*    |          |          |         |          |          |          |          |        |          |          |
|  8 | O       |   543.1* | 41.6*    |          |          |         |          |          |          |          |        |          |          |
|  9 | F       |   696.7* |          |          |          |         |          |          |          |          |        |          |          |
| 10 | Ne      |   870.2* | 48.5*    |    21.7* |    21.6* |         |          |          |          |          |        |          |          |
| 11 | Na      |  1070.8† | 63.5†    |    30.65 |    30.81 |         |          |          |          |          |        |          |          |
| 12 | Mg      |  1303.0† | 88.7     |    49.78 |    49.50 |         |          |          |          |          |        |          |          |
| 13 | Al      |   1559.6 | 117.8    |    72.95 |    72.55 |         |          |          |          |          |        |          |          |
| 14 | Si      |     1839 | 149.7*b  |    99.82 |    99.42 |         |          |          |          |          |        |          |          |
| 15 | P       |   2145.5 | 189*     |     136* |     135* |         |          |          |          |          |        |          |          |
| 16 | S       |     2472 | 230.9    |   163.6* |   162.5* |         |          |          |          |          |        |          |          |
| 17 | Cl      |   2822.4 | 270*     |     202* |     200* |         |          |          |          |          |        |          |          |
| 18 | Ar      |  3205.9* | 326.3*   |   250.6† |   248.4* | 29.3*   | 15.9*    | 15.7*    |          |          |        |          |          |
| 19 | K       |  3608.4* | 378.6*   |   297.3* |   294.6* | 34.8*   | 18.3*    | 18.3*    |          |          |        |          |          |
| 20 | Ca      |  4038.5* | 438.4†   |   349.7† |   346.2† | 44.3    | †        | 25.4†    | 25.4†    |          |        |          |          |
| 21 | Sc      |     4492 | 498.0*   |   403.6* |   398.7* | 51.1*   | 28.3*    | 28.3*    |          |          |        |          |          |
| 22 | Ti      |     4966 | 560.9†   |   460.2† |   453.8† | 58.7†   | 32.6†    | 32.6†    |          |          |        |          |          |
| 23 | V       |     5465 | 626.7†   |   519.8† |   512.1† | 66.3†   | 37.2†    | 37.2†    |          |          |        |          |          |
| 24 | Cr      |     5989 | 696.0†   |   583.8† |   574.1† | 74.1†   | 42.2†    | 42.2†    |          |          |        |          |          |
| 25 | Mn      |     6539 | 769.1†   |   649.9† |   638.7† | 82.3†   | 47.2†    | 47.2†    |          |          |        |          |          |
| 26 | Fe      |     7112 | 844.6†   |   719.9† |   706.8† | 91.3†   | 52.7†    | 52.7†    |          |          |        |          |          |
| 27 | Co      |     7709 | 925.1†   |   793.2† |   778.1† | 101.0†  | 58.9†    | 59.9†    |          |          |        |          |          |
| 28 | Ni      |     8333 | 1008.6†  |   870.0† |   852.7† | 110.8†  | 68.0†    | 66.2†    |          |          |        |          |          |
| 29 | Cu      |     8979 | 1096.7†  |   952.3† |    932.7 | 122.5†  | 77.3†    | 75.1†    |          |          |        |          |          |
| 30 | Zn      |     9659 | 1196.2*  |  1044.9* |  1021.8* | 139.8*  | 91.4*    | 88.6*    | 10.2*    | 10.1*    |        |          |          |
| 31 | Ga      |    10367 | 1299.0*b |  1143.2† |  1116.4† | 159.5†  | 103.5†   | 100.0†   | 18.7†    | 18.7†    |        |          |          |
| 32 | Ge      |    11103 | 1414.6*b | 1248.1*b | 1217.0*b | 180.1*  | 124.9*   | 120.8*   | 29.8     | 29.2     |        |          |          |
| 33 | As      |    11867 | 1527.0*b | 1359.1*b | 1323.6*b | 204.7*  | 146.2*   | 141.2*   | 41.7*    | 41.7*    |        |          |          |
| 34 | Se      |    12658 | 1652.0*b | 1474.3*b | 1433.9*b | 229.6*  | 166.5*   | 160.7*   | 55.5*    | 54.6*    |        |          |          |
| 35 | Br      |    13474 | 1782*    |    1596* |    1550* | 257*    | 189*     | 182*     | 70*      | 69*      |        |          |          |
| 36 | Kr      |    14326 | 1921     |  1730.9* |  1678.4* | 292.8*  | 222.2*   | 214.4    | 95.0*    | 93.8*    | 27.5*  | 14.1*    | 14.1*    |
| 37 | Rb      |    15200 | 2065     |     1864 |     1804 | 326.7*  | 248.7*   | 239.1*   | 113.0*   | 112*     | 30.5*  | 16.3*    | 15.3*    |
| 38 | Sr      |    16105 | 2216     |     2007 |     1940 | 358.7†  | 280.3†   | 270.0†   | 136.0†   | 134.2†   | 38.9†  | 21.3     | 20.1†    |
| 39 | Y       |    17038 | 2373     |     2156 |     2080 | 392.0*b | 310.6*   | 298.8*   | 157.7†   | 155.8†   | 43.8*  | 24.4*    | 23.1*    |
| 40 | Zr      |    17998 | 2532     |     2307 |     2223 | 430.3†  | 343.5†   | 329.8†   | 181.1†   | 178.8†   | 50.6†  | 28.5†    | 27.1†    |
| 41 | Nb      |    18986 | 2698     |     2465 |     2371 | 466.6†  | 376.1†   | 360.6†   | 205.0†   | 202.3†   | 56.4†  | 32.6†    | 30.8†    |
| 42 | Mo      |    20000 | 2866     |     2625 |     2520 | 506.3†  | 411.6†   | 394.0†   | 231.1†   | 227.9†   | 63.2†  | 37.6†    | 35.5†    |
| 43 | Tc      |    21044 | 3043     |     2793 |     2677 | 544*    | 447.6    | 417.7    | 257.6    | 253.9*   | 69.5*  | 42.3*    | 39.9*    |
| 44 | Ru      |    22117 | 3224     |     2967 |     2838 | 586.1*  | 483.5†   | 461.4†   | 284.2†   | 280.0†   | 75.0†  | 46.3†    | 43.2†    |
| 45 | Rh      |    23220 | 3412     |     3146 |     3004 | 628.1†  | 521.3†   | 496.5†   | 311.9†   | 307.2†   | 81.4*b | 50.5†    | 47.3†    |
| 46 | Pd      |    24350 | 3604     |     3330 |     3173 | 671.6†  | 559.9†   | 532.3†   | 340.5†   | 335.2†   | 87.1*b | 55.7†a   | 50.9†    |
| 47 | Ag      |    25514 | 3806     |     3524 |     3351 | 719.0†  | 603.8†   | 573.0†   | 374.0†   | 368.3    | 97.0†  | 63.7†    | 58.3†    |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element |     K 1s | L1 2s    | L2 2p1/2 | L3 2p3/2 | M1 3s   | M2 3p1/2 | M3 3p3/2 | M4 3d3/2 | M5 3d5/2 | N 4s   | N2 4p1/2 | N3 4p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 48 | Cd      |    26711 | 4018     |     3727 |     3538 | 772.0†  | 652.6†   | 618.4†   | 411.9†   | 405.2†   | 109.8† | 63.9†a   | 63.9†a   |
| 49 | In      |    27940 | 4238     |     3938 |     3730 | 827.2†  | 703.2†   | 665.3†   | 451.4†   | 443.9†   | 122.9† | 73.5†a   | 73.5†a   |
| 50 | Sn      |    29200 | 4465     |     4156 |     3929 | 884.7†  | 756.5†   | 714.6†   | 493.2†   | 484.9†   | 137.1† | 83.6†a   | 83.6†a   |
| 51 | Sb      |    30491 | 4698     |     4380 |     4132 | 946†    | 812.7†   | 766.4†   | 537.5†   | 528.2†   | 153.2† | 95.6†a   | 95.6†a   |
| 52 | Te      |    31814 | 4939     |     4612 |     4341 | 1006†   | 870.8†   | 820.0†   | 583.4†   | 573.0†   | 169.4† | 103.3†a  | 103.3†a  |
| 53 | I       |    33169 | 5188     |     4852 |     4557 | 1072*   | 931*     | 875*     | 630.8    | 619.3    | 186*   | 123*     | 123*     |
| 54 | Xe      |    34561 | 5453     |     5107 |     4786 | 1148.7* | 1002.1*  | 940.6*   | 689.0*   | 676.4*   | 213.2* | 146.7    | 145.5*   |
| 55 | Cs      |    35985 | 5714     |     5359 |     5012 | 1211*b  | 1071*    | 1003*    | 740.5*   | 726.6*   | 232.3* | 172.4*   | 161.3*   |
| 56 | Ba      |    37441 | 5989     |     5624 |     5247 | 1293*b  | 1137*b   | 1063*b   | 795.7†   | 780.5*   | 253.5† | 192      | 178.6†   |
| 57 | La      |    38925 | 6266     |     5891 |     5483 | 1362*b  | 1209*b   | 1128*b   | 853*     | 836*     | 274.7* | 205.8    | 196.0*   |
| 58 | Ce      |    40443 | 6549     |     6164 |     5723 | 1436*b  | 1274*b   | 1187*b   | 902.4*   | 883.8*   | 291.0* | 223.2    | 206.5*   |
| 59 | Pr      |    41991 | 6835     |     6440 |     5964 | 1511    | 1337     | 1242     | 948.3*   | 928.8*   | 304.5  | 236.3    | 217.6    |
| 60 | Nd      |    43569 | 7126     |     6722 |     6208 | 1575    | 1403     | 1297     | 1003.3*  | 980.4*   | 319.2* | 243.3    | 224.6    |
| 61 | Pm      |    45184 | 7428     |     7013 |     6459 | ---     | 1471     | 1357     | 1052     | 1027     | ---    | 242      | 242      |
| 62 | Sm      |    46834 | 7737     |     7312 |     6716 | 1723    | 1541     | 1420     | 1110.9*  | 1083.4*  | 347.2* | 265.6    | 247.4    |
| 63 | Eu      |    48519 | 8052     |     7617 |     6977 | 1800    | 1614     | 1481     | 1158.6*  | 1127.5*  | 360    | 284      | 257      |
| 64 | Gd      |    50239 | 8376     |     7930 |     7243 | 1881    | 1688     | 1544     | 1221.9*  | 1189.6*  | 378.6* | 286      | 271      |
| 65 | Tb      |    51996 | 8708     |     8252 |     7514 | 1968    | 1768     | 1611     | 1276.9*  | 1241.1*  | 396.0* | 322.4*   | 284.1*   |
| 66 | Dy      |    53789 | 9046     |     8581 |     7790 | 2047    | 1842     | 1676     | 1333     | 1292.6*  | 414.2* | 333.5*   | 293.2*   |
| 67 | Ho      |    55618 | 9394     |     8918 |     8071 | 2128    | 1923     | 1741     | 1392     | 1351     | 432.4* | 343.5    | 308.2*   |
| 68 | Er      |    57486 | 9751     |     9264 |     8358 | 2207    | 2006     | 1812     | 1453     | 1409     | 449.8* | 366.2    | 320.2*   |
| 69 | Tm      |    59390 | 10116    |     9617 |     8648 | 2307    | 2090     | 1885     | 1515     | 1468     | 470.9* | 385.9*   | 332.6*   |
| 70 | Yb      |    61332 | 10486    |     9978 |     8944 | 2398    | 2173     | 1950     | 1576     | 1528     | 480.5* | 388.7*   | 339.7*   |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element | N4 4d3/2 | N5 4d5/2 | N6 4f5/2 | N7 4f7/2 | O1 5s   | O2 5p1/2 | O3 5p3/2 | O4 5d3/2 | O5 5d5/2 | P1 6s  | P2 6p1/2 | P3 6p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 48 | Cd      |    11.7† | l0.7†    |          |          |         |          |          |          |          |        |          |          |
| 49 | In      |    17.7† | 16.9†    |          |          |         |          |          |          |          |        |          |          |
| 50 | Sn      |    24.9† | 23.9†    |          |          |         |          |          |          |          |        |          |          |
| 51 | Sb      |    33.3† | 32.1†    |          |          |         |          |          |          |          |        |          |          |
| 52 | Te      |    41.9† | 40.4†    |          |          |         |          |          |          |          |        |          |          |
| 53 | I       |     50.6 | 48.9     |          |          |         |          |          |          |          |        |          |          |
| 54 | Xe      |    69.5* | 67.5*    |      --- |      --- | 23.3*   | 13.4*    | 12.1*    |          |          |        |          |          |
| 55 | Cs      |    79.8* | 77.5*    |      --- |      --- | 22.7    | 14.2*    | 12.1*    |          |          |        |          |          |
| 56 | Ba      |    92.6† | 89.9†    |      --- |      --- | 30.3†   | 17.0†    | 14.8†    |          |          |        |          |          |
| 57 | La      |   105.3* | 102.5*   |      --- |      --- | 34.3*   | 19.3*    | 16.8*    |          |          |        |          |          |
| 58 | Ce      |     109* | ---      |      0.1 |      0.1 | 37.8    | 19.8*    | 17.0*    |          |          |        |          |          |
| 59 | Pr      |   115.1* | 115.1*   |      2.0 |      2.0 | 37.4    | 22.3     | 22.3     |          |          |        |          |          |
| 60 | Nd      |   120.5* | 120.5*   |      1.5 |      1.5 | 37.5    | 21.1     | 21.1     |          |          |        |          |          |
| 61 | Pm      |      120 | 120      |      --- |      --- | ---     | ---      | ---      |          |          |        |          |          |
| 62 | Sm      |      129 | 129      |      5.2 |      5.2 | 37.4    | 21.3     | 21.3     |          |          |        |          |          |
| 63 | Eu      |      133 | 127.7*   |        0 |        0 | 32      | 22       | 22       |          |          |        |          |          |
| 64 | Gd      |      --- | 142.6*   |     8.6* |     8.6* | 36      | 28       | 21       |          |          |        |          |          |
| 65 | Tb      |   150.5* | 150.5*   |     7.7* |     2.4* | 45.6*   | 28.7*    | 22.6*    |          |          |        |          |          |
| 66 | Dy      |   153.6* | 153.6*   |     8.0* |     4.3* | 49.9*   | 26.3     | 26.3     |          |          |        |          |          |
| 67 | Ho      |     160* | 160*     |     8.6* |     5.2* | 49.3*   | 30.8*    | 24.1*    |          |          |        |          |          |
| 68 | Er      |   167.6* | 167.6*   |      --- |     4.7* | 50.6*   | 31.4*    | 24.7*    |          |          |        |          |          |
| 69 | Tm      |   175.5* | 175.5*   |      --- |      4.6 | 54.7*   | 31.8*    | 25.0*    |          |          |        |          |          |
| 70 | Yb      |   191.2* | 182.4*   |     2.5* |     1.3* | 52.0*   | 30.3*    | 24.1*    |          |          |        |          |          |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element |     K 1s | L1 2s    | L2 2p1/2 | L3 2p3/2 | M1 3s   | M2 3p1/2 | M3 3p3/2 | M4 3d3/2 | M5 3d5/2 | N1 4s  | N2 4p1/2 | N3 4p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 71 | Lu      |    63314 | 10870    |    10349 |     9244 | 2491    | 2264     | 2024     | 1639     | 1589     | 506.8* | 412.4*   | 359.2*   |
| 72 | Hf      |    65351 | 11271    |    10739 |     9561 | 2601    | 2365     | 2108     | 1716     | 1662     | 538*   | 438.2†   | 380.7†   |
| 73 | Ta      |    67416 | 11682    |    11136 |     9881 | 2708    | 2469     | 2194     | 1793     | 1735     | 563.4† | 463.4†   | 400.9†   |
| 74 | W       |    69525 | 12100    |    11544 |    10207 | 2820    | 2575     | 2281     | 1872     | 1809     | 594.1† | 490.4†   | 423.6†   |
| 75 | Re      |    71676 | 12527    |    11959 |    10535 | 2932    | 2682     | 2367     | 1949     | 1883     | 625.4† | 518.7†   | 446.8†   |
| 76 | Os      |    73871 | 12968    |    12385 |    10871 | 3049    | 2792     | 2457     | 2031     | 1960     | 658.2† | 549.1†   | 470.7†   |
| 77 | Ir      |    76111 | 13419    |    12824 |    11215 | 3174    | 2909     | 2551     | 2116     | 2040     | 691.1† | 577.8†   | 495.8†   |
| 78 | Pt      |    78395 | 13880    |    13273 |    11564 | 3296    | 3027     | 2645     | 2202     | 2122     | 725.4† | 609.1†   | 519.4†   |
| 79 | Au      |    80725 | 14353    |    13734 |    11919 | 3425    | 3148     | 2743     | 2291     | 2206     | 762.1† | 642.7†   | 546.3†   |
| 80 | Hg      |    83102 | 14839    |    14209 |    12284 | 3562    | 3279     | 2847     | 2385     | 2295     | 802.2† | 680.2†   | 576.6†   |
| 81 | Tl      |    85530 | 15347    |    14698 |    12658 | 3704    | 3416     | 2957     | 2485     | 2389     | 846.2† | 720.5†   | 609.5†   |
| 82 | Pb      |    88005 | 15861    |    15200 |    13035 | 3851    | 3554     | 3066     | 2586     | 2484     | 891.8† | 761.9†   | 643.5†   |
| 83 | Bi      |    90524 | 16388    |    15711 |    13419 | 3999    | 3696     | 3177     | 2688     | 2580     | 939†   | 805.2†   | 678.8†   |
| 84 | Po      |    93105 | 16939    |    16244 |    13814 | 4149    | 3854     | 3302     | 2798     | 2683     | 995*   | 851*     | 705*     |
| 85 | At      |    95730 | 17493    |    16785 |    14214 | 4317    | 4008     | 3426     | 2909     | 2787     | 1042*  | 886*     | 740*     |
| 86 | Rn      |    98404 | 18049    |    17337 |    14619 | 4482    | 4159     | 3538     | 3022     | 2892     | 1097*  | 929*     | 768*     |
| 87 | Fr      |   101137 | 18639    |    17907 |    15031 | 4652    | 4327     | 3663     | 3136     | 3000     | 1153*  | 980*     | 810*     |
| 88 | Ra      |   103922 | 19237    |    18484 |    15444 | 4822    | 4490     | 3792     | 3248     | 3105     | 1208*  | 1058     | 879*     |
| 89 | Ac      |   106755 | 19840    |    19083 |    15871 | 5002    | 4656     | 3909     | 3370     | 3219     | 1269*  | 1080*    | 890*     |
| 90 | Th      |   109651 | 20472    |    19693 |    16300 | 5182    | 4830     | 4046     | 3491     | 3332     | 1330*  | 1168*    | 966.4†   |
| 91 | Pa      |   112601 | 21105    |    20314 |    16733 | 5367    | 5001     | 4174     | 3611     | 3442     | 1387*  | 1224*    | 1007*    |
| 92 | U       |   115606 | 21757    |    20948 |    17166 | 5548    | 5182     | 4303     | 3728     | 3552     | 1439*b | 1271*b   | 1043†    |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element | N4 4d3/2 | N5 4d5/2 | N6 4f5/2 | N7 4f7/2 | O1 5s   | O2 5p1/2 | O3 5p3/2 | O4 5d3/2 | O5 5d5/2 | P1 6s  | P2 6p1/2 | P3 6p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 71 | Lu      |   206.1* | 196.3*   |     8.9* |     7.5* | 57.3*   | 33.6*    | 26.7*    |          |          |        |          |          |
| 72 | Hf      |   220.0† | 211.5†   |    15.9† |    14.2† | 64.2†   | 38*      | 29.9†    |          |          |        |          |          |
| 73 | Ta      |   237.9† | 226.4†   |    23.5† |    21.6† | 69.7†   | 42.2*    | 32.7†    |          |          |        |          |          |
| 74 | W       |   255.9† | 243.5†   |    33.6* |    31.4† | 75.6†   | 45.3*b   | 36.8†    |          |          |        |          |          |
| 75 | Re      |   273.9† | 260.5†   |    42.9* |    40.5* | 83†     | 45.6*    | 34.6*b   |          |          |        |          |          |
| 76 | Os      |   293.1† | 278.5†   |    53.4† |    50.7† | 84*     | 58*      | 44.5†    |          |          |        |          |          |
| 77 | Ir      |   311.9† | 296.3†   |    63.8† |    60.8† | 95.2*b  | 63.0*b   | 48.0†    |          |          |        |          |          |
| 78 | Pt      |   331.6† | 314.6†   |    74.5† |    71.2† | 101.7*b | 65.3*b   | 51.7†    |          |          |        |          |          |
| 79 | Au      |   353.2† | 335.1†   |    87.6† |     84.0 | 107.2*b | 74.2†    | 57.2†    |          |          |        |          |          |
| 80 | Hg      |   378.2† | 358.8†   |   104.0† |    99.9† | 127†    | 83.1†    | 64.5†    | 9.6†     | 7.8†     |        |          |          |
| 81 | Tl      |   405.7† | 385.0†   |   122.2† |   117.8† | 136.0*b | 94.6†    | 73.5†    | 14.7†    | 12.5†    |        |          |          |
| 82 | Pb      |   434.3† | 412.2†   |   141.7† |   136.9† | 147*b   | 106.4†   | 83.3†    | 20.7†    | 18.1†    |        |          |          |
| 83 | Bi      |   464.0† | 440.1†   |   162.3† |   157.0† | 159.3*b | 119.0†   | 92.6†    | 26.9†    | 23.8†    |        |          |          |
| 84 | Po      |     500* | 473*     |     184* |     184* | 177*    | 132*     | 104*     | 31*      | 31*      |        |          |          |
| 85 | At      |     533* | 507      |     210* |     210* | 195*    | 148*     | 115*     | 40*      | 40*      |        |          |          |
| 86 | Rn      |     567* | 541*     |     238* |     238* | 214*    | 164*     | 127*     | 48*      | 48*      | 26     |          |          |
| 87 | Fr      |     603* | 577*     |     268* |     268* | 234*    | 182*     | 140*     | 58*      | 58*      | 34     | 15       | 15       |
| 88 | Ra      |     636* | 603*     |     299* |     299* | 254*    | 200*     | 153*     | 68*      | 68*      | 44     | 19       | 19       |
| 89 | Ac      |     675* | 639*     |     319* |     319* | 272*    | 215*     | 167*     | 80*      | 80*      | ---    | ---      | ---      |
| 90 | Th      |   712.1† | 675.2†   |   342.4† |   333.1† | 290*a   | 229*a    | 182*a    | 92.5†    | 85.4†    | 41.4†  | 24.5†    | 16.6†    |
| 91 | Pa      |     743* | 708*     |     371* |     360* | 310*    | 232*     | 232*     | 94*      | 94*      | ---    | ---      | ---      |
| 92 | U       |   778.3† | 736.2†   |   388.2* |   377.4† | 321*ab  | 257*ab   | 192*ab   | 102.8†   | 94.2†    | 43.9†  | 26.8†    | 16.8†    |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|


*** Bremsstrahlung

Talk about Bremsstrahlung as a requirement for the CDL data?

** Cosmic rays
:PROPERTIES:
:CUSTOM_ID: sec:theory:cosmic_radiation
:END:

Cosmic rays, or cosmic radiation refers to two aspects of a related
phenomenon. Primary cosmic radiation is the radiation arriving at
Earth from the Sun, galactic and extragalactic sources. The main
contribution are highly energetic protons, but other long lived
elementary particles and nuclei also contribute to a lesser
extent. Cosmic rays are isotropic at most energies, because of the
influence of galactic magnetic fields. Their energies range from
$\SI{1e9}{eV}$ up to $\SI{1e21}{eV}$. It is generally assumed that
particles below \SI{1e18}{eV} are of mainly galactic origin, whereas
the above is dominated by extragalactic sources. The flux of the
primary cosmic rays generally follows a power law
distribution. Different contributions follow a generally similar power
law. \cite{Zyla:2020zbs} (chapter on cosmic rays)

When cosmic rays interact with the molecules of Earth's atmosphere,
mesons are produced, mainly pions. Neutral pions generate showers of
photons and electron-positron pairs. Charged pions on the other hand
decay into muons and anti muon-neutrinos. Muons are produced over
electrons in this case, due to chirality. As they are more massive
than electrons they have a larger component of the opposite chirality
than their neutrino partner, which is necessary for this 'forbidden'
decay due to angular momentum conservation.

They are produced at an altitude of roughly $\SI{15}{km}$. A large
fraction of them reaches Earth's surface as they are highly
relativistic. Their spectrum is described by a convolution of the
production energy, their energy loss due to ionization in the
atmosphere and possible decay.

Muons are of interest in the context of helioscope experiments, as
they present a dominant source of background, especially in gaseous
detectors (directly and indirectly due to fluorescence). And because
current helioscope experiments are built near the surface, little
attenuation of muon flux happens. Therefore, a good understanding of
the expected muon flux is required.

Above $\SI{100}{GeV}$ muon decay is negligible. At those energies the
muon flux at the surface strictly follows the same power law as the
primary cosmic ray flux. Following Gaisser \cite{gaisser2016cosmic},
in this regime it can be described by

#+NAME: eq:theory:muon_flux_gaisser
\begin{equation}
\frac{\mathrm{d}N_μ}{\mathrm{d}E_μ \mathrm{d}Ω} \approx \frac{0.14
E_μ^{-2.7}}{\si{\centi\meter\squared \second \steradian \giga\electronvolt}} \times \left[ \frac{1}{1 + \frac{1.1
E_μ \cos ϑ}{\SI{115}{GeV}}} + \frac{0.054}{1 + \frac{1.1 E_μ \cos
ϑ}{\SI{850}{GeV}}} \right]
\end{equation}

where the first term in parenthesis is the pion and the second the
kaon contribution.

For lower energies, \cite{doi:10.1142/S0217751X18501750} provide a set
of fitted functions based on [[#eq:theory:muon_flux_gaisser]] with a
single power law

\[
I(E, θ) = I_0 N (E_0 + E)^{-n} \left(1 + \frac{E}{ε}\right)^{-1} D(θ)^{-(n - 1)},
\]

where $I_0$, the intensity under zenith angle, and
$ε$ is another fit parameter for the replacement of the separate meson
masses in eq. [[#eq:theory:muon_flux_gaisser]]. $D(θ)$ is the path length
through the atmosphere under an angle $θ$ from the zenith. $N$ is a
normalization constant given by

\[
N = (n - 1) (E_0 + E_c)^{n-1},
\]

where $n$ corresponds to the effective power of the cosine behavior
and is the final fit parameter. $E_0$ accounts for the energy loss due
to interactions in the atmosphere and $E_c$ is the lowest energy given
in a data set.

If the Earth is assumed flat, it is $D(θ) = 1/\cosθ$ (which is often
assumed for simplicity and is a reasonable approximation as long as
only angles close to $θ = 0$ are considered). To describe a trajectory
through Earth's curved atmosphere $D(θ)$ can be written as:

\[
D(θ) = \sqrt{
  \left(
    \frac{R²}{d²} \cos² θ + 2\frac{R}{d} + 1
  \right)
} -
  \frac{R}{d}\cos θ
\]
where $R$ is the Earth radius, $d$ the vertical path length (i.e. the
height at which the muon is created) and $θ$ the zenith angle.

While this parametrization is very useful to describe the few specific
datasets shown in \cite{doi:10.1142/S0217751X18501750} and provides a
way to fit any measured muon flux at a specific location, it is
limited in applicability to arbitrary locations, altitudes and
angles. For that an approach that does not require a fit to a dataset
is preferable, namely by utilizing the a combination of the
approximation by Gaisser, eq. [[#eq:theory:muon_flux_gaisser]], and the
interaction of muons with the atmosphere. As such, we modify the
equation for the intensity $I$ to the following:

\[
I(E, θ) = I_0 (n-1) (E_θ(E, θ) + E_c)^{n-1} (E_θ(E, θ) + E)^{-n} \left[ \frac{1}{1 + \frac{1.1
E_μ \cos ϑ}{\SI{115}{GeV}}} + \frac{0.054}{1 + \frac{1.1 E_μ \cos
ϑ}{\SI{850}{GeV}}} \right] D(θ)^{-(n - 1)},
\]

where we take $n = 3$ exactly. One could put in the best fit for the
general cosine behavior under zenith angles, $n = n_{\text{fit}} + 1$,
but for simplicity we just use 3 here. Take $E_θ(E, θ)$ to be the
energy of a muon left from initial energy $E$ at generation in the
upper atmosphere after transporting it through the atmosphere under
the angle $θ$. The transport must take into account the density change
using the barometric height formula of the atmosphere. Transport is
done using the Bethe-Bloch equation as introduced in
sec. [[#sec:theory:bethe_bloch]] assuming an atmosphere made up of
nitrogen, oxygen and argon. As such we remove all parameters except
an initial intensity $I_0$, which can be set to the best fit of the
integrated muon flux at the zenith angle at sea level. In the
following figures we simply use $I_0 = \SI{90}{\per\meter\squared
\per\steradian \per\second}$. Figure [[fig:theory:muon_flux_surface]]
shows the expected differential muon flux using these parameters for
different angles at sea level. On the left the initial energy of the
muons is shown before transporting through the atmosphere. For each
angle the lines cut off at the energy below which the muon would
likely stopped by the atmosphere according to its energy loss per
distance. On the right we see the same final energy of the same muons
at the surface. The lines are cut to the lowest muon energy that was
calculated for which more than \SI{1}{GeV} was left at the
surface. These numbers match reasonably well with different datasets
for different locations under different angles, but they should *not*
be considered as more than a starting point for a general expectation.

#+CAPTION: Differential muon flux at sea level for different zenith angles.
#+CAPTION: \ref{fig:theory:muon_flux_surface:initial} shows the initial energy of the muon. The cut-off corresponds to the
#+CAPTION: lowest energy transported through the atmosphere. \ref{fig:theory:muon_flux_surface:final} shows the
#+CAPTION: final muon energy at the surface, with the lowest computed value above
#+CAPTION: $\SI{1}{GeV}$ shown. 
#+NAME: fig:theory:muon_flux_surface
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\linewidth]{/home/basti/phd/Figs/muons/initial_energy_vs_flux_and_angle_cosmic_muons.pdf}
    \caption{Initial energy}
    \label{fig:theory:muon_flux_surface:initial}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\linewidth]{/home/basti/phd/Figs/muons/final_energy_vs_flux_and_angle_cosmic_muons.pdf}
    \caption{Final energy}
    \label{fig:theory:muon_flux_surface:final}
  \end{subfigure}
\end{figure}

Because of their large energies, muons behave as minimally ionizing
particles (MIPS), which means their mean energy loss is more or less
independent of the muon's energy. They are in the trough of the
Bethe-Bloch equation, see sec. [[#sec:theory:bethe_bloch]]. This means the
exact energy of each muon is irrelevant and for background studies
only the actual rate of muons is important.

*PLOT OF PRIMARY RADIATION*

*SECONDARY MUON PRODUCTION*

*MUON FLUX AT ZENITH*, *MUON FLUX UNDER ANGLE* (cos²)

*REFERENCE TO MUON CHIRALITY OVER ELECTRON PROD*


*** Calculation of muon angular / energy dependence at surface   :noexport:

The code here is directly based on code written in my notes
[[file:~/org/Doc/StatusAndProgress.org]] being tangled into a file
=/tmp/muon_flux.nim=. 

#+begin_src nim :results silent :tangle /home/basti/phd/code/muons.nim
import math, macros, unchained
import seqmath, ggplotnim, sequtils, strformat

let K = 4 * π * N_A * r_e^2 * m_e * c^2 # usually in: [MeV mol⁻¹ cm²]

defUnit(cm³•g⁻¹)
defUnit(J•m⁻¹)
defUnit(cm⁻³)
defUnit(g•mol⁻¹)
defUnit(MeV•g⁻¹•cm²)
defUnit(mol⁻¹)
defUnit(keV•cm⁻¹)
defUnit(g•cm⁻³)
defUnit(g•cm⁻²)

proc electronDensity(ρ: g•cm⁻³, Z, A: UnitLess): cm⁻³ =
  result = N_A * Z * ρ / (A * M_u.to(g•mol⁻¹))

proc I[T](z: float): T =
  ## use Bloch approximation for all but Argon (better use tabulated values!)
  # 188.0 eV from NIST table 
  result = if z == 18.0: 188.0.eV.to(T) 
           else: (10.eV * z).to(T)

proc calcβ(γ: UnitLess): UnitLess =
  result = sqrt(1.0 - 1.0 / (γ^2))

proc betheBloch(z, Z: UnitLess,
                   A: g•mol⁻¹,
                   γ: UnitLess,
                   M: kg): MeV•g⁻¹•cm² =
  ## result in MeV cm² g⁻¹ (normalized by density)
  ## z: charge of particle
  ## Z: charge of particles making up medium
  ## A: atomic mass of particles making up medium
  ## γ: Lorentz factor of particle
  ## M: mass of particle in MeV (or same mass as `m_e` defined as)
  let β = calcβ(γ)
  let W_max = 2 * m_e * c^2 * β^2 * γ^2 /
    (1 + 2 * γ * m_e / M + (m_e / M)^2)
  let lnArg = 2 * m_e * c^2 * β^2 * γ^2 * W_max / (I[Joule](Z)^2)
  result = (K * z^2 * Z / A * 1.0 / (β^2) * (
    0.5 * ln(lnArg) - β^2
  )).to(MeV•g⁻¹•cm²)

proc mostProbableLoss(z, Z: UnitLess, A: g•mol⁻¹, γ: UnitLess,
                      x: g•cm⁻²): keV =
  ## Computes the most probable value, corresponding to the peak of the Landau
  ## distribution, that gives rise to the Bethe-Bloch formula.
  ##
  ## Taken from PDG chapter 'Passage of particles through matter' equation
  ## `34.12` in 'Fluctuations in energy loss', version 2020).
  ##
  ## `x` is the "thickness". Density times length, `x = ρ * d`. The other parameters
  ## are as in `betheBloch` above.
  let β = calcβ(γ)
  let ξ = K / 2.0 * Z / A * z*z * (x / (β*β))
  const j = 0.200
  let I = I[Joule](Z)
  result = (ξ * ( ln((2 * m_e * c^2 * β^2 * γ^2).to(Joule) / I) + ln(ξ.to(Joule) / I) + j - β^2)).to(keV) # - δ*(β*γ)

proc density(p: mbar, M: g•mol⁻¹, temp: Kelvin): g•cm⁻³ =
  ## returns the density of the gas for the given pressure.
  ## The pressure is assumed in `mbar` and the temperature (in `K`).
  ## The default temperature corresponds to BabyIAXO aim.
  ## Returns the density in `g / cm^3`
  let gasConstant = 8.314.J•K⁻¹•mol⁻¹ # joule K^-1 mol^-1
  let pressure = p.to(Pa) # pressure in Pa
  # factor 1000 for conversion of M in g / mol to kg / mol
  result = (pressure * M / (gasConstant * temp)).to(g•cm⁻³)

proc E_to_γ(E: GeV): UnitLess =
  result = E.to(Joule) / (m_μ * c^2) + 1

proc γ_to_E(γ: UnitLess): GeV =
  result = ((γ - 1) * m_μ * c^2).to(GeV)

type
  Element = object
    Z: UnitLess
    M: g•mol⁻¹
    A: UnitLess # numerically same as `M`
    ρ: g•cm⁻³
proc initElement(Z: UnitLess, M: g•mol⁻¹, ρ: g•cm⁻³): Element =
  Element(Z: Z, M: M, A: M.UnitLess, ρ: ρ)

# molar mass. Numerically same as relative atomic mass
let M_Ar = 39.95.g•mol⁻¹
let ρAr = density(1050.mbar, M_Ar, temp = 293.15.K)
let Argon = initElement(18.0.UnitLess, 39.95.g•mol⁻¹, ρAr)

proc intBethe(e: Element, d_total: cm, E0: eV, dx = 1.μm): eV =
  ## integrated energy loss of bethe formula after `d` cm of matter
  ## and returns the energy remaining
  var γ: UnitLess = E_to_γ(E0.to(GeV))
  var d: cm
  result = E0
  var totalLoss = 0.eV
  while d < d_total and result > 0.eV:
    let E_loss: MeV = betheBloch(-1, e.Z, e.M, γ, m_μ) * e.ρ * dx
    result = result - E_loss.to(eV)
    γ = E_to_γ(result.to(GeV))
    d = d + dx.to(cm)
    totalLoss = totalLoss + E_loss.to(eV)
  result = max(0.float, result.float).eV

proc plotDetectorAbsorption() =
  let E_float = logspace(-2, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  let E_loss = energies.mapIt(
    (it.to(eV) - intBethe(Argon, 3.cm, it.to(eV))).to(keV).float
  )
  let df = toDf(E_float, E_loss)
  ggplot(df, aes("E_float", "E_loss")) +
    geom_line() +
    xlab("μ Energy [GeV]") + ylab("ΔE [keV]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle("Energy loss of Muons in 3 cm Ar at CAST conditions") +
    ggsave("/home/basti/phd/Figs/muons/ar_energy_loss_cast.pdf")
plotDetectorAbsorption()

let Atmosphere = @[(0.78084, initElement(7.0.UnitLess, 14.006.g•mol⁻¹, 1.2506.g•dm⁻³.to(g•cm⁻³))), # N2
                   (0.20964, initElement(8.0.UnitLess, 15.999.g•mol⁻¹, 1.429.g•dm⁻³.to(g•cm⁻³))),  # O2
                   (0.00934, initElement(18.0.UnitLess, 39.95.g•mol⁻¹, 1.784.g•dm⁻³.to(g•cm⁻³)))]  # Ar

proc plotMuonBethe() =
  let E_float = logspace(-2, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  var dEdxs = newSeq[float]()
  for e in energies:
    var dEdx = 0.0.MeV•g⁻¹•cm²
    for elTup in Atmosphere:
      let (w, element) = elTup
      let γ = E_to_γ(e)
      dEdx += w * betheBloch(-1, element.Z, element.M, γ, m_μ)
    dEdxs.add dEdx.float
  let df = toDf(E_float, dEdxs)
  ggplot(df, aes("E_float", "dEdxs")) +
    geom_line() +
    xlab("μ Energy [GeV]") + ylab("dE/dx [MeV•g⁻¹•cm²]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle("Energy loss of Muons in atmosphere") +
    ggsave("/home/basti/phd/Figs/muons/energy_loss_muons_atmosphere.pdf")  
plotMuonBethe()
#if true: quit()
import math, unchained, ggplotnim, sequtils

const R_Earth = 6371.km
func distanceAtmosphere(θ: Radian, d: KiloMeter = 36.6149.km): UnitLess =
  ## NOTE: The default value for `d` is not to be understood as a proper height. It.s an
  ## approximation based on a fit to get `R_Earth / d = 174`!
  result = sqrt((R_Earth / d * cos(θ))^2 + 2 * R_Earth / d + 1) - R_Earth / d * cos(θ)

defUnit(cm⁻²•s⁻¹•sr⁻¹)  
defUnit(m⁻²•s⁻¹•sr⁻¹)
proc muonFlux(E: GeV, θ: Radian, E₀, E_c: GeV,
              I₀: m⁻²•s⁻¹•sr⁻¹,
              ε: GeV): m⁻²•s⁻¹•sr⁻¹ =
  const n = 3.0
  let N = (n - 1) * pow((E₀ + E_c).float, n - 1)
  result = I₀ * N * pow((E₀ + E).float, -n) *
    #pow((1 + E / ε).float, -1) *
    ( ( 1.0 / (1 + 1.1 * E * cos(θ) / 115.GeV).float) + (0.054 / (1 + 1.1 * E * cos(θ) / 850.GeV).float) ) * 
    pow(distanceAtmosphere(θ), -(n - 1))

from numericalnim/integrate import simpson
proc plotE_vs_flux(θ: Radian, E₀, E_c: GeV, I₀: m⁻²•s⁻¹•sr⁻¹, ε: GeV,
                   suffix = "") =
  let energies = linspace(E_c.float, 100.0, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(it, θ, E₀, E_c, I₀, ε).float) # .to(cm⁻²•s⁻¹•sr⁻¹)
  let df = toDf(energies, flux)

  echo "Integrated flux: ", simpson(flux, energies)
  
  ggplot(df, aes("energies", "flux")) +
    geom_line() +
    xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle(&"Flux dependency on the energy of muons at θ = {θ.to(°)}{suffix}") +
    ggsave(&"/home/basti/phd/Figs/muons/energy_vs_flux_cosmic_muons{suffix}.pdf")
plotE_vs_flux(0.Radian,
              2.5.GeV, #4.29.GeV,
              0.5.GeV, 70.7.m⁻²•s⁻¹•sr⁻¹, 854.GeV)


let E₀ = 25.0.GeV
let I₀ = 90.0.m⁻²•s⁻¹•sr⁻¹
let E_c = 1.GeV
let ε = 2000.GeV

proc plotFlux_at_CAST() =
  let energies = linspace(0.5, 100.0, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(it, 88.0.degToRad.Radian, E₀, E_c, I₀, ε).float)
  let df = toDf(energies, flux)
  ggplot(df, aes("energies", "flux")) +
    geom_line() +
    xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle("Flux dependency on the energy at θ = 88° at CAST altitude") +
    ggsave("/home/basti/phd/Figs/muons/flux_at_cast_88_deg.pdf")
plotFlux_at_CAST()

proc computeMeanEnergyLoss() =
  let energies = linspace(0.5, 100.0, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(
    it, 88.0.degToRad.Radian, E₀, E_c, I₀, ε).float
  )
  let E_loss = E.mapIt(
    (it.to(eV) - intBethe(Argon, 3.cm, it.to(eV))).to(keV).float
  )
  let fluxSum = flux.sum
  let df = toDf(energies, E_loss, flux)
      .mutate(f{"flux" ~ `flux` / fluxSum},
              f{"AdjFlux" ~ `E_loss` * `flux`})
  echo "Mean energy loss: ", df["AdjFlux", float].sum
computeMeanEnergyLoss()

proc computeHeight(S: Meter, θ: Radian): KiloMeter =
  ## For given remaining distance distance along the path of a muon
  ## `S` (see fig. 1 in 1606.06907) computes the remaining height above
  ## ground. Formula is the result of inverting eq. 7 to `d` using quadratic
  ## formula. Positive result, because negative is negative.
  result = (-1.0 * R_Earth + sqrt(R_Earth^2 + S^2 + 2 * S * R_Earth * cos(θ)).m).to(km)

import algorithm
defUnit(K•m⁻¹)
proc barometricFormula(h: KiloMeter): g•cm⁻³ =
  let hs = @[0.0.km, 11.0.km]
  let ρs = @[1.225.kg•m⁻³, 0.36391.kg•m⁻³]
  let Ts = @[288.15.K, 216.65.K]
  let Ls = @[-1.0 * 0.0065.K•m⁻¹, 0.0.K•m⁻¹]
  let M_air = 0.0289644.kg•mol⁻¹
  let R = 8.3144598.N•m•mol⁻¹•K⁻¹
  let g_0 = 9.80665.m•s⁻²
  let idx = hs.mapIt(it.float).lowerBound(h.float) - 1
  case idx
  of 0:
    # in Troposphere, using regular barometric formula for denities
    let expArg = g_0 * M_air / (R * Ls[idx])
    result = (ρs[idx] * pow(Ts[idx] / (Ts[idx] + Ls[idx] * (h - hs[idx])), expArg)).to(g•cm⁻³)
  of 1:
    # in Tropopause, use equation valid for L_b = 0
    result = (ρs[idx] * exp(-1.0 * g_0 * M_air * (h - hs[idx]) / (R * Ts[idx]))).to(g•cm⁻³)
  else: doAssert false, "Invalid height! Outside of range!"

import random
randomize(43)
proc intBetheAtmosphere(E: GeV, θ: Radian, dx = 10.cm): eV =
  ## integrated energy loss using Bethe formula for muons generated at
  ## `15.km` under an angle of `θ` to the observer for a muon of energy
  ## `E`.
  # Main contributions in Earth's atmosphere
  const τ = 2.19618.μs # muon half life
  let elements = Atmosphere
  var γ: UnitLess = E_to_γ(E.to(GeV))
  result = E.to(eV)
  var totalLoss = 0.eV
  let h_muon = 15.km # assume creation happens in `15.km`
  let S = h_muon.to(m) * distanceAtmosphere(θ.rad, d = h_muon)
  var S_prime = S
  while S_prime > 0.m and result > 0.eV:
    let h = computeHeight(S_prime, θ)
    let ρ_at_h = barometricFormula(h)
    var E_loss = 0.0.MeV
    for eTup in elements: # compute the weighted contribution of the element fraction
      let (w, e) = eTup
      E_loss += w * betheBloch(-1, e.Z, e.M, γ, m_μ) * ρ_at_h * dx

    ## Add step for radioactive decay of muon.
    ## - given `dx` compute likelihood of decay
    ## - eigen time of muon: dx / v = dt. dτ = dt / γ
    ## - muon decay is λ = 1 / 2.2e-6s
    let β = calcβ(γ)
    # compute effective time in lab frame
    let δt = dx / (β * c)
    # compute eigen time
    let δτ = δt / γ
    # probability of a decay in this time frame
    let p = pow(1 / math.E, δτ / τ)
    # decay with likelihood `p`
    #echo "γ = ", γ, " yields ", p, " in δτ ", δτ, " for energy ", E
    if rand(1.0) < (1.0 - p):
      echo "Particle decayed after: ", S_prime
      return 0.eV
          
    result = result - E_loss.to(eV)
    S_prime = S_prime - dx
    γ = E_to_γ(result.to(GeV))
    totalLoss = totalLoss + E_loss.to(eV)
  echo "total Loss ", totalLoss.to(GeV)
  result = max(0.float, result.float).eV

block MuonLimits:
  let τ_μ = 2.1969811.μs
  # naively this means given some distance `s` the muon can
  # traverse `s = c • τ_μ` (approximating its speed by `c`) before
  # it has decayed with a 1/e chance
  # due to special relativity this is extended by γ
  let s = c * τ_μ
  echo s
  # given production in 15 km, means
  let h = 15.km
  echo h / s
  # so a reduction of (1/e)^22. So 0.
  # now it's not 15 km but under an angle `θ = 88°`.
  let R_over_d = 174.UnitLess
  let n = 3.0
  let E₀ = 25.0.GeV
  let I₀ = 90.0.m⁻²•s⁻¹•sr⁻¹
  let E_c = 1.GeV
  let ε = 2000.GeV

  # distance atmospher gives S / d, where `d` corresponds to our `h` up there
  let S = h * distanceAtmosphere(88.0.degToRad.rad)
  # so about 203 km
  # so let's say 5 * mean distance is ok, means we ned
  let S_max = S / 5.0
  # so need a `γ` such that `s` is stretched to `S_max`
  let γ = S_max / s
  echo γ
  # ouch. Something has to be wrong. γ of 61?

  # corresponds to an energy loss of what?
  let Nitrogen = initElement(7.0.UnitLess, 14.006.g•mol⁻¹, 1.2506.g•dm⁻³.to(g•cm⁻³))
  echo "================================================================================"
  echo "Energy left: ", intBethe(Nitrogen, S.to(cm), 6.GeV.to(eV), dx = 1.m.to(μm)).to(GeV)
  proc print(E: GeV, θ: Radian) =
    let left = intBetheAtmosphere(E, θ = θ).to(GeV)
    echo "E = ", E, ", θ = ", θ, ", Bethe = ", E - left
  print(6.GeV, 0.Radian)
  #print(200.GeV, 0.Radian)  
  #print(200.GeV, 88.°.to(Radian))
  #print(200.GeV, 75.°.to(Radian))

  let E_loss75 = 100.GeV - intBetheAtmosphere(100.GeV, 75.°.to(Radian)).to(GeV)
  plotE_vs_flux(75.°.to(Radian),
                E_loss75, #23.78.GeV, #25.GeV, #E_loss75,
                1.0.GeV,
                90.m⁻²•s⁻¹•sr⁻¹, #65.2.m⁻²•s⁻¹•sr⁻¹,
                2000.GeV, # 854.GeV,
                "_at_75deg")

  
  echo "S@75° = ", h * distanceAtmosphere(75.0.degToRad.rad, d = 15.0.km)
  echo "================================================================================"  
echo E_to_γ(4.GeV)
echo E_to_γ(0.GeV)

proc plotE_vs_flux_and_angles(E_c: GeV, I₀: m⁻²•s⁻¹•sr⁻¹, ε: GeV,
                              suffix = "") =
  ## Generates a plot of the muon flux vs energy for a fixed set of different
  ## angles.
  ##
  ## The energy loss is computed using a fixed 
  let energies = logspace(log10(E_c.float), 2.float, 100)
  let angles = linspace(0.0, 80.0, 9)
  block CalcLossEachMuon:
    var df = newDataFrame()
    for angle in angles:
      let E = energies.mapIt(it.GeV)
      let θ = angle.°.to(Radian)
      var flux = newSeq[float]()
      var E_initials = newSeq[float]()
      var E_lefts = newSeq[float]()
      for e in E:
        let E_left = intBetheAtmosphere(e, θ).to(GeV)
        if E_left <= 0.0.GeV:
          echo "Skipping energy : ", e, " as muon was lost in atmosphere"
          continue
        elif E_left <= E_c:
          echo "Skipping energy : ", e, " as muon has less than E_c = ", E_c, " energy left"
          continue
        let E₀ = e - E_left
        flux.add muonFlux(e, θ, E₀, E_c, I₀, ε).float
        E_initials.add e.float        
        E_lefts.add E_left.float
      let dfLoc = toDf({E_initials, E_lefts, flux, "angle [°]" : angle})
      df.add dfLoc
    ggplot(df, aes("E_initials", "flux", color = factor("angle [°]"))) +
      geom_line() +
      xlab("Initial energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
      scale_x_log10() + scale_y_log10() +
      ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
      ggsave(&"/home/basti/phd/Figs/muons/initial_energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")
  
    ggplot(df, aes("E_lefts", "flux", color = factor("angle [°]"))) +
      geom_line() +
      xlab("Energy at surface [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
      scale_x_log10() + scale_y_log10() +
      ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
      ggsave(&"/home/basti/phd/Figs/muons/final_energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")
  block StaticLoss:
    var df = newDataFrame()
    for angle in angles:
      let E = energies.mapIt(it.GeV)
      let θ = angle.°.to(Radian)
      let E₀ = 100.GeV - intBetheAtmosphere(100.GeV, 0.0.Radian).to(GeV)    
      let flux = E.mapIt(muonFlux(it, θ, E₀, E_c, I₀, ε).float)
      let dfLoc = toDf({energies, flux, "angle [°]" : angle})
      df.add dfLoc
    ggplot(df, aes("energies", "flux", color = factor("angle [°]"))) +
      geom_line() +
      xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
      scale_x_log10() + scale_y_log10() +
      ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
      ggsave(&"/home/basti/phd/Figs/muons/energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")


#proc plotE_vs_flux_and_angles(E_c: GeV, I₀: m⁻²•s⁻¹•sr⁻¹, ε: GeV,
#                              suffix = "") =
#  ## Generates a plot of the integrated muon flux vs angles for a fixed set of different
#  ## energies.
#  let angles = linspace(0.0, 90.0, 100)
#  var df = newDataFrame()
#  let energies = linspace(E_c.float, 100.0, 1000)
#  let E = energies.mapIt(it.GeV)
#  for angle in angles:
#    let θ = angle.°.to(Radian)
#    let E₀ = 100.GeV - intBetheAtmosphere(100.GeV, θ).to(GeV)
#    let flux = E.mapIt(muonFlux(it, θ, E₀, E_c, I₀, ε).float) 
#    let dfLoc = toDf({energies, flux, "angle [°]" : angle})
#    df.add dfLoc
#  ggplot(df, aes("energies", "flux", color = factor("angle [°]"))) +
#    geom_line() +
#    xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
#    scale_x_log10() + scale_y_log10() +
#    ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
#    ggsave(&"/home/basti/phd/Figs/muons/energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")

# different angles!      
#block MuonBehavior:
#  plotE_vs_flux_and_angles(1.0.GeV, 90.m⁻²•s⁻¹•sr⁻¹, 854.GeV)

proc unbinnedCdf(x: seq[float]): (seq[float], seq[float]) =
  ## Computes the CDF of unbinned data
  var cdf = newSeq[float](x.len)
  for i in 0 ..< x.len:
    cdf[i] = i.float / x.len.float
  result = (x.sorted, cdf)

import random, algorithm
proc sampleFlux(samples = 1_000_000): DataFrame =
  randomize(1337)
  let energies = linspace(0.1, 100.0, 100_000)
  #let energies = logspace(0, 2, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(it, 88.0.degToRad.Radian, E₀, E_c, I₀, ε).float)
  # given flux compute CDF
  let fluxCS = flux.cumSum()
  let fluxCS_sorted = flux.sorted.cumSum()
  let fluxCDF = fluxCS.mapIt(it / fluxCS[^1])
  let fluxCDF_sorted = fluxCS_sorted.mapIt(it / fluxCS_sorted[^1])

  let (data, cdf) = unbinnedCdf(flux)

  let dfX = toDf(energies, fluxCS, fluxCS_sorted, fluxCDF, fluxCDF_sorted)
  ggplot(dfX, aes("energies", "fluxCS")) +
    geom_line() +
    ggsave("/t/cumsum_test.pdf")
  ggplot(dfX, aes("energies", "fluxCDF")) +
    geom_line() +
    ggsave("/t/cdf_test.pdf")    
  ggplot(dfX, aes("energies", "fluxCS_sorted")) +
    geom_line() +
    ggsave("/t/cumsum_sorted_test.pdf")    
  ggplot(dfX, aes("energies", "fluxCDF_sorted")) +
    geom_line() +
    ggsave("/t/cdf_sorted_test.pdf")

  ggplot(toDf(data, cdf), aes("data", "cdf")) +
    geom_line() +
    ggsave("/t/unbinned_cdf.pdf")
  
  #if true: quit()
  var lossesBB = newSeq[float]()
  var lossesMP = newSeq[float]()
  var energySamples = newSeq[float]()

  let dedxmin = 1.519.MeV•cm²•g⁻¹
  echo "Loss = ", (dedxmin * Argon.ρ * 3.cm).to(keV)
  
  for i in 0 ..< samples:
    # given the fluxCDF sample different energies, which correspond to the
    # distribution expected at CAST
    let idx = fluxCdf.lowerBound(rand(1.0))
    let E_element = E[idx]
    # given this energy `E` compute the loss
    let lossBB = (E_element.to(eV) - intBethe(Argon, 3.cm, E_element.to(eV), dx = 50.μm)).to(keV).float
    lossesBB.add lossBB
    let lossMP = mostProbableLoss(-1, Argon.Z, Argon.M, E_Element.E_to_γ(), Argon.ρ * 3.cm)
    lossesMP.add lossMP.float
    #echo "Index ", i, " yields energy ", E_element, " and loss ", loss
    energySamples.add E_element.float
  let df = toDf(energySamples, lossesBB, lossesMP)
    .gather(["lossesBB", "lossesMP"], "Type", "Value")
  ggplot(df, aes("Value", fill = "Type")) +
    geom_histogram(bins = 300, hdKind = hdOutline, alpha = 0.5, position = "identity") +
    margin(top = 2) +
    xlim(5, 15) +
    ggtitle(&"Energy loss of muon flux at CAST based on MC sampling with {samples} samples") +
    ggsave("/home/basti/phd/Figs/muons/sampled_energy_loss.pdf")

  ggplot(df, aes("energySamples")) +
    geom_histogram(bins = 300) +
    margin(top = 2) +
    ggtitle(&"Sampled energies for energy loss of muon flux at CAST") +
    ggsave("/home/basti/phd/Figs/muons/sampled_energy_for_energy_loss.pdf")
  let (samples, bins) = histogram(energySamples, bins = 300)
  let dfH = toDf({"bins" : bins[0 ..< ^1], samples})
    .filter(f{`bins` > 0.0 and `samples`.float > 0.0})
  ggplot(dfH, aes("bins", "samples")) +
    geom_line() +
    scale_x_log10() + 
    margin(top = 2) +
    ggtitle(&"Sampled energies for energy loss of muon flux at CAST") +
    ggsave("/home/basti/phd/Figs/muons/sampled_energy_for_energy_loss_manual.pdf")

  ggplot(toDf(energies, flux), aes("energies", "flux")) +
    geom_line() +
    scale_x_log10() +
    ggsave("/tmp/starting_data_e_flux.pdf")

  ggplot(toDf(energies, flux), aes("energies", "flux")) +
    geom_line() +
    ggsave("/tmp/linear_starting_data_e_flux.pdf")
    

discard sampleFlux(samples = 1_000_000)
#+end_src


** Gaseous detector fundamentals

*HOW TO START CHAPTER / SECTION?*

Gaseous detectors consist of a volume filled with some kind of
gas. Usually a noble gas with a small amount of molecular gas. Some
kind of entrance window allows the particles to be detected to
enter. An electric field is applied over the gas volume, strong enough
to cause electron-ion pairs created by ionization of the incoming
particles to drift to opposite ends of the volume. At least on the
side of the anode (where the electrons arrive), a readout of some form
is installed to measure the time of arrival, amount of collected
charge and / or the position of the electrons. Depending on the
details, this in principle allows for a 3D reconstruction of the
initial event in the gas volume. The details of choice of detector
gas, applied electric fields, gas volume dimensions and types of
readout have a very large impact on the applications a detector is
useful for. In the following we will focus on the physics concepts
required for gaseous detectors with few \si{cm} long drift volumes and
high spatial resolution readouts.




Note: this section covers the basic fundamentals that will be later
referenced in the thesis. For a much more in-depth understanding of
these concepts, see references \cite{sauli2014gaseous} and
\cite{kolanoski2020particle} and to some extent the PDG
\cite{Zyla:2020zbs} (in particular chapters on particle detectors and
passage of particles through matter; chapter number varies by year).


Write a few general things about gaseous detectors here. I.e. contain
usually mainly a noble gas, with some quencher for rotational and
vibrational modes. These 'cool' the electrons down so that they are in
the Townsend minimum and effectively increases the drift velocity.

Electric fields should be strong enough to let electrons and ions
drift in opposite directions and have a fast enough drift velocity,
but low enough to not cause further ionization.

*** Gas mixtures and Dalton's law [/]
:PROPERTIES:
:CUSTOM_ID: sec:theory:daltons_law
:END:


Of common interest when dealing with gas mixtures is the notion of
partial pressures. In ideal gas theory, a mixture of gases at a
pressure $P$ can be considered to be the sum of the 'partial
pressures' of each gas species

\[
P = \sum_i p_i.
\]

The contribution of each gas only depends on the species' mole
fraction, which means given the mole fractions. Typically when
considering gas mixtures the fractions of each gas species is given as
a percentage. The percentage already refers to the mole fraction of
each species. As such, the partial pressure of a single species can be
expressed as:

\[
p_i = n_i P
\]

where $n_i$ is the mole fraction of species $i$.

This is an extremely valuable property when computing different
interactions of particles with gas mixtures. For example when
computing the absorption of X-rays after in propagating through a
certain distance of gas, as one can compute absorption for each
partial pressure independently and combine the contributions after
(whether they be added, multiplied or something else of course depends
on the considered process).

- [ ] *FIND GOOD REFERENCE FOR DALTON'S LAW*

*** Mean free path

*NOTE*: This is already explained for X-rays in the previous
section. Do we need this concept in some more detail? Otherwise we can
also remove it later. 

See photons above.

Of major importance for the detection of particles in a gaseous
detector is the mean free path. This is the mean length a particle
traverses in a medium before interactions. For charged particles it
yields the mean distance between individual interaction points,
whereas for a photon it gives the mean length the photon traverses
through the detector before interaction.

Especially for photons this value is of crucial importance, as it
tells us at what distance photons will likely convert depending on
their energy. This is described by the absorption length as mentioned
in section [[#sec:theory:xray_matter_gas]]. This is important as it
directly affects the possible drift distance and thus diffusion
available to the generated electrons.  *TOO MUCH DETAIL, AS WE HAVE
NOT INTRODUCED DETECTORS YET!!*

*** Ionization energy and average energy per electron-ion pair

*FIND GOOD REFERENCES* beyond these two. Better would be a primary
like reference. \cite{bronic1992relation, doi:10.1080/00223131.2014.974710} 

Why expect ~26 eV for argon

Talk about ionization energy vs. the actual mean energy loss for a
single ionization. Argon ionization energy is only like 15 eV or so,
but effective one is 26.

Leads to our 226 or so primary electrons for our 55Fe spectra.

In order to understand the signals detected by a gaseous detector the
average number of electrons created by an incident particle should be
known. Denoted by the $W$-value, it is defined by

\[
W = \frac{I}{\langle N \rangle} 
\]

where $I$ is the mean ionization energy of the gas and $\langle N
\rangle$ the average number of electron-ion pairs generated per
interaction. This number is usually smaller one, \numrange{0.6}{0.7}
for noble gases and even below \num{0.5} for molecular gases. Not all
energy of the incoming particle is always deposited in the form of
generation of, for example, a photoelectron. Other forms of energy
loss are possible. In molecular gases vibrational and rotational modes
offer even more possibilities, resulting in the smaller values.

The mean excitation energy of an element is the weighted combination
of the most likely energy levels the element is ionized from. The
exact values are dependent on the specific element and tabulated
values like from NIST \cite{hubbell1996nist}. Above some $Z$ a
rough approximation of $I = \SI{10}{eV} Z$ can be substituted,
developed by Bloch \cite{bloch1933bremsvermogen}.

The precise number for $W$ strongly depends on the used gas mixture
and typically requires experimental measurements to determine or Monte
Carlo based simulations. Tools for Monte Carlo simulations include
GEANT4 \cite{GEANT4:2002zbu} [fn:geant4] and MCNelectron
\cite{doi:10.1080/00223131.2014.974710} [fn:mcn_electron]. These are
based on atomic excitation cross sections, which are well tabulated in
projects like ENDF \cite{brown2018endf} (citation for latest data
release) [fn:endf_website] and LXCat \cite{pancheshnyi2012lxcat,
pitchford2017lxcat, carbone2021data} [fn:lxcat_website].

# Note: there is also MCNP6 https://mcnp.lanl.gov/ which I will
# conveniently *not* mention, as it is under ridiculous US export
# regulations and therefore the source code is not visible for non US
# citizens. Screw that.

[fn:geant4] [[https://geant4.cern.web.ch]]

[fn:mcn_electron] http://web.vu.lt/ff/a.poskus/mcnelectron/

[fn:endf_website] https://www.nndc.bnl.gov/endf-b8.0/index.html

[fn:lxcat_website] [[https://lxcat.net]]

[fn:w_value_fano_factor] Interestingly, there is an empirical somewhat
linear relationship between the W-value as shown here and the Fano
factor \cite{bronic1992relation}.
*NOTE*: Given how Fano discovered / described Fano noise, it's maybe
not quite surprising that this is related! 


*** Diffusion

*SEE Hilke2020 FOR OVERVIEW OF DIFFUSION MATH*

Diffusion is the process of the random walk of electrons either in
longitudinal or transverse (orthogonal to the electric field)
direction they exhibit, when drifting towards the readout. Depending
on the specific detector technology, some transverse diffusion may be
a desired property. For long drift distances, magnetic fields can be
used to significantly reduce the transverse diffusion.

For a point like source of multiple electrons, after diffusion of some
distance a 2 dimensional gaussian distribution will be expected.

Transverse diffusion depends, as one expects from a 2D random walk,
via the square root of the drift distance.

In general for precise numbers, numerical simulations using a tool
like Magboltz must be performed or measurements taken.

*EXPLAIN WHERE COMES FROM, COMES DOWN TO $D_t$ AND PARAMETER FROM MAGBOLTZ* 
\[
σ_t = D_t · \sqrt{x}
\]

*this is important as it relates to the 1.5 σ_transverse cut we do for
data cleaning!*

Describe diffusion based on gas. Needed to get expected photon size
based on conversion at specific height.

What effects affect diffusion?

Random walk + a force acting on particles.

*COMPUTE USING PYBOLTZ: https://github.com/UTA-REST/PyBoltz*

*** Drift velocity

*MENTION MOLECULAR GASES HAVE HIGHER DRIFT VELOCITY*

Talk about drift velocity of electrons for a given electric
field. Required to know time scales associated with e.g. muons + FADC,
time it takes for X-rays to drift (for random coincidences in long
frames etc.)

*USE FORMULA PDG*

The detector used in this thesis does not make use of magnetic
fields. Thus, all terms but the first are zero. Further, the electric
field is constant, leading to the following simplification:


Based on the so called 'friction force model' an analytical expression
for the drift velocity in an electromagnetic field can be written to:
\[
\vec{v} = \frac{e}{m_e} \frac{τ}{1 + ω²τ²}\left( \vec{E} + \frac{ωτ}{B}
(\vec{E} × \vec{B}) + \frac{ω²τ²}{B²}(\vec{E} · \vec{B}) \vec{B} \right)
\]
with the electron charge $e$ and mass $m_e$, in an electric field
$\vec{E}$ and magnetic field $\vec{B}$, given the Lamor frequency 
$ω = eB / m_e$ and the mean collision time $τ$. \cite{Zyla:2020zbs}

For the typical case in Micromegas detectors without a magnetic field
$B = 0, ω = 0$ and a constant, homogeneous electric field $E$, this
reduces to the Townsend expression:

\[
v = \frac{e E τ}{m_e}
\]

These can be computed using software packages like MAGBOLTZ (or its
Python port PyBoltz) that solve the underlying transport equation, the
Boltzmann equation:

\begin{align}
  \frac{∂f}{∂t} + \vec{v} \frac{∂}{∂\vec{r}}f + \frac{∂}{∂\vec{v}}\vec{g} &= Q(t) \\
  \vec{g} &= \left(\frac{e\vec{E}}{m} + \vec{ω} × \vec{v}\right) f
\end{align}
*FIX THIS*

*BOLTZMANN EQUATION: https://en.wikipedia.org/wiki/Boltzmann_equation*

*COMPUTE USING PYBOLTZ: https://github.com/UTA-REST/PyBoltz*

*** Gas amplification, avalanche effect [0/1]
:PROPERTIES:
:CUSTOM_ID: sec:theory:gas_gain_polya
:END:


*FIX TYPING OF POLYA DISTRIBUTION*

In order to turn the individual electrons into a measurable signal,
gaseous detectors use some kind of gas amplification stage. Details
vary, but it is usually a region in the gas volume close to the
readout with a very strong electric field (multiple $si{kV.cm^-1}$)
such that each electron causes many secondary ionizations, leading to
an avalanche effect. In case of the detectors described in this
thesis, amplification factors between \numrange{2000}{4500} are
desired.

The statistical distribution describing the number of electrons after
gas amplification is the Polya distribution

\[
p(x) = \frac{N}{G} \frac{(1 + θ)^{1 + θ}}{Γ(1 + θ)}
\left(\frac{x}{G}\right)^θ \exp{- \frac{(1 + θ) x}{G}}
\]

where $N$ is a normalization constant, $θ$ is another parameter
performing scaling of the distribution and $G$ is the effective gas
gain. $Γ$ refers to the gamma function. It is to note that the term
"polya distribution" in this context is different from other
mathematical definitions, in which polya distribution usually means a
negative binomial distribution. The above definition goes back to
Alkhazov \cite{alkhazov1970statistics} and in slight variations is
commonly used. Due to the complexity of this definition, care needs to
be taken when performing numerical fits to data with this function
(using bounded parameters and preferring more general non-linear
optimization routines instead of a normal Levenberg-Marquardt
approach).

The largest impacts on the expected gas amplification have the
electric field, the choice of gas and the temperature of the
gas. While the former two parameters are comparatively easy to
control, the temperature in the amplification region may vary and is
hard to measure. As such depending on the detector details and
application, gas gain variations are expected and corrections based on
a running gas gain value may be necessary.

If it fits here, Polya distribution to describe avalanche effect.

What gas properties affect the gas gain? Temperature, density etc.

Gas gain.

- [ ] *MENTION UV PHOTONS AND HENCE MOLECULAR GASES CALLED QUENCHER
  GAS*
- [ ] *ADD PLOT OF FUNCTION?*  

*** Energy resolution

Because of the statistical processes associated with the full
detection method used in gaseous detectors, even a perfect delta like
signal in energy, will lead to a natural spread of the measured
signal. The convolution of different ionization yields, potential
losses and gas gain variation all contribute to such a spread.



As such a typical measure of interest for gaseous detectors is the
energy resolution, which is commonly defined by

\[
ΔE = \frac{\text{FWHM}(E)}{E}
\]

which is to say the full-width-half maximum (FWHM) of the distribution
of a line at given energy $E$. Typical values for the energy
resolution are smaller than \SI{15}{\percent}.

If the absolute magnitude of the FWHM at a given energy is constant,
which at least is partially reasonable, as the width is not fully due
to energy dependent effects, the energy resolution is proportional to
$1/E$. 

*THINK ABOUT REPHRASING THIS / GIVING A VALUE FOR IDEAL RESOLUTION?*
(See Alkhazov paper maybe?)

The Fano factor, defined by the variance over the mean of a
distribution $F = σ² / μ$ (typically within some time window), helps
to improve the ideal energy resolution. It arises in the associated
statistical processes, because there are a finite number of possible
interactions, which limits the statistics. *CHECK IF SENTENCE
CORRECT!* In practice the energy
resolution of gaseous detectors is usually limited by other effects. 


What is energy resolution, definition.

E / σ_E or something like this.

Why important for our detector.

*WRITE SOMETHING FANO?* See Sauli about it. Section 7.5 on energy
resolution and section 3.6 about photo ionization of X-rays.

Fano factors are related to this! Theory and observation
disagree. Fano factor fixes this by doing a scaling. Related to the
fact that theory assumes a perfectly statistical process, but reality
has fixed number of possible interactions, hence not really perfect statistics.

*** Escape photons / peaks | 55Fe as a typical calibration source

Finally, gaseous detectors need to be calibrated, monitored and
tested. This is commonly done with a $^{55}\text{Fe}$
source. $^{55}\text{Fe}$ is a radioactive isotope of iron, which
decays under inverse beta decay to $^{55}\text{Mn}$. Due to the
required restructuring of the electronic shells, the manganese is in
an excited state. While the emission of an Auger electron with
$\SI{5.19}{keV}$ dominates with a probability of \SI{60}{\percent}, as
an X-ray source the $Kα₁$ and $Kα₂$ lines with combined energies of
about $\SI{5.9}{keV}$ are of note.

When using such a $^{55}\text{Fe}$ source as a calibration source for
an argon filled gaseous detector, the \SI{5.9}{keV} photons will
produce a photo-electron in argon. If this electron fully releases its
energy via further ionizations, the 'photopeak' will be observed at
around $\SI{5.9}{keV}$. If however another photon is produced with an
energy below the $K 1s$ energy of argon ($\SI{3.2}{keV}$) - for example
a photon produced via $Kα₁$ or $Kα₂$ fluorescence of argon, both at
about $\SI{2.95}{keV}$ - such a photon has a very long absorption
length in the gas volume
(cf. fig. [[fig:theory:transmission_examples]]). This can cause such a
photon to easily escape the active detection region, especially if the
sensitive region of the detector is comparatively small. The result is
a measured signal of $E_i - E_k = \SI{5.9}{keV} - \SI{2.95}{keV} \approx
\SI{2.9}{keV}$, called the 'escape peak'. \cite{sauli2014gaseous, kolanoski2020particle, hubbell1996nist}

*ADD CITATIONS*. For Sauli / Wermes & NIST for numbers.

Explain escape photons, escape peaks, how that gives us an escape peak
in the 55Fe spectra as well as a line at 3 keV in our background data.

Explain Fe ↦ Mn excited ↦ Mn + γ and what spectrum looks like

*INSERT EXAMPLE FIGURE OF SPECTRUM*


** Micromegas working principle

\textbf{Micro} \textbf{Me}sh \textbf{Ga}seous \textbf{S}tructures
(Micromegas) are a kind of \textbf{M}icro\textbf{p}attern
\textbf{G}aseous \textbf{D}etectors (MPGDs) first introduced in 1996
\cite{GIOMATARIS199629, GIOMATARIS1998239}. The modern Micromegas is
the Microbulk Micromegas \cite{Andriamonje_2010}.

Interestingly, the name Micromegas is based on the novella Micromégas
by Voltaire published in 1752 \cite{voltaire1752micromegas}, an early
example of a science fiction story. \cite{GIOMATARIS199629}

These detectors are - as the name implies - gaseous detectors
containing a 'micro mesh'. In the most basic form they are a made of a
closed detector volume that is filled with a suitable gas (often Argon
based gas mixtures are used; Xenon based detectors are in development
for certain applications) allowing ionization. The volume is split
into two different sections, a large drift volume typically
$\mathcal{O}(\text{few }\si{cm})$ and an amplification region, sized
$\mathcal{O}(\SIrange{50}{100}{μm})$. 

At the top of the volume is a cathode to apply an electric
field. Below the mesh is the readout area at the bottom of the
volume. In standard Micromegas detectors strips or pads are used as a
readout.

The electric field in the drift region is strong enough to avoid
recombination of the created electron-ion pairs and to provide
reasonably fast drift velocities $\mathcal{O}(\si{cm.μs⁻¹})$. 

The amplification gap on the other hand is precisely used to multiply
the primary electrons using an avalanche effect. Thus, the electric
field reaches values of $\mathcal{O}(\SI{50}{kV.cm⁻¹})$.

These drift and amplification volumes are achieved by an electric
field between a cathode and the mesh as well as the mesh and the
readout area. 

For a more detailed overview of Micromegas detectors and their
history, see *CITE WHAT?* 
# \cite{} 


#+begin_center
#+CAPTION: Working principle of a general Micromegas detector. An ionizing photon enters through the
#+CAPTION: detector window into the gas-filled detector body. After a certain distance it produces
#+CAPTION: a photo electron, which ionizes further gas molecules for a specific number of primary
#+CAPTION: electrons (depending on the incoming photon's energy) and gas mixture. The primary electrons
#+CAPTION: drift towards the micromesh due to the drift voltage, thereby experiencing diffusion. 
#+CAPTION: In the much higher voltage in the amplification gap an avalanche of electrons is produced, 
#+CAPTION: enough to trigger the readout electronics (strips or pads).
#+CAPTION: Note that the numbers shown in the figure are exemplary and vary between individual
#+CAPTION: detectors.
#+NAME: micromegas_schematic
[[~/org/Figs/thesis/detectors/micromegas_schematic.pdf]]
#+end_center


** Timepix ASIC

The Timepix ASIC (Application Specific Integrated Circuit) is a $256 ×
256$ pixel ASIC (\SI{55}{\micro\meter} pitch), based on the Medipix
ASIC developed for medical imaging applications by the Medipix
Collaboration \cite{medipix}. The pixels are distributed over an
active area of $\num{1.4}\times\SI{1.4}{\cm^2}$. Each pixel contains a charge
sensitive amplifier, a single threshold discriminator and a
$\SI{14}{bit}$ pseudo random counting logic. It requires use of an
external clock, in the range of \SIrange{10}{150}{MHz}, with
\SI{40}{MHz} being typical clock frequency for the use cases described
in this thesis.

A picture of a Timepix ASIC is shown in
fig. [[fig:detector:timepix_asic]].

#+CAPTION: Picture of a Timepix ASIC
#+NAME: fig:detector:timepix_asic
#+ATTR_LATEX: :width 0.4\textwidth
[[~/phd/Figs/timepix_gold.png]]

*INSERT TIMEPIX FIGURE?*

- [ ] *CITE LUPBERGER AS REFERENCE FOR THOROUGH TIMEPIX OVERVIEW*

The Timepix uses a shutter based readout, either with a fixed shutter
time or using an external trigger to close a frame. Each pixel further
can work in four different modes:

- hit counting mode / single hit mode: simply counts the number of
  times the threshold of a pixel was crossed (or whether a pixel was
  activated once in single hit mode).
- \textbf{T}ime \textbf{o}ver \textbf{T}hreshold (ToT): In the ToT
  mode the counter of a pixel will count the number of clock cycles
  that the charge on the pixel exceeds the set threshold, which is set
  by an $\SI{8}{bit}$ \textbf{D}igital to \textbf{A}nalog
  \textbf{C}onverter (DAC) while the shutter is open. ToT is
  equivalent to the collected charge of each pixel.
- \textbf{T}ime \textbf{o}f \textbf{A}rrival (ToA): The ToA mode
  records the number of clock cycles from

  *DOES TOA IN TPX1 START FROM SHUTTER OPEN OR START FROM PIXEL HIT?*

  - [ ] *LUPBERGER THESIS EXPLAINS IT*
  - [ ] *PIXELS COUNT TO MAX 11810 AS WELL OF COURSE. THAT'S THE TIME
    LIMIT. AT 40 MHZ THIS IS ABOUT 295 μs TIME*
    
  
  starts counting the clock cycles from the first time the charge
  exceeds the set threshold until the shutter closes. Thus, it allows
  to calculate the time at which the pixel first crossed the
  threshold.

After the shutter is closed in the Timepix, the readout is performed
during which the detector is effectively dead. For a single Timepix
the readout takes about *HOW MANY?* ms. 


Check Lucian's master thesis for information about Timepix & gaseous
detector physics. :)

*TALK HERE ABOUT DIFFERENT TOS CALIBRATIONS?*

*ADD ALL USED DETECTOR CALIBRATIONS IN FULL TO APPENDIX. INCLUDE THE
PLOTS FOR TOT. TABLE OF TOT FIT PARAMETERS ETC*

*** Timepix3

The successor of the Timepix, the Timepix3 already exists. It is
generally similar to the Timepix, but provides 3 important advantages
for the applications in this thesis:
- clock rates of up to \SI{300}{MHz} for higher possible data rates
  (less interesting for data taking in an axion helioscope)
- a stream based data readout. This means no fixed shutter times and
  no dead time during readout. Instead data is sent out when it is
  recorded in parallel.
- each pixel can record ToT *and* ToA at information at the same
  time. This allows to record the charge recorded by a pixel as well
  as the time it was activated, yielding 3D event reconstruction with
  precise charge information.

An open source readout was developed by the University of Bonn and is
available under \cite{tpx3-daq} [fn:detector:tpx3_daq]. A gaseous
detector based on this is currently in the prototyping phase, see the
upcoming \cite{shiffer_phd_thesis}.


[fn:detector_tpx3_daq] [[https://github.com/SiLab-Bonn/tpx3-daq]] 




Introduce as something for which readout etc. is currently in
development. Mention improvements so that we can refer back to them in
our conclusion that having time information would be great.

Further out, the Timepix4 is also already finalized. No work on a
readout for these applications has been started yet. 

** GridPix

First experiments of combining a Micromegas with a Timepix readout
were done in 2005 \cite{campbell2005detection} by using classical
approaches to place a micromesh on top of the Timepix, at the time
still called /TimePixGrid/. While this worked in principle, it showed
a Moiré pattern, due to slight misalignment between the holes of the
micromesh and the pixels of the Timepix. Shortly after, an approach
based on photolithographic post-processing was developed to perfectly
align the Timepix pixels each with a hole of a micromesh
\cite{CHEFDEVILLE2006490}, called the /InGrid/ (integrated grid). The
commonly used name for a gaseous detector using an InGrid nowadays is
GridPix. For an overview of the process as it is performed nowadays to
produce InGrids, see \cite{lucianMsc}. *NOTE: ASK LUCIAN IF HE STILL
RECOMMNENDS HIS OWN THESIS FOR THIS*.

The InGrid consists of a \SI{1}{μm} thick aluminum grid, resting on
small pillars \SI{50}{μm} above the Timepix. A silicon-nitride
\ce{Si_x N_y} layer protects the Timepix from direct exposure to the
amplification processes. The main advantage over previous Micromegas
technologies of the GridPix is its ability to detect single electrons.
As long as the diffusion distance is long enough to avoid multiple
electrons entering a single hole of the InGrid, each primary electron
produced during the initial ionization event is recorded.

Fig. [[fig:detector:ingrid_explanation]] shows an image of such an InGrid.

#+CAPTION: Image of an InGrid, which was partially cut for inspection under an
#+CAPTION: electron microscope. The pillars seen support the micromesh and
#+CAPTION: have a height of \SI{50}{μm}. Each hole is perfectly aligned with
#+CAPTION: a pixel of the Timepix below. Typical voltages applied between
#+CAPTION: the grid and the Timepix are shown
#+NAME: fig:detector:ingrid_explanation
[[~/org/Figs/ingrid_principle.pdf]]

Production nowadays in Berlin IZM. Show sketch of production process?
Imo should be enough to refer to Lucian's thesis for production
process. Is there a paper about IZM process? Ask Yevgen & Lucian.

\SI{50}{\micro\meter} pillars (amplification gap). Typical gas gains
of 2000-5000. 

Polya plot.

Important: single electron detection efficiency. 

*** Caveats

E.g. things like charge up effects etc. discussed in other theses.

** 2014 / 2015 GridPix detector [/]
:PROPERTIES:
:CUSTOM_ID: sec:detector:detector_2014_15
:END:

In the course of \cite{krieger2018search} a first GridPix based
detector for usage at an axion helioscope, CAST, was developed. While
the main result was on the coupling constant of the chameleon
particle, an axion-electron coupling result was computed in
\cite{SchmidtMaster}.

The detector consists of a single GridPix in a \SI{78}{mm} diameter
gas volume and a drift distance of \SI{3}{cm}. The detector has a
\SI{2}{μm} Mylar entrance window X-rays. This detector serves as the
foundation for the detector used in the course of this thesis. See
fig. [[fig:detector:exploded_schematic]] for an exploded schematic of the
detector. Further, fig. [[fig:detector:background_rate_2014]] shows the
achieved background rate of this detector in the center $\num{5}
\times \SI{5}{mm^2}$ region of the detector. The background rate shows
the copper $Kα$ line near \SI{8}{keV}, possibly overlaid with a muon
contribution as well as the expected argon $Kα$ lines at
\SI{3}{keV}. Below \SI{2}{keV} the background starts to rise more and
more the lower the energy becomes, likely due to background and signal
like events being less geometrically different at low energies (fewer
pixels). The average background rate in the range from
\SIrange{0}{8}{keV} is \SI{2.8793e-05}{keV^{-1}.cm^{-2}.s^{-1}}.

- [ ] *WHICH COPPER LINE? AND WHICH ARGON?*

#+CAPTION: Exploded view of the GridPix detector used during the 2014/15 data taking campaign
#+CAPTION: at CAST. Consists of a \SI{3}{cm} drift volume with a \SI{78}{mm} inner diameter
#+CAPTION: and a single GridPix at the center.
#+NAME: fig:detector:exploded_schematic
[[~/org/Figs/ingrid_detector_exploded_krieger_thesis.png]]

#+CAPTION: Background rate in the center $\num{5} \times \SI{5}{mm^2}$ for the GridPix used in
#+CAPTION: 2014/15 at CAST. It corresponds to a background rate of \SI{2.8793e-05}{keV^{-1}.cm^{-2}.s^{-1}}
#+CAPTION: in the range from \SIrange{0}{8}{keV}. *INSERT INTERACTIVE VEGA-LITE VERSION*
#+NAME: fig:detector:background_rate_2014
[[~/phd/Figs/background_rate_2014_gold.pdf]]

As an example and a reference shown here. The foundation of what is
done in this thesis.

Not sure if this section is the right place. But: Could add background
rate achieved by that detector here?
*YES*
- background rate
- background over chip (latter comes later??)

- [ ] *ADD AVERAGE BACKGROUND RATE IN TEXT*.  

*** Create background rate plot for 2014 data                    :noexport:

We simply generate the code with our background rate plotting script,
as the 2014/15 dataset background rate is stored in our resources of
the TPA repository:
#+begin_src sh
plotBackgroundRate --show2014 --xMax 10.0 \
  --title "Background rate in center 5·5 mm² for GridPix 2014/15 CAST data"
#+end_src
(Note: the half space between numbers and unit for the gold area)

which also outputs the integrated background rates:

#+begin_src
-xMax 10.0 --title "Background rate in center 5·5 mm² for GridPix 2014/15 CAST data"
Dataset: 2014/15
         Integrated background rate in range: 0.0 .. 12.0: 3.0372e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.0 .. 12.0: 2.5310e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.5 .. 2.5: 8.4056e-05 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.5 .. 2.5: 4.2028e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.5 .. 5.0: 1.4269e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.5 .. 5.0: 3.1708e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.0 .. 2.5: 1.2016e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.0 .. 2.5: 4.8065e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 4.0 .. 8.0: 5.7818e-05 cm⁻² s⁻¹
         Integrated background rate/keV in range: 4.0 .. 8.0: 1.4454e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.0 .. 8.0: 2.3034e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.0 .. 8.0: 2.8793e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 2.0 .. 8.0: 1.1610e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 2.0 .. 8.0: 1.9350e-05 keV⁻¹·cm⁻²·s⁻¹
#+end_src

* Septemboard detector                                             :Detector:
#+LATEX: \minitoc
The detector in use in the 2014 / 2015 data taking campaign, presented
in section [[#sec:detector:detector_2014_15]] had a few significant
drawbacks for more sensitive searches, in particular for searches at
low energies $\lesssim\SI{2}{\keV}$ and/or searches requiring low
backgrounds over larger areas on the chip (for example the chameleon
search done in \cite{krieger2018search}).

All detector upgrades were done to alleviate one or more of these
drawbacks. We will now go through each of the new detector features
and highlight the aspects it is intended to improve on.

Section [[#sec:detector:scintillators]] introduces two new scintillators as
vetoes. These require the addition of an external shutter for the
Timepix, which is realized by usage of a flash ADC (FADC), see section
[[#sec:detector:fadc]]. Further, an independent but extremely important addition is
the replacement of the Mylar window by a silicon nitride window,
section [[#sec:detector:sin_window]]. Another aspect is the addition of another 6
GridPixes around the central GridPix, the 'Septemboard' introduced in
section [[#sec:detector:septemboard]]. 

The full detector is presented in section [[#sec:detector:detector_overview]]





Why do we build such a 'complicated' detector?

Background increases to edges, esp. corners.

Background rate has known peaks. 3 keV for the Argon escape
peak. Can't do anything about that in current iteration.

Peak at 8-9 keV. A mix of a copper peak and orthogonal muons, which
are expected to emit about 8 keV through 3 cm. More on this later in
[[Background rate]].

Window doesn't transmit at < 2 keV


The first section introduces the reasoning behind building a more
complicated detector. Existing detector has multiple downsides, seen
in background rate & detector efficiency.

In the further sections we discuss each additional detector feature in
detail and explain why it was added / what drawback of the previous
detector should be improved on.

After we have introduced the detector as a whole we talk about the
calibrations that are necessary to perform sensible measurements.

*IN EACH SUBSECTION START WITH WHAT IT'S SUPPOSED TO HELP WITH?*

** Scintillator vetoes [1/9]
:PROPERTIES:
:CUSTOM_ID: sec:detector:scintillators
:END:

The first general improvement is the addition of two scintillators for
veto purposes. While both have slightly different goals, each is there
to help with the removal of muon signals in the detector or muon
induced events (for example X-ray fluorescence). Given that cosmic
muons (ref. section [[#sec:theory:cosmic_radiation]]) dominate the background by
flux, statistically there is a high chance of muons creating X-ray
like signatures in the detector (more on that below). By tagging muons
before they interact near the detector, these can be correlated with
events seen on the GridPix and thus possibly be vetoed if precise time
information is available.

- [ ] *REPHRASE*

The first scintillator is a large paddle installed above the detector
installation, aiming to tag a large fraction of cosmic muons
traversing in the area around the detector. It has a Canberra 2007
base, which accepts positive HV. The PMT is a Bicron
Corp. 31.49x15.74M2BC408/2-X, where the first two numbers are the
scintillators dimensions in inches. The full outer dimensions of the
scintillator paddle are closer to $\SI{42}{cm} \times \SI{82}{cm}$. It
is the same scintillator paddle used during the Micromegas data taking
behind the LLNL telescope prior and after the data taking campaign
with the detector described in this thesis.

For this scintillator, muons which traverse through this scintillator
and the gaseous detector volume are not the main use case. They can be
easily identified by the geometric properties of the induced tracks
(their zenith angles are relatively small, resulting in track like
signatures as the GridPix readout is orthogonal to the zenith
angle). There is a small chance however that a muon can excite an atom
of the detector material, which may emit an X-ray upon
deexcitation. One particular source of background can be attributed to
the presence of copper whose $Kα$ lines are at $\sim\SI{8.04}{\keV} as
well as fluorescence of the argon gas with its $Kα$ lines at
$\sim\SI{2.95}{keV}$ (see. table [[tab_all_xray_fluorescence]] in
sec. [[#sec:theory:xray_fluorescence]]).

The second scintillator is a small silicon photomultiplier (SiPM)
installed on the underside of the PCB on which the septemboard is
installed. This scintillator was calibrated and set up as part of
\cite{JannesBsc}. We are interested in tagging precisely those muons,
which enter the detector orthogonally to the readout plane. This
implies zenith angles of almost \SI{90}{\degree} such that the
elongation in the transverse direction of the muon track is small
enough to result in a small eccentricity. From the Bethe equation we
commonly expect muons to deposit about \SI{8}{\keV} along the
\SI{3}{\cm} of drift volume in the detector, assuming the conditions
as used in the detector at CAST (see
fig. [[fig:theory:muon_argon_3cm_bethe_loss]] for the energy loss). This
coincides with the copper Kα lines and should lead to another source
of background in this energy range. Although the muon background will
have a much wider distribution than the copper lines.

- [ ] *REFERENCE SECTION ON MUON LOSSES*

- [ ] *REFERENCE JANNES BSC THESIS FOR SIPM*

- [ ] *GIVE NAME OR WHATEVER OF SIPM*
- [X] *GIVE NAME OR WHATEVER OF BIG PADDLE*  

- [ ] *CONSIDER REPHRASING SENTENCE ABOUT BETHE EQ GIVING US 8 KEV*

- [ ] *ADD NOEXPORT OF CALCULATIONS OF MUON ANGLES POSSIBLE*

- [ ] *SCHEMATIC OF MUON IONIZATION*

- [ ] *NOTE: MAYBE INSTEAD START WITH SEPTEMBOARD? THEN IN OTHER FEATURES
CAN MENTION THAT THINGS ARE ONLY FOR CENTER CHIP EG*

** FADC [/]
:PROPERTIES:
:CUSTOM_ID: sec:detector:fadc
:END:

As the Timepix is read out in a shutter based fashion and typical
shutter lengths for low rate experiments are long compared to the rate
of cosmic muons, the scintillators introduced in previous section
require an external trigger to close the Timepix shutter early if a
signal is measured on the Timepix. This is one the main purposes of
the \text{f}lash \textbf{a}nalog to \textbf{d}igital
\textbf{c}onverter (FADC) that is part of the detector.

The specific FADC used for the detector is an Caen V1792a *WHICH
REVISION?*. It runs at a frequency of \SI{1}{\GHz} and has a cyclic
register with \num{10240} channels. This means it covers the last
$\sim\SI{10}{\micro\second}$ at any time. The raw signal decoupled
from the grid is first fed into an Ortec 142 B pre-amplifier, which
then feeds into an Ortec 474 shaping amplifier, which integrates and
shapes the signal as well as amplifies it. For a detailed introduction
to this FADC system, see the thesis of A. Deisting \cite{Deisting} and
\cite{SchmidtMaster} for further work integrating it into this
detector.

- [ ] *HAVE PRE AMPLIFIER BEFORE FADC. ORTEC*

#+CAPTION: Schematic of the setup to decouple signals induced on the grid of the
#+CAPTION: InGrid. The signal is decoupled in the sense that the capacitor essentially
#+CAPTION: acts as a low pass filter, thus removing the constant HV. Only the
#+CAPTION: high frequency components of the induced signals on top of the HV pass
#+CAPTION: into the branch leading to the FADC. In the detector of this thesis, 
#+CAPTION: a capacitance of \SI{10}{nF} was used instead. The decoupling is implemented 
#+CAPTION: on the intermediate board. Schematic taken from \cite{Deisting}. 
#+NAME: fig:detector:fadc_circuit
[[~/phd/Figs/decouple_fadc.pdf]]

The analogue signal measured by the FADC is the induced signal on the
grid of the central GridPix (introduced in detail in section
[[#sec:septemboard]]) via a small $C_{\text{dec}} = \SI{10}{nF}$ capacitor
in parallel to the high voltage line. For a schematic of the circuit
see fig. [[fig:detector:fadc_circuit]]. When a primary electron traverses
through a hole in the grid and is amplified, the back flowing ions
induce a small voltage spike on top of the constant high voltage
applied to the grid. The parallel capacitor filters out the constant
high voltage and only transmits the time varying induced signals. Such
signals - the envelope of possibly many primary electrons - are
measured by the FADC.

#+CAPTION: Schematic showing how the FADC and scintillators are used together
#+CAPTION: to tag possible coincidence events and close the shutter early to
#+CAPTION: reduce the likelihood of multi-hit events. If the scintillator
#+CAPTION: triggers when the shutter is open, a clock starts counting up to
#+CAPTION: 4096 clock cycles. On every new trigger this clock is reset. If
#+CAPTION: the FADC triggers, the scintillator clock values are read out and
#+CAPTION: can be used to correlate events in the scintillator with FADC and
#+CAPTION: GridPix information. Further, the FADC trigger is used to close the
#+CAPTION: Timepix shutter \SI{50}{μs} after the trigger.
#+NAME: fig:detector:scintillator_fadc_shutter_close
[[~/phd/Figs/scintillator_fadc_shutter_close.pdf]]

This signal can be used for two distinct things:
1. it may be used as a trigger to close the shutter of the ongoing
   event. Ideally, we want to only measure a single physical event
   within one shutter window. A long shutter time can statistically
   result in multiple events happening, which the FADC trigger helps
   to alleviate.
2. By nature of the signal production & drift properties of the
   primary electrons before they reach the grid, the signal shape can
   theoretically be used to determine a rough longitudinal shape of
   the event. The length of the FADC event should be proportional to
   the size of the primary electron cloud distribution along the
   'vertical' detector axis. 

The former allows us to reduce the number of events with multiple
physical events and acts as a trigger for the scintillators. This in
turn means possible muon induced X-ray fluorescence can be vetoed. The
latter potentially allows to differentiate between a muon traversing
orthogonally through the readout plane and an X-ray due to their
longitudinal shape difference.

The working principle of how the FADC and the scintillators can be
used together to remove certain kinds of background by correlating
events in the scintillators, the FADC and the GridPix is shown in
fig. [[fig:detector:scintillator_fadc_shutter_close]].

- [ ] *PICTURE OF FADC*

- [ ] *COPY OVER SECTION ABOUT MUONS / TOA INFO FROM IAXO TDR TEXT?*

** SiN window [/]
:PROPERTIES:
:CUSTOM_ID: sec:detector:sin_window
:END:

Next up, a major limitation of the previous detector was its limited
combined efficiency below $\SI{2}{keV}$, due to its \SI{2}{μm} Mylar
window. Therefore, the next improvement for the new detector is an
ultra-thin silicon nitride \ce{Si_3 N_4} window of \SI{300}{nm}
thickness and \SI{14}{mm} diameter, developed by Norcada™ *WEBSITE*. A
strongback support structure consisting of 4 lines of \SI{200}{μm}
thick and \SI{500}{μm} wide \ce{Si_3 N_4}, helps to support a pressure
difference of up to \SI{1.5}{bar}. On the outer side a \SI{20}{nm}
thin layer of aluminum is coated to allow the window to be part of the
detector cathode. The strongback occludes about \SI{17}{\percent} of
the full window area. In reality it is slightly more, as the
strongbacks become somewhat wider towards the edges. In the center
most region they are straight and in the center $\num{5} \times
\SI{5}{mm²}$ area, they occlude \SI{22.2}{\percent}.

Fig. \subref{fig:detector:strongback_structure_mc} shows the idealized strongback
structure without a widening towards the edges of the
window. Fig. \subref{fig:detector:window_image} shows an image of one such
window under testing conditions in the laboratory, as it withstands a
pressure difference of \SI{1.5}{bar}.

*FIX REFERENCE TO INLINE LATEX LABELS!*

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/SiN_window_occlusion.png}
    \caption{Window strongback schematic}
    \label{fig:detector:strongback_structure_mc}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/300nm_SiN_holds.jpg}
    \label{fig:detector:window_image}
    \caption{Image}
  \end{subfigure}
  \label{fig:detector:window_image_and_strongback}
  \caption{\subref{fig:detector:strongback_structure_mc} shows an idealized schematic of the
    window strongback based on a simple MC simulation. \SI{22.2}{\percent} of the area inside the
    inner $\num{5} \times \SI{5}{mm^2}$ area (black square) are occluded.
    \subref{fig:detector:window_image} shows an image of one such window while testing in the
    laboratory, if it holds \SI{1.5}{\bar}.
  }
\end{figure}

- [ ] *POSSIBLY UPDATE IMAGE OF WINDOW*

As the main purpose is the increase of transmission at low energies,
let's compare the transmission between the mylar window of the old
detector and the new \ce{Si_3 N_4}
window. Fig. [[fig:detector:window_efficiency_comparison]] shows the
transmission of the two different window setups in the energy range
below \SI{3}{keV}. The \ce{Si_3 N_4} window shows a significant
increase in transmission below \SI{2}{keV}, which is very important
for the sensitivity in solar axion-electron and chameleon searches,
which both peak near \SI{1}{keV} in their solar flux. The window alone
significantly increases the signal to noise ratio of these physics searches.

#+CAPTION: Comparison of the transmission of a \SI{2}{μm} Mylar window and a
#+CAPTION: \SI{300}{nm} \ce{Si_3 N_4} window. The efficiency gains become
#+CAPTION: more and more pronounced the lower the energy is, aside from the
#+CAPTION: absorption edge of carbon at around \SI{250}{eV} and above about
#+CAPTION: \SI{1.75}{keV}. In the interesting range around \SI{1}{keV} significant
#+CAPTION: transmission gains are achieved.
#+NAME: fig:detector:window_efficiency_comparison
[[~/phd/Figs/detector/window_transmisson_comparison.pdf]]

*** Calculation of strongback window structure plot :noexport:

#+begin_src nim :tangle code/window_strongback.nim
## Super dumb MC sampling over the entrance window using the Johanna's code from `raytracer2018.nim`
## to check the coverage of the strongback of the 2018 window
##
## Of course one could just color areas based on the analytical description of where the
## strongbacks are, but this is more interesting and looks fun. The good thing is it also
## allows us to easily compute the fraction of pixels within and outside the strongbacks.
import ggplotnim, random, chroma
proc colorMe(y: float): bool =
  const
    stripDistWindow = 2.3  #mm
    stripWidthWindow = 0.5 #mm
  if abs(y) > stripDistWindow / 2.0 and
     abs(y) < stripDistWindow / 2.0 + stripWidthWindow or
     abs(y) > 1.5 * stripDistWindow + stripWidthWindow and
     abs(y) < 1.5 * stripDistWindow + 2.0 * stripWidthWindow:
    result = true
  else:
    result = false

proc sample() =
  randomize(423)
  const nmc = 5_000_000
  let black = color(0.0, 0.0, 0.0)
  var dataX = newSeqOfCap[float](nmc)
  var dataY = newSeqOfCap[float](nmc)
  var inside = newSeqOfCap[bool](nmc)
  for idx in 0 ..< nmc:
    let x = rand(-7.0 .. 7.0)
    let y = rand(-7.0 .. 7.0)
    if x*x + y*y < 7.0 * 7.0:
      dataX.add x
      dataY.add y
      inside.add colorMe(y)
  let df = toDf(dataX, dataY, inside)
  echo "A fraction of ", df.filter(f{`inside` == true}).len / df.len, " is occluded by the strongback"
  let dfGold = df.filter(f{abs(idx(`dataX`, float)) <= 2.25 and
                           abs(idx(`dataY`, float)) <= 2.25})
  echo "Gold region: A fraction of ", dfGold.filter(f{`inside` == true}).len / dfGold.len, " is occluded by the strongback"
  ggplot(df, aes("dataX", "dataY", fill = "inside")) +
    geom_point(size = 1.0) +
    # draw the gold region as a black rectangle
    geom_linerange(aes = aes(y = 0, x = 2.25, yMin = -2.25, yMax = 2.25), color = "black") +
    geom_linerange(aes = aes(y = 0, x = -2.25, yMin = -2.25, yMax = 2.25), color = "black") +
    geom_linerange(aes = aes(x = 0, y = 2.25, xMin = -2.25, xMax = 2.25), color = "black") +
    geom_linerange(aes = aes(x = 0, y = -2.25, xMin = -2.25, xMax = 2.25), color = "black") +
    xlab("x [mm]") + ylab("y [mm]") +
    ggtitle("Idealized schematic of the window layout. Strongback in red.") +
    ggsave("/home/basti/phd/Figs/SiN_window_occlusion.png", width = 1150, height = 1000)
sample()
#+end_src

#+RESULTS:

*** Calculation of transmission efficiency [0/0]                 :noexport:

Let's calculate the transmission for =Si₃N₄= and Mylar windows using
[[https://github.com/SciNim/xrayAttenuation][=xrayTransmission=]].

#+begin_src nim :tangle /home/basti/phd/code/window_transmission_comparison.nim
import std / strutils
import xrayAttenuation, ggplotnim
# generate a compound of silicon and nitrogen with correct number of atoms
let Si₃N₄ = compound((Si, 3), (N, 4))
#Si₃N₄.plotTransmission(3.44.g•cm⁻³, 300.nm.to(Meter))
# instantiate Mylar
let mylar = compound((C, 10), (H, 8), (O, 4))
# mylar.plotTransmission(1.4.g•cm⁻³, 2.μm.to(Meter), energyMax = 3.0)

echo mylar.name()
echo Si₃N₄.name()
# define energies in which to compute the transmission
# (we don't start at 0, as at 0 energy the parameters are not well defined)
let energies = linspace(1e-2, 3.0, 1000)

proc compTrans[T: AnyCompound](el: T, ρ: g•cm⁻³, length: Meter): DataFrame =
  result = toDf({ "Energy [keV]" : energies })
    .mutate(f{float: "μ" ~ el.attenuationCoefficient(idx("Energy [keV]").keV).float},
            f{float: "Trans" ~ transmission(`μ`.cm²•g⁻¹, ρ, length).float},
            f{"Compound" <- el.name()})
var df = newDataFrame()
# compute transmission for Si₃N₄ (known density and desired length)
df.add Si₃N₄.compTrans(3.44.g•cm⁻³, 300.nm.to(Meter))
# and for 2μm of mylar
df.add mylar.compTrans(1.4.g•cm⁻³, 2.μm.to(Meter))
# create a plot for the transmissions
echo df
let dS = r"$\SI{300}{nm}$" #pretty(300.nm, 3, short = true)
let dM = r"$\SI{2}{\micro\meter}$" #pretty(2.μm, 1, short = true)
let si = r"$\mathrm{Si}₃\mathrm{N}₄$"
ggplot(df, aes("Energy [keV]", "Trans", color = "Compound")) +
  geom_line() +
  xlab("Energy [keV]") + ylab("Transmission") +
  xlim(0.0, 3.0) + 
  ggtitle(r"Transmission examples of $# $# and $# Mylar" % [dS, si, dM]) +
  ggsave("/home/basti/phd/Figs/detector/window_transmisson_comparison.pdf",
         #width = 800, height = 600,
         useTex = true, standalone = true) 
#+end_src


** Septemboard - 6 GridPixes around a center one [0/7]
:PROPERTIES:
:CUSTOM_ID: sec:detector:septemboard
:END:

The main motivation for extending the readout area from a single chip
to a 7 chip readout is to reduce background towards the outer sides of
the chip, in particular in the corners. Against common intuition
however, it also plays a role for events, which have cluster centers
near the center of the readout. The latter is due to gas ionization
being a statistical process. In particular in lower energy events,
tracks may have gaps in them large enough to avoid being detected as a
single cluster for standard radii in cluster searching
algorithms. This is particularly of interest as different searches
produce an 'image' at different positions and sizes on the
detector. While the center chip is large enough to fully cover the
image for essentially all models, it may not be in the regions of
lowest background. Hence, improvements to larger areas are needed.

*REFERENCE PAPER ABOUT TRACKS IN TPCS. IONIZATION STATISTICAL AND SO ON*

*THE LATTER NEEDS MORE WORDING ELSEWHERE / CLUSTERING ALGORITHM EXPL /
SEPTEM VETO*

- [ ] *USE EXACT MEASURES OF THE TIMEPIX BASED ON TIMEPIX MANUAL*

The septemboard is implemented in such a way to optimize the loss of
active area due to bonding requirements and general manufacturing
realities. As the Timepix ASIC is a \SI{16.1}{mm} by \SI{14.1}{mm}
large chip (the bonding area adding \SI{2}{mm} on one side), the upper
two rows are installed such that they are inverted to another. The
bonding area is above the upper row and below the center row. The
bottom row again has its bonding area below. This way the top two rows
are as close together as realistically possible, with a decent gap on
the order of \SI{2}{mm} between the middle and bottom row. Any gap is
potentially problematic as it implies loss of signal in that area,
complicating the possible reconstruction methods.

All 7 GridPix are connected in a daisy-chained way. This means that in
particular for data readout, each chip is read out one after
another. The dead time for readouts therefore is approximately 7 times
the readout time of a single Timepix. A single Timepix has a readout
time of $\sim\SI{25}{ns}$ at a clock frequency of \SI{40}{MHz} (the
frequency used for this detector). This leads to an expected readout
time of the full septemboard of
\SI{175}{ns}. [fn:detector_readout_time] Such a long readout time
leads to a strong restriction of the possible applications for such a
detector. Fortunately, for the use cases in a very low rate experiment
such as CAST, long shutter times are possible, mitigating the effect
on the fractional dead time to an extent.

Fig. [[cluster_centers_likelihood]] shows a heatmap of all cluster centers
during roughly \SI{2000}{\hour} of background data after passing these
clusters through a likelihood based cut method aiming to filter out
non X-ray like clusters (details of this follow later in chapter
*CHAPTER FOR LIKELIHOOD METHOD*). It is clearly visible that the further a
cluster center is towards the chip edges, and especially the corners,
the more likely it is to be considered an X-ray like cluster. This has
an easy geometric explanation. Consider a perfect track traversing
over the whole chip. In this case it is clearly eccentric. Move the
same track such that its center is in one of the corners and rotate it
by \SI{45}{\degree} and suddenly the majority of the track won't be
detected on the chip anymore. Instead something roughly circular
remains visible, 'fooling' the likelihood method. For a schematic
illustrating this, see fig *SHOW CUT OFF FROM ONE OF MY TALKS*.

The septemboard therefore is expected to significantly reduce the
background over the whole center chip, with the biggest effect in the
regions with the most amount of background. 

\input{~/phd/Figs/backgroundClusters/background_cluster_centers.tex}
- [ ] *TODO: NEED CAPTION AND LABEL FOR BACKGROUND CLUSTERS*

- [ ] *SIDE BY SIDE INCLUDING A SEPTEM EVENT SHOWING TRACK CUT LEADS
  TO CIRCLE*

- [ ] *MENTION SEPTEMBOARDS ARE NAMED BY LETTERS, WHICH ONE USED IN
  DETECTOR*

- [ ] *SHOW SCHEMATIC OF LAYOUT*

- [ ] *FIND OUT WHERE 25 NS READOUT FOR SINGLE TIMEPIX COMES FROM*

- [ ] *READOUT TIME:*
    #+begin_quote
  The main driver for the readout speed is the time to readout the
  complete matrix (one frame) from the chip and this value is fixed for
  a given FCLOCK frequency. A frame consists of 917504 bits, which have
  to be packed to the data stream. As the data is sampled with FCLOCK,
  the same amount of clock cycles is needed, what defines the readout
  time
    #+end_quote
   page 83 of Lupberger thesis. 917504 * 25ns (one clock at 40MHz) = 22.9442 ms per frame under
  ideal conditions

[fn:detector_readout_time] We will later see that the practical
readout time of the final detector is closer to almost \SI{500}{ms}
under high rate conditions.  

*** Compute the cluster backgrounds                              :noexport:

To compute these cluster backgrounds, we need the following
ingredients:
- the fully reconstructed data files =DataRuns201*_Reco.h5= 
- the prepared CDL data from the 2019 dataset
  =calibration-cdl_2019.h5= and the X-ray reference datasets that
  define the X-ray like properties.
- apply the likelihood method to all background events in one of the
  files (gives enough statistics) to get a resulting file containing
  only passed clusters *over the whole chip*.

With the resulting file we can then use
[[file:~/CastData/ExternCode/TimepixAnalysis/Plotting/plotBackgroundClusters/plotBackgroundClusters.nim]]
to plot these cluster centers.

Assuming the reconstructed data files are found in *...* and the CDL
data files in *...*, let's generate the data after likelihood method:
#+begin_src sh
~/CastData/ExternCode/TimepixAnalysis/Analysis/ingrid/likelihood ~/CastData/data/DataRuns2017_Reco.h5 --h5out /tmp/lhood_2017_full_chip.h5 \
  --altCdlFile ~/CastData/data/CDL_2019/calibration-cdl-2018.h5 \
  --altRefFile ~/CastData/data/CDL_2019/XrayReferenceFile2018.h5 \
  --cdlYear=2018 --region=crAll 
#+end_src

Now we can create the plot:
#+begin_src sh
cd ~/CastData/ExternCode/TimepixAnalysis/Plotting/plotBackgroundClusters
nim c -d:danger --threads:on plotBackgroundClusters.nim
./plotBackgroundClusters -f /tmp/lhood_2017_full_chip.h5 --useTikZ
#+end_src

*** GENERAL

*REFERENCE* that schematic of how everything is connected is explained
in the detector @ CAST? Or explain it here, then refer back?

** Water cooling and temperature readout for the septemboard [0/1]

During development of the septemboard one particular set of problems
manifested. While testing a prototype board with 5 active GridPix in a
gaseous detector, the readout was plagued by excessive noise
problems. The detector exhibited a large number of frames with more
than \num{4096} active pixels (the limit for a zero suppressed
readout) and common pixel values of \num{11810} indicating overrun ToT
counters. On an occupancy (sum of all active pixels) of the individual
chips, it is quite visible the data is clearly not due to cosmic
background. Fig. [[fig:detector:occupancy_sparking_run_241]] shows such an
occupancy with the color scale topping out at the $80^{\text{th}}$
percentile of the counts for each chip individually. The chip in the
bottom left shows a large number of sparks (overlapping half ellipses
pointing downwards) at the top end. Especially the center chip in the
top row shows highly structured activity, which is in contrast to the
expectation of a homogeneous occupancy for a normal background
run. In addition on all chips some level of general noise on certain
pixels is visible (some being clearly more active than others
resulting in a scatter of 'points').

#+CAPTION: Occupancy of a testing background run with $\mathcal{O}(\SI{1}{s})$ long frames
#+CAPTION: using septemboard F during development without any kind of cooling.
#+NAME: fig:detector:occupancy_sparking_run_241
[[~/phd/Figs/detector/sparking/sparking_occupancy_80_quantile_run_241.pdf]]

The intermediate board and carrier board used during these tests were
the first boards equipped with two PT1000 temperature sensors. One on
the bottom side of the carrier board and another on the intermediate
board. Each is read out using a =MAX31685= micro controllers. Both of
which are communicated with via a =MCP2210= USB-to-SPI micro
controllers over a single USB port on the intermediate board. The
single =MCP2210= communicates with both temperature sensors via the
Serial Peripheral Interface (SPI). In the run shown in
fig. [[fig:detector:occupancy_sparking_run_241]] the temperature sensors
were not functional yet, as the readout software was not written
yet. The required logic was added to the Timepix Operating System
(TOS), the readout software of the detector, motivated by this noise
activity to monitor the temperature before and during a data taking
period. The temperature on the carrier board indicated temperatures on
the order of \SI{75}{\degree\celsius} in background runs similar to
the one of fig. [[fig:detector:occupancy_sparking_run_241]]. One way to
get a measure for the noise like activity seen on the detector is to
look at the rate of active pixels over time. With values well above
numbers expected due to background, excess temperature seemed a
possible cause for the issues. As no proper cooling mechanism was
available, a regular desk fan was placed pointing at the detector when
it was run without any kind of shielding. This saw the temperature
under the carrier board drop from \SI{76}{\degree\celsius} down to
\SI{68}{\degree\celsius}. As a result the majority of noise
disappeared as can be seen in
fig. \ref{fig:detector:sparking_run_with_fan_mean_hits} with the
temperature curve during the full run in
fig. \ref{fig:detector:sparking_run_with_fan_temps}. [fn:detector_sparking_run_268] [fn:detector_troubleshooting]

The features visible in the occupancy plots are thus likely multiple
different artifacts due to too high temperatures. A mixture of real
sparks (bottom left chip in
fig. [[fig:detector:occupancy_sparking_run_241]]), instabilities that
possibly affect either voltages for the pixels (and thus change the
thresholds of each pixel). As the temperature is measured on the
bottom side of the carrier board, temperatures in the amplification
region are likely significantly higher. As the gas gain is
proportional to the temperature, it is possible slight height
differences of the InGrid cause local amplification events, similar to
a photomultiplier tube. 

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/detector/sparking/temperature_sparking_run_268.pdf}
    \caption{Temperature}
    \label{fig:detector:sparking_run_with_fan_temps}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/detector/sparking/mean_hit_rate_sparking_run_268.pdf}
    \label{fig:detector:sparking_run_with_fan_mean_hits}
    \caption{Mean hit rate}
  \end{subfigure}
  \label{fig:detector:sparking_run_with_fan}
  \caption{\subref{fig:detector:sparking_run_with_fan_temps} shows the temperature on the bottom side of the
    carrier board ('septem') and intermediate board ('IMB') during the background run. The point at which
    the desk fan is placed next to the detector is clearly visible by the \SI{8}{\degree\celsius} drop in
    temperature from about \SI{76}{\degree\celsius} to \SI{68}{\degree\celsius}. 
    \subref{fig:detector:sparking_run_with_fan_mean_hits} shows the mean hit rate of each of the 5 chips
    installed on the carrier board at the time during the same run. The placement of the desk fan is easily
    visible as a reduction in mean rate on all chips.
  }
\end{figure}

Following this a bespoke water cooling was designed made from
oxygen-free copper with *X MM* holes for water to circulate through
the copper body. The body has the same diameter as the intermediate
board and is installed right below. The water circulation is handled
by an off-the-shelf pump and radiator from
Alphacool [fn:detector_alphacool] intended for water cooling setups
for desktop computers. The pump manages a water flow rate of about
\SI{0.3}{\liter\per\minute} through the small holes in the copper. In
common operation the temperatures on the carrier board are between
\SIrange{45}{50}{\degree\celsius} and noise free operation is
possible. 

- [ ] *REF TOBI THESIS & UPCOMING PAPER*






- [ ] *REFERENCE CODE TO TEMP READOUT?*

[fn:detector_troubleshooting] The realization that the issues are
purely due to temperature effects was only after several months of
eliminating many other options, both on the software as well as the
hardware side. In particular power supply instabilities were long
considered to be a source of problems. While they possibly also had an
impact, better power supplies were built with larger capacitors to
better deal with large variations in required power. 

[fn:detector_alphacool] https://www.alphacool.com/

[fn:detector_sparking_run_268] See the full thesis version for the
occupancy of the run with temperature readout in the subsection
after this if interested.

*** Sparking behavior :noexport:

See the mails containing "Septem F" (among other things) for the
information about sparking behavior. From that we can also deduce the
run numbers of the noisy runs (run 241 is one of them); just keep in
mind that the run numbers are overlapping with some CAST run numbers,
as for CAST we started again at 0.

Specific run path of noisy run used in occupancy plot above:
=Run_241_170216-13-49=
So run from February 2017.


Let's plot the temperature during the sparking run in which we
installed the fan.

This is essentially a reproducible version of the following plot:
[[file:~/org/Figs/temps_plot_septemF_76_68deg_1s.pdf]]
#+begin_src nim :tangle /home/basti/phd/code/sparking_temperature.nim
import ggplotnim, times

const path = "/mnt/1TB/CAST/2017/development/Run_268_170418-05-43/temp_log.txt"

proc p(x: string): DateTime =
  result = x.parse("YYYY-MM-dd'.'HH:mm:ss", local())
let df = readCsv(path, sep = '\t', skipLines = 2, colNames = @["IMB", "Septem", "DateTime"])
  .filter(f{string -> bool: p(`DateTime`) < initDateTime(19, mApr, 2017, 0, 0, 0, 0, local())})
  .gather(@["IMB", "Septem"], "Type", "Temperature")
  .mutate(f{"Timestamp" ~ p(`DateTime`).toTime().toUnix()})

## XXX: fix plotting of string columns as date scales, due to discrete / continuous mismatch and lacking
## `dataScale` field
ggplot(df, aes("Timestamp", "Temperature", color = "Type")) +
  geom_line() +
  # scale_x_continuous() +
  ggtitle("Temperature during run on 2017/04/18 in which fan was placed next to detector") + 
  xlab("Time of day") + ylab("Temperature [°C]") +
  margin(top = 2.0) + 
  scale_x_date(isTimestamp = true,
               formatString = "HH:mm:ss",
               dateSpacing = initDuration(hours = 2),
               dateAlgo = dtaAddDuration,
               timeZone = local()) +                
  ggsave("/home/basti/phd/Figs/detector/sparking/temperature_sparking_run_268.pdf")
df.writeCsv("/home/basti/phd/resources/temperature_sparking_run_268.csv")  
#+end_src

#+RESULTS:
| INFO: The integer column `Timestamp` has been automatically determined to be continuous. To overwrite this behavior add a `+ scale_x/y_discrete()` call to the plotting chain. Choose `x` or `y` depending on which axis this column refers to. Or apply a `factor` to the column name in the `aes` call | i.e. `aes(... | Timestamp | ...)`. |

Next up we need to compute the mean hit rate of the four most active
chips and plot it against time.

How will we go about doing that? Read and reconstruct the run, then
manually extract hits per time, bin by time and that's it?

#+begin_src sh
cd /mnt/1TB/CAST/2017/development/
raw_data_manipulation -p Run_268_170418-05-43 --runType background --out raw_268_sparking.h5
reconstruction raw_268_sparking.h5 --out reco_268_sparking.h5
#+end_src

With the resulting file, we can now generate the plot of the hits over
time.

This is a reproducible version of the following plot:
[[file:~/org/Figs/hitrate_per_time_septemF_76_68deg_1s.pdf]]
#+begin_src nim :tangle /home/basti/phd/code/sparking_hit_rate_over_time.nim
import std / [options, sequtils, times]
import ggplotnim, nimhdf5, unchained
defUnit(Second⁻¹)
import ingrid / tos_helpers
const path = "/mnt/1TB/CAST/2017/development/reco_268_sparking.h5"
let h5f = H5open(path, "r")

var df = newDataFrame()
var dfR = newDataFrame()
for chip in 0 ..< 5:
  let dsets = @["hits"]
  let dfC = h5f.readRunDsets(
    268,
    chipDsets = some((chip: chip, dsets: dsets)),
    commonDsets = @["timestamp"]
  )
    .mutate(f{"chip" <- chip})
    .arrange("timestamp")
  df.add dfC

  # and directly compute the hit frequency
  let hits = dfC["hits", int]
  let time = dfC["timestamp", int]
  let ts = time.map_inline((x - time[0]).s)
  const Interval = 30.min
  var i = 0
  var rate = newSeq[Second⁻¹]()
  var rateTime = newSeq[float]()
  while i < time.len:
    var h = 0
    var Δt = 0.s
    let t0 = time[i]
    echo "Starting at t0 = ", t0
    while Δt < Interval and i < time.len:
      h += hits[i]
      if i > 0:
        Δt += ts[i] - ts[i-1]
      inc i
    rate.add (h.float / Δt)
    echo "To ", time[i-1]
    rateTime.add((time[i-1] + t0) / 2.0)
    h = 0
  dfR.add toDf({"rate" : rate.mapIt(it.float), rateTime, "chip" : chip})
echo df
echo dfR

dfR = dfR.filter(f{int -> bool: fromUnix(`rateTime`).inZone(local()) < initDateTime(19, mApr, 2017, 0, 0, 0, 0, local())})
ggplot(dfR, aes("rateTime", "rate", color = factor("chip"))) +
  geom_point() +
  scale_y_log10() + 
  scale_x_date(isTimestamp = true,
               formatString = "HH:mm:ss",
               dateSpacing = initDuration(hours = 2),
               dateAlgo = dtaAddDuration,
               timeZone = local()) +                
  ggsave("/home/basti/phd/Figs/detector/sparking/mean_hit_rate_sparking_run_268.pdf")

dfR.writeCsv("/home/basti/phd/resources/mean_hit_rate_sparking_run_268.csv", precision = 10)
#+end_src

Finally, combine both and plot together:
#+begin_src nim :tangle /home/basti/phd/code/temperature_and_sparking.nim
import std / times
import ggplotnim
const path = "/home/basti/phd/resources/"
let df = readCsv(path & "temperature_sparking_run_268.csv")
let dfR = readCsv(path & "mean_hit_rate_sparking_run_268.csv")
  .group_by("chip")
  .mutate(f{"rateNorm" ~ `rate` / max(`rate`) * 80.0})
  .rename(f{"Timestamp" <- "rateTime"})

let sa = secAxis(name = "Hit rate [a.u.]",
                 trans = f{1.0 / 80.0})
                 #invTransFn = f{`rateNorm` * 80.0})

ggplot(df, aes("Timestamp", "Temperature", color = "Type")) +
  geom_line() +
  geom_point(data = dfR, aes = aes("Timestamp", "rateNorm", color = factor("chip"))) + 
  # ggtitle("Temperature during run on 2017/04/18 in which fan was placed next to detector") + 
  xlab("Time of day") + ylab("Temperature [°C]") +
  margin(top = 2.0) +
  scale_y_continuous(secAxis = sa) + 
  scale_x_date(isTimestamp = true,
               formatString = "HH:mm:ss",
               dateSpacing = initDuration(hours = 2),
               dateAlgo = dtaAddDuration,
               timeZone = local()) + 
  legendPosition(0.835, 0.1) +
  yMargin(0.05) + 
  ggsave("/home/basti/phd/Figs/detector/sparking/temperature_and_sparking_run_268.pdf")

#+end_src

#+RESULTS:


And finally, let's also recreate the occupancy plot
[[file:~/phd/Figs/detector/sparking/occupancy_sparking_septem5chips_300V.pdf]] of run 241 during
development to showcase the sparking behavior.

In order to do that, we first need to reconstruct the run containing
the data:
#+begin_src sh
cd /mnt/1TB/CAST/2017/development/
raw_data_manipulation -p Run_241_170216-13-49 --runType background --out raw_241_sparking.h5
reconstruction raw_241_sparking.h5 --out reco_241_sparking.h5
#+end_src

With the reconstructed data file at hand, we can first of all generate
a large number of plots for each chip:
#+begin_src sh
plotData --h5file reco_241_sparking.h5 \
         --runType rtBackground \
         --config ~/CastData/ExternCode/TimepixAnalysis/Plotting/karaPlot/config.toml \
         --ingrid --occupancy
#+end_src
which can be adjusted according to the user's preference of course.

(For this plot in particular it's really important not use the =ToT=
cutting feature in =raw_data_manipulation= via the =rmToTLow= and
=rmToTHigh= in the =config.toml= file)

With the file in place, let's now create the plot of the occupancies
for each chip, embedded in the layout of the septemboard (at least for
the 5 chips that were on this septemboard F).

#+begin_src nim :tangle /home/basti/phd/code/occupancy_sparking_septem_layout.nim
import std / os except FileInfo
import std / strutils
import ingrid / [tos_helpers, ingrid_types]
import nimhdf5, ggplotnim, ginger

## The Septemboard layout code is a port of the code used in the python based event 
## display for TOS.

const
  Width = 14.1
  Height = 14.1
  BondHeight = 2.0
  FullHeight = Height + BondHeight
  NumChips = 7

  # If this is set to `true` the final plot will only contain the actual raster image. No legend or axes
  OnlyRaster = true

  Run = 241

type
  SeptemRow = object
    left: float
    right: float
    wspace: float
    top: float
    bottom: float

## XXX: replace the logic by one where we compute the relative positions on a
## 1x1 ratio grid for each chip separately instead of rows!

proc initSeptemRow(nChips: int, x_size, y_size, x_dist, x_offset, y_t_offset, y_b_offset, dist_to_row_below: float): SeptemRow =
  # this class implements a single row of chips of the septem board
  # nChips: number of chips in row
  # x_dist: distance in x direction between each chip
  # x_offset: offset of left edge of first chip in row from
  #           left side of center row
  # calculate width and height of row, based on chips and dist
  let width = nChips.float * Width + (nChips - 1).float * x_dist
  let height_active = Height
  let height_full = FullHeight + dist_to_row_below
  # using calc gridspec one calculates the coordinates of the row on
  # the figure in relative canvas coordinates
  # include padding by adding or subtracting from left, right, top, bottom
  result.left      = x_offset / x_size
  result.right     = result.left + width / x_size
  result.wspace    = x_dist / x_size
  result.top       = 1.0 - y_t_offset / y_size
  result.bottom    = result.top - height_active / y_size

proc initSeptemBoard(padding, fig_x_size, fig_y_size, scaling_factor: float): seq[SeptemRow] =
  # implements the septem board, being built from 3 septem rows

  proc initRows(y_size, scaled_x_size, scaled_y_size, y_row1_row2, y_row2_row3, row2_x_dist: float): seq[SeptemRow] =
    # this function creates the row objects for the septem class
    # calculation of row 1 top and bottom (in abs. coords.):
    let
      # (top need to add padding to top of row 1)
      row1_y_top    = y_size - BondHeight - Height
      # bottom in abs. coords.
      row1_y_bottom = 2 * FullHeight + y_row1_row2 + y_row2_row3 - Height
      # offset of left side from septem in abs. coords.
      row1_x_offset = 6.95
    # now create the first row with all absolute coordinates
    result.add initSeptemRow(2, scaled_x_size, scaled_y_size, 0.85, row1_x_offset, row1_y_top, row1_y_bottom, y_row1_row2)
    # calculation of row 2 top and bottom (top & bottom of row2 not affected by padding):
    let
      row2_y_top    = y_size - FullHeight - y_row1_row2 - Height
      row2_y_bottom = FullHeight + y_row2_row3 + BondHeight - Height
      # no offset for row2, defines our left most position in abs. coords.
      row2_x_offset = 0.0 #padding * x_size
    result.add initSeptemRow(3, scaled_x_size, scaled_y_size, row2_x_dist, row2_x_offset, row2_y_top, row2_y_bottom, y_row2_row3)
    # calculation of row 3 top and bottom (add padding to bottom):
    let
      row3_y_top    = y_size - 2 * FullHeight - y_row1_row2 - y_row2_row3 - Height
      row3_y_bottom = BondHeight - Height
      row3_x_offset = 7.22
    result.add initSeptemRow(2, scaled_x_size, scaled_y_size, 0.35, row3_x_offset, row3_y_top, row3_y_bottom, 0)

  # include a padding all around the septem event display of 'padding'
  # use size of figure to scale septem accordingly to have it always properly
  # scaled for the given figure
  # take the inverse of the scaling factor (want 1/2 as input to scale to half size)
  let scaling_factor = 1.0 / scaling_factor
  # first calculate the ratio of the figure
  let fig_ratio = float(fig_x_size) / float(fig_y_size)
  # distances between different rows in absolute coordinates
  let
    y_row1_row2 = 0.38
    y_row2_row3 = 3.1
    # size in y direction of whole septem board in absolute coordinates
    y_size      = 3 * FullHeight + y_row1_row2 + y_row2_row3
    # already define row2_x_dist here (in absolute coordinates) to calculate x_size
    row2_x_dist = 0.35
    # 3 chips * width + 2 * distance between chips (in absolute coordinates)
    x_size      = 3 * Width + (3 - 1) * row2_x_dist
  # calculate the ratio of the septem board
  var ratio = float(x_size) / float(y_size)
  # now calculate the needed ratio to get the correct scaling of the septem on any
  # figure scale. fig_ratio / own ratio
  ratio = fig_ratio / ratio
  let
    # scaled x and y sizes
    scaled_x_size = x_size * ratio * scaling_factor
    scaled_y_size = y_size * scaling_factor
  # and now create the row objects
  result = initRows(y_size, scaled_x_size, scaled_y_size, y_row1_row2, y_row2_row3, row2_x_dist)

proc readVlen(h5f: H5File,
              fileInfo: FileInfo,
              runNumber: int,
              dsetName: string,
              chipNumber = 0,
              dtype: typedesc = float): seq[seq[dtype]] =
  ## reads variable length data `dsetName` and returns it
  ## In contrast to `read` this proc does *not* convert the data.
  let vlenDtype = special_type(dtype)
  let dset = h5f[(fileInfo.dataPath(runNumber, chipNumber).string / dsetName).dset_str]
  result = dset[vlenDType, dtype]

proc calcOccupancy[T](x, y: seq[seq[T]], z: seq[seq[uint16]] = @[]): Tensor[float] =
  ## calculates the occupancy of the given x and y datasets
  ## Either for a `seq[seq[T: SomeInteger]]` in which case we're calculating
  ## the occupancy of a raw clusters or `seq[T: SomeFloat]` in which case
  ## we're dealing with center positions of clusters
  result = newTensor[float]([NPix, NPix])
  # iterate over events
  for i in 0 .. x.high:
    let
      xEv = x[i]
      yEv = y[i]
    var zEv: seq[uint16]
    if z.len > 0:
      zEv = z[i]
    ## continue if full event.
    ## TODO: replace by solution that also works for clusters!!
    #if xEv.len >= 4095: continue
    for j in 0 .. xEv.high:
      if zEv.len > 0:
        result[xEv[j].int, yEv[j].int] += zEv[j].float
      else:
        result[xEv[j].int, yEv[j].int] += 1.0

proc occForChip(h5f: H5File, chip: int, fileInfo: FileInfo): (Tensor[int], Tensor[int], Tensor[float]) =        
  const NPix = 256
  let
    xD = h5f.readVlen(fileInfo, Run, "x", chip, dtype = uint8)
    yD = h5f.readVlen(fileInfo, Run, "y", chip, dtype = uint8)
    zD = h5f.readVlen(fileInfo, Run, "ToT", chip, dtype = uint16)
  let occ = calcOccupancy(xD, yD) # , zD)
  var
    x = newTensorUninit[int](NPix * NPix)
    y = newTensorUninit[int](NPix * NPix)
    z = newTensorUninit[float](NPix * NPix)
  var i = 0
  for idx, val in occ:
    x[i] = idx[0]
    y[i] = idx[1]
    z[i] = val
    inc i
  result = (x, y, z)
      
proc handleOccupancy(h5f: H5File,
                     chip: int,
                     fileInfo: FileInfo,
                     quant: float = 0.0): PlotView =
  # get x and y datasets, stack and get occupancies
  let (x, y, z) = h5f.occForChip(chip, fileInfo)
  let df = toDf(x, y, z)
  var quant = quant
  if quant == 0.0:
    quant = percentile(z, 80)
  result = ggcreate(
    block:
      var plt = 
        ggplot(df, aes("x", "y", fill = "z"), backend = bkCairo) +
          geom_raster() +
          scale_fill_continuous(scale = (low: 0.0, high: quant)) + #high: 1600.0)) +
          xlim(0, NPix) + ylim(0, NPix)
      if OnlyRaster:
        plt = plt + theme_void() + hideLegend()
      plt
  )
  #ggplot(df, aes("x", "y", fill = "z"), backend = bkCairo) +
  #    geom_raster() +
  #    scale_fill_continuous(scale = (low: 0.0, high: 1600.0)) +
  #    xlim(0, NPix) + ylim(0, NPix) +
  #    ggsave("/t/test_occ_0_.pdf")

proc drawBounds(v: Viewport) =
  v.drawBoundary(writeName = true)
  for ch in mitems(v.children):
    ch.drawBounds()

proc calcQuantileChip3(h5f: H5File, fileInfo: FileInfo): float =
  let (x, y, z) = h5f.occForChip(3, fileInfo)
  result = percentile(z, 80)  

proc addRow(view: Viewport, h5f: H5File, septem: seq[SeptemRow], fileInfo: FileInfo, i, num, chipStart: int, showEmpty = false) =
  let width = septem[i].right - septem[i].left
  let height = septem[i].top - septem[i].bottom

  var row = view.addViewport(left = septem[i].left, bottom = septem[i].bottom,
                             width = width, height = height)
  row.layout(num, 1) #, margin = quant(septem[i].wspace, ukRelative))

  #let quant = calcQuantileChip3()
  
  for j in 0 ..< num:
    if not showEmpty:
      let plt = handleOccupancy(h5f, chipStart + j, fileInfo) #, quant)
      let v = if OnlyRaster: plt.view[4] else: plt.view
      var pltView = v.relativeTo(row[j]) 
      row.embedAt(j, pltView)
    row[j].drawBoundary()

  view.children.add row

## Read the data from the reconstructed H5 file of run 241
const path = "/mnt/1TB/CAST/2017/development/reco_$#_sparking.h5" % $Run
let h5f = H5open(path, "r")
let fileInfo = getFileInfo(h5f)

let
  fig_x_size = 10.0
  fig_y_size = 12.04186
  ratio = fig_x_size / fig_y_size

let septem = initSeptemBoard(0.0, fig_x_size, fig_y_size, 1.0)
let ImageSize = fig_x_size * DPI
let view = initViewport(c(0.0, 0.0),
                        quant(fig_x_size, ukInch), quant(fig_y_size, ukInch), backend = bkCairo,
                        wImg = ImageSize, hImg = ImageSize / ratio)

view.addRow(h5f, septem, fileInfo, 0, 2, 5, showEmpty = true)
view.addRow(h5f, septem, fileInfo, 1, 3, 2)
view.addRow(h5f, septem, fileInfo, 2, 2, 0)

view.draw("/home/basti/phd/Figs/sparking_occupancy_80_quantile_run_$#.pdf" % $Run)
#+end_src

Running the above code for run 268 (the run we installed the fan and
had temperature readout) yields fig. [[fig:detector:occupancy_sparking_run_268]].

#+CAPTION: Occupancy of a testing background run with $\mathcal{O}(\SI{1}{s})$ long frames
#+CAPTION: using septemboard F during development without any kind of cooling and temperature
#+CAPTION: logging. Temperatures on the underside of the carrier board reached \SI{76}{\degree\celsius}
#+CAPTION: before the fan was placed next to it.
#+NAME: fig:detector:occupancy_sparking_run_268
[[~/phd/Figs/detector/sparking/sparking_occupancy_80_quantile_run_268.pdf]]


** Full detector overview [0/4]
:PROPERTIES:
:CUSTOM_ID: sec:detector:detector_overview
:END:

- [ ] *TALK ABOUT SIZES OF FULL DETECTOR*

Generally the main detector follows the same design as the old
detector shown in sec. [[#sec:detector:detector_2014_15]], mainly so that
mounting it inside of the lead shielding and to the vacuum pipes is
possible without significant changes.

An exploded view of the full detector can be seen in
fig. [[fig:detector:full_septemboard_exploded]]. The FADC and large veto
scintillator paddle are not visible in the schematic of course. At the
center of the detector is the 'septemboard', 7 GridPix on a carrier
board. The housing with an inner diameter of \SI{78}{mm} is again made
of acrylic glass, same as in the old detector. The top shows the
\SI{300}{nm} \ce{Si_3 N_4} window, which also acts as part of the
detector cathode. The copper anode slots in right above the
septemboard. The carrier board sits on the intermediate board and
itself it is above the water cooling made of oxygen-free copper. At
the bottom, the SiPM veto scintillator can be seen.

The septemboard used in the final detector is septemboard H. The chips
of these are listed in tab. [[tab:detector:septem_h_chips]].

#+CAPTION: Overview of the different chips on septemboard H. The first part of the name corresponds
#+CAPTION: to the position on the wafer and =W69= is Timepix wafer number \num{69}.
#+NAME: tab:detector:septem_h_chips
|---------+--------|
| Chip    | Number |
|---------+--------|
| E6 W69  |      0 |
| K6 W69  |      1 |
| H9 W69  |      2 |
| H10 W69 |      3 |
| G10 W69 |      4 |
| D9 W69  |      5 |
| L8 W69  |      6 |
|---------+--------|


- [ ] *SEPTEMBOARD CAN BE NAMED HERE INSTEAD OF ABOVE POSSIBLY*
- [ ] *REARRANGE THE TABLE TO ALIGN LEFT COLUMN*  

#+CAPTION: Exploded view of the main GridPix septemboard detector. The FADC and
#+CAPTION: large veto scintillator paddle are not shown for obvious reasons. At the
#+CAPTION: center of the detector is the 'septemboard', 7 GridPix on a carrier board.
#+CAPTION: The housing is made of acrylic glass, same as in the old detector. The
#+CAPTION: top shows the \SI{300}{nm} \ce{Si_3 N_4} window. Below the intermediate board
#+CAPTION: is the water cooling made of pure copper. At the bottom, the SiPM veto
#+CAPTION: scintillator can be seen.
#+NAME: fig:detector:full_septemboard_exploded
#+ATTR_LATEX: :height 0.5\textheight
[[~/phd/Figs/detector/detector-mk4c-assembly-exploded-whitebg-no-cables-cropped.jpg]]

*AS LAST SECTION?*

- [ ] *REPLACE IMAGE BY A PROPER RAYTRACED RENDER*
  
** Detector readout system (Virtex, ...) [0/1]

The detector is operated by a Xilinx Virtex-6 \textbf{F}ield
\textbf{P}rogrammable \textbf{G}ate \textbf{A}rray (FPGA) in the form
of a Virtex-6 ML605 evaluation board. [fn:ml605_weblink] It is
connected to the intermediate board via two
\textbf{H}igh-\textbf{D}efinition \textbf{M}ultimedia
\textbf{I}nterface (HDMI) cables. The Virtex-6 contains the firmware
controlling the Timepix ASICs and correlating the scintillator and
FADC signals (see sec. [[sec:daq:tof]]). The high voltage (HV) supply both for the
septemboard as well as for the scintillators sit inside a VME crate,
which also houses the FADC. A USB connection is used to read out and
control the FADC and HV supply via the computer running the data
acquisition and control software (see sec. [[sec:daq:tos]]). A schematic
of this setup is shown in fig. [[fig:detector:flowchart_setup]].

#+CAPTION: Flowchart of the whole detector and readout system
#+NAME: fig:detector:flowchart_setup
[[file:~/org/Doc/Detector/figs/2016_detector_setup_schematic.pdf]]

Note however, that in this plot the SiPM is not illustrated, as it is
connected to the bottom of the intermediate board and only provides an
offline flag to be used in the analysis.

- [ ] *CLARIFY SIPM. PROBABLY ADD TO PLOT*
  
[fn:ml605_weblink]
https://www.xilinx.com/products/boards-and-kits/ek-v6-ml605-g.html
(visited 2022/10/17)

** Detector efficiency [0/1]

For the applications at CAST, the detector is filled with $\ce{Ar}$ / $\ce{iC_4 H_{10}}$ :
\SI{97.7}{\%} / \SI{2.3}{\%} gas. Combined with its \SI{300}{nm}
\ce{Si_3 N_4} window, the combined detection efficiency can be
computed, if the \SI{20}{nm} \ce{Al} coating for the detector cathode
is included by computing the product of the different
efficiencies. The efficiency of the window and coating are the
transmissions of X-rays at different energies for each material $t_i$. For
the gas, the absorption probability of the gas $a_i$ is needed. As such

\[
ε_{\text{tot}} = t_{\ce{Si_3 N_4}} · t_{\ce{Al}} · a_{\ce{Ar} / \ce{iC_4H_{10}}}
\]

describes the full detector efficiency assuming the parts of the
detector, which are not obstructed by the window strongbacks. For a
statistical measure of detection efficiency the occlusion of the
window needs to be taken into account. Because it is position
(and thus area) dependent, the need to include it is decided on a case
by case basis. For the absorption of a gas mixture, we can use
Dalton's law and compute the absorption of the individual gases according
to their mole fractions (their percentage as indicated by the gas
mixture) and then compute it for each partial pressure

\[
a_i = \text{Absorption}(P_{\text{total}} · f_i)
\]

where $P_{\text{total}}$ is the total pressure of the gas mixture (in
this case \SI{1050}{mbar} and $f_i$ is the fraction of the gas
$i$. 'Absorption' simply refers to the generic function computing the
absorption for a gas at a given pressure (see sec. [[#sec:theory:daltons_law]]).

The full combined efficiency as presented here is shown in
fig. [[fig:detector:combined_efficiency]]. Different aspects dominate the
combined efficiency (purple line) in different energy ranges. At
energies above \SI{5}{keV} the probability of X-rays to not generate a
photoelectron within the \SI{3}{cm} of drift distance becomes the
major factor for a loss in efficiency. This means the combined
efficiency at \SI{10}{keV} is slightly below \SI{30}{\percent}. The
best combined efficiency of about \SI{95}{\percent} is reached at
about \SI{3.75}{keV} where both the absorption is likely and the
energy is high enough to transmit well through the window. The argon
$K 1s$ absorption edge is clearly visible at around \SI{3.2}{keV}. At
energies below the mean free path of X-rays is significantly longer as
the $K 1s$ absorption is a significant factor in the possible
generation of a photoelectron. The window leads to a similar, but inverse, effect
namely due to the $K 1s$ line of \ce{Si} at around
$\SI{1.84}{keV}$. Because transmission is desired through the window
material, the efficiency /increases/ once we go below that
energy. Finally, the nitrogen $K 1s$ line also contributes to an
increase in efficiency once we cross below about \SI{400}{eV}. The
average efficiencies in the energy ranges between \SIrange{0}{5}{keV} and
\SIrange{0}{10}{keV} are *X* and *Y*, respectively.

The improvement in efficiency at energies below \SI{3}{keV} in
comparison to the mylar window used in the 2014/15 detector (see
sec. [[#sec:detector:sin_window]]) leads to a significant
improvement in possible signal detection at those energies, which is
especially important for searches with peak fluxes around
\SIrange{1}{2}{keV} as is the case for the axion-electron coupling or
a possible chameleon coupling.

#+CAPTION: Combined detection efficiency for the full detector, taking into account
#+CAPTION: the gas filling of \SI{1050}{mbar} $\ce{Ar}$ / $\ce{iC_4 H_{10}}$, the \SI{300}{nm}
#+CAPTION: \ce{Si_3 N_4} window and its \SI{20}{nm} \ce{Al} coating. 
#+NAME: fig:detector:combined_efficiency
[[~/phd/Figs/detector/detector_efficiency.pdf]]

Outside of that, the general background rate expected from the
detector should match and exceed the previous detector, due to the
additional detector features. 

- [ ] *ADD NUMBERS FOR AVERAGE EFFICIENCY IN RANGES, WHERE X AND Y*
- [ ] *REPLACE BY NATIVE TIKZ PLOT + VEGA*  

*** Calculation of full detection efficiency   :noexport:


#+begin_src nim :tangle /home/basti/phd/code/detector_efficiency.nim
import std / strutils
import xrayAttenuation, ggplotnim
# generate a compound of silicon and nitrogen with correct number of atoms
let Si₃N₄ = compound((Si, 3), (N, 4))
let al = Aluminium.init()

# define energies in which to compute the transmission
# (we don't start at 0, as at 0 energy the parameters are not well defined)
let energies = linspace(0.03, 10.0, 1000)

# instantiate an Argon instance
let ar = Argon.init()
# and isobutane
let iso = compound((C, 4), (H, 10))

proc compTrans[T: AnyCompound](el: T, ρ: g•cm⁻³, length: Meter): Column =
  let df = toDf({ "Energy [keV]" : energies })
    .mutate(f{float: "μ" ~ el.attenuationCoefficient(idx("Energy [keV]").keV).float},
            f{float: "Trans" ~ transmission(`μ`.cm²•g⁻¹, ρ, length).float},
            f{"Compound" <- el.name()})
  result = df["Trans"]
    
var df = toDf({ "Energy [keV]" : energies })
# compute transmission for Si₃N₄ (known density and desired length)
df[Si₃N₄.name()] = Si₃N₄.compTrans(3.44.g•cm⁻³, 300.nm.to(Meter))
# and aluminum coating
df[al.name()] = al.compTrans(2.7.g•cm⁻³, 20.nm.to(Meter))

# and now for the gas mixture.
# first compute partial pressures
const fracAr = 0.977
const fracIso = 0.023
# using it we can compute the density of each by partial pressure theorem (Dalton's law)
let ρ_Ar = density(1050.mbar.to(Pascal) * fracAr, 293.K, ar.molarMass)
let ρ_Iso = density(1050.mbar.to(Pascal) * fracIso, 293.K, iso.molarWeight)

# now add transmission of argon and iso
df[ar.name()] = ar.compTrans(ρ_Ar, 3.cm.to(Meter))
df[iso.name()] = iso.compTrans(ρ_Iso, 3.cm.to(Meter))

let nSiN = r"\SI{300}{nm} \ce{Si_3 N_4}"
let nAl = r"\SI{20}{nm} \ce{Al}"
let nAr = r"\SI{3}{cm} \ce{Ar} Absorption"
let nIso = r"\SI{3}{cm} \ce{iC_4 H_{10}} Absorption"
let nArIso = r"\SI{3}{cm} \SI{97.7}{\percent} \ce{Ar} / \SI{2.3}{\percent} \ce{iC_4 H_{10}}"

# finally just need to combine all of them in useful ways
# - argon + iso
df = df.mutate(f{"Trans_ArIso" ~ `Argon` * `C4H10`},
               f{"Abs ArIso" ~ 1.0 - `Trans_ArIso`},
               f{"Abs Ar" ~ 1.0 - `Argon`},
               f{"Abs Iso" ~ 1.0 - `C4H10`},
               f{"Efficiency" ~ idx("Abs ArIso") * `Si3N4` * `Aluminium`})
  .rename(f{nSiN <- "Si3N4"},
          f{nAl <- "Aluminium"},
          f{nAr <- "Abs Ar"},
          f{nIso <- "Abs Iso"},
          f{nArIso <- "Abs ArIso"}) # ,                    
  .gather([nSiN, nAl, nAr, nIso, nArIso, "Efficiency"], "Material", "Efficiency")

ggplot(df, aes("Energy [keV]", "Efficiency", color = "Material")) +
  geom_line() +
  xlab("Energy [keV]") + ylab("Efficiency") +
  xlim(0.0, 10.0) + 
  ggtitle(r"Transmission (absorption for gases) of relevant detector materials and combined \\" &
    "detection efficiency of the Septemboard detector",
    titleFont = font(10.0)) +
  margin(top = 1.25, right = 2.0) +
  legendPosition(0.42, 0.15) + 
  ggsave("/home/basti/phd/Figs/detector/detector_efficiency.pdf",
         #width = 800, height = 600,
         useTex = true, standalone = true) 
#+end_src

* Data acquisition, detector monitoring and preparation            :Detector:
#+LATEX: \minitoc
Having introduced the detector used for the data taking in this
thesis, we will now introduce the data acquisition (DAQ) software for the
detector (sec. [[#sec:daq:tof]] and [[#sec:daq:tos]]), discuss the data
formats used for readout as well as the logging facilities. Further,
we will introduce the calibrations performed for the Timepix to
achieve a correct operation with a GridPix detector as well as the
calibrations for the scintillators and FADC. Finally, we will present
the monitoring tools to monitor the detector operation (different
event displays) which are used for different data taking purposes.

- introduce TOS
- introduce data format
- logging data (temperature)
- different timepix calibrations (here?) maybe just introduce
  different calibrations and then in data taking part talk about what
  they actually look like?

- [ ] *INTRODUCE DAQ ACRONYM*  

** Timepix Operating Firmware - TOF [0/2]
:PROPERTIES:
:CUSTOM_ID: sec:daq:tof
:END:

Starting with the firmware of the detector, the \textbf{T}imepix
\textbf{O}perating \textbf{F}irmware (TOF), which runs on the Virtex-6
FPGA. TOF controls the Timepix ASICs of the Septemboard (both the slow
control aspects as well as the data taking) as well as coordinating
the scintillator signals and FADC trigger. It is a VHDL *OR NOT???*
project, intended to run at a clock frequency of
\SI{40}{MHz}. Communication with the GridPixes is done via two
\textbf{H}igh-\textbf{D}efinition \textbf{M}ultimedia
\textbf{I}nterface (HDMI) cables, while communication with the readout
software on the DAQ computer is handled via Ethernet.

For a detailed introduction to TOF, see \cite{*LUPBERGER THESIS*} as
well as \cite{*TOBI UPCOMING THESIS*}.


The firmware versions used for each data taking periods will be listed
with the other relevant parameters for each period in section *SECTION
NEEDS TO BE WRITTEN*.

- [ ] *CHECK IF VHDL*
- [ ] *LUPBERGER THESIS*

** Timepix Operating Software - TOS [0/2]
:PROPERTIES:
:CUSTOM_ID: sec:daq:tos
:END:

The \textbf{T}imepix \textbf{O}perating \textbf{S}ystem (TOS) is the
computer-side data acquisition software to read out Timepix based
detectors. It is an object oriented C++ project, available at *PUSH TO
GITHUB*. [fn:TOS_versions] *ACCORDING TO WIENER VME MANUAL ALL FILES
ARE OPEN SOURCE*
https://wikihost.nscl.msu.edu/S800Doc/lib/exe/fetch.php?media=wiki:manual_vm-usb_9_01_1.pdf
The project needs to be used in conjunction with the \textbf{T}imepix
\textbf{O}perating \textbf{F}irmware (TOF), which communicates with
TOS via Ethernet. The TOS project started as far back as 2009 by
people at the University of Mainz. Next is a short overview over the
basic blocks that make up the main logic of the software.

[fn:TOS_versions] There are unfortunately 2 different versions of TOS,
as development diverged for different readout systems. One version is
for the Xilinx Virtex-6 (V6) ML605 evaluation board and the other for
the \textbf{S}calable \textbf{R}eadout \textbf{S}ystem (SRS). The V6
version can read out only a single detector (with up to 8 Timepix
ASICs), but supports readout of an Ortec FADC and controlling a Wiener
HV module via VME. The SRS version instead supports neither of these
additional features, but supports multiple detectors at the same
time. The detector used in this thesis is read out using the Virtex-6
board.



- [ ] *PUSH TOS TO GITHUB OR SIMILAR AND REFERENCE*
- [ ] *CHECK AGAIN WIENER VME SOURCES OPEN SOURCE*  
*ADD FULL NAME OF V6 BOARD*

The fully object oriented nature of the project means that there are
different classes for the different software pieces:
- =Console=: A class representing the user facing REPL
  (Return-Evaluate-Print-Loop, an 'interpreter') to control the
  software
- =PC=: A class representing the network layer and communication side
  of the software, sitting between the console and lower layers.
- =FPGA=: A class representing the functionality required to control
  the FPGA on the Virtex-6 evaluation board.
- =Chip=: A class representing each Timepix ASIC and its
  functionality.
- =HFManager=: A class unifying the FADC & Wiener HV control unit as
  they are both controlled via USB, installed in a VME crate. This
  class contains individual attributes that contain explicit classes
  for these two devices. The name is shortened for 'High Voltage and
  FADC Manager'.
  - =V1729=: A class representing the Ortec Flash ADC.
  - =HV*=: Multiple classes representing HV channels, groups and more.
- =MCP2210=: A class representing the PT1000 temperature sensors
  installed on the detector via a =MCP2210= micro controller,
  optionally connected via USB. The actual micro-controllers with
  attached PT1000s are =MAX31685= models.
- there are a few further classes of minor interest to the general
  functionality of TOS (tab command completion and history, classes
  to set masks on the chips, etc.)

In general TOS is a fully command line driven software package, with
its own REPL (Return, Evaluate, Print, Loop; the name for an
interactive terminal process, which takes commands that are evaluated
and returns to the terminal). It brings all the expected features one
might wish from a REPL, including auto completion, history lookup,
emacs style keybindings and more.

The aforementioned =HFManager= and the temperature sensors are
optional pieces that are not required for basic Timepix
operation. Their functionality has to be activated via a manual
command, =ActivateHFM=. This triggers the USB connection to the VME
crate and tries to find the Wiener HV module as well as the Ortec FADC
in the crate. Additionally, the temperature sensors are attempted to
be found (via a secondary, optional USB connection). If the latter are
found a continuous temperature logging begins. Outside of actual data
taking the temperature is logged into the internal =log= directory of
the TOS directory as =temp_log.txt=. [fn:temp_logs_lost]

[fn:temp_logs_lost] This default temperature logging location was also
used as an unintended fallback mechanism during data taking, if the HV
of the detector was considered out of certain bounds. Unfortunately,
the bounds checking was faulty which is why it was disabled manually
during data taking at CAST, as it triggered data taking aborts. This
however triggered a secondary code path for the temperature logging,
storing it in that default location. As an effect the majority of CAST
temperature logging data has been lost, as most of it was overwritten
several times. About daily manual temperature measurements are still
left and show the detector operating in a good temperature
range. Precise correlations with certain detector behaviors are
unfortunately impossible. The two different code paths for the
temperature logging are essentially a bug in the code that was never
intended, stemming from the fact that temperature logging must be done
to a 'global' location outside of data taking (as no data taking
specific directory exists). Due to how the temperature logging and HV
& FADC controls were added to TOS, these things were more entangled
than necessary. A more thorough testing period of the detector and
software package should have been performed, but was not in scope.



A short snippet of the temperature log is shown in listing
[[code:daq:temperature_readout]].

- [ ] *INSERT TEMPERATURE LOGGING EXAMPLE SNIPPET*


The HV controls are specific to Wiener HV power supplies. In principle
the implemented functionality is a fully featured HV controller that
supports all Wiener functionality like grouping different channels to
ramp up together, kill channels on a trip and much more.

An example of a typical startup procedure is shown in listing
[[TOS_startup_commands]]. Note that most essential commands in TOS also
have shortened names via numbers, due to historic reasons (TOS
originally did not have autocompletion or allowed moving the cursor in
text input, making typing complex names cumbersome and error prone),
which is why many of the inputs are simple numbers.

#+CAPTION: An example of the typical startup routine of TOS for a background data taking measurement at CAST
#+CAPTION: for the Septemboard based GridPix detector. The indented lines refer to commands given to the 
#+CAPTION: previous command at top level.
#+LABEL: TOS_startup_commands
#+begin_src sh
user@ingrid-DAQ~/ ./TOS
  > 7 # number of chips
  > 4 # preload
> SetChipIDOffset
  > 190
> lf # load FSR values for the chips
  > # return 7 times enter to load default paths
> uma # create a uniform matrix for all chips
  > 1 # Matrix settings
  > 0
  > 1
  > 1
  > 0
> LoadThreshold # load threshold equalisation files
  > 4 # write matrix
  > 3 # read out
  > 3 # 2nd readout to make sure pixels are 'empty'
> ActivateHFM # startup HV & FADC controls
> SetFadcSettings # load the FADC settings
> Run # start a data taking run
  > 1 # run time via # frames
  > 0
  > 0
  > 0
  > 2 # shutter range select
  > 30 # shutter time select (2 + 30 yields ~2.4 s frames)
  > 0 # zero suppression
  > 1 # FADC usage
  > 0 # accept FADC settings
#+end_src

Data taken with TOS is stored - for historic reasons - in raw ASCII
text files. Two different readout modes (with different output
formats) are supported. For the following explanation it is assumed
the Timepix is used in the ToT (Time-over-Threshold) mode.
1. full matrix readout: reads out the whole Timepix ASIC(s) and writes
   a single 256x256 pixel matrix as an ASCII file (for each chip). 256
   lines, each containing space separated ToT values for each pixel.
2. zero suppressed readout: reads out only those pixels that have ToT
   values larger than 0, up to \num{4096} pixels. Stores the data in
   TSV files (tab separated values) =X Y ToT= with an additional
   header. The header contains a global "run" and "event" header,
   which contains information about the run the event is taken from
   and a "chip" header, which contains information about the specific
   Timepix ASIC(s) being read out (up to 8 can be read out at the same
   time using TOS).

The Timepix is only capable of shutter based readouts. Typically, a
fixed shutter is used. The readout is complicated for the case of
using an FADC, in which case an FADC signal can be used as an external
trigger to close the shutter early. This will be further explained in
the FADC section, [[FADC]]
*REWRITE THIS PART, REFER TO SCHEMATIC ABOUT TIMEPIX*

As for our purposes most events are extremely sparse (< 500 pixels
active) the zero suppressed readout is the only relevant readout
mode. An example of the file type produced in this mode is in listing
[[zero_suppressed_readout]].

#+CAPTION: Example of an event read out in zero suppressed readout mode. The ASCII output data
#+CAPTION: consists of a global run and event header (indicated by =##=), a chip header (indicated by 
#+CAPTION: =#= and actual data in format =X Y ToT= values). Each chip header is followed by
#+CAPTION: by all active pixels on that chip in the event.
#+NAME: zero_suppressed_readout
#+begin_src sh
## [General]
## runNumber:        339
## runTime:       	 7200
## runTimeFrames: 	 0
## pathName:         data/runs/Run_339_190218-10-36
## dateTime:         2019-02-18.10:36:34
## numChips:         7
## shutterTime:      2
## shutterMode:      verylong
## runMode:          0
## fastClock:        0
## externalTrigger:  0
## [Event]
## eventNumber:      2
## useHvFadc:    	 1
## fadcReadout:    	 1
## szint1ClockInt:	 0
## szint2ClockInt:	 0
## fadcTriggerClock: 647246
# chipNumber: 0
# chipName:   E 6 W69
# numHits:    0
# chipNumber: 1
# chipName:   K 6 W69
# numHits:    0
# chipNumber: 2
# chipName:   H 9 W69
# numHits:    2
106	160	75
211	142	2
# chipNumber: 3
# chipName:   H 10 W69
# numHits:    23
238	154	51
242	153	18
...
# chipNumber: 4
# chipName:   G 10 W69
# numHits:    0
# chipNumber: 5
# chipName:   D 9 W69
# numHits:    0
# chipNumber: 6
# chipName:   L 8 W69
# numHits:    4
139	254	146
166	233	11810
234	203	11810
70	57	315
#+end_src

Link to repositories (maybe we can make the Virtex TOS public?) 

- [ ] Link to TOF firmware.

- [ ] Septem event display example.


*** TOS output data format
:PROPERTIES:
:CUSTOM_ID: sec:tos_output_format
:END:

TOS needs to talk about data format that was used in V6 TOS. Stupid
ASCII files. Mention that in hindsight the time should have been
invested to either use a really dumb binary format (like NIO) or HDF5
(even if painful from C++).


Already shown an example above in the section. Move this into this section?


*** TOS development                                              :noexport:

As mentioned in one of the footnotes in the previous section, there
are nowadays 2 independent versions of TOS.

The detector used for CAST in 2014/15 (and thus its successor used in
this thesis) was based on a readout using the Virtex 6 FPGA. This
system was, at the point I started on my master thesis in 2015,
already quite diverged from the SRS based system, which was mainly
developed for multi chip detectors that were initially planned for a
large GridPix based TPC to be used for the ILD (the detector planned
for the ILC, the International Linear Collider to be built in Japan).

In addition there was recent a master thesis (by Alexander Deisting, ref
*CITE DEISTING*), which included work on using an FADC to read out the
induced charges on the grid of the InGrid by decoupling the signal
using a capacitor.
The software library to interact with the used FADC had partially been
implemented into the Virtex 6 TOS. 

As the FADC was an integral part in the new detector design, it was
natural to start with the Virtex 6 version.

At the same time the SRS TOS version at the time was even more
ugly than the same code paths in the Virtex 6 TOS.

... 

A large amount of time spent

*what else*


** schematic of whole readout chain [0/1]

*ELSEWHERE AS WELL?*

Create a full flow chart of how everything is connected.

We have our notes about where each cable goes etc.

We have a schematic in the master thesis. That can be modified a bit
for the PhD thesis.

- [X] *THIS IS IN DETECTOR OVERVIEW NOW*

** Timepix calibrations etc.

*ELSEWHERE AS WELL*

What kind of calibrations exist. How do they work, what do they do
etc.

From a purely detector standpoint.

Polya distribution goes here somewhere. Related to gaseous detector
physics & our detector in particular.

Before a Timepix based detector can be used for data taking, different
calibrations have to be performed.

We will discuss the main calibrations that are performed, starting
with a =THS= optimization and threshold equalization
(sec. [[#sec:daq:ths_opt_equalization]]). Next, the S-Curve scan
(sec. [[S-Curve scan]]) and finally the ToT calibration, section [[ToT
calibration]]. In these the first 3 are calibrations that are used to
set different DACs on the Timepix to 'good' values. The last
calibration on the other hand is one to *interpret* the ToT values in
amounts of charge.

- [ ] *REPHRASE, SCURVE NOT TO SET A DAC. SCURVE USED TO ESTIMATE THE THRESHOLD IN ELECTRONS*

In principle there are many other calibrations one could perform, as
the Timepix has *CHECK NUMBER* 10 different DACs. Most are used with
default values that are seen in *TABLE OF CALIBRATION*.

These calibrations are mainly explained to give context for the used
detector calibrations at CAST. All calibrations can be found in
appendix *APPEND CALIBRATIONS*.

Important references for the Timepix in general and for the
calibration procedures explained below are
\cite{LLOPART2007485_timepix, LlopartCudie_1056683, timepix_manual, lupberger2016pixel}.

*** =THS= optimization and threshold equalization
:PROPERTIES:
:CUSTOM_ID: sec:daq:ths_opt_equalization
:END:

For an optimal operation of a Timepix based detector, each pixel
should ideally have the same threshold. While all pixels are
theoretically identical, imperfections in the production process will
always lead to slight differences, either locally (transistor
threshold voltage or current mismatches
\cite{LLOPART2007485_timepix,pelgrom1989matching} ) or global effects
like small supply voltage instabilities. Therefore, each pixel has 4
independently selectable current sources to minimize the spread of
threshold values
\cite{timepix_manual,LLOPART2007485_timepix}. Together all 4 sources
act as an effective 4-bit DAC to slightly adjust the threshold. The
absolute current for the 4 sources is dependent on the global =THS=
DAC, allowing currents in the range of \SIrange{0}{40}{nA}.

To achieve a good calibration for a homogeneous threshold, first the
=THS= DAC has to be set correctly. This is referred to as the =THS=
optimization. Once the correct value is found, the 4-bit DAC on each
pixel can be adjusted to minimize the spread of threshold values of
all pixels together.

If the =THS= DAC is set too high, the 4-bit DAC on each pixel will be
too coarse for a fine adjustment (as the 'current steps' will be too
large). If it is too low, not enough range will be available to adjust
each pixel to an equal noise / sensitivity level (not enough current
available via the 4 current sources). The goal of the =THS=
optimization is therefore to find just the right value, as to provide
a range of values such that all values can be shifted to the same
threshold of the threshold DAC =THL=.

The algorithm scans a range of =THL= values through a subset of 4096
pixels using pixel 4-bit DAC values first of 0 for all pixels and then
the maximum value of 15. At each =THL= value and 4-bit value the
number of hits due to pure noise is recorded for each pixel. The
weighted mean of the =THL= values using the number of hits as weight
is the value of interest for each pixel and each 4-bit DAC 0 and 15
value, the effective =THL= noise value for that pixel. For each of the
two cases we can then compute a histogram of the number of pixels at
each =THL= value. The resulting histogram will be a normal
distribution around a specific =THL= value. The stopping criterion,
which defines the final =THS= value, is such that these two
distributions overlap at the 3 RMS level. This is performed by
comparing the means of the 0 and 15 value distribution at a starting
=THS= value and again at half of that =THS= value. Using linear
regression of the two differences, the optimal =THS= value is
computed.

- [ ] *I THINK THS OPT DOES NOT!! USE TEST PULSES* Yes, pretty sure
  now. The THS optimization (and obviously threshold equalization)
  does not use test pulses

- [ ] *INTRODUCE THE NAME 'PIXEL DAC' INSTEAD 4-BIT DAC?*  

- [ ] *MAYBE REPHRASE THE FOLLOWING. BUT THIS IS WHAT'S HAPPENING. THE TOS CODE IS PRETTY SIMPLE, JUST BLOATED AND UGLY*

With a suitable =THS= value set, the actual threshold equalization can
start. The algorithm used is fundamentally very similar to the logic
of the =THS= optimization. Each pixel of the chip is scanned for a
range of =THL= values and the weighted =THL= noise mean is computed
both at a 4-bit DAC value of 0 and at 15. The normalized deviation of
each pixel's =THL= value to the mean =THL= value of all pixels is
computed. Using a linear regression the optimal required shift (in
units of the 4-bit DAC) yields the final 4-bit DAC value for each
pixel.

An example of the 0 and 15 value distributions as well as the
distribution using the final 4-bit DAC values for each pixel is shown
in fig. [[fig:daq:optimal_ths_distributions]]. [fn:daq_histo_source] Each
of the distributions represent different 4-bit DAC settings of all
pixels of the chip. Orange ("min") represents all pixels using a 4-bit
DAC value of 0, purple ("max") of 15. In green is the same
distribution for the case where every pixel uses its optimal 4-bit DAC
value. The threshold equalization thus yields a very strong reduction
in the =THL= spread of all pixels. Fig. [[fig:daq:4bit_dac_distribution]]
shows how all pixels are spread in the values of the 4-bit DAC. The
narrow equalized line of fig. [[fig:daq:optimal_ths_distributions]] is
achieved by a normal distribution around \num{8} of the 4-bit DAC
values, with only very few at the edges of the DAC (\num{0} and \num{15}).

#+CAPTION: Distributions of different 4-bit DAC settings of all
#+CAPTION: pixels of the chip. Orange ("min"): all pixels using a 4-bit
#+CAPTION: DAC value of 0, purple ("max"): 15. Green: every pixel uses the
#+CAPTION: optimal 4-bit DAC value after equalization. The result is a significant
#+CAPTION: in =THL= value spread of all pixels.
#+NAME: fig:daq:optimal_ths_distribution
[[~/phd/Figs/detector/calibration/ths_optimization_distributions_example.pdf]]

#+CAPTION: Distribution of all 4-bit DAC values for the pixels after the
#+CAPTION: threshold equalization. A normal distribution around a middle
#+CAPTION: value is expected to largest likelihood of achieving a flat
#+CAPTION: threshold around the whole chip. Very few pixels are either in 
#+CAPTION: value \num{0} or \num{15}, implying few pixels likely outside their
#+CAPTION: range to adjust to the required threshold. In this example
#+CAPTION: represented is the center chip of the Septemboard with its calibration
#+CAPTION: from July 2018.
#+NAME: fig:daq:4bit_dac_distribution
[[~/phd/Figs/detector/calibration/optimized_equalization_bits_example.pdf]]

#+CAPTION: Heatmap of the distribution of the 4-bit DAC values of all chips
#+CAPTION: as they are spread over the full Timepix. In this example
#+CAPTION: represented is the center chip of the Septemboard with its calibration
#+CAPTION: from July 2018.
#+NAME: fig:daq:4bit_dac_heatmap
[[~/phd/Figs/detector/calibration/heatmap_threshold_equalization_example.pdf]]


- [ ] *FIRST EXPLAIN THS OPT, THEN EQ, BOTH USING THE PLOT*  

- [X] *REWRITE BELOW FOLLOWING THE ABOVE NOW*
- [X] *MENTION THIS IS TO MAKE EQUALIZATION OF EACH PIXEL DAC NICE*

- [ ] *PSEUDO CODE ALGORITHM? I THINK IT WOULD CLARIFY THE EXPLANATION QUITE A BIT. ESPECIALLY BECAUSE IT'S NOT DIFFICULT. JUST TOS IS
  UGLY*

*PLOT OF THESE TWO HISTOGRAMS. SHOW MAYBE IDEALIZED EXAMPLE OF BAD THS
AND GOOD THS VALUE*

- [X] *LOOK AT TOS CODE AGAIN*
  
- [X] *LOOK AT TOS CODE FOR EQUALIZATION AGAIN*

*CROSS CHECK THE NAMES ETC*

[fn:daq_histo_source] The plot is generated from the
=thresholdMeans.txt= file created as part of the equalization
procedure in TOS.


[fn:daq_tos_code_quality] Having to check out the TOS code to verify
the logic of the THS optimization and equalization procedures reminded
me of the abhorrent code quality of that code base. Holy moly...

**** Generate the plot for the THS optimization result :noexport:

#+begin_src nim :tangle code/ths_optimization.nim
import ggplotnim

proc main(fname: string) =
  var df = readCsv(fname, sep = '\t', colNames = @["x", "y", "min", "max", "bit", "opt"])
  let breaks = linspace(-0.5, 15.5, 17).toSeq1D
  echo breaks
  ggplot(df, aes("bit")) +
    geom_histogram(breaks = breaks, hdKind = hdOutline) +
    scale_x_continuous() +
    xlim(-0.5, 16.5) +
    xlab("4-bit DAC") + 
    ggtitle("Distribution of all equalization bits after optimization") + 
    ggsave("/home/basti/phd/Figs/detector/calibration/optimized_equalization_bits_example.pdf",
           useTeX = true, standalone = true)
  df = df.gather(["min", "max", "opt"], "type", "THL")
  ggplot(df, aes("THL", fill = "type")) +
    geom_histogram(binWidth = 1.0, position = "identity", hdKind = hdOutline, alpha = 0.7) +
    ggtitle("THL distributions for all equalization bits at 0, 15 and optimized") +
    ggsave("/home/basti/phd/Figs/detector/calibration/ths_optimization_distributions_example.pdf",
           useTeX = true, standalone = true)
when isMainModule:
  import cligen
  dispatch main
#+end_src

#+begin_src sh
./code/ths_optimization -f ~/septemH_calibration/SeptemH_FullCalib_2018_2/chip3/thresholdMeans3.txt
#+end_src

#+begin_src nim :tangle code/threshold_equalization_heatmap.nim
import ggplotnim
import std / [sequtils, strutils]

proc main(fname: string) =
  let aranged = toSeq(0 .. 255).mapIt($it)
  var df = readCsv(fname, sep = '\t', colNames = aranged)
  df["y"] = toSeq(0 .. 255)
  df = df.gather(aranged, "x", "4-bit DAC")
    .mutate(f{"x" ~ `x`.parseInt})
  echo df
  
  ggplot(df, aes("x", "y", fill = "4-bit DAC")) +
    geom_raster() + 
    #scale_x_continuous() +
    #xlim(-0.5, 16.5) +
    xlim(0, 255) + ylim(0, 255) + 
    ggtitle("Heatmap of all equalization bits after optimization") + 
    ggsave("/home/basti/phd/Figs/detector/calibration/heatmap_threshold_equalization_example.pdf",
           useTeX = true, standalone = true)

when isMainModule:
  import cligen
  dispatch main
#+end_src

#+begin_src sh
./code/threshold_equalization_heatmap -f ~/septemH_calibration/SeptemH_FullCalib_2018_2/chip3/threshold3.txt
#+end_src

**** Relevant code for calculation of mean values from TOS :noexport:

Filling of =sum= in =THscan=. =array_pos= is effectively the =THL=
value currently being scanned. =pix_tempdata= is the response matrix
of each pixel (contains hit counter for each pixel). Also fills
=hit_counter=, which is simply the counts.
#+begin_src c++
    fpga->DataFPGAPC(pix_tempdata2,chp); //!!!only one chip!!!
    for(short y=step;y<256;y+=(256/pix_per_row)){
	for(short x=0;x<256;x++){
	    if(pix_tempdata2[y][x]>=20 and pix_tempdata2[y][x]!=11810){
		//if (pix_tempdata2[y][x]>=200) {std::cout << "hits for thl " << thl <<" :" << pix_tempdata2[y][x] << std::endl;}
		p3DArray[y][x][array_pos] = pix_tempdata2[y][x];
		//if(LFSR_LookUpTable[(*VecData)[chp][y][x]]>=20 and LFSR_LookUpTable[(*VecData)[chp][y][x]]!=11810){
		//p3DArray[y][x][array_pos] = LFSR_LookUpTable[(*VecData)[chp][y][x]];
		sum[y][x]+=p3DArray[y][x][array_pos]*(array_pos);
		hit_counter[y][x]+=p3DArray[y][x][array_pos];
	    }
	    else{
		p3DArray[y][x][array_pos] = 0;
		sum[y][x]+=0;
		hit_counter[y][x]+=0;
	    }
	}
    }
#+end_src
And in the =THSopt= the code to compute the mean:

#+begin_src c++
	for(y=0;y<256;y++){
	    for(x=0;x<256;x++){
		if (hit_counter0[y][x]!=0){
		    mean0[y][x] = sum0[y][x]/hit_counter0[y][x];
		    mean0entries += 1;
		    summean0 += mean0[y][x];
		}
		if (hit_counter15[y][x]!=0){
		    mean15[y][x] = sum15[y][x]/hit_counter15[y][x];
		    mean15entries += 1;
		    summean15 += mean15[y][x];
		}
	    }
	}
#+end_src

Length of shutter used is
#+begin_src c++
    // calling CountingTime with second argument == 1
    // corresponds to n = 1, power of 256
    fpga->CountingTime(10, 1);
#+end_src
(could compute the length, but not important right now)

Given that the =THscan= is run for each THL value (and thus summing up
all contributions of all THL values for =sum0=), the algorithm
effectively computes:
#+begin_src
mean = Σ_i #hits_i * THL_i / Σ_i #hits_i
#+end_src
which is simply *the weighted mean of the =THL= value, weighted by the
number of hits.* Essentially we compute the THL value with the most
dominant noise? In a sense it makes sense as changing the 4-bit DAC
will move around the position of that noise effectively. The 

The point of interest then here is the fact that the number of hits
depends on the THL value strongly. We only see the number of injected
test pulses, if we're above the noise. Ideally we don't want to see
any noise due to too low =THL= range. Therefore let's check what is
used in TOS.

We will verify this by computing the same value for an S-curve
calibration file:
#+begin_src nim
import ggplotnim

const path = "/home/basti/septemH_calibration/SCurve/chip_3/voltage_100.txt"
let df = readCsv(path, sep = '\t', header = "#", colNames = @["THL", "counts"])
  .filter(f{`THL` > 424})
echo df
let thls = df["THL", float]
let counts = df["counts", float]
var sum = 0.0
var hits = 0.0
for (thl, count) in zip(thls, counts):
  sum += count * thl
  hits += count
echo "Mean value = ", sum / hits
#+end_src

#+RESULTS:
| DataFrame |  with |      2 |           columns | and | 175 | rows: |
|       Idx |   THL | counts |                   |     |     |       |
|    dtype: |   int |    int |                   |     |     |       |
|         0 |   425 |   1000 |                   |     |     |       |
|         1 |   426 |   1000 |                   |     |     |       |
|         2 |   427 |   1000 |                   |     |     |       |
|         3 |   428 |   1000 |                   |     |     |       |
|         4 |   429 |   1000 |                   |     |     |       |
|         5 |   430 |   1000 |                   |     |     |       |
|         6 |   431 |   1000 |                   |     |     |       |
|         7 |   432 |   1000 |                   |     |     |       |
|         8 |   433 |   1000 |                   |     |     |       |
|         9 |   434 |   1000 |                   |     |     |       |
|        10 |   435 |   1000 |                   |     |     |       |
|        11 |   436 |   1000 |                   |     |     |       |
|        12 |   437 |   1000 |                   |     |     |       |
|        13 |   438 |   1000 |                   |     |     |       |
|        14 |   439 |   1000 |                   |     |     |       |
|        15 |   440 |   1000 |                   |     |     |       |
|        16 |   441 |   1000 |                   |     |     |       |
|        17 |   442 |   1000 |                   |     |     |       |
|        18 |   443 |   1000 |                   |     |     |       |
|        19 |   444 |   1000 |                   |     |     |       |
|           |       |        |                   |     |     |       |
|      Mean | value |      = | 463.8075954222876 |     |     |       |

which results in a mean value of 463.8. Given the range of data
that's, surprise, what we would expect from a weighted mean with the
hit counter used.

Of course, in the =THS= optimization the input is purely noise and not
a fixed set of test pulses.

*** Final =THL= (threshold) DAC value selection [0/1]

... THL scan at desired shutter length! Semi automatically. Scan a
take no noise + 2

Once the detector is =THS= optimized and threshold equalized, the
final threshold value of the =THL= DAC can be determined for the data
taking. While measurements like an S-Curve scan (see
sec. [[#sec:daq:scurve_scan]]) can be used to understand where the noise
level of the chip is in terms of =THL= values, it is typically not a
reliable measure as the real noise depends strongly on the shutter
length. If an experiment - like a low rate experiment as CAST -
requires long shutter lengths, the best way to determine the lowest
possible noise-free =THL= value is to perform a simple scan through
all =THL= values using the shutter length in use for the experiment.

For a correctly equalized chip a sharp drop off of noisy pixels should
be visible at a certain threshold. In principle the =THL= value at
which no more pixels are noisy is the ideal =THL= value.

- [ ] *REPHRASE AND NOT TALK ABOUT ENC HERE?*
Each Timepix pixel has an electronic noise charge (ENC) of *CHECK
THIS* electrons. Of course the behavior of the charges on the pixels
are statistically distributed. For the different calibrations
typically very short shutter opening times are used to get fast
calibrations. For practical data takings at experiments like CAST,
very long shutter times on the order of $\mathcal{O}(> \SI{1}{\s})$
are used however. Due to the statistical nature of noise, a =THL=
value that is noise less may not be fully noise free for long
shutters. Therefore, one often uses =THL= values that are slightly
larger (i.e. ~3 values larger of the 10 bit DAC).

In this sense the S-Curve scan is a good cross check for whether the
=THL= value seems sensible, but in practice a =THL= scan with a longer
shutter time is more useful. 

- [ ] *CHECK ENC VALUE OF TIMEPIX AND CITE TIMEPIX PAPER*
  -> ENC is ~100 (timepix paper), but the ENC isn't the relevant
  property here. I think I misunderstood what the ENC really is.
- [ ] *FOR THE SECTION ABOVE I THINK ONLY THE MINIMALLY DETECTABLE
  CHARGE IS RELEVANT?*
- [ ] *REWRITE FULL SECTION WITH A CLEAR HEAD*  

*** ToT calibration
:PROPERTIES:
:CUSTOM_ID: sec:daq:tot_calibration
:END:

The purpose of the ToT (\textbf{T}ime \textbf{o}ver
\textbf{T}hreshold) calibration is not to perform a calibration for
stable operation of a Timepix based detector, but rather to interpret
the data received. It is needed to interpret the =ToT= values recorded
by each pixel as a charge, i.e. a number of recorded electrons.

This is done by injecting charges onto the individual pixels - 'test
pulses'. Capacitors are present to inject very precise voltage bursts
onto the pixels. In case of the Timepix 1, each pixel uses a
capacitance of \SI{8}{fF} \cite{timepix_manual}. Knowing the
capacitance and the voltage induced on them, the number of injected
electrons can be easily calculated from

\[
Q = C U.
\]

By varying the injected charge and recording the resulting ToT values
of the pixels a relation between electrons and ToT values is
determined:

#+begin_comment
  ## calculates the charge in electrons from the TOT value, based on the TOT calibration
  ## from MarlinTPC:
  ## measured and fitted is ToT[clock cycles] in dependency of TestPuseHeight [mV]
  ## fit function is:
  ##   ToT[clock cycles] = a*TestPuseHeight [mV]  + b - ( c / (TestPuseHeight [mV] -t) )
  ## isolating TestPuseHeight gives:
  ##   TestPuseHeight [mV] = 1/(2*a) * (ToT[clock cycles] - (b - a*t) +
  ##                         SQRT( (ToT[clock cycles] - (b - a*t))^2 +
  ##                               4*(a*b*t + a*c - a*t*ToT[clock cycles]) ) )
  ## conversion from charge to electrons:
  ##   electrons = 50 * testpulse[mV]
  ## so we have:
  ## Charge[electrons] = 50 / (2*a) * (ToT[clock cycles] - (b - a*t) +
  ##                     SQRT( (ToT[clock cycles] - (b - a*t))^2 +
  ##                           4*(a*b*t + a*c - a*t*ToT[clock cycles]) ) )
#+end_comment

\[
f(p) = a p + b - \frac{c}{p - t}
\]
where $a, b, c$ and $t$ are parameters to be determined via a
numerical fit and $p$ is the test pulse height in \si{mV}.

As such, inverting the relation this can be used to compute a charge
for a given =ToT= value: 

\[
f(\mathrm{ToT}) = \frac{α}{2 a} \left( \mathrm{ToT} - (b - a t) +
\sqrt{ \left( \mathrm{ToT} - (b - a t) \right)^2 + 4 (a b t + a c - a
t \mathrm{ToT} ) } \right)
\]
where $\mathrm{ToT}$ is the time over threshold value recorded for a
pixel, the constants $a, b, c, t$ the fit parameters determined above
and $α$ the conversion factor relating the number of electrons from a
pulse height of $\SI{1}{mV}$. 

An example of a ToT calibration of one chip is shown in
fig. [[fig:septem:tot_calibration_example]].

*TODO*:
- [ ] add =--outpath= argument to =plotCalibration= and use it to
  place it where we read it from
#+begin_src sh :exports none
# To generate fig:septem:tot_calibration_example
plotCalibration --tot --chip=3 --runPeriod=Run2 --useTeX
#+end_src

#+ATTR_LATEX: :width 0.8\textwidth
#+NAME: fig:septem:tot_calibration_example
#+CAPTION: Example of a ToT calibration measurement for the chip *INSERT CHIP*
#+CAPTION: as it was done for the CAST data taking period 2. *TODO: REPLACE BY TikZ!*
[[~/phd/Figs/tot_calib_3.pdf]]

Required understanding for our charge calibration.

Show function that is being fitted to it.

- [ ] *NOTE: AS FAR AS I CAN TELL, THE TOT CALIBRATION ALREADY REQUIRES A CORRECT =THL= DAC VALUE!*

*** S-Curve scan [3/15]
:PROPERTIES:
:CUSTOM_ID: sec:daq:scurve_scan
:END:

The S-Curve scan is one of 2 different ways to determine the optimal
=THL= value.

- [ ] *MAIN PURPOSE IS NOT!! THL VALUE DETERMINATION*


The purpose of the S-curve scan is to understand the relationship
between injected charges in electron and the =THL= DAC values by
providing a ${\text{\# } e^-}/\mathtt{THL}\text{ step}$ number (or
without a =ToT= calibration $\mathtt{ToT}/\mathtt{THL}$). 

It works by injecting charges onto each pixel and checking the pixel
response of each pixel at different =THL= values. Below a certain
=THL= value all pixels will respond to the injected charge. At some
point certain pixels will be insensitive to the induced charge and a
90° rotated "S" will form. By fitting an error function to this S an
ideal =THL= value can be deduced.

By calculating =THL= value at which half of all test pulses are
recorded, we can compute the number of electrons corresponding to that
=THL= DAC value, as we know the amplitude of the test pulse and thus
number of injected electrons.

Fig. [[fig:daq:s_curve_example]] shows an S-Curve scan of chip 0 of the
Septemboard using the calibration from July 2018. The center peak in
the middle is the noise peak of the detector at the shutter length
used for the S-Curve scan. The symmetrical shape is due to specific
implementation details of how the pixels function, the upper side is
the one of interest. The falling edge of each curve can be fit by the
cumulative distribution function of a normal distribution. The center
point (half way between both plateaus) corresponds to the effective
threshold of the detector at that injected charge.

- [ ] *TURN INTO IF ELSE FUNCTION FOR z* (defined in seqmath)
  #+begin_src nim
  let z = (x - x0) / (sigma * sqrt(2.0))
  if z > 1.0:
    result = 0.5 * erfc(z)
  else:
    result = 0.5 * (1.0 - erf(z))

  #+end_src

#+NAME: eq:daq:s_curve_fit_function  
\[
f(μ, σ, N) = \frac{N}{2} · \text{erfc}((x - μ) / (σ · \sqrt{2}))
\]

where the parameter $N$ is simply a scaling factor and $μ$ represents
the x value of the half-amplitude point. $σ$ is the spread of the drop
and $\text{erfc}$ is the complementary error function $\text{erfc}(x)
= 1 - \text{erf}(x)$. The error function is of course just the
integral over a normal distribution up to the evaluation point $x$:

\[
\text{erf}(x) = \frac{2}{\sqrt{π}} ∫_0^{x} e^{-t²} dt
\]

Given that the number of injected electrons is known for each test
pulse amplitude (see sec. [[#sec:daq:tot_calibration]]), we can compute
the relationship of the number of electrons per =THL= value step. This
is called the =THL= calibration and an example corresponding to
fig. [[fig:daq:s_curves_example]] is shown in
fig. [[fig:daq:thl_calibration_example]], where the =THL= values used
correspond to the $μ$ parameters of
eq. [[eq:daq:s_curve_fit_function]]. The resulting fit is useful, as it
allows to easily convert a given =THL= DAC value into an effective
number of electrons, which then corresponds to the effective threshold
in electrons required to activate a pixel on average. When looking at
the distribution of charges in a dataset, that cutoff in electrons is
of interest (see sec. [[#sec:daq:polya_distribution_threshold]]).

- [ ] *ADD FIT FUNCTION FOR SCURVE*

- [ ] *REFER TO THE CODE THAT DOES THE FIT*
  https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/calibration/calib_fitting.nim#L111

#+CAPTION: S-Curve scan of chip 0 of the Septemboard using the calibration from
#+CAPTION: July 2018. The scan works by injecting \num{1000} test pulses at different
#+CAPTION: amplitudes onto the pixels. Each line represents one such measurement
#+CAPTION: and each point is the mean number of counted hits for all pixels with injected
#+CAPTION: test pulses.
#+CAPTION: The center peak in the middle is the noise peak of the
#+CAPTION: detector. The symmetrical shape is due to specific implementation
#+CAPTION: details of how the pixels function. The upper side is the one of
#+CAPTION: interest. The falling edge of each curve can be fit by the complement of the
#+CAPTION: cumulative distribution function of a normal distribution. The center point
#+CAPTION: (half way between both plateaus) corresponds to the effective threshold 
#+CAPTION: of the detector at that injected charge. The fit parameters for all calibrations
#+CAPTION: are shown in tab. *INSERT*.
#+NAME: fig:daq:s_curves_example
[[~/phd/Figs/detector/calibration/s_curves_0.pdf]]

#+CAPTION: The =THL= calibration can be used to gauge the 'threshold gain' the
#+CAPTION: =THL= DAC has on the number of electrons required to cross the threshold.
#+CAPTION: The =THL= DAC in the Timepix normally adjusts the threshold by about
#+CAPTION: \num{25} electrons per DAC value \cite{timepix_manual}, which is reproduced
#+CAPTION: well here (parameter $1/m$). The root of the linear fit (written as
#+CAPTION: $f⁻¹(y=0)$ in the annotation) corresponds to the position of the noise peak
#+CAPTION: in fig. [[fig:daq:s_curves_example]].
#+NAME: fig:daq:thl_calibration_example
[[~/phd/Figs/detector/calibration/thl_calibration_chip_0.pdf]]



- [ ] *FIX UP TYPESETTING OF FIT PARAMETERS IN THL PLOT*

- [ ] *INSERT AND REFERENCE TABLE OF ALL FIT PARAMETERS FOR THE SCURVES*

- [ ] *UNDERSTAND HOW WE CAN USE SCURVE TO DEDUCE THRESHOLD AND EXPLAIN IT*

- [ ] *FIX PARAMETERS OF THL CALIBRATION. THEY ARE NONSENSICAL AND NOT ALIGNED*

- [ ] *CHECK WHAT 25e/THL IS CALLED IN TABLE OF TIMEPIX MANUAL*

- [X] *ADD THAT AT EVEN LOWER VALUE WE JUST SEE NOISE AND THEN DUE TO
  IMPLEMENTATION DETAILS THE WHOLE THING INVERTS*

- [X] *ADD ITS OWN SHORT SECTION ABOUT THRESHOLD SCANNING WITH BELOW
  REWRITTEN TEXT*

- [ ] *ADD NUMBER OF EXPECTED ELECTRONS A THRESHOLD AS MENTIONED IN TIMEPIX ORIGINAL PAPER*

- [X] *PLOT OF SCURVE SCANS*

- [ ] *APPENDIX ALL SCURVE SCANS FOR CAST DATA TAKING*

- [ ] *S-CURVE CAN BE USED TO DETERMINE #electron / THL DAC VALUE*
  (first gets THL value against pulse height of course)
- [ ] *MAKE THAT FIT AND SHOW EXAMPLE*

- [ ] *ADD EQUATION FOR MINIMUM DETECTABLE CHARGE AND GIVE A NUMBER*  

**** Compute electrons per THL DAC value [0/2]                  :noexport:

- [ ] *FIGURE OUT WHY 2017 CALIBRATION HAS ABOUT 50e/THL COMPARED TO
  25e/THL!*

- [ ] *REPLACE BELOW BY =plotCalibration= CALL?* That already handles
  it, even though currently via plotly.


For the S-Curve plot 
#+begin_src sh
./plotCalibration --scurve --chip 0 --runPeriod Run3 --useTeX --legendX 200.0 --legendY 3800
#+end_src
and for the THL calibration:
#+begin_src sh
./plotCalibration --scurve --chip 0 --runPeriod Run3 --useTeX --legendX 422.0 --legendY 3550
#+end_src
the only difference being the legend placement (as the coordinates are
applied to both plots).

The following is essentially the main code required to plot the
SCurves, determine the middle point and fit THL calib (not the SCurve
fit though):
#+begin_src nim :tangle /home/basti/phd/code/s_curve_electrons_per_thl.nim
import std / [strutils, strscans, os, strformat]
import ggplotnim
import unchained

proc charge(voltage: mV): UnitLess =
  ## Returns the number of electrons given a voltage pulse of amplitude `voltage`
  ## at the 8.fF capacitor of the Timepix1
  result = 8.fF * voltage / e

#const path = "/home/basti/septemH_calibration/SCurve/chip_3/voltage_*.txt"
#const path = "/home/basti/septemH_calibration/CalibJul2018/SCurves/chip_1/voltage_*.txt"
const path = "/home/basti/septemH_calibration/SeptemH_FullCalib_InGridDatabase/chip3/SCurve/voltage_*.txt"
#const path = "/home/basti/septemH_calibration/SeptemH_FullCalib_2018_2/chip0/SCurve/voltage_*.txt"
var charges = newSeq[float]()
var thls = newSeq[int]()
for file in walkFiles(path):
  let (success, _, voltage) = scanTuple(file.extractFilename, "$*_$i.txt$.")
  if voltage == 0: continue # skip 0
  charges.add charge(voltage.mV)
  ## we'll do the simplest approach to get the correct THL value:
  ## - strip everything before noise peak (to have single THL value)
  ## - compute
  var df = readCsv(file, sep = '\t', header = "#", colNames = @["THL", "counts"])
  let thlAtMax = df.filter(f{int: `counts` == `counts`.max})["THL", int][0] # must be single element
  const TestPulses = 1000
  df = df.filter(f{`THL` > thlAtMax})
    .mutate(f{int: "DiffHalf" ~ abs(`counts` - TestPulses div 2)})
    .filter(f{int: `DiffHalf` == min(col("DiffHalf"))}) # f{int: `DiffHalf` < 200})
  thls.add df["THL", int][0] # must be single element

import polynumeric
let fit = polyFit(thls.toTensor.asType(float),
                  charges.toTensor,
                  polyOrder = 1)
echo fit
proc linear(x, m, b: float): float = m * x + b

let thlFit = linspace(thls.min, thls.max, 10)
let chargesFit = linspace(charges.min, charges.max, 10)
var dfFit = toDf({ "thls" : thlFit,
                   "charges" : thlFit.map_inline(linear(x, fit[1], fit[0])) })
echo dfFit
let df = toDf(thls, charges)

ggplot(df, aes("thls", "charges")) + 
  geom_point() +
  geom_line(data = dfFit, aes = aes("thls", "charges"), color = parseHex("FF00FF")) +
  xlab("THL DAC") + ylab("Injected charge [e⁻]") + 
  ggtitle(&"Fit parameters: m = {fit[1]:.2f} e⁻/THL, b = {fit[0]:.2f} e⁻") +
  ggsave("/home/basti/phd/Figs/charge_per_thl.pdf")
#+end_src

#+RESULTS:

**** Compute minimally detectable charge                        :noexport:

Ref:
- \cite{LLOPART2007485_timepix} Timepix paper
- \cite{LlopartCudie_1056683} Llopert PhD thesis

The following quotes explain how to compute the effective threshold:

page 5/10:
#+begin_quote
The electronic noise and effective threshold can be measured using the
s-curve method [8] when the pixel is set in counting mode.
#+end_quote

page 5/10:
#+begin_quote
The effective threshold is at 50% of this s-curve. The charge
difference between the 97.75% and 2.25% of the s- curve is four times
the RMS noise of the front end assuming a gaussian distributed noise.
#+end_quote

#+begin_quote
The measured electronic noise is 99:4 ± 3:8 e⁻ rms for hole
collection and 104:8 ± 6 e⁻ rms for electron collection.  The
measured DAC step gain is 24:7 ± 0:7 e⁻ =step for hole collection
and 25:4 ± 1:2 e⁻ =step for electron collection.
#+end_quote

page 7/10:
#+begin_quote
The threshold variation before equalization is
~240 e⁻ rms and after equalization the achieved noise free
threshold variation is ~35 e⁻ rms for both polarities.
#+end_quote

page 7/10:
#+begin_quote
The minimum detectable charge can be calculated by quadratically
adding the measured electronic noise and the threshold variation
because both measurements are uncorrelated.
#+end_quote

#+begin_quote
Before equalization the minimum detectable charge for the full matrix
is ~1600 e⁻ and after equalization is ~650 e⁻ for both polarities.
#+end_quote

This means:
- [ ] compute the 97.75 ⇔ 2.25% range of the S-curve. Yields 4 times
  RMS noise. Width in THL of that can be converted to #e⁻ using THL
  calibration.
  -> electronic noise $N_e$
- [ ] compute width of optimized threshold variation based on
  histogram. Fit gaussian (?) to optimized threshold variation. σ of
  that gaussian is width in THL. Convert THL to electrons.
  -> threshold variation $N_t$

- [ ] *CHECK IF THIS IS CORRECT*:
  If I'm not mistaken, the noise peak we see in the S-curve scan is
  essentially the same as the optimized distribution from the
  threshold equalization.

Then with those two parameters we compute the effective detectable
charge as:

\[
N_d = √(N_e² + N_t²)
\]

which for the numbers listed above yields

\[
N_d = √(105² + 35²) = 110
\]

which is not close to the expected 650 e⁻!

Checking in the PhD thesis of Llopert, page 115, equation 4.5 is:

\[
\text{MinDetect}Q = 6·\sqrt{ ENC² + σ_{\text{dist}}²}
\]
which then works out nicely (110·6 = 660 is close enough)!

So in theory we can compute this for all our chips and all
calibrations.

- [ ] *CALCULATE FOR ALL CHIPS AND PUT INTO APPENDIX*


*** Pólya distribution & gas gain
:PROPERTIES:
:CUSTOM_ID: sec:daq:polya_distribution_threshold
:END:

In a gaseous detector the gas amplification (see
sec. [[sec:theory:gas_gain_polya]]) allows to easily exceed the minimum
detectable charge of $\mathcal{O}(\SIrange{500}{1000}{e^-})$. The
typically used =THL= threshold will be quite a bit higher than the
'theoretical limit' however for multiple reasons. One can either
compute the effective threshold in use based on the =THL= calibration
as explained in sec. [[sec:daq:scurve_scan]], or use an experimental
approach by utilizing the Pólya distribution as introduced in
sec. [[#sec:theory:gas_gain_polya]]. By taking data over a certain period
of time and computing a histogram of the charge values recorded by
each pixel, a Pólya distribution naturally arises.

This Pólya distribution has two different use cases. First of all it
is the source of the empirical gas gain the detector actually operated
under. On the one hand one of the parameters of the Pólya
parametrization as introduced in section [[#sec:theory:gas_gain_polya]] is
a measure for the gas gain. On the other hand, the mean of the
histogram can also be used as a measure for the gas gain (which is the
main number used in later chapters).

Secondly, the Pólya can also be used to determine the actual
activation threshold of the detector, by simply checking what the
lowest charge is that sees significant statistics.

- [X] *TALK ABOUT GAS GAIN*
- [ ] *MAYBE MOVE EXPLANATION ABOUT HOW TO EXTRACT GAS GAIN FROM POLYA
  TO EXPLANATION IN THEORY?*
- [ ] *IF IT STAYS HERE, INTRODUCE WHAT "MEAN OF HISTOGRAM" EVEN MEANS*  
  
An example of such a Pólya distribution is seen in
fig. [[fig:daq:polya_example_chip0]], where we see the same chip 0 using
the same calibration from July 2018 as in the figures in the previous
section [[#sec:daq:scurve_scan]]. The data is a \SI{30}{min} interval of
background data at CAST. The reasoning behind looking at a fixed time
interval for the Pólya will be explained in section [[#sec:?:gas_gain_time_binning]].
The pink line represents the fit of the Pólya
distribution to the data. The dashed part of the line was not used for
the fit and is only an extension using the final fit parameters. The
cutoff at the lower end due to the chip's threshold is clearly
visible. The fit determines a gas gain of about \num{2700}, compared
to the mean of the data yielding about \num{2430}. 

Based on the data a threshold value of - very roughly - \num{1000} can
be estimated. Using the =THL= calibration of the chip as shown in
fig. [[fig:daq:thl_calibration_example]] yields a value of

\[
Q(\text{THL} = 419) = 26.8 · 419 - 10300 = 929.2
\]

where we used the fit parameters as printed on the plot ($1/m$ and
$f⁻¹(y=0)$) and the =THL= DAC value of \num{419} as used during the
data taking for this chip. Indeed, the real threshold is in the same
range, but clearly a bit higher than the theoretical limit for this
chip. This matches our expectation.

#+CAPTION: An example of a Pólya distribution of chip 0 using the calibration
#+CAPTION: of July 2018 based on \SI{30}{min} of background data.
#+CAPTION: The lower cutoff is easily visible. The pink line represents the
#+CAPTION: fit of the Pólya distribution to the data. In the dashed region the
#+CAPTION: fit was only extended. The 
#+NAME: fig:daq:polya_example_chip0
[[~/phd/Figs/gas_gain_run_306_chip_0_placeholder_example.pdf]]

- [ ] *USE IT TO DETERMINE THRESHOLD*
- [X] *COMPUTE THRESHOLD IN EXAMPLE FROM THL CALIB AND COMPARE*
- [X] *INTRODUCE IT IS USED AS THE PRACTICAL WAY TO COMPUTE GAS GAIN*
- [ ] *MENTION THAT WE BIN BY TIME OF 90min AND THAT WE WILL EXPLAIN
  IN LATER CHAPTER HOW TIME INTERVAL WAS CHOSEN*

Explain how all charge values combined as a histogram generate a
~Pólya distribution from which we can deduce the gas gain.

**** Generate Polya plot for chip 0, run period 3 :noexport:

The current placeholder polya distribution (although it's the right
chip and calibration) is:
#+begin_src sh
basti at void in /mnt/1TB/CAST/2018_2/out/DataRuns2018_Raw_2020-04-28_16-13-28 λ
  cp gas_gain_run_306_chip_0_5_30_min_1545294386.pdf \
     ~/phd/Figs/gas_gain_run_306_chip_0_placeholder_example.pdf
#+end_src

** Temperature monitoring


Well, move this to the TOS part that already touches on temperature
monitoring and make it a subsection of that? Then the footnote can
maybe become regular text as well?

#+begin_src
# Temperature log file
# Temp_IMB  Temp_Septem   DateTime
26.5186     42.1472	      2019-02-16.16:11:45
26.5217     42.2798	      2019-02-16.16:11:51
26.5202     42.4371	      2019-02-16.16:11:57
26.5309     42.5944	      2019-02-16.16:12:03
26.5324     42.7347	      2019-02-16.16:12:09
26.5355     42.8627	      2019-02-16.16:12:15
26.5416     42.9707	      2019-02-16.16:12:21
26.5432     43.0771	      2019-02-16.16:12:27
26.5616     43.1804	      2019-02-16.16:12:33
26.5692     43.2684	      2019-02-16.16:12:39
26.5708     43.3454	      2019-02-16.16:12:45
26.5908     43.4164	      2019-02-16.16:12:51
26.5969     43.4904	      2019-02-16.16:12:57
26.6015     43.5598	      2019-02-16.16:13:03
26.6184     43.6154	      2019-02-16.16:13:09
26.6215     43.6709	      2019-02-16.16:13:15
26.6368     43.7264	      2019-02-16.16:13:21
...
#+end_src

** Event display

** Scintillator calibration - maybe here after all?


* Data reconstruction [0/1]
#+LATEX: \minitoc

- explain the whole data reconstruction pipeline? What we do with
  ingrid data, clustering, reconstruction
- everything up to energy calibration
- [ ] wherever we finally show the real calibrations of the detector
  for each run, show:
  - the full FSR (for one chip, then differences for each,
    particularly THS & THL)
  - show plot of THL calibration from SCurves, with the THL value as a
    "rectangle" line (from y axis to fit, down to x axis)
  - in Polya plot show the theoretical threshold in electrons as a
    vertical line (computed from the used THL DAC value and THL calibration)

** FADC

*** Pedestals & signal reconstruction

Yes, this needs to be about essentially a FADC calibration.

*ALL THE SIGNAL RECONSTRUCTION GOES TO A CHAPTER LATER WHERE WE EXPLAIN INGRID RECO*

Before the FADC data can be used, the raw data needs to be converted
from the internal, cyclic representation into a 10240 long array.

...

By default each channel of the FADC has an arbitrary value in the
range between \num{0} to \num{10000}. This needs to be corrected for
by taking a so called 'pedestal run'. It is simply a readout of the
FADC in the absence of any signal. This pedestal run then is
subtracted from each actual FADC event to remove the pedestal
baseline. 

*** Noise sensitive

Because of the small amplitude of the associated signals induced on
the grid, electromagnetic interference is a serious issue with this
FADC setup. Ideally, the detector should be installed in a Faraday
cage and a short, shielded LEMO cable should be used to connect it to
the 

** Scintillator calibrations

- [ ] *SIPM CALIBRATED IN BSC OF JANNES*

- [ ] *VETO PADDLE CALIBRATED IN RD51*

** FADC calibration

FADC does not require a proper calibration. However, better
measurements of the effect of the different integration /
differentiation settings of the amplifier would have been very
valuable. [fn:detector_fadc_amp_measurements]

Outside of that 

[fn:detector_fadc_amp_measurements] 

* Detector installation at CAST & data taking                         :Part3:
#+LATEX: \minitoc
** Detector

The InGrid Mk. IV Septemboard detector is a gaseous detector intended
for operation at the CAST experiment behind the LLNL telescope (airport
side). 

Note that this document does not attempt to be a complete reference of
the detector down to the physical principles. It is rather supposed to
provide an overview of the relevant pieces of information regarding
its operation at CAST. 

*** Components

The full (main) detector as used in 2017/18 is shown in
Fig. [[fig:mkIV-ingrid]].
#+CAPTION: InGrid Mk. IV Septemboard detector used at CAST in 2017/18.
#+NAME: fig:mkIV-ingrid
[[file:~/org/Doc/Detector/figs/detector-mk4c-assembly-exploded-whitebg-no-cables-cropped.jpg]]

It consists of a $\SI{3}{\cm}$ drift volume, which is filled with
$\ce{Ar} / \ce{iC_4H_{10}}$ at $\SI{1050}{\milli \bar}$. At the top of
the detector, separating the gas volume from the vacuum on the
telescope side, is a $\SI{300}{\nm}$ $\ce{Si_x N_y}$ window, with
$\num{4}$ $\ce{Si}$ ribbons of $\SI{500}{\um}$ thickness and
$\SI{200}{\um}$ width.

These windows are tested up to $\Delta P = \SI{1.5}{\bar}$ pressure
difference for at least $\num{5}$ cycles, before being commissioned
for usage at CAST.

The main part of the detector, is the Septemboard, a 7 chip carrier of
InGrids. The center chip is the main data taking chip, on which the
telescope focuses the X-rays converted in the magnet (axion or
chameleon image from the
Sun), while the outer ring of chips is used as a background
suppression tool, in case long tracks passing through the corners of
the center chip. 
#+BEGIN_COMMENT
*include typical xray and track*
*Include potential axion and chameleon images*.
#+END_COMMENT

Aside from the main detector as presented in fig. [[fig:mkIV-ingrid]],
the detector is supported by two scintillators and a flash ADC (FADC).
- one SiPM on the backend of the detector (as depicted in
  fig. [[fig:mkIV-ingrid]]), to veto cosmics passing through the detector
  orthogonally
- one veto scintillator paddle above the lead shielding
- an FADC to read out decoupled analogue grid signal of center chip,
  which is induced by the electrons drifting through towards the Timepix
FADC and veto paddle can be used together to remove cosmics, which
trigger X-ray fluorescence lines of the detector material, by
looking at the time difference between the last veto signal and an
FADC signal. If it is smaller than $\sim\SI{3}{\micro\second}$, there
is a potential correlation. See fig. [[fig:fadc-trigger-schematic]] for a
schematic of the functioning principle.

#+CAPTION: Working principle of FADC and veto scintillator
#+NAME: fig:fadc-trigger-schematic
[[file:~/org/Doc/Detector/figs/scintillator_FADC_correlation.pdf]]

**** Veto scintillator

The veto scintillator in use is the old MM veto scintillator.

The scintillator has a Canberra 2007 base, which accepts positive
HV. The PMT is a Bicron Corp. 31.49x15.74M2BC408/2-X, where the first
two numbers are the scintillators dimensions in inch.

The following will briefly discuss the calibration of it, which was
done in the RD51 gaseous detector lab on <2017-10-28 Sat>. 

For calibration an Ortec 9302 amplifier after the PMT with a gain of
20 was used. This is fed into an LRS 621CL discriminator. The PMT and
base are used at a HV of $+\SI{1200}{\volt}$.

Scintillator is of size $\SI{42}{\cm}$ times $\SI{82}{\cm}$. Which is
an area of

#+BEGIN_SRC nim :exports both :results output
let x = 0.42
let y = 0.82
echo x * y 
#+END_SRC

#+RESULTS:
: 0.3444

At a cosmic muon rate of $\sim\SI{100}{\hertz \per \meter \squared
\steradian}$, the expected signal rate of munons is thus $\sim
\SI{33}{\hertz}$.

#+BEGIN_SRC nim :exports both :results output
let area = 0.34
let total_muons = 60000.0
echo area * total_muons
#+END_SRC

#+RESULTS:
: 20400.0

Threshold values are scaled by a factor of 10. Coincedence using
Theodoros 2 scintillator paddles in RD51 lab. 
- upper scinti: $\SI{-2070}{\volt}$
- lower scinti: $\SI{-2050}{\volt}$

Measurement time for each value: $\SI{10}{\minute}$

| Threshold / mV | Counts Szinti | Counts Coincedence |
|----------------+---------------+--------------------|
|           -598 |         31221 |                634 |
|           -700 |         30132 |                674 |
|           -804 |         28893 |                635 |
|           -903 |         28076 |                644 |
|          -1005 |         27012 |                684 |
|          -1103 |         25259 |                566 |
|          -1200 |         22483 |                495 |
|          -1303 |         19314 |                437 |
|          -1403 |         16392 |                356 |
|          -1505 |         13677 |                312 |
|          -1600 |         11866 |                267 |
|          -1701 |         10008 |                243 |

from which a threshold of $\SI{-110}{\milli\volt} was selected, after analysis.




**** Cabling

FADC Trig out:
- trig out -> level adapter (NIM module) into NIM IN, set to +NORM+ /
  *COMPL* (*this is active*)
  TTL out -> TTL signal clipper (TTL 5V -> 2.4V) into port marked =I=
  TTL signal clipper -> adapter board into *left LEMO at back* (viewed
  from behind the crate; cable still at CAST)

FPGA to FADC (shutter signal)
- Adapter board *right LEMO at back* (viewed from behind crate) ->
  level adapter (NIM module), set to *NORM* / +COMPL+ into TTL IN
  NIM out -> FADC EXT EN TRIG

Veto scintillator (*NOTE* this may be *WRONG*; input to adapter board
that is); signal order is reversed!
- Adapter board *left LEMO on top* (viewed from behind the crate,
  input number *1* on adapter board) -> discriminator OUT (top discriminator in NIM module)
  discriminator IN -> back of Amplifier Discriminator NIM module
  amplifier input -> veto scintillator signal
  The signal is needs to be *2.4 V TTL signal!*




*** Efficiency

The combined detector efficiency is given by the combination of X-ray
transmission through the silicon nitride window, its $\SI{20}{\nm}$
$\ce{Al}$ coating and the absorption probability in the gas volume of
the detector. After conversion the actual quantum efficiency of the
InGrids is of $O(1)$.

Fig. [[fig:detector-efficiency]] shows a plot of the combined detector
efficiency.

#+CAPTION: Calculated combined detector efficiency of the InGrid Mk. IV Septemboard detector.
#+NAME: fig:detector-efficiency
[[file:~/org/Doc/Detector/figs/transmission_curves_SiN_window_ind_plus_argon.pdf]]

*** Full detector schematic

The full detector can be presented in a flow chart as seen in
fig. [[fig:detector-flowchart]].

#+CAPTION: Flowchart of the whole detector and readout system
#+NAME: fig:detector-flowchart
[[file:~/org/Doc/Detector/figs/2016_detector_setup_schematic.pdf]]

Note however, that in this plot the SiPM is not illustrated, as it is
connected to the bottom of the intermediate board and only provides an
offline flag to be used in the analysis.


** High voltage supply

The high voltage supply is an iseg HV module, which is located in the
VME crate on the airport side of the magnet. The HV is controlled via
a USB connection to the VME crate, which it shares with the FADC. The
veto scintillator however has its own HV supply, since it needs a
positive HV, instead of a negative one.

The detector uses $\num{7}$ different high voltages. $\num{5}$ of
these are for the detector itself, $\num{1}$ for the SiPM and the last
for the veto scintillator on top. Their voltages are shown in
tab. [[tab:hv]]. 

#+CAPTION: Table of high voltages in use for the InGrid Mk. IV. 
#+CAPTION: Note that the veto scintillator is not controlled via
#+CAPTION: the iseg module, but by a CAEN N470.
#+NAME: tab:hv
#+ATTR_LATEX: :booktabs
| Description | Channel | Voltage / V | TripCurrent / mA |
|-------------+---------+-------------+------------------|
| grid        |       0 |        -300 |            0.050 |
| anode       |       1 |        -375 |            0.050 |
| cathode     |       2 |       -1875 |            0.050 |
| ring 1      |       3 |        -415 |            0.100 |
| ring 29     |       4 |       -1830 |            0.100 |
| veto scinti |       5 |       +1200 |                2 |
| SiPM        |       6 |       -65.6 |             0.05 |


The voltages in use should remain unchanged, however in case they were
to change, the actual values in use are defined in
[[file:~/TOS/config/HFM_settings.ini][~/TOS/config/HFM_settings.ini]].

The HV cables in use are red cables with LEMO HV connectors. They run
from the detector to an iseg HV module sitting in a VME crate on the
airport side of the magnet. The cables are marked with zip ties and
the same names as in tab. [[tab:hv]]. 

The interlock system for the high voltage supply is detailed in
section [[HV interlock]], together with the other interlock systems in place.

** Vacuum system

This section covers the vacuum system of the detector. It is pumped
via a single primary pump and two turbo pumps. One turbo pump is used
to pump the main vacuum vessel of the beam pipe, while the second
small turbo pump is used to pump the interstage part of our X-ray
source manipulator to reduce leakage during movement of the source.

Fig. [[fig:vacuum-schematic]] shows a schematic of the whole vacuum
system. 

#+CAPTION: Schematic of the vacuum system behind the LLNL telescope
#+NAME: fig:vacuum-schematic
#+ATTR_LATEX: :width 1\textwidth :options angle=90
[[file:~/org/Doc/Detector/figs/vacuum_system2017.png]]

The pressures of P3 and P-MM are used as an interlock for VT3 and
the gas supply, respectively. 
#+BEGIN_COMMENT
*check if P3-BA is the correct one, not P3*.

P3 is the correct one
#+END_COMMENT


** Watercooling system & gas supply

In this section the watercooling system as well as the gas supply is
discussed. In section [[Combined schematic]] a combined schematic of both systems is
shown. 

*** Watercooling 

In order to keep the detector cool enough to avoid noise and damage to
the septemboard, a watercooling system is used. This section describes
the relevant information for the system.

To readout the temperature two PT1000 temperature sensors are
installed on the detector. One is located on the bottomside of the
intermediate board (outside of the detector volume), while the other
is located on the bottom side of the Septemboard. This temperature
$T_{\text{Septem}}$ is also included in the schematic
[[fig:detector-schematic]], because it is part of the HV interlock, as
described in [[HV interlock]].

Fig. [[fig:watercooling]] shows the main part of the system including the
pump, reservoir and radiator. The tubing is specifically chosen in
*blue* to clear up potential confusion with other tubes used in the
detector system. These tubes use special Festo quick couplings, which
cannot be connected to the connectors of the gas supply, to avoid
potential accidents. The tubes have zipties installed on them, which
label the tubes as well, with the naming convention as it is used in
fig. [[fig:detector-schematic]]. 
*NOTE: NAMES NOT CORRECT YET!*

#+CAPTION: Picture of the water cooling system of the InGrid Mk. IV detector
#+NAME: fig:watercooling
<file to be inserted>

**** Maintenance

At the end of every shift it should be checked, whether the water
level in the reservoir is still within the black lines seen in
Fig. [[fig:watercooling]]. If not, water should be added by the shift
coordinator (or trusted shifters; you know if you're one of these). 


*** Gas supply

The gas supply uses red tubing (in parts where flexible tubing is
used) to differentiate itself from the watercooling
system. Additionally, the tubes have zipties showing which tube is
which. These are located on both ends of the tubes. The naming
convention is the same as in [[fig:detector-schematic]].

The connectors of the gas line are standard Swagelok connectors.

As can be seen in the schematic, the gas supply has 4 valves on the
inlet side and 2 on the outlet side. In addition a buffer gas volume
is installed before the detector for better flow control. 

It follows a short explanation of the different valves:

- $V_{\text{in, 1}}$ is the main electrovalve installed right after the gas
  bottle outside the CAST hall. 
- $V_{\text{interlock}}$ is installed is the electrovalve installed
  below the platform where the beamline is located. This valve is part
  of the gas supply interlock, as described in section [[Gas supply
  interlock]].
- $V_{\text{in, 2}}$ is the manual valve located on the second gas
  supply mounting below the beamline. 
- $V_{\text{in, N1}}$ is the first needle valve, which is located on
  the sceond gas supply mounting below the beamline. It is the one
  part of the flow meter placed there.
- $V_{\text{P}}$ is the valve inside the pressure controller, which is
  placed roughly below the telescope (on the platform), while
  $P_{\text{Detector}}$ is the pressure gauge inside this controller.



*** Combined schematic 

Fig. [[fig:detector-schematic]] shows a combined schematic of both the
watercooling system and the gas supply. Additionally, the relevant
interlock systems and their corresponding members are shown.

#+CAPTION: Combined schematic of the detector system, consisting of the
#+CAPTION: water cooling system and the gas supply. The interlock systems
#+CAPTION: are shown with dashed lines. See section [[Interlock systems]]
#+CAPTION: regarding explanations of when the interlock is activated.
#+NAME: fig:detector-schematic
#+ATTR_LATEX: :width 1\textwidth :options angle=90
[[file:~/org/Doc/Detector/figs/detector_system2017.png]]


** Interlock systems

This section describes the interlock systems, which are related to the
detector. There are 3 interlock systems to speak of. 
- The CAST magnet interlock, which prohibits the gate valve VT3 to be
  opened, if the pressure in the vacuum system is not good enough.
- A gas supply interlock, which makes sure the detector is only
  flushed with gas, if all other parameters are considered nominal
  (mainly a good vacuum in the system).
- A HV interlock, which makes sure the detector is only under HV, if
  the temperature of the detector is still good (otherwise a lot of
  sparks are produced) and the currents on the HV lines are nominal.

*** HV interlock

The HV system is part of an interlock, which tracks the following
properties:
- detector temperature
- currents on HV lines
- TO BE IMPLEMENTED: gas pressure inside the detector

The detector temperature is measured at two points by PT1000
sensors. One of these is located on the bottom side of the
intermediate board (and thus is more a measure the the temperature
surrounding the detector), while the second is located on the bottom
side of the septemboard. The second is the best possible measure for
the temperature of the InGrids. However, there is still a PCB
separating the sensor from the actual InGrids. This means there is
probably a temperature difference of a minimum of $\SI{10}{\celsius}$
between the measured value and the actual temperature of the InGrids. 

Whenever the TOS is configured to use the FADC readout and control the
HV (note: the two are intertwined, since both sit in the same VME
crate, which is controlled via a single USB connection), a background
process which monitors the temperature is started. If the temperature
exceeds the following boundaries
#+BEGIN_EXPORT latex
$\SI{0}{\celsius} \leq T \leq \SI{60}{\celsius}$,
#+END_EXPORT
on the lower side of the septemboard, the HV is shut down
immediately. The lower bound is of less practical value in a physical
sense, but in case of sensor problems negative temperature
values may be reported. As the upper bound a value is taken at which
sparks seen on the pixels become unacceptable. This bound is
potentially going to be lowered to $\SI{50}{\celsius}$ in the future,
at which no noticeable noise is detectable. 

The interlock currents at which the HV trips are already shown in
tab. [[tab:hv]]. During ramp up of the HV, these trip currents are set
higher to avoid trips, while capacitors are being charged.

In the future the gas pressure within the detector is included into
the interlock system to shut down the HV if the pressure inside the
detector leaves a certain safe boundary, since this might indicate a
leak in the detector or an empty gas bottle.

*** Gas supply interlock

The gas supply is also part of an interlock system. In case of a
window rupture the potential amount of gas that might enter the vacuum
system should be limited by electrovalves. In the future the pressure
inside the detector will be included into the gas supply
interlock. This is to make sure the gas inlet and outlet are closed in
case the pressure inside the detector drops (which might indicate a
leak somewhere or an empty gas bottle) or in case of rising
pressure. 

The latter is not as important thought, because a pressure controller is
already installed behind the detector, which controls the flow such
that the pressure stays at $\SI{1050}{\milli \bar}$. While a failure
of the controller is thinkable, potentially leading to a pressure
increase inside the detector, it is questionable whether this could be
dealt with using this interlock system. That is because the pressure
sensor used is part of the pressure controller.

Thus, three electrovalves are placed on the gas line of the
detector. One, $V_{\text{in}}$, is outside of the building next to the
gas bottles (see fig. [[fig:electrovalve-outside]]). The second valve
$V_{\text{interlock}}$ is located right before the buffer volume, next
to the watercooling system, below the shielding platform. The final
electrovalve $V_{\text{out}}$ is located after the pressure
controller on a blue beam, which supports the optical table below the
telescope (see fig. [[fig:electrovalve-V-out]]). These valves are normally
closed, i.e. in case of power loss they automatically close. They are
open if a voltage is applied to them. 

The valves are connected to the pressure sensor $P_{\text{MM}}$ (see
fig. [[fig:vacuum-schematic]]). The pressures to activate the interlock
system is defined by upper and lower thresholds asymmetrically. They
are as follows:
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{MM, Gas enable}} \leq \SI{9.9e-3}{\milli \bar}
\end{align}
#+END_EXPORT
and 
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{MM, Gas disable}} \leq \SI{2e-2}{\milli \bar}
\end{align}
#+END_EXPORT
#+BEGIN_COMMENT
*CHECK THESE VALUES, they are still wrong I believe*.
#+END_COMMENT

#+CAPTION: Location of the electrovalve $V_{\text{in}}$ located outside the building.
#+NAME: fig:electrovalve-outside
[[file:~/org/Doc/Detector/figs/electrovalve_outside.jpg]]

#+CAPTION: Location of the electrovalve $V_{\text{interlock}}$ next to the 
#+CAPTION: watercooling system below the shielding table.
#+NAME: fig:electrovalve-V-interlock
[[file:~/org/Doc/Detector/figs/electrovalve_V_interlock.jpg]]

#+CAPTION: Location of the electrovalve $V_{\text{out}}$ connected to the beam
#+CAPTION: supporting the optical table, on which the telescope is mounted.
#+NAME: fig:electrovalve-V-out
[[file:~/org/Doc/Detector/figs/electrovalve_V_out.jpg]]


*** CAST interlock

The main CAST magnet interlock, as it is relevant to our detector, is
as follows. The gate valve VT3 separating the magnet volume from the
telescope volume is interlocked. Only if the vacuum in the telescope
volume is good enough, VT3 can be opened while the interlock is
activated. 

For this the pressure of $P_{\text{3}}$ is considered relevant
(cp. fig. [[fig:vacuum-schematic]]). The upper and lower thresholds which
activate and deactivate the interlock are asymmetric and as follows:
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{3, VT3 enable}} &\leq \SI{1e-5}{\milli\bar}
\end{align}
#+END_EXPORT
while
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{3, VT3 disable}} &\leq \SI{8e-5}{\milli\bar}.
\end{align}
#+END_EXPORT
This is to make sure there can be no rapid toggling between the two
states during pumping or flushing the system. 


** Operation

This chapter provides some guidance about typical operations necessary
during maintenance or installation of the detector / vacuum system.

*** Ramping the HV

The high voltage supply can be controlled in two different
ways. Besides differing in usability terms (one is manual, the other
automatic), the main difference between the two is the HV interlock,
which is only partially usable in case of the manual HV control.
1. in the manual way using the Linux software supplied by iseg. On the
   InGrid-DAQ computer it is located in
   [[file:/home/ingrid/src/isegControl/isegControl][~/src/isegControl/isegControl]]. Depending on the setup of the
   machine, the software may need superuser rights to access the USB
   connection. With the software the given channel as shown in
   tab. [[tab:hv]] can be set up and the HV can be ramped up. Note: one
   needs to activate SetKillEnable such that the HV is shut down in
   case of a current trip (exceeding of specified current). One should
   then set 'groups' of different channels, so that grid, anode and
   ring 1 are shut down at the same time, in case of a current trip,
   as well as ring 29 and the cathode! In addition the trip current
   needs to be manually set about a factor 5 higher during ramping,
   because of capacitors, which need to be charged first. Otherwise
   the channels trip immediately. In this case the HV interlock is
   restricted to basic current restrictions. Anything detector related
   is not included!
2. in the automatic way via the TOS. The TOS takes care of everything
   mentioned above. To use the TOS for the HV control (and thus also
   use the complete HV interlock, as it exists at the moment), perform
   the following steps:
   1. check [[file:~/TOS/config/HFM_settings.ini][~/TOS/config/HFM_settings.ini]] and compare with tab. [[tab:hv]]
      whether settings seem reasonable
   2. after starting TOS and setting up the chips, call
      #+BEGIN_SRC sh
      > ActivateHFM
      #+END_SRC
      which will set up TOS to use the combined HV and FADC (due to
      both inside the same VME crate, they are intertwined). This
      configures the FADC and reads the desired HV settings, but does
      not set the HV settings on the module yet.
   3. to write the HV to the HV module, call
      #+BEGIN_SRC sh
      > InitHV
      #+END_SRC
      which will write the HV settings from HFM_settings.ini to the HV
      module. At the end it will ask the user, whether the HV should
      be ramped up:
      #+BEGIN_SRC sh
      Do you wish to ramp up the channels now? (Y / n)
      #+END_SRC
      If yes, the ramping progress will be shown via calls to the
      CheckModuleIsRamping() function (which can also be called
      manually in TOS). 
   This should properly ramp up all channels. It is possible that TOS
   fails to connect to the VME crate and hence is not able to ramp up
   the channels. The most likely reason for this is that the
   isegControl software is still open, since only one application can
   access a single USB interface at the same time.

*** Vacuum

The vacuum system as described in sec. [[Vacuum system]] usually does not
require manual intervention during normal operation.

For maintenance the following two sections describe how to pump the
system safely as well as how to flush it with nitrogen. Both processes
are rather delicate due to the sensitive $\ce{Si_x N_y}$
window. Pumping needs to be done slowly, $O(\SI{1}{\milli\bar \per
\second})$. To be able to do this, the needle valve
$V_{\text{Needle}}$ (cf. fig. [[fig:vacuum-schematic]]) is installed. One
may separate the vacuum volume into two separate vacua. A bad vacuum
before the primary pump and after the turbo pumps T1 and T2 and a good
vacuum before the turbo pump T2. There are three connections from the
good vacuum to the bad one. 
1. through T2, closable via $V_{\text{T2}}$, $\SI{40}{\mm}$ tubing
2. through the needle valve $V_{\text{needle}}$, $\SI{16}{\mm}$ tubing
3. through T1 via the manipulator interstage, normally closed (see the
  note below), $\SI{25}{\mm}$ tubing
3 is mainly irrelevant for pumping purposes, since there is no valve
to open or close; it is always closed by a 2-O-ring seal to the good
vacuum. While 1 is the main path for pumping during operation, it is 2
which is used during a pumping down or flushing of the system, since
it can be controlled very granularly. 

For both explanations below, it is very important to always think
about each step (are the correct valves open / closed? etc.). A small
mistake can lead to severe damage of the hardware (turbo pumps can
break, the window can rupture).

_Note_: There is a third very small vacuum volume before T1, which is
the volume up to the manipulator interstage. This volume is separate
from the main good vacuum chamber, due to a 2-O-ring seal on both ends
of the manipulator. Compare with fig. [[fig:vacuum-schematic]] at the
location of the two clamped flanges 'above' the manipulator. One
2-O-ring seal is at the upper flange and one at the lower. This is
because the manipulator part furthest from the beampipe is under
air. In order to seal the air and the vacuum especially during
movement of the source, these seals are in place. However, while the
2-O-ring seals provide decent sealing, it is not perfect. This is why
the small turbo pump T1 is in place at all, to reduce the amount of
air, which might enter the system during source manipulation. Another
aspect to keep in mind is potential air, which can get trapped in
between the two O-rings. This air will be released during movement of
the seals. Especially after the system was open to air, it is expected
that a small pressure increase on $P_{\text{MM}}$ can be seen during
operation, despite T1 being in place. After several movement cycles
, $O(10)$, these peaks should be negligible. 

**** Pumping the vacuum

Before pumping it is a good idea to connect two linear gauges to the
two $P_{\text{Linear}}$ pressure sensors.
To pump the system safely, perform the following steps:
1. Make sure every pump is turned off.
2. Make sure every valve in the system is closed:
   1. $V_{\text{Primary}}$
   2. $V_{\text{Leak}}$
   3. $V_{\text{T2}}$
   4. $V_{\text{Needle}}$
3. Connect a linear gauge to $P_{\text{P, Linear}}$ on the primary pump line.
4. Start the primary pump. Tubing up to $V_{\text{Primary}}$ will be
   pumped, visible on linear gauge connected to
   $P_{\text{P, Linear}}$. Check that the second linear gauge remains
   unchanged, if not $V_{\text{Primary}}$ and $V_{\text{Needle}}$ is
   open!
5. Once $P_{\text{P, Linear}}$ shows $\leq \SI{10}{\milli bar}$,
   slowly open $V_{\text{Primary}}$, again checking $P_{\text{N,
   Linear}}$ remains unchanged. This will increase the pressure on
   $P_{\text{P, Linear}}$ again until the volume is pumped.
6. This step is the most crucial. With $V_{\text{T2}}$ still closed,
   very carefully open $V_{\text{Needle}}$, while keeping an eye on
   $P_{\text{N, Linear}}$. Note that $V_{\text{Needle}}$ has two
   locking mechanisms. The knob at the end with the analog indicator
   and a general lock in front of that. While the analog indicator
   shows =000=, open the general lock. Then slowly start turning the
   knob. At around =300= the pressure on $P_{\text{N, Linear}}$ should
   slowly start to decrease. Keep turning the knob until you reach a
   pump rate of $O(\SI{1}{\milli \bar \per \second})$. You will have
   to keep opening the needle valve further, the lower the pressure is
   to keep the pump rate constant.
7. Once both linear gauges have equalized (up to different offsets),
   close the needle valve again.
8. Open $V_{\text{T2}}$.
9. Start T2 by turning on the power and pressing the right most
   button. Use the arrow buttons to select the 'actual RPM' setting to
   see that the turbo is spinning up. Final speed should be set to
   $\SI{1500}{\Hz}$.
10. While T2 is spinning up, start T1 by turning on the power at the
    back. There is no additional button to be pressed.

The system should now be in the following state:
- $V_{\text{Leak}}$ closed
- $V_{\text{Needle}}$ closed
- $V_{\text{T2}}$ open
- $V_{\text{Primary}}$ open
- T2 & T1 running
- Primary pump running
If so, the system is now pumping. Note that it may take several days
to reach a vacuum good enough to satisfy the interlock.

**** Flushing the system

Flushing the system is somewhat of a reverse of pumping the
system. Follow these steps to safely flush the system with
nitrogen. See section [[Nitrogen supply]] for an explanation of which
valves need to be operated to open the nitrogen line.
Before flushing the system connect two linear gauges to both
$P_{\text{Linear}}$ sensors.
1. Make sure the turbo pumps are turned off, if not yet turn both off
   and wait for them to have come to a halt.
2. Turn off the primary pump.
3. Close $V_{\text{T2}}$. $V_{\text{Leak}}$ and $V_{\text{Needle}}$
   should already be closed, while $V_{\text{T2}}$ and
   $V_{\text{Primary}}$ should still be open.
4. Connect the nitrogen line to the blind flange before
   $V_{\text{Leak}}$. 
5. Slowly open $V_{\text{Leak}}$, while checking both linear
   gauges. Make sure only the pressure on $P_{\text{P, Linear}}$
   increases, while $P_{\text{N, Linear}}$ remains under vacuum. If
   not, another valve is still open. Close $V_{\text{Leak}}$
   immediately again!
6. Keep flushing nitrogen, until $P_{\text{P, Linear}}$ gets close to
   $\SI{1000}{\milli\bar}$ (the sensors will never actually reach
   that value).
7. Close $V_{\text{Leak}}$ again to make sure you do not put the
   system over one atmosphere of pressure.
8. This step is the most crucial. With $V_{\text{T2}}$ still closed,
   very carefully open $V_{\text{Needle}}$, while keeping an eye on
   $P_{\text{N, Linear}}$. Note that $V_{\text{Needle}}$ has two
   locking mechanisms. The knob at the end with the analog indicator
   and a general lock in front of that. While the analog indicator
   shows =000=, open the general lock. Then slowly start turning the
   knob. At around =300= the pressure on $P_{\text{N, Linear}}$ should
   slowly start to increase. Keep turning the knob until you reach a
   pump rate of $O(\SI{1}{\milli \bar \per \second})$.
9. You will notice that the pressure on $P_{\text{P, Linear}}$ will
   start to decrease, since the air will distribute in a larger
   volume. Open $V_{\text{Leak}}$ again slightly to keep $P_{\text{P,
   Linear}}$ roughly constant.
10. Keep flushing with $\SI{1}{\milli\bar\per\second}$ until both
    sensors read $O(\SI{1000}{\milli\bar})$.
11. Close all valves in the system again.

This way the system is safely flushed with nitrogen. This helps to
pump faster after a short maintenance, because less humidity can enter
the system.

*** COMMENT Gas supply

If the requirements of the gas supply interlock are satisfied
(cf. sec. [[Gas supply interlock]]), it is possible to flush the detector
with gas. For that, follow these steps:
1. Make sure the pressure controller is connected and running. Check
   InGrid-PLC computer in control room and see if pressure control
   software is running. If gas supply is currently closed, reported
   pressure inside the detector is usually reported to
   $\SIrange{960}{980}{\milli\bar}$.
2. Outside the building, open the main valve of the currently active
   gas bottle (check the arrow on the bottle selector mechanism). See
   fig. [[fig:gas-bottle-outside]].
3. Open the second valve near the bottle.
4. Pressure values should be:
   - gas bottle: $\sim\SIrange{30}{100}{\bar}$
   - pre-line pressure: $\sim\SI{7}{\bar}$
   - line pressure: $\sim\SI{0.45}{\bar}$
5. Activate the gas supply at the interlock box by turning the key to
   =Security on= and pressing the large button. See
   fig. [[fig:interlock-box]].
6. Go to the airport side of the magnet. Open the valve on the InGrid
   gas panel below the telescope platform. See
   fig. [[fig:ingrid-gas-panel]].
7. Slowly open the needle valve on the flow meter on the previous
   panel. Increase gas flow up to $\sim\SI{2}{\liter\per\hour}$.
8. Open the needle valve on the gas supply line on the side of the
   platform (see fig. [[fig:gas-needle-valve]]).
9. After $\SIrange{5}{10}{\minute}$ the pressure controller on the
   InGrid-PLC computer should report $\SI{1050}{\milli\bar}$.
# 7. Make sure the electrovalves on the second gas panel (see
#    fig. NOT HERE. NO PANEL) are open. THESE VALVES CANNOT BE CHECKED
#    EXPLICITLY. IF INTERLOCK BOX IS ACTIVE, WILL BE OPEN?! MAYBE CHECK
#    BOX POWER SUPPLY? NO LED I THINK.


Now the detector should be flushed with $\ce{Ar} /
\ce{iC_4H_{10}}$. Before turning on the HV, make sure to flush for at
least $\SI{12}{\hour}$ to be on the safe side.

#+CAPTION: Location of the Argon-Isobutane bottle and the main valves outside the building.
#+NAME: fig:gas-bottle-outside
[[file:~/org/Doc/Detector/figs/gas_bottles_outside.jpg]]


#+CAPTION: Location of the gas interlock box
#+NAME: fig:interlock-box
[[file:~/org/Doc/Detector/figs/gas_interlock_box.jpg]]

#+CAPTION: Location of the InGrid gas panel below the telescope platform on the airport side.
#+NAME: fig:ingrid-gas-panel
[[file:~/org/Doc/Detector/figs/gas_panel.jpg]]

#+CAPTION: Location of the needle valve on the gas supply line
#+NAME: fig:gas-needle-valve
<file to be inserted>

*** Nitrogen supply

Nitrogen is supplied by a nitrogen bottle outside the building. To
open the nitrogen line, 5 valves need to be opened. The line ends in a
copper pipe on the airport side, which is usually there rolled up (the
copper is somewhat flexible).
1. Open the lever on the nitrogen bottle outside the building (see
   fig. [[fig:nitrogen-bottle-outside]]).
2. Open the valve next to the bottle.
3. Go to the gas lines next to the control room. The right most line
   (see fig. [[fig:valves-control-room]] and
   fig. [[fig:nitrogen-valve-control-room]]) is the nitrogen line. Open
   the valve.
4. Open the needle valve on the flow meter to the right of the
   previous valve.
5. Open the needle valve on the airport side of the magnet (see
   fig. [[fig:nitrogen-airport-side]]).
This should be all to open the nitrogen line. The flow through the
pipe is not too large, but it should be large enough to feel it on the
back of the hand.

#+CAPTION: Location of the Nitrogen bottle and the main valves outside the building.
#+NAME: fig:nitrogen-bottle-outside
[[file:~/org/Doc/Detector/figs/nitrogen_bottle.jpg]]

#+CAPTION: Location of the valves next to the control room
#+NAME: fig:valves-control-room
[[file:~/org/Doc/Detector/figs/nitrogen_valve_location.jpg]]

#+CAPTION: The actual nitrogen valve on the set of valves near the control room.
#+NAME: fig:nitrogen-valve-control-room
[[file:~/org/Doc/Detector/figs/nitrogen_valve.jpg]]


#+CAPTION: Location of the flow meter near the valve next to the control room
#+NAME: fig:nitrogen-flow-meter-control-room
[[file:~/org/Doc/Detector/figs/nitrogen_flow_meter.jpg]]

#+CAPTION: Location of the needle valve on the airport side
#+NAME: fig:nitrogen-airport-side
<file to be inserted>


#+BEGIN_EXPORT latex
\newpage
#+END_EXPORT

** Cabling & software setup

The requires:
- Virtex:
  - power
  - 2 HDMI to intermediate board
  - mini USB into JTAG port on backside
  - RJ45 from ethernet port into 2nd ethernet card on DAQ PC

The RJ45 connection is only required to flash the firmware onto the
Virtex.

For the flashing of the firmware, take into account the USB driver
setup described in =void_settings.org=.

*** Ethernet connection with Virtex

The ethernet connection with the Virtex needs to be set up
manually.

On the one hand it is required to use a static IP address for the
secondary ethernet device and in addition we need to set an ARP entry
(note: the =arp= program is part of the =net-tools= package, name same
in ubuntu & void linux).

Under Ubuntu said setup can be done using the network manager. In Void
we need to use =ip= from the terminal.

The settings are as follows:
- IP address: 10.1.2.3
- Subnet: 24

Setup of the device can be done according to the example here:
https://docs.voidlinux.org/config/network/index.html
namely (with superuser rights):
#+begin_src sh
ip addr show
# check the name of the correct, secondary device
ip link set dev enp4s0 up # name on tpc19
ip addr add 10.1.2.3/24 brd + dev enp4s0
#+end_src
afterwards we can set the ARP entries (ref: https://confluence.team.uni-bonn.de/display/PHYGASDET/How+to+automatically+set+ARP+entries):
#+begin_src sh
arp -i enp4s0 -s 10.1.2.2 AA:BA:DD:EC:AD:E2
#+end_src

**** Make these two steps automatic under void

In principle it should be enough to set the above steps into =/etc/rc.local=.

*** Setting up the chips in TOS

This section is specific to the Septemboard used at CAST.

Following the steps described in the shifter documentation
[[file:~/org/Doc/ShiftDocumentation/shifter_documentation.org]]
#+begin_src sh
#+BEGIN_SRC python
7 # number of chips
4 # preload
SetChipIDOffset
190
lf
# 7 times enter to load default paths
uma
1 # Matrix settings
0
1
1
0
LoadThreshold # load threshold equalisation files
4 # write matrix
3 # read out
3
ActivateHFM
SetFadcSettings
Run
1 # run time via # frames
0
0
0
2 # shutter range select
30 # shutter time select
0 # zero suppression
1 # FADC usage
0 # accept FADC settings
#+end_src

The above would launch a full background run.

** Appendix


The appendix contains additional information, which would take up too
much space in the document itself.

*** Lead shielding plan
This is the build plan for the lead shielding.
#  \includepdf[pages=-]{misc/shielding-pb-bricks-assembly-ingrid2017.pdf}

** Installation & setup

Use detector documentation written for CERN (Thank fucking god I had
to write this back then).

** Lead shielding at CAST 

PDF of lead shielding. Extract one image as reference, refer to full
one in appendix.

** X-ray finger runs

2 X-ray finger runs were made. One near beginning, one near end.

Plot of X-ray finger centers.

Mention how this plays into the analysis side, that it means we need
to adjust the ray tracing.

** CAST log files, data format bla

** Issues etc. during data taking period

Noise issues, scintillators not working in Run 2 due to firmware bug.

** Detector behavior over time

Plot of the (known) temperature at PCB from shift forms.
Unfortunately, most of the high resolution temperature logs were lost due to a
software bug.
Cooling power varied over time, probably due to slight clogging.

Plot of the peak position of the 55Fe calibration runs.

*** Gas gain binning
:PROPERTIES:
:CUSTOM_ID: sec:?:gas_gain_time_binning
:END:

Explain why we did it and how we ended up at 90 min time binning.

** Run 2 and Run 3

Different detector calibrations in each run.

Amount of data in each. Take table from StatusAndProgress.

Run table somewhere in appendix, link to online version.




* Detector preparation / study / characterization etc.                :Part3:
#+LATEX: \minitoc
There are two different kinds of calibrations used for the data taking
campaign at CAST. One is a data taking campaign behind an X-ray tube
at the CAST Detector Lab (CDL) to characterize the geometric
properties of X-rays at different energies (as the foundation for
discrimination methods), discussed in section
[[#sec:preparation:cdl]]. The second are measurements using a
$^{55}\text{Fe}$ source installed on a pneumatic manipulatior at CAST
to perform regular calibration runs to monitor the detector behavior
and serve as a basis for the energy calibration of events, see
section [[#sec:preparation:55fe]].

*NOTE*: Should we therefore maybe split up the section rather by type
of calibration? Certainly clearer that way. Only question is how to
best present the other calibrations then (FADC, scintillators).

** CAST Detector Lab
:PROPERTIES:
:CUSTOM_ID: sec:preparation:cdl
:END:

Measurements for X-ray reference data

Detector lab measurements were only performed after the data taking
period at CAST was over. From a logical standpoint it makes more sense
to talk about it before though.

Everything required in StatusAndProgress. Will need to redo all plots
of course.

** Detector calibrations + characterization plots

*** FADC spectrum & threshold [/]

- [ ] show spectra
- [ ] show 55Fe spectrum of FADC data
- [ ] apply Savitzky Golay filter to FADC spectra & describe
- [ ] train NN on FADC data and see what we can gain <- this goes
  towards analysis chapter of course!
  Best use a CNN with 1D input data & kernel!  

** 55Fe spectra
:PROPERTIES:
:CUSTOM_ID: sec:preparation:55fe
:END:

Example spectrum. What's the point of these spectra.

** Energy calibration, how done?

Mention something about section [[#sec:large_events_few_pixels_tot]] in
=StatusAndProgress=, i.e. events that convert very close to grid and
thus have few pixels, but a lot of energy as determined by the
ToT. This is an argument in favor of using ToT over #pix.


* Chapter about analysis principle                                 :Software:
#+LATEX: \minitoc
*IDEA*: Maybe this chapter should only be about everything from raw
data to clustering, charge & energy calibration, gas gain, computation
of geometric properties? Well, two of these are already mentioned in
the previous chapter.

*NOTE:* We need to better understand how to:
- explain the theoretical foundations of what we do, e.g. cluster
  finding algorithms. Certain things, e.g. cluster finding algos could
  also just go to the appendix. Interesting, but technically just a detail.
- introduce the software stack we use
- introduce the physics for the calibration (e.g. ToT calib, ...)
- explain the algorithms used in the software

Can we disentangle this from the purely detector focused things? I'm
not so sure.

After introducing detector specific calibrations etc. we can go on to
what the steps are that are required to turn a calibrated detector
(one that is sensitive to N electrons essentially) into something that
can do physics.

Need some chapter that talks about the detector specific details that
explain how a limit / physics result is obtained.

- [ ] turn the ingrid reconstruction schematic into a generalized flow chart?

** Take data. Output data is ASCII files

Parsing of data in format.

Present format.
#+begin_quote
Generic header.

Data.
#+end_quote

Store data in HDF5 files. Not much going on here aside from making it
fast.

** Reconstruct & calibrate data

Read data from HDF5 files. 

What does reconstruction mean?

Multiple things.

*** 1. perform cluster finding

Present our current two clustering algorithms. 

- dumb search in radius around each pixel (add foot note that the
  implementation in MarlinTPC had a bug), based on *rectangular*
  search, not circular
- optional: DBSCAN, short introduction give full reference to
  implementation.

**** Investigation of buggy clustering in MarlinTPC             :noexport:

*** 2. for each cluster, compute geometric properties

Table of the computed properties.

As they are geometric easy to explain.

Highlight the ones used for likelihood. Done here? 

Show our sketch explaining what each property means from one of the
talks. Maybe need to fix the radius variable?



*** 3. (optional / required for analysis) charge calibration

Use Timepix ToT calibration (ref theory section before where we
explain how it works).

Given ToT calibration apply function to get number of electrons (given
that we ran in ToT mode).

*** 4. (optional / required for analysis) compute gas gain

Computing gas gain. Polya fit. Explain not fit parameter used, but
mean of data.

Heavy gas gain variation over time. 

Explain that thus behavior chosen that minimizes effect by binning in
time.

90 minutes.

Show plot with old way (full runs) vs. new length.

Results in stable operation. This section probably belongs somewhere
else? 

**** Study for optimal gas gain time length                     :noexport:



*** 5. (optional / required for analysis) energy computation

Requires: charge calibration, gas gain

Very easy in theory. In practice complicated.

Theoretically, two ways:

1. pixel counting. Due to single electron detection efficiency (or a
   slight correction for under/overcounting) can just multiply hits by
   eV per hit
2. charge calibration plus reference spectrum of 55Fe runs. 

Both cases are very simple *iff* the detector is stable over
time. Then just take closest 55Fe run and compute correction factor
for hits / conversion factor from peak in charge values.

But: instability means we need to average over more data.

Compute for all runs.

Fit.

Apply fit.

*** 6. (optional) FADC reconstruction

Apply pedestals.

Determine lowest point. Determine rising / falling times in ns.

Compute other properties.

** Compute reference spectra 

Possibly explain in chapter about CDL? Or talk there only about the
*data* we took there, but not in detail about *what* this data is *for*?

If so explain here.

** Log file reader to get tracking (maybe no export)

Talk about log file reader (full section definitely :noexport:), used
to mark times in runs that correspond to tracking.

** Likelihood method

Explain likelihood method in theory (maybe do in section before).

Explain our methods for linear interpolation between the reference
spectra.

Apply reference data for limit at specific custom software efficiency.

Started at 80% reference and then tweaked for optimal ε = S/√B (or
something). 

Likelihood method gives us everything we need for background
rate. Whatever comes out gives us left over clusters.

*** Septem veto
:PROPERTIES:
:CUSTOM_ID: sec:septem_veto
:END:

Talk about the septem veto we finally use.

In the septem veto the main idea is to go back to the raw data for any
event, which contains a cluster on the central chip, which is
signal-like based on the likelihood method presented above. For these,
a so called 'septem event' is built based on the raw pixel data of all
chips. This is simply an 'event' in the same notion as understood by
the =reconstruction= tool (c/f [[sec:reconstruction]]), i.e. a two
dimensional array of the ToT values. Except in this case it is not a
$256 \times 256$ array, but rather a $3 \cdot 256 \times 3 \cdot 256$
array, where the full septemboard detector is merged into a single
event without any spacing between the chips (more on that below). 

These septem events are then pushed through the whole reconstruction
and calibration pipeline. Thanks to starting from an event that now
includes information that was previously not taken into account (pixel
activity outside the center chip), the cluster finding algorithm can
detect larger clusters than previously. This can change the shape of
the cluster that was previously considered signal like. In the case
that this cluster now looks more like background, it will be vetoed by
this technique.

The decision to merge the different chips into a single event
*without* any spacing between the chips is made to ensure good cluster
finding. The spacing between chips is of course a dead zone where no
activity can be measured. For a cluster finding algorithm this may
cause a cutoff that should not happen, as the information is simply
not *available*. Ideally, one could imagine an algorithm that
interpolates data between the chips based on the information on the
two neighboring chips. But this is too experimental. 

If there is data on the neighboring chip, it is extremely likely there
was ionization between the chips as well, meaning the merging of the
chips "only" makes the event less eccentric than the physical
event. If there is no data on the neighboring chip, the merging has no
effect, the cluster will simply look the same as in the original
single chip event. 

This excludes two possibilities:
1. a physical event may have no active pixels between the chips, despite
   having active pixels on both chip borders. This is extremely
   unlikely, if the events are significantly close to the border. The
   main case of this would be two real X-rays (extremely low
   probability) or either of the clusters is a track parallel to
   border of the chip. 
2. a more likely loss information for events without information on
   the neighboring chips, despite the physical event being more
   eccentric than the recorded one. This is a real limitation that
   cannot be worked around.

**** Explain why no spacing between chips

**** Hough transformation experiments                           :noexport:

*** Scintillator veto

Talk about scintillator veto. Main ideas of course.

*** FADC veto

Explain the veto we use based on FADC.



*** Comparison with other attempts                               :noexport:

Show the other attempts we did about the different ways to
interpolate.

** Compute limit

Limit computation done. Needs to be after ray tracing introduction I'd
say. Input for theory is required.

Perform signal / background rejection.

Get background rate + signals in tracking.

Get expected flux from theory.

Get detector efficiencies.

Combine efficiencies & theory flux in raytracing simulation.

Compute 'real' expected signal.

Use suitable limit calculation method to compute a limit.

We can split this into two pieces?:

** How to compute background rate

** How to compute a limit

For =mclimit= use the notes in StatusAndProgress about how limit
calculation works. Might be good in general, because a lot of it
applies elsewhere anyway.

Describe unbinned likelihood method from Nature paper adapted to our
work. We can plot some funny plots explaining how it works.


* Software                                                         :Software:
#+LATEX: \minitoc
Introduce used software for analysis.

Previous code used MarlinTPC (already extended a framework for use for
gaseous detectors, focus on strips). Additional extension to use our
new detector features would be beyond the scope of the framework. 

- [ ] *POSSIBLY MAKE THIS A LONG APPENDIX* Then we can just refer to
  that appendix and at the same time then don't have to worry about
  keeping it very focused on things that "should be" in a thesis.

** Nim

Shortly introduce Nim & why it was chosen.

Efficient, productive, gets out of my way.

** TimepixAnalysis

Framework written for data analysis.

Rewrites Timepix / InGrid related code from MarlinTPC in Nim and
extends it (e.g. supports Timepix3).

[[https://github.com/Vindaar/TimepixAnalysis]]

After the thesis is published it is possible that this repository will
become the de facto repository for the thesis and the actual analysis
code will become its own repository. We'll see.

*THESE SECTIONS MUST BE MERGED WITH THE ANALYSIS BELOW*. Maybe let
this chapter simply be a high level overview: introduce Nim and the
why. Mention the TimepixAnalysis repo only as a "this is the code for
the analysis, the details of which will be explained in the next
section? In that case one might merge the whole chapter with the next
one and simply have these as the introductory part of the chapter.

*** =raw_data_manipulation=

*LINK TO HDF5 FORMAT IF FIRST TIME MENTIONING*

The first step of the analysis pipeline is essentially just a parsing
stage of the data generated by TOS (see section [[sec:tos_output_format]]
for an explanation of it) and storing it in a compressed HDF5 data
file.

The program is fed with a directory containing a TOS run, i.e. a
single data taking period ranging typically from minutes to days in
length, or a directory that itself contains multiple TOS run directories.

All data files contained in a run directory will then be parsed in a
multithreaded way. The files are memory mapped and parsed in parallel
into a =Run= data structure, which itself contains =Event= structures.

Depending on the designated run type of a file, some slight
processing steps are performed. *WHAT?*

If FADC files are present in a directory, these will also be parsed
into =FadcEvent= structures in a similar fashion.

Each run is then written into the output HDF5 file as a group. The
meta data about each run and event are stored as attributes and
additional datasets, respectively.

An example structure of a resulting HDF5 file is shown in:
*EXAMPLE LAYOUT WITH EXAMPLE ATTRIBUTES AND DATASETS?*

In addition the tool also supports input from HDF5 files containing
the raw data from a Timepix3 detector. That data is parsed and
reprocessed into the same kind of file structure.

#+CAPTION: Usage of the =raw_data_manipulation= tool. Input is in the form of a run directory / a directory
#+CAPTION: containing multiple run directories. The parsed output is stored in compressed HDF5 files.
#+NAME: list:raw_data_manipulation_help
#+begin_src shell-session
Version: 13809be built on: 2021-05-07 at 00:53:39
  InGrid raw data manipulation.

Usage:
  raw_data_manipulation <folder> [options]
  raw_data_manipulation <folder> --runType <type> [options]
  raw_data_manipulation <folder> --out=<name> [--nofadc] \
    [--runType=<type>] [--ignoreRunList] [options]
  raw_data_manipulation <folder> --nofadc [options]
  raw_data_manipulation --tpx3 <H5File> [options]
  raw_data_manipulation --tpx3 <H5File> --runType <type> [options]
  raw_data_manipulation --tpx3 <H5File> --runType <type> --out=<name> \
    [options]
  raw_data_manipulation -h | --help
  raw_data_manipulation --version

Options:
  --tpx3 <H5File>     Convert data from a Timepix3 H5 file to TPA format
  --runType=<type>    Select run type (Calib | Back | Xray)
                      The following are parsed case insensetive:
                      Calib = {"calib", "calibration", "c"}
                      Back = {"back", "background", "b"}
                      Xray = {"xray", "xrayfinger", "x"}
  --out=<name>        Filename of output file
  --nofadc            Do not read FADC files
  --ignoreRunList     If set ignores the run list 2014/15 to indicate
                      using any rfOldTos run
  --overwrite         If set will overwrite runs already existing in the
                      file. By default runs found in the file will be skipped.
                      HOWEVER: overwriting is assumed, if you only hand a
                      run folder!
  -h --help           Show this help
  --version           Show version.
#+end_src

*** =reconstruction=
:PROPERTIES:
:CUSTOM_ID: sec:reconstruction
:END:

After the raw data has been converted to storage in HDF5, the
=reconstruction= tool is used to start the actual analysis of the
data.

As the name implies, the first stage of data analysis is in the form
of reconstructing the basic properties of each event. In this stage
all events are processed in a multithreaded way. A cluster finding
algorithm is applied to each event on each chip separately, splitting
a single event into possibly multiple clusters. Clusters are defined
based on a certain notion of distance (the details depend on the
clustering algorithm used). The multiple clusters from a single event
are then treated fully equally for the rest of the analysis. The fact
that they originate from the same event has no further relevance (with
a slight exception for one veto technique, which utilizes clustering
over multiple chips, more on that in section [[sec:septem_veto]]).

For the individual clusters geometric properties will be
computed. These are the long and short axis, the eccentricity as well
as the statistical moments up to kurtosis along the long and short
axis. The full list is shown in tab. [[tab:geometric_properties]].

#+CAPTION: Table of all the (mostly) geometric properties of a single cluster computed during the
#+CAPTION: =reconstruction= tool. All but the likelihood, charge and energy properties are computed
#+CAPTION: during the first pass of the tool.
#+NAME: tab:geometric_properties
| Property                  | Meaning                                                          |
|---------------------------+------------------------------------------------------------------|
| igCenterX                 | =x= position of cluster center                                   |
| igCenterY                 | =y= position of cluster center                                   |
| igHits                    | number of pixels in cluster                                      |
| igEventNumber             | event number cluster is from                                     |
| igEccentricity            | eccentricity of the cluster                                      |
| igSkewnessLongitudinal    | skewness along long axis                                         |
| igSkewnessTransverse      | skewness along short axis                                        |
| igKurtosisLongitudinal    | kurtosis along long axis                                         |
| igKurtosisTransverse      | kurtosis along short axis                                        |
| igLength                  | size along long axis                                             |
| igWidth                   | size along short axis                                            |
| igRmsLongitudinal         | RMS along long axis                                              |
| igRmsTransverse           | RMS along short axis                                             |
| igLengthDivRmsTrans       | length divided by transverse RMS                                 |
| igRotationAngle           | rotation angle of long axis over chip coordinate system          |
| igEnergyFromCharge        | energy of cluster computed from its charge                       |
| igLikelihood              | likelihood value for cluster                                     |
| igFractionInTransverseRms | fraction of pixels within radius of transverse RMS around center |
| igTotalCharge             | integrated charge of total cluster in electrons                  |
| igNumClusters             |                                                                  |
| igFractionInHalfRadius    | fraction of pixels in half radius around center                  |
| igRadiusDivRmsTrans       | radius divided by transverse RMS                                 |
| igRadius                  | radius of cluster                                                |
| igLengthDivRadius         | length divided by radius                                         |

The properties are computed here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L308-L366
and here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L517-L569

*NOTE:* How should we take care of linking to our code? Of course need
tagged version that corresponds to stuff in the thesis, but beyond
that?


After all geometrical properties have been computed, the next step is
to apply the ToT calibration (sec. [[sec:daq:tot_calibration]]) to the ToT
values of all clusters, resulting in the equivalent charge in
electrons. The charge values for all recorded pixels are then used to
compute a histogram, which roughly follows a Pólya distribution
(sec. [[sec:polya_distribution]]). From the mean value of that
distribution a value for the gas gain is obtained, which is a
necessary input to perform an energy calibration for each cluster.

Second step of analysis, performs most of the major steps.

- cluster finding
- calculation of geometric properties
- charge calibration
- gas gain computation
- energy calibration
- ...



*** =likelihood=

Apply likelihood method for background suppression.

*** =computeLimit=

Computes the limit *NOT THE ONE USED*

*** Other

**** =cdl_spectrum_creation=

Generates the data from the CDL data that is used as X-ray reference
data for the likelihood method.

**** ...

Many other tools are present. Mainly different plotting tools and
tools dealing with other data, e.g. log files of the CAST experiment.



* Raytracing - where does this belong? [0/1]                       :Software:
#+LATEX: \minitoc
Generally, this should become a *section* in the chapter that
introduces the inputs required for the limit calculation. Namely:

*Signal hypotheis - raytracing from Sun to detector*

(It can be a reasonably long section, I think that's fair)


Ray tracing through the detector. Put this before limit calculation stuff?

The whole theoretical side needs to be described in the theory chapter
in [[Axion-electron flux]]. Then here we can just describe how one
implements this (in particular in the noexport section).

Raytracing in a Weekend: \cite{Shirley2020RTW1}

For an in depth guide to raytracing, from theoretical principles to a
pretty sophisticated raytracer, see the amazing 'Physically based
rendering' \cite{pharr2016physically}. 


- [ ] *PLOT OF MIRROR SHELLS*

- [ ] *AXION ELECTRON IMAGE*

- [ ] *PRIMAKOFF IMAGE*

- [ ] *CHAMELEON IMAGE*

- [ ] *NUMBERS FOR FLUX FRACTION ENCOUNTERED WHERE*

- [ ] *INTRODUCE CONCEPT OF RAYTRACING*

- [ ] *CITE PBR*

- [ ] *MAYBE SHOW RAYTRACING IN A WEEKEND PICTURE AS EXAMPLE*


[fn:raytracing_interactive] An interactive raytracer for the
applications of solar axion fluxes, which allows to investigate the
scene (geometry of objects) in 'visible light' as well as serve as an
X-ray raytracer is in development. For time reasons that development
is somewhat on halt unfortunately. https://github.com/Vindaar/rayTracingInOneWeekend/tree/interactiveRayTracer


** Related to explicit axion image [/]

- [ ] *SHOW PLOTS CHARACTERIZING USED SOLAR MODEL*
- [ ] *REFERENCE SOLAR MODEL*

** TODO Can we finish our interactive ray tracer?

Need:
- light sources (4h of work at most)
- cylinders, hyperboloids, paraboloids as objects (once we figure out
  one, the rest should be relatively easy)
- placing different telescope layers etc. (2h)

In theory this *should* be possible as an extensive weekend project!
I'd say this is definitely worth it.


** Computation of atomic processes :noexport:

Computation of atomic processes done in *CODE*. 




* Background rate computation                                      :Analysis:
#+LATEX: \minitoc
Mitigation strategies for detector behavior, e.g. gain variation over time.

** Understanding background rate

3 keV is easy to understand.

8-9 keV is more difficult. 

** Muon calculations                                              :noexport:

Probably not going to make it into final thesis? We'll see, take from
StatusAndProgress. Maybe shortened version will make it.

** FROM IAXO TDR PART: Analysis software & background rate

*NOTE*: This needs to be split up into a part that explains the vetoes
& the parts that show the achieved background rates. Also needs more
explanation on most topics, e.g. how likelihood cut works.


To achieve the desired background rates both special hardware features
as well sophisticated software features are required.

The main hardware features beyond the general ability to achieve
single electron efficiency and thus reconstruct the geometric event
shapes and their energies, are:
- scintillators allowing to tag likely background induced X-rays
- either in case of pure ToT & shutter based readout: an FADC reading
  out the induced signal on the grid to act as a trigger and provide
  longitudinal shape information
  or in case of the GridPix3, which allows ToT and ToA readout at the
  same time, in a stream based manner: ToA information yields
  precise longitudinal shape information and allows to perform offline
  time based clustering
- multiple GridPix around the central 'main' GridPix to clarify event
  shapes of either sparse events or events near the edge of the chip

Each of these requires specific methods to achieve a background
reduction. In the following each aspect will be explained separately
and their possible effect is shown based on a GridPix1 based detector,
which was deployed at CAST in 2017 and 2018.

*TODO*: write summary of following sections

*** Analysis software

Data reconstruction and analysis of GridPix data is performed with the
[[https://github.com/Vindaar/TimepixAnalysis][TimepixAnalysis]] framework, written in the [[https://nim-lang.org][Nim programming language]].

The software is capable of reading GridPix1 data from multiple readout
systems as well as GridPix3 data.

In addition to providing a full analysis readout chain, from raw data
parsing, to clustering and characterisation of individual cluster
properties, it provides a large number of convenience tools and
plotting utilities.

*** Basic background rate
:PROPERTIES:
:CUSTOM_ID: sec:likelihood_method
:END:


As a reference first the background rate achievable using only a
single GridPix1 without any additional features will be discussed.

The detection principle of the GridPix detector implies physically
different kinds of events will have different geometrical shapes.

*TODO:* merge these into a subfig environment or something

#+begin_center
#+CAPTION: Example event of a $^{55}\text{Fe}$ X-ray photon taken with the
#+CAPTION: GridPix1 detector at CAST. The event shape is mostly spherical
#+CAPTION: as there is a single point of origin for the photo-electron.
#+CAPTION: Diffusion as a random process yields the shape.
[[~/org/Figs/statusAndProgress/exampleEvents/calibration_event_run266_chip3_event5791_region_crAll_hits_200.0_250.0_centerX_4.5_9.5_centerY_4.5_9.5_applyAll_true_numIdxs_100.pdf]]
#+end_center

#+begin_center
#+CAPTION: Example background event taken with the GridPix1 event at CAST.
#+CAPTION: A typical track like shape is visible, likely from a muon with
#+CAPTION: some additional interaction. The irregular shape is caused by
#+CAPTION: background events not having a single origin, but rather ionizing
#+CAPTION: the gas at many points on their path through the detector.
#+CAPTION: *TODO MAYBE CHANGE EVENT*
[[~/org/Figs/statusAndProgress/exampleEvents/background_event_run267_chip3_event1456_region_crAll_hits_200.0_250.0_centerX_4.5_9.5_centerY_4.5_9.5_applyAll_true_numIdxs_100.pdf]]
#+end_center

Combined caption (once merged):

Use the individual captions as is, with references to a) and b).  On
the left hand side of each plot, a list of all geometric properties
and their values that are calculated for the visible clusters is
shown. Some of these properties are used for the classification of
events into signal and background like events.

The method to distinguish the two types of events, is based on a
likelihood cut. X-ray data taken at multiple energies (possibly taken
with an X-ray tube) are used to define reference distributions for
(currently) 3 different geometrical variables:
1. the eccentricity $ε$ of the cluster, determined by
   computing the long and short axis of the two dimensional cluster and
   then computing the ratio of the RMS of the projected positions of
   all active pixels within the cluster along each axis.
2. the fraction of all pixels within a circle of the radius of one
   transverse RMS from the cluster center, $f$.
3. the length of the cluster (full extension along the long axis)
   divided by the transverse RMS, $l$. 

These variables are obviously highly correlated, but still provide a
very good separation between the typical shapes of X-rays and
background events. They mainly characterize the "spherical-ness" as
well as the density near the center of the cluster, which is precisely
the intuitive sense in which these type of events differ.

*TODO*: rewrite / remove parts of the ln L part. Don't use ln
The reference distributions are then treated as a probability density,
specifically the likelihood for a cluster to be "X-ray-like". For one
property $i$ we thus define a likelihood $\mathcal{L}_i(x_i)$, where $x_i$ is the
value of the property $i$. This gives us the total likelihood:

\[
\mathcal{L}(ε, f, l) = \mathcal{L}_{ε}(ε) \cdot \mathcal{L}_{f}(f)
\cdot \mathcal{L}_l(l)
\]

where the subscript is denoting the individual likelihood distribution
and the argument corresponds to the individual value of each property.

#+begin_comment
Due to numerical issues dealing with very small probabilities, instead
of using the raw likelihood $\mathcal{L}$, instead the negative log is
used:

\[
-\ln \mathcal{L}(ε, f, l) = - \ln \mathcal{L}_ε(ε) - \ln \mathcal{L}_f(f)- \ln \mathcal{L}_l(l)
\]

For the GridPix1 detector, data with 8 different X-ray energies (via
multiple targets and filters with an X-ray tube) was taken. Each of
these energies first define the X-ray property in a fixed energy
range. Consider fig. [[fig:eccentrility_mn]] for an example comparing the
distribution for the eccentricity of the X-ray data around
$\SI{6}{keV}$ for X-ray vs. background like data.

As only 8 energies is problematic for multiple reasons (e.g. discontinuities of the
properties at the interval boundaries), for each cluster with energy $E_i$ a linear
interpolation of the reference distributions between the nearest two
neighboring distributions is performed.
#+end_comment

To finally classify events as signal or background, one then sets a
desired "software efficiency" $ε_{\text{eff}}$, which is defined as:
\[
ε_{\text{eff}} = \frac{∫_0^{L} \mathcal{L}(ε, f, l) \, \mathrm{d} L'}{∫_0^{∞} \mathcal{L}(ε, f, l) \, \mathrm{d} L'}
\]
where $L'$ denotes a specific $\mathcal{L}$ value, which yields the
desired $ε_{\text{eff}}$.
#+begin_comment
In practical terms one computes the
normalized cumulative sum of the log likelihood and searches for the point at
which the desired $ε_{\text{eff}}$ is reached.
#+end_comment

The software efficiency commonly used and for all figures presented
below is $\SI{80}{\percent}$.

With the software efficiency defined, the $-\ln\mathcal{L}$ of each
cluster is simply computed using the linear interpolation of the log
likelihood distribution determined based on the cluster energy. A
cluster is considered a signal if its $L$ is smaller than the $L$
computed for the desired $ε_{\text{eff}}$ at the energy of the cluster.

Using this approach for the GridPix1 data taken at CAST, a background
rate shown in fig. [[fig:background_rate_eff80_only_center]] is achieved.

#+begin_center
#+CAPTION: Background rate achieved based on the $\ln\mathcal{L}$ method at
#+CAPTION: $ε_{\text{eff}} = \SI{80}{\percent}$ using the GridPix1 CAST 2017/18 data
#+CAPTION: without the application of any vetoes.
#+NAME: fig:background_rate_eff80_only_center
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2017_2018_no_vetoes.pdf]]
#+end_center

*** Scintillators as vetoes

*TODO*: rewrite this paragraph in context of full chapter
The usage of scintillators (ideally 4π around the whole detector
setup) can be very helpful to reduce the background rate further. The
likelihood method presented in the previous section is capable of
separating X-rays from background events. However, given the
required background levels, cosmic induced X-ray fluorescence plays a
significant role in the datasets. A muon that excites a piece of the
detector material, which as a result emits an X-ray cannot be
separated from a desired X-ray originating from an axion.

A scintillator setup can be used to tag events. For a fully
encapsulated detector, any (at least) muon induced X-ray would be
preceded by a signal in one (or multiple) scintillators. As such, if
the time $t_s$ between the scintillator trigger and the time of activity
recorded with the GridPix is small enough, the two are likely to be in
real coincidence.

In addition the scintillator triggers are only taken into account for
clusters, which are signal like. If one applies a strict cut on $t_s$,
for example $400\,\text{clock cycles}$ at \SI{40}{MHz} ($\SI{10}{μs}$,
the value used for the GridPix1 detector at CAST), the rate of random
coincidences should be extremely low (or in other words the added dead
time is minuscule). The cutoff of $\SI{10}{μs}$ for the GridPix1 is
chosen as that is the order of the time scale associated with the maximum drift
time in the gas volume, which is of course much longer than any
fluorescence related time scales.

The resulting improvement of the background rate is shown in
fig. [[fig:background_rate_scinti_veto]], albeit only for the end of 2018
data as the scintillator trigger was not working correctly before.

#+begin_center
#+CAPTION: Background rate achieved based on the addition of a scintillator cut veto
#+CAPTION: of $\SI{10}{μs}$ for any cluster that initially passes the log likelihood
#+CAPTION: cut. Improvements are relatively small, which is mainly due to the relatively
#+CAPTION: small coverage of the veto scintillator used & generally low expected rates of
#+CAPTION: indcued signal like events.
#+NAME: fig:background_rate_scinti_veto
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2018_scinti_veto.pdf]]
#+end_center

*** FADC / ToA as veto

Beyond the usage of a likelihood method for geometrically X-ray like
signals and scintillators to suppress X-ray fluorescence, another
background is expected at helioscope experiments, in particular during
solar tracking periods.

Even for an almost fully 4π coverage of scintillators around the
detector setup, there is exactly one part that is never covered: the
window of the detector towards the magnet bore.

The distribution of muons at surface level follow a roughly
$\cos²(θ)$ distribution ($θ$ the zenith angle). During background
taking times (i.e. magnet is horizontal), few muons are expected to
reach the detector via the magnet bore ($θ \approx
\SI{90}{\degree}$). During solar tracking the expected rate is
expected to increase as the magnet is pointed upwards.

Muons entering in such a way traverse the gas volume orthogonally to
the readout plane. The projection on the readout is thus also roughly
spherical (same as an X-ray). The speed of the muon compared to the
time scale of gas diffusion & clock speed of the readout electronic
means that a muon ionizes the gas along its path effectively
instantly.

*TODO*: likely remove part 1, then rewrite text accordingly
Two distinctions can be made between X-rays and such muons:
1. (hard to detect) Each ionized electron undergoes diffusion along
   its path to the readout plane. Those that are ionized far away from
   the readout yield large diffusion, whereas those close to the
   readout barely any. Assuming a constant ionization per distance,
   this implies the muon track is formed like a cone. The electrons
   arriving at the readout first are almost exactly on the muon path
   and the later ones have more and more diffusion.  In a setup with a
   GridPix3, which allows for ToA readout this effect may be visible
   (yet to be tested). With the CAST GridPix1 setup, which used an
   FADC for the induced grid signal, this is not visible, as there is
   no relation between pixel positions and time information.
2. The effective instant ionization implies that such an cluster has a
   'duration' that is equivalent to the drift velocity times the gas
   volume height. For a typical GridPix setup of height $\SI{3}{cm}$
   with an Argon/Isobutane gas mixture, this implies times of
   $\mathcal{O}(\SI{2}{μs})$. Compared to that the duration of an
   X-ray is roughly the equivalent of the geometrical size in the
   readout plane, which for the same conditions is
   $\mathcal{O}(\SI{3}{mm})$, expressed as a time under the drift
   velocity.
   Thus, if the duration of a cluster is reasonably well known, this
   can easily separate the two types of clusters.

For a Argon/Isobutane mixture at $\SI{1050}{mbar}$ the energy
deposition of most muons will be in the range of
$\SIrange{8}{10}{keV}$, which in any case is outside of the main
region of interest for axion searches.

Note: for a detector with an almost perfect 4π coverage, the
scintillators *behind* the detector would of course trigger for such
muons. Indeed, it is likely that using that information would already
be enough to remove such events. A discrimination based on time
information yields a more certain result than a large scintillator
might, which (even if to a small degree) does introduce random
coincidences.

In an test background run using a GridPix3, which was pointed towards
the zenith, 50 clusters remained after the likelihood cut. Using the
duration of the clusters, another 15 could be removed, showing the
usefulness of the approach.

*TODO: get correct numbers!*

*** Outer GridPix as veto - 'septem veto'

The final hardware feature that is used to improve the background
rate, is the outer ring of GridPix. The size of large clusters is a
significant fraction of a single GridPix. This means that depending on
the cluster center position, parts of the cluster may very well be
outside of the chip. While the most important area of the chip is the
center area (due to the X-ray optics focusing the axion induced
X-rays), misalignment and the extended nature of the 'axion image'
mean that a significant portion of the chip should be as low in
background as possible.

Fig. [[fig:background_clusters_no_septem_veto]] shows the cluster centers
based on the background data taken at CAST in 2017 and 2018 remaining
after the likelihood cut. Evidently, the cluster density is
significantly lower in the center area than towards the edges and in
particular the corners. The closer the cluster center is to the edges,
the higher the chance that parts of it are cut off. In particular,
cutting of from a track like cluster most likely *reduces* the length
and thus makes the cluster *more* spherical.

#+begin_center
#+CAPTION: Each point represents the cluster center of a single cluster that passes
#+CAPTION: the likelihood cut. The color scale in addition represents whether multiple
#+CAPTION: cluster centers were on the same pixel. The data is the full 2017/18 background
#+CAPTION: data. It is very evident that the gold region (marked as a square) has the
#+CAPTION: lowest background. From there towards the edges and in particular the corners
#+CAPTION: the background increases significantly. This is mostly a geometric effect,
#+CAPTION: for which an example can be seen in fig. [[fig:example_clusters_septem_veto]].
#+CAPTION: *TODO ADD THE GOLD REGION OUTLINE*
#+NAME: fig:background_clusters_no_septem_veto
#+end_center

Normally the individual chips are treated as separate in the analysis
chain. The 'septem veto' is the name for an additional veto step,
which can be optionally applied to the center chip. With it, each
cluster that is considered signal like based on the likelihood cut,
will be analysed in a second step. The full event is reconstructed
again from the beginning, but this time as an event covering *all* 7
chips. This allows the cluster finding algorithm to detect clusters
beyond the center chip boundaries. After finding all clusters, the
normal cluster reconstruction to compute all properties is done
again. Finally, for each cluster in the event again the likelihood
value is computed and compared with the likelihood cut. If now all
clusters whose center is on the central chip are considered
background-like, the event is vetoed (because the initial signal-like
cluster turned out to be part of a larger cluster).

An example that shows two clusters on the center chip, one of which
was initially interpreted as a signal like event before being vetoed
by the 'septem veto', is shown in
fig. [[fig:example_clusters_septem_veto]]. The colors indicate the
clusters each pixel belongs to according to the cluster finding
algorithm. As the chips are treated separately initially, there are
two clusters found on the center chip. The purple and cyan cluster
"portions" of the center chip. The purple part passes the likelihood
cut (X-rays at such low energies are much less spherical on average;
same diffusion, but less electrons) initially, which triggers the
'septem veto'. A full 7 GridPix event reconstruction shows the
additional parts of the two clusters. The purple cluster is finally
rejected.

It is a good example, as it shows a cluster that is still relatively
close to the center, and yet still 'connects' to another chip.

#+begin_center
#+CAPTION: An example event showing all 7 GridPix of the CAST GridPix1 detector.
#+CAPTION: The outlines are the boundaries of each chip (without the real spacing between
#+CAPTION: them) and the color of each point indicates the cluster which it is part of
#+CAPTION: according to the cluster finder.
#+CAPTION: Initially the purple cluster (center chip portion) passes the log likelihood cut
#+CAPTION: (i.e. is signal like), but is vetoed by the 'septem veto'
#+CAPTION: as there are more pixels outside the center chip that are part of this cluster.
#+CAPTION: The cyan cluster in the bottom left of the center chip is in addition a good example of
#+CAPTION: how in particular cutting a track in the corners leads to a much more spherical
#+CAPTION: cluster.
#+NAME: fig:example_clusters_septem_veto
[[~/org/Figs/statusAndProgress/exampleEvents/background_septem_vetoed.pdf]]
#+end_center

The background rate with the septem veto is shown in
fig. [[fig:background_rate_septem_veto]], where we see that most of the
improvement is in the lower energy range $< \SI{2}{keV}$. This is the
most important region for the solar axion flux for the axion-electron coupling.

#+begin_center
#+CAPTION: Background rate achieved based on the 'septem veto' (in addition to the
#+CAPTION: scintillator cut) for the full 2017/18 dataset within the center
#+CAPTION: $\SI[parse-numbers=false]{5 \times 5}{mm²}$. Significant improvement in the
#+CAPTION: $< \SI{2}{keV}$ range, which is most important for axion-electron coupling solar
#+CAPTION: flux.
#+NAME: fig:background_rate_septem_veto
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2017_2018_scinti_veto_septem_veto.pdf]]
#+end_center

*** 'Line veto' 

There is one more further optional step, dubbed the 'line veto', which
checks whether there are clusters whose long axis "points at" the
cluster that passed the log likelihood cut. The idea being that there
is a high chance that such clusters are correlated, especially because
ionization is an inherently statistical process. An example of an
event being vetoed by the 'line veto' is shown in
fig. [[fig:example_clusters_line_veto]].

#+begin_center
#+CAPTION: Example event, which highlights the use case of the 'line veto'. The
#+CAPTION: blue cluster in the upper chip is eccentric and its long axis 'points'
#+CAPTION: towards the red center cluster (which initially passes the $\ln\mathcal{L}$ cut).
#+CAPTION: The black circle is a measure for the radius of the center cluster. If the
#+CAPTION: line of the eccentric cluster cuts the circle, the cluster is vetoed.
#+NAME: fig:example_clusters_line_veto
[[~/org/Figs/statusAndProgress/exampleEvents/background_event_vetoed_by_lineveto.pdf]]
#+end_center

Applying this veto to the full center chip improves the amount of
background significantly over the background seen in
fig. [[fig:background_clusters_no_septem_veto]]. The equivalent plot using
the septem veto is seen in fig. [[fig:background_clusters_septem_veto]].

#+begin_center
#+CAPTION: The equivalent figure to fig. [[fig:background_clusters_no_septem_veto]] but including
#+CAPTION: the 'septem veto'. The main improvement happens towards the corners. In total the
#+CAPTION: number of background clusters drops by a factor of 4, from $\sim\num{43000}$ to
#+CAPTION: $\sim\num{9600}$.
#+CAPTION: *TODO THIS INCLUDES THE LINE VETO. COMPARISON SHOULD BE SHOWN LATER!*
#+NAME: fig:background_clusters_septem_veto
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_clusters_2017_2018_septemveto_lineveto.pdf]]
#+end_center

In total this is a reduction of a factor of 4 over the whole chip. But
even in the center most region (a square of the center \SI{25}{mm²})
sees an improvement, especially at low energies. 

*** Final background rate using all vetoes

All the vetoes discussed above yield a very good improvement of the
background rate, shown in fig. [[fig:background_rate_all_vetoes]], which
contains the comparisons of all vetoes discussed above. Each veto
builds on the previous ones.

The background rate between $\SIrange{0}{8}{keV}$ ends up at
$<\SI{1.1e-5}{keV⁻¹ cm⁻² s⁻¹}$. While the vetoes allow for a good
reduction over the initial background rate (in particular over the
whole chip, as seen in fig. [[fig:background_clusters_septem_veto]], the
limitations of the achieved background needs to be discussed in the
context of a GridPix3 based detector with 7 GridPix.

First of all the main features visible in the background rate are of
course the argon fluorescence line at around $\SI{3}{keV}$ and the
copper fluorescence lines at $\sim\SIrange{8}{9}{keV}$. There are two
main ways to excite these lines:
1. via cosmics
2. via radioactive impurities of the detector material
These also split into two groups:
1. the inducing particle induces these *within* the sensitive area of
   the readout (only possible for the excitation of the argon line or
   the copper of the anode)
2. the inducing particle induces these *outside* the sensitive area of
   the readout
   
In the first case the GridPix1 detector runs into a severe limitation
due to its readout. The readout of the Timepix1 is shutter based. The
combination of 7 such GridPix1 leads to a significantly long readout
time, which is why a shutter length of about $\SI{2.4}{s}$ was chosen
for the data taking at CAST. As we only had an FADC to trigger and
thus close the shutter prematurely for the center chip, the long time
scales mean the chance of random coincidences of events on the outer
chips is significant. For example a muon that traverses over the outer
chips, but neither fulfills the septem or line veto, there is no way
to be certain whether the cluster seen on the center chip is
correlated or not. While an aggressive "no activity on outer chips
allowed" veto is possible, it severely increases the dead time due to
the long shutter times. This particular case is perfectly resolved by
the usage of the GridPix3, as that version not only
allows for a data driven readout resolving the problem of long
shutter times, but also allows for *simultaneous* readout of ToT and
ToA. So with a GridPix3 detector such random coincidences are reduced
to 'real' random coincidences, which are of the time scale of the
physical processes we are interested in.

The second case will remain an issue even with a GridPix3 based
detector. *However*, passive mitigation of this is possible by
using a different gas mixture (e.g. xenon based) to avoid the
argon fluorescence line altogether.

*TODO*: once merged, replace/add radiopure talk with reference to
corresponding section
Further, the GridPix3 detector will be built using radiopure
materials. This should significantly reduce the amount of induced
fluorescence to those parts that are cosmic induced. And finally the
cosmic induced events will also be further reduced by usage of a fully
covering scintillator veto system.

All of these combinations should lead to a significant improvement of
the background rate. 

#+begin_center
#+CAPTION: Background rate in the center $\SI[parse-numbers=false]{5 \times 5}{mm²}$ region using
#+CAPTION: the full 2017/18 GridPix1 dataset from CAST. Each successive veto, applied in the order
#+CAPTION: in which they are explained above is shown cumulatively. The 'line veto' contains all
#+CAPTION: discussed vetoes. It yields a background rate in the region between $\SIrange{0}{8}{keV}$ of
#+CAPTION: $<\SI{1.1e-5}{keV⁻¹ cm⁻² s⁻¹}$.
#+NAME: fig:background_rate_all_vetoes
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2017_2018_scinti_veto_septem_veto_line_veto.pdf]]
#+end_center

*** Neural network based classification

The likelihood cut based method presented in section
[[#sec:likelihood_method]] works well, but does not use the full potential
of the data. It mainly uses length / eccentricity related properties,
which are hand picked and ignores the possible separation power of all
other properties.

Multiple different ways to use all separation power exist. One
promising approach is the usage of artificial neural networks (ANN). A
multi-layer perceptron (MLP; (*reference something?*) ) is a simple ANN model, which consists of an
input and output layer plus N fully connected hidden layers. By
training such a network on the already computed geometric properties
of the clusters, computational requirements remain relatively
moderate.

As a reference an MLP was trained (implementation [[https://github.com/Vindaar/TimepixAnalysis/blob/master/Tools/NN_playground/train_ingrid.nim][here]]) on a mix of
X-ray reference data (as signal-like training data) and a subset of
the CAST background data. The implementation was done using [[https://github.com/scinim/flambeau][Flambeu]], a
wrapper for [[https://pytorch.org/][libtorch]], using the following parameters:

- Input neurons: 12
- Hidden layers: 1
- Neurons on hidden layer: 500
- Output neurons: 2
- Activation function: =ReLU= (Rectified linear unit) (*ref?*)
- Gradient algorithm: Stochastic Gradient Descent (SGD) (*ref?*)
- Learning rate: 0.005
- Momentum: 0.2
- Batch size: 100 

The 12 input neurons were fed with all geometric properties that do
not scale directly with the energy (no number of active pixels or
direct energy) or position on the chip (as the training data is skewed
towards the center).

This is considered a "reference" implementation, as it is essentially
the simplest ANN layout possible. As a comparison to the likelihood
method the receiver operating characteristic (ROC) curves (*REFERENCE
SOMETHING*) for the different
X-ray reference datasets is used. The signal and background data used
for each case (likelihood and MLP) is the test dataset used to test
the MLP performance after training. Fig. [[fig:roc_curves_logl_mlp]] shows
these ROC curves with the line style indicating the method and the
color corresponding to the different targets and thus different
fluorescence lines. The improvement in background rejection at a fixed signal efficiency
exceeds $\SI{10}{\percent}$ at multiple energies.

The usage of such neural networks is plainly a replacement for the
likelihood cut method used to detect the initial cluster candidates
and during classification of the septem/line veto. It does not replace
any of the vetoes, as these include information outside the center
chip, which is not available for the neural network (training and
validation becomes much more complicated if all chips were to be used,
due to the random coincidence problem mentioned in a previous section).

#+begin_center
#+CAPTION: ROC curves for the comparison of the likelihood cut method (solid lines) to the
#+CAPTION: MLP predictions (dashed lines), colored by the different targets used to generate the
#+CAPTION: reference datasets. The background data used for each target corresponds to background
#+CAPTION: clusters in an energy range around the fluorescence line.
#+CAPTION: The MLP visibly outperforms the likelihood cut method in all energies. At the same
#+CAPTION: signal efficiency (x axis) a significantly higher background rejection is achieved.
#+NAME: fig:roc_curves_logl_mlp
[[~/org/Figs/statusAndProgress/neuralNetworks/roc_curve_mlp_vs_likelihood_split_by_target_1000_epochs_no_energy_hits.pdf]]
#+end_center

**** Combination of NN w/ vetoes

[[file:~/CastData/ExternCode/TimepixAnalysis/Tools/NN_playground/predict_event.nim]]

#+begin_src sh
./predict_event ~/CastData/ExternCode/TimepixAnalysis/resources/LikelihoodFiles/lhood_2017_crGold_septemveto_lineveto_dbscan.h5 \
                ~/CastData/ExternCode/TimepixAnalysis/resources/LikelihoodFiles/lhood_2018_crGold_septemveto_lineveto_dbscan.h5 \
  --lhood --cutVal 3.2 --totalTime 3400
#+end_src

Within 0 - 8 keV:
6.413398692810459e-6 keV⁻¹•cm⁻²•s⁻¹
Within 0 - 2.8 & 4.0 - 8.0 keV:
4.133025759323338e-6 keV⁻¹•cm⁻²•s⁻¹

yields

[[~/org/Figs/statusAndProgress/neuralNetworks/background_rate_after_logl_septemveto_lineveto_and_mlp.pdf]]



*** Example using GridPix3 data

Maybe separate, maybe merged into the other sections.



* Limit calculation                                                :Analysis:
#+LATEX: \minitoc

In a physics experiment after performing all measurements there comes
the question of "did I measures something and do I want to compute
some confidence interval on an observable or did I measure nothing and
want to set a limit on the observable?"

These questions can be answered in a variety of different ways. 

In the end it is highly dependent on a Frequentist vs. Bayesian
approach to statistics.

#+begin_comment
If we decide to present different limits, we should have one section
(maybe in theory) where we present our methodology and then compute
the limits based on that method for each of the different cases:
- chameleon
- axion photon
- axion electron

Using background rate & methods to determine it.

*Need* to show the log L phase space according to Igor. Well, that
seems useful anyway.

*TODO* somewhere explain what an expected vs. a real limit is.
#+end_comment

** Generic limit calculation method
:PROPERTIES:
:CUSTOM_ID: sec:stats:limit_method
:END:


We will now present a limit calculation method that is based on the
limit presented in \cite{cast_nature}, but extended to provide a fully
generic limit calculation method that requires no restriction to
specific regions of interest.

The likelihood function used in \cite{cast_nature} is
#+NAME: eq:nature_likelihood_function
\begin{align}
\ln \mathcal{L} = -R_T + \sum_i^n \ln R(E_i, d_i, \vec{x}_i) 
\end{align}
where $R_T$ is the total expected signal and $R$ the sum of signal and
background contributions. The details will be explained further down.

First we will derive the Bayesian method and discuss the individual contributions.

#+begin_comment
Describe log L and χ² distribution and how to compute limit.

Unphysicality, fix by rescaling, χ² min + 4 thing
*UPDATE*: good that we now understand how this actually works,
i.e. integrate the posterior probability (likelihood * prior / normalization)
#+end_comment

The maths of the likelihood expression we use, is mostly straight
forward.

A likelihood function is purely defined as the product of the
individual probabilities for each 'channel' in our measurement. That
way the likelihood gives us the total probability to get this exact
measurement outcome out of all possible outcomes.

If we start from a likelihood ratio \footnote{Likelihood ratio simply
means taking a ratio of two different likelihood functions.} of the
signal + background hypothesis over the pure background hypothesis, in
the binned case we can derive formula [[#eq:nature_likelihood_function]]
from first principles. The number of measured counts in each bin is
simply a Poisson distribution:

#+begin_comment
Clarify what a "bin" refers to and what "channels" are. 
#+end_comment

\[
P_{\text{Pois}}(k; λ) = \frac{λ^k e^{-λ}}{k!}
\]
for each bin an expected number of counts $λ$ (the mean) then means a probability given $P$
for a "measured" number of counts $k$. Combining multiple "channels"
is then simply the product of these individual channels, giving us the
likelihood for one experiment:

\[
\mathcal{L} = \prod_i P_{i, \text{Pois}}(k; λ) = \prod_i \frac{λ_i^{k_i} e^{-λ_i}}{k_i!}
\]

Applying this to the previously mentioned likelihood ratio $Q$ gives
us:

\[
Q = \frac{\prod_i P_{i, \text{Pois}}(n_i; s_i + b_i)}{\prod_i P_{i, \text{Pois}}(n_i; b_i)} =
  \prod_i \frac{ \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)} }{ \frac{b_i^{n_i}}{n_i!} e^{-b_i}}
\]

where $n_i$ is simply the number of measured candidates within the
signal sensitive region in each bin $i$. Typically, each bin might be a
bin in energy, but it can be any kind of "bin" as long as each bin
corresponds to something that follows a Poisson distribution. We will
make use of this fact in a bit.

This can be interpreted as an extended likelihood function, as the
ratio of two Poisson distributions does not satisfy the normalization
condition:

\[
\int_{-∞}^{∞}P\, \mathrm{d}x = 1
\]

anymore. Instead we have:

\[
\int_{-∞}^{∞}Q\, \mathrm{d}x = N
\]

where $N$ can be interpreted as a hypothetical number of total number
of counts measured in the experiment; the starting point of the
definition of the extended maximum likelihood estimation.

From here we derive the logarithm of the expression to get the
numerically more stable $\ln \mathcal{L}$ expression:

#+NAME: eq:likelihood_1_plus_s_over_b_form
\begin{align*}
\ln \mathcal{Q} &= \ln \prod_i \frac{ \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)}  }{ \frac{b_i^{n_i}}{n_i!} e^{-b_i} } \\
  &= \sum_i \ln \frac{ \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)}  }{ \frac{b_i^{n_i}}{n_i!} e^{-b_i} } \\
  &= \sum_i \ln \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)}  - \ln \frac{b_i^{n_i}}{n_i!} e^{-b_i}  \\
  &= \sum_i n_i \ln (s_i + b_i) - \ln n_i! - (s_i + b_i) - (n_i \ln b_i - \ln n_i! -b_i)  \\
  &= \sum_i n_i \ln (s_i + b_i) - (s_i + b_i) - n_i \ln b_i + b_i  \\
  &= \sum_i n_i \ln (s_i + b_i) - (s_i + b_i - b_i) - n_i \ln b_i  \\
  &= \sum_i n_i \ln \left(\frac{s_i + b_i}{b_i}\right) - s_i  \\
  &= -s_{\text{tot}} + \sum_i n_i \ln \left(\frac{s_i + b_i}{b_i} \right) \\
  &\text{or alternatively} \\
  &= -s_{\text{tot}} + \sum_i n_i \ln \left(1 + \frac{s_i}{b_i} \right) \\
\end{align*}

here $s_{\text{tot}}$ represents the total number of "signal" like
counts expected (in our case total number of expected photons due to
axion conversion).

The last two lines show us that all that is really important is that
the normalization of $s_i$ and $b_i$ are the same. The absolute
normalization (e.g. if it's $\si{keV⁻¹}$ or absolute counts etc.) plays no
role as that will be a constant multiplier. That constant can always
be neglected in the total likelihood (a constant only moves the logL
curve up / down, but does not change its maximum!).

Coming back to the "channels" / the binning: if we choose our bins
such that they are bins in time, so small that each bin either
contains 0 or 1 count, we reduce this to our desired unbinned log
likelihood, if we start from the second to last line above and drop
the constant $-\ln b_i$ term:

\[
\ln \mathcal{L} = -R_{\text{tot}} + \sum_{\text{candidates}} \ln(s_i + b_i)
\]
where the sum now runs over each candidate instead of the abstract
"channels".

With an understanding of where the formula comes from, we can more
safely make statements about what the shape of the logL curve is going
to look like. For that it is important to realize that:
- $-R_{\text{tot}}$ depends on $g_{ae²}$, $-R_{\text{tot}}(g_{ae²})$
- $s_i$ depends on $g_{ae²}$, $\vec{x}$ and the cluster energy $E$,
  $s_i(g_{ae²}, \vec{x}, E)$
- $b_i$ only depends on the cluster energy $E$

This means $b_i$ for all intents and purposes is constant under a
change of the coupling constant for a fixed set of candidate
clusters. For a scan over $\ln\mathcal{L}$ this is precisely given.

Now let's consider what each part's contribution will look like as a
$\ln\mathcal{L}$ curve:

1. $-R_{\text{tot}}$: the total number of counts depends on the axion
   flux, the tracking time and the total detection efficiencies. The
   latter two are simply constants when integrating over the region of
   interest in energy, namely \SIrange{0}{10}{\keV}. The axion flux
   scales as:
   \[
   f(g') = f(g) \frac{g^{\prime 2}}{g²}
   \]
   i.e. a squared rescaling of the flux. Given that we scan the logL
   space in $g_{ae²}$, this means the total flux (the integral of $f$
   over all energies) just scales linearly with $g_{ae²}$.
   Due to the minus sign in front, the result is plainly a line with
   negative slope going through the origin at $g_{ae²} = 0$.
2. $b_i$: the background hypothesis is a function only depending on
   the energy of each cluster (and implicitly on the relevant area and
   tracking time). For a fixed set of candidates during a $g_{ae²}$
   scan, its contribution is plainly constant.
3. $s_i$: this is the complicated one. It not only depends on
   $g_{ae²}$, but also the energy $E$ and more importantly the
   position of the cluster center $\vec{x}$. The latter is used for
   the effective flux at each position on the chip that is expected
   from axion conversion after focusing of the X-ray telescope.
   In principle the cluster center positions are constant for a single
   scan of $g_{ae²}$. This means effectively the signal $s_i$ behaves
   exactly like $R_{\text{tot}}$ under $g_{ae²}$. The resulting
   behavior is thus also linear, except with a positive slope.
   The big difference between $s_i$ and $R_{\text{tot}}$ however is
   that $R_{\text{tot}}$ is integrated over all energies, whereas
   $s_i$ is only evaluated at specific energies (in keV⁻¹).

#+begin_comment
Rephrase this whole part & remove the confusion, as it's now fully
understood how to approach it.
#+end_comment

Combining these three facts we expect to find some maximum somewhere,
where the $R_{\text{tot}}$ term and the $s_i$ term cancel each
other. The $b_i$ term only contributes an offset (which however
depends on the candidates, which is why it cannot be ignored!).

This brings us to a particular problem:
What happens if the candidates are all located outside of the axion
sensitive region? In that case their contribution will be zero, due to
the position dependency of $\vec{x}$. This leads to a pure
$R_{\text{tot}}$ negative slope on top of a constant background $b_i$.
In this case the logL curve does *not* have a maximum! And in cases
where arbitrarily little contribution is had, there *will* be a
maximum somewhere, but it will be very far into the unphysical range,
at which point the 1σ width (based on logL_max - 0.5) yield a width
that leads to a physical limit at 0 (due to the gaussian CDF being
essentially 1 many σ away from the center).

Given our statistics of $O(30)$ candidates in our tracking time, this
presents a problem. For toy experiments there is a high chance of
getting precisely that problem. A large number of candidates (70 - 90%
maybe) will be outside the sensitive region, resulting in no good way
to determine the limit.

**** Further expl: Bayes integral *AFTER MAIL FROM IGOR ON <2021-10-03 Sun>*:

Essentially saying that we simply integrate over and demand:

0.95 = ∫_-∞^∞ L(g_ae²) Π(g_ae²) / L_0 d(g_ae²)

where L is the likelihood function (*not* the ln L!), Π is the prior
that is used to exclude the unphysical region of the likelihood phase
space, i.e. it is:

Π(g_ae²) = { 0 if g_ae² < 0, 1 if g_ae² >= 0 }

And L_0 is simply a normalization constant to make sure the integral
is normalized to 1.

Thus, the integral reduces to the physical range:

0.95 = ∫_0^∞ L(g_ae²) / L_0 d(g_ae²)

where the 0.95 is, due to normalization, simply the requirement of a
95% confidence limit.

With this out of the way I implemented this into the limit calculation
code as the =lkBayesScan= limit.

** Extending the method for systematic uncertainties
:PROPERTIES:
:CUSTOM_ID: sec:limit:limit_method
:END:

The limit calculation method is based on the approach presented in
\cite{cast_nature}, with modifications to better suit the GridPix
detector and make the method more generic (under exchange of the
model to be studied).

#+begin_comment
Extend this by the derivation for the marginal likelihood that shows
how one gets to the shown equation from what's shown in the previous section.
#+end_comment

We will now go through the ingredients for the limit method one by
one. The final likelihood including nuisance parameters we evaluate is
(see section [[#sec:stats:limit_method]] for the derivation):

\[
\mathcal{L}_{SBM} = ∫_{-∞}^∞∫_{-∞}^∞∫_{-∞}^∞∫_{-∞}^∞ \exp(-s'_{\text{tot}}) \cdot \prod_i \left(1 +
\frac{s_i''}{b_i'}\right) \cdot
\exp\left[-\frac{θ_b²}{2 σ_b²} - \frac{θ_s²}{2 σ_s²} -
\frac{θ_x²}{2 σ_x²} - \frac{θ_y²}{2 σ_y²} \right]
\, \mathrm{d}\,θ_b \mathrm{d}\,θ_s \mathrm{d}\,θ_x \mathrm{d}\,θ_y.
\]
where primed symbols refer to the base symbol with a modification due
to the value of the corresponding nuisance parameter, i.e.
$x' = x(1 + θ_x)$. The double primed $s_i''$ not only includes $θ_s$,
but also the position dependent nuisance parameters $θ_x$ and $θ_y$
(see again the previous section).

The inputs required to compute a likelihood value are (with the
relevant parameters):
- a set of candidate clusters (either from the real solar tracking or
  randomly sampled ones) with cluster centers at $(x_i, y_i)$ and
  associated energies $E_i$ (over which the product $i$ runs).
- the solar axion flux produced the model to be analyzed, as a
  function of energy (depending on $g_{ae}$ and $g_{aγ}$, but the
  $g_{aγ}$ contribution can be ignored for certain choices of $g_{ae}$
  and $g_{aγ}$.
- the conversion probability of axions in a magnetic field (depending
  on $g_{aγ}$.
- the efficiency of the X-ray optics as a function of energy $E$.
- the transmission probability of X-rays through the detector window
  as a function of $E$ and the entrance position $(x, y)$.
- the absorption probability of X-rays in the used Argon gas as a
  function of energy $E$.
- the average depth $\langle d \rangle$ at which the X-rays produce a photo-electron in
  the Argon gas for the expected flux of converted solar axions (after
  propagation through the X-ray optics and detector window).
- the resulting flux of axion induced X-rays as a function of the
  position $(x, y)$ on the detector, depending on $g_{ae}$.
- the expected background rate at any position $(x, y)$ in the
  detector and any energy $E$.

From here we will go through each of these contributions to explain
how each is obtained and what they look like.

- [ ] Should we here essentially just refer back to the "theory like"
  sections before where each of these ingredients is already
  introduced? At least for things like Argon absorption / detection
  efficiency etc. those will certainly be presented before. That means
  by showing them here again, we essentially show the same thing
  again.
  For things like the background interpolation that I would just
  introduce "somewhere here".

  One option would be: for all where it _makes sense_, have a big
  "inputs plot" (maybe a facet, or a =ggmulti= plot) of all inputs we
  have? (*UPDATE*: <2022-08-13 Sat 15:48> see sanity checks for
  likelihood code)
  Then again, here we mainly present the *technique* still. So for
  example the final candidates wouldn't show up here. But ok, it's
  *only* the candidates that actually changes.

*** Candidates

The candidates are the X-ray like clusters remaining after the background
rejection algorithm has been applied for the data taken during the solar
tracking. For the computation of the expected limit the set of
candidates is drawn from the background rate distribution via sampling
from a Poisson distribution with the mean of the background rate.

A set of toy candidates is shown in
fig. [[fig:limit:toy_candidates]]. Each point represents one toy candidate
at its cluster center position. The color scale represents the energy
of each cluster in \si{keV}.

#+ATTR_LATEX: :width 0.8\textwidth
#+CAPTION: A set of toy candidates drawn from the background rate using a Poisson distribution
#+CAPTION: with mean of the background rate at different positions and energies. Each point is
#+CAPTION: the center of a cluster with the color scale showing the energy of that cluster.
#+CAPTIOn: *TODO:* REPLACE THE PLOT!
#+NAME: fig:limit:toy_candidates
[[~/org/Figs/statusAndProgress/limitCalculation/problematic_candidates_syst_uncert_limit.pdf]]

*** Solar axion flux [0/3]

The solar axion flux for the model to be studied must be known both as
a function of energy $E$ and also as a differential flux as a function
of the solar radius to produce the expected axion image via raytracing
(see sec. [[#sec:raytracing]]).

This means in principle we require knowledge about the production as
shown in the heatmap of fig. [[fig:limit:axion_production_heatmap]]. (Move
this to theory?)

- [ ] generate heatmap of production as function of energy and solar
  radius
- [ ] or show here just the signal?
- [ ] the idea being here that we highlight what one needs to replace
  in order to compute a limit of something else possibly (which then
  allows us later to have a section "axion-photon" or "chameleon"
  where we just present the inputs "see sec. blub, here's the
  production heatmap" kind of deal

*** Conversion probability

The conversion probability of the arriving axions is simply a constant
factor, depending on $g_{aγ}$, see section
[[#sec:theory:axion_conversion]] for the derivation from the general
formula.

The simplified expression for coherent conversion in a constant
magnetic field \footnote{Note that in a perfect analysis one would
compute the conversion in a realistic magnetic field, as the field
strength is not perfectly homogeneous. That would require a very
precise field map of the magnet. In addition the calculations for
axion conversions in inhomogeneous magnetic fields is significantly
more complicated. As far as I understand it requires essentially a
"path integral like" approach of all possible paths through the
magnet, where each path sees different, varying field strengths. Due
to the small size of the LHC dipole prototype magnet and general
stringent requirements for homogeneity this is not done for this
analysis. However, likely for future (Baby)IAXO analyses this will be
necessary.} is

\[
P(g_{aγ}, B, L) = \left(\frac{g_{aγ} \cdot B \cdot L}{2}\right)^2
\]
where the relevant numbers for the CAST magnet are:
- $B = \SI{9}{T}$
- $L = \SI{9.26}{m}$
and in the basic axion-electron analysis a fixed axion-photon coupling
of $g_{aγ} = \SI{1e-12}{\per\giga\electronvolt}$.

Looking closely at the units of this expression, the equation as it is
written uses natural units. This requires either conversion of the
equation into SI units by adding the "missing" constants or converting
the SI units into natural units. As the result is a unit less number,
the latter approach is simpler.

The conversion factors from Tesla and meter to natural units are as follows:
#+begin_src nim :results raw
import unchained
echo "Conversion factor Tesla: ", 1.T.toNaturalUnit()
echo "Conversion factor Meter: ", 1.m.toNaturalUnit()
#+end_src

#+RESULTS:
Conversion factor Tesla: 195.353 ElectronVolt²
Conversion factor Meter: 5.06773e+06 ElectronVolt⁻¹

*TODO*: Move this out of the thesis and just show the numbers in text?
Keep the "derivation / computation" for the "full" version (:noexport:
?).

As such, the resulting conversion probability ends up as:

#+begin_src nim :results raw
import unchained, math
echo "9 T    = ", 9.T.toNaturalUnit()
echo "9.26 m = ", 9.26.m.toNaturalUnit()
echo "P      = ", pow( 1e-12.GeV⁻¹ * 9.T.toNaturalUnit() * 9.26.m.toNaturalUnit() / 2.0, 2.0)
#+end_src

#+RESULTS:
9 T    = 1758.18 ElectronVolt²
9.26 m = 4.69272e+07 ElectronVolt⁻¹
P      = 1.701818225891982e-21

\begin{align}
P(g_{aγ}, B, L) &= \left(\frac{g_{aγ} \cdot B \cdot L}{2}\right)^2 \\
               &= \left(\frac{\SI{1e-12}{\per GeV} \cdot \SI{1758.18}{eV^2} \cdot \SI{4.693e7}{eV}}{2}\right)^2 \\
               &= \num{1.702e-21}
\end{align}

Note that this is of the same (inverse) order of magnitude as the flux
of solar axions ($\sim10^{21}$ in some sensible unit of time), meaning
the experiment expects $\mathcal{O}(1)$ counts, which is sensible.

*** Telescope efficiency

- [ ] Refer back to section that describes the LLNL telescope!

The X-ray telescope further has a direct impact not only on the shape
of the axion signal on the readout, but also the total number of
X-rays transmitted. The effective transmission of an X-ray telescope
is significantly lower than in the optical range. This is typically
quoted using the term "effective area". In section
[[#sec:cast:llnl_telescope]] the effective area of the two X-ray optics
used at CAST in shown.

The term effective area refers to the equivalent area a perfect X-ray
telescope would cover. As such, the real efficiency $ε_{\text{tel}}$ can be computed by
the ratio of the effective area $A_{\text{eff}}$ and the total area of the optic $A_{\text{tel}}$.

\[
ε_{\text{tel}}(E) = \frac{A_{\text{eff}}(E)}{A_{\text{tel}}}
\]

where the effective area $A_{\text{eff}}$ depends on the energy
\footnote{Note that $ε_{\text{tel}}$ here is the average effective
efficiency of the full telescope and *not* the reflectivity of a
single shell. As a Wolter I optic requires two reflections
$ε_{\text{tel}}$ is equivalent to the reflectivity squared
$R²$. Individual reflectivities of shells are further complicated by
the fact that different shells receive parallel light under different
angles, which means the reflectivity varies between shells. Therefore
this is a measure for the average efficiency.}. In case of CAST
the relevant total area is not actually the cross-sectional area of
the optic itself, but rather the exposed area due to the diameter of
the magnet coldbore. With a coldbore diameter of $d_{\text{cb}} = \SI{43}{mm}$ the
effective area can be converted to $ε_{\text{tel}}$.

The resulting effective area is shown in
fig. [[fig:limit:window_trans_telescope_eff]] in the next section together
with the window transmission and gas absorption.

*** Window transmission and Argon gas absorption

The detector entrance window is the next point affecting the possible
signal to be detected. The windows, as explained in section
[[#sec:detector:windows]] are made from $\SI{300}{nm}$ thick silicon
nitride



- [ ] plot of the effective area
- [ ] compute window transmission with =xrayAttenuation=
- [ ] compare with Henke

*** Combined detection efficiency

The previous two sections cover aspects which affect the detection
efficiency of the detector and thus impact the amount of signal
available. Combined they yield a detection efficiency as shown in
fig. [[fig:limitCalculation:combined_detection_eff]]. As can be seen, the
combined detection efficiency maxes out at about 40% around 1.5 keV
(*CHECK NUMBERS*). Note that this does not include the effect of the
window strongback, which is separately taken into account for the
exact position dependent points (for the signal contributions).

*TODO*: Also include the version that is split up into the individual
pieces somewhere!

#+ATTR_LATEX: :width 0.8\textwidth
#+CAPTION: The combined detection efficiency of the detector, taking into account the
#+CAPTION: telescope efficiency via the effective area, the window absorption probability
#+CAPTION: and the absorption probability in the detector gas.
#+CAPTION: 
#+CAPTION: *TODO:* REPLACE THE PLOT! ONLY DET EFF
#+NAME: fig:limitCalculation:combined_detection_eff
[[~/org/Figs/statusAndProgress/limitSanityChecks/sanity_detection_eff.pdf]]

*** Average absorption depth of X-rays

In order to compute a realistic axion image based on raytracing the
plane at which to compute the image needs to be known, as the focal
spot size changes significantly depending on the distance to the focal
point of the X-ray optics.

This is of particular importance for a gaseous detector, as the
raytracing only makes sense up to the generation of a photoelectron,
after which the electrons undergo diffusion. Therefore, one needs to
compute the average absorption depth of X-rays in the relevant energy
ranges for the used gas mixture of the detector.

*INSERT COMPUTATION OR REFERENCE IT BEFORE*

As it is, the average depth is computed to be $\langle d \rangle =
\SI{1.22}{cm}$ behind the detector window.

*** Raytracing axion image

The axion image computed according to the description in
sec. [[#sec:raytracing]] is shown in fig. [[fig:limitCalculation:axion_image]]

#+ATTR_LATEX: :width 0.8\textwidth
#+CAPTION: Axion image as computed using raytracing for the AGSS09 solar model
#+CAPTION: and under the assumption that the axion-electron coupling constant
#+CAPTION: $g_{ae}$ (*GIVE NUMBER*) dominates over the axion-photon coupling $g_{aγ}$.
#+CAPTION: The left image shows the raw axion image whereas the right one includes
#+CAPTION: the window strongback
#+CAPTION: *NOTE: EXTEND TO RIGHT W/ STRONGBACK*
#+NAME: fig:limitCalculation:axion_image
[[~/org/Figs/statusAndProgress/limitSanityChecks/axion_image_limit_calc_no_window_no_theta.pdf]]

*** Background [0/6]

The background must be evaluated at the position and energy of each
cluster candidate. As the background is not constant in energy or
position on the chip, we need a continuous description in those
dimensions of the background rate.

In order to obtain such a thing, we start from all X-ray like clusters
remaining after background rejection, see
fig. [[fig:limit:background_clusters]] where each point is a cluster
center with the color indicating its energy (similar to the candidates
plot further up).

Figures:
1. background clusters
2. (optional) plot showing "selection" of clusters based on
   =queryBallPoint=? I.e. show all clusters in grey, radius & then in
   color those that are in the radius?
3. background "interpolation" based purely on query ball point of raw
   data, at a slice of energy.
4. in a facet with 3 show same after normalization?
5. show effect of area cutoff correction. Also results in a "final"
   background rate interpolated.


Highlight:
So what? This allows us to evaluate the background rate correctly on
the full chip! Generic ALPs can be studied this way, as we don't have
to manually define regions on the chip with specific backgrounds etc.!
One of the fundamental points about making this whole procedure generic.

- [ ] explain using k-d tree to efficiently look up "neighbors" at any
  point (x, y, E). In particular explain how energy works. Not taken
  into account in distance aside from whether inside. So gaussian
  weighting only in x/y.
  
- [ ] use number & distance to these points to compute a weighted
  number of elements in desired "radius"
- [ ] potentially rescale number based on area cut off due to edges of
  the chip. how does this work.
- [ ] renormalize from an effective "number" of clusters to a rate. . how does rescaling work.

- [ ] explain how the integration works etc, copy from sections
  [[sec:correct_inter_cutoff]] and [[sec:limit:gaussian_weight_normalization]]
  in status.

- [ ] *TODO*: check the integration of the gaussian weight again. Is
  that really correct??!! Ahh, it might be correct. What we try to do
  is not to compute anything related to the actual neighbors found in
  the radius, but rather to get the "equivalent area" of the weighted
  data!


**** Sampling of background interpolation

Take interpolation. For sampling purposes we need to sample from
background according to rate. How?
Take a grid in x, y, E of N grid cells. Take background in those
volumes & normalize to # counts in tracking time. Then Poisson sample
from that as mean. Sample an (x, y, E) "position" in that cube.

10x10x20 ? cells used. Plot of the cells, normalized to counts.

*** Systematics

Talk about the systematics. The different systematics used, the table
of systematics.



**** Derivation of the systematics                              :noexport:

Copy over from =[status]=. 

*** Putting it all together

First: show the basic algorithm in pseudo code to compute a likelihood
value for a set of parameters ($g_{ae}²$, and the $θ$ values).

- expected rate,
- nuisance parameter penalty terms
- loop over candidates, for each candidate
  - compute signal
  - compute background
  -> combine

From here either integrate out $θ$ manually, or sample via MCMC. Goes
straight to next section.  

*** MCMC to sample the distribution

*** Expected limit, MC toy sampling



** Axions

*** Axion-electron coupling

**** The candidates

Unblinding the data, the solar tracking candidates left after
application of the likelihood cut method and vetoes, are shown in
fig. [[fig:limit:solar_track_candidates]].

All other inputs for the limit calculation remains the same as
presented in the previous section sec. [[#sec:limit:limit_method]].

- [ ] insert plot of solar tracking candidates!

*** Axion-photon coupling

*** Chameleon coupling

** Compute limit w/ our method (whatever that will finally be)

** Comparison to 2013 limit (using their method)

** Limit calculation using neural networks                         :PENDING:

** TODO Chameleons ?


* Outlook                                                             :Part5:

Timepix3 based detector will be big improvement, as long readout times
without time information are probably the biggest issue (and partially
biggest mistake) in the data taking campaign.

* Summary & conclusion                                                :Part5:



* Acknowledgments                                                     :Part5:

Thanks to Klaus & group.

Thanks to Araq for building Nim.

Thanks to Nim community, and especially:
Mamy (@mratsim), Hugo (@hugogranstrom), Clonkk, Chuck (@cblake), Andrea Ferreti (alea among others), @brentp
(plotly was a *huge* help in the beginning), @Bluenote10 (NimData was
great), @yglukhov (nimpy in particular!!)


# Use biblatex for the bibliography
# Add bibliography to Table of Contents
# Comment out this command if your references are printed for each chapter.
#+LATEX: \printbibliography[heading=bibintoc]

* Appendix                                                         :Appendix:
#+LATEX: \minitoc
#+LATEX: \listoffigures{}

#+LATEX: \listoftables{}

** Configurations

*** TOS configuration file [/]

This is the configuration file as it was used at CAST during the data
taking periods.

- [ ] *ALSO LINK AN ONLINE VERSION?*

#+begin_src toml
[General]
sAddress_fadc = 1
baseAddress_hv = 0x4000

[HvModule]
setKillEnable                   = true
# Voltage and Current RampSped currently set to arbitrary value
# in percent / second
moduleVoltageRampSpeed          = 0.1
moduleCurrentRampSpeed          = 50
# checkModuleTimeInterval       = 60, checks the status of the
# module every 60 seconds during a Run, between two events
checkModuleTimeInterval         = 60

# if this flag is set to true, anode and grid
# will be coupled to one group
[HvGroups]
anodeGridGroupFlag              = true
# grid is master channel of set on group
anodeGridGroupMasterChannel     = 5
anodeGridGroupNumber            = 0
monitorTripGroupFlag            = true
monitorTripGroupNumber          = 1
rampingGroupFlag                = true
rampingGroupNumber              = 2                          
gridChannelNumber               = 5
anodeChannelNumber              = 6
cathodeChannelNumber            = 9

[HvChannels]
# grid, anode and cathode settings
# all currents given in A (vmecontrol shows mA)
0_Name                          = grid
0_Number                        = 5
0_VoltageSet                    = 300
0_VoltageNominal                = 500
0_VoltageBound                  = 10
0_CurrentSet                    = 0.000050
0_CurrentNominal                = 0.000500 
0_CurrentBound                  = 0
                                
1_Name                          = anode
1_Number                        = 6
1_VoltageSet                    = 375
1_VoltageNominal                = 500
1_VoltageBound                  = 10
1_CurrentSet                    = 0.000050
1_CurrentNominal                = 0.000500
1_CurrentBound                  = 0
                                
2_Name                          = cathode
2_Number                        = 9
2_VoltageSet                    = 1875
2_VoltageNominal                = 2500
2_VoltageBound                  = 15
2_CurrentSet                    = 0.000050
2_CurrentNominal                = 0.000500
2_CurrentBound                  = 0
                                
3_Name                          = Ring1
3_Number                        = 7
3_VoltageSet                    = 415
3_VoltageNominal                = 500
3_VoltageBound                  = 15
3_CurrentSet                    = 0.000100
3_CurrentNominal                = 0.000500
3_CurrentBound                  = 0
                                
4_Name                          = Ring29
4_Number                        = 8
4_VoltageSet                    = 1830
4_VoltageNominal                = 2500
4_VoltageBound                  = 15
4_CurrentSet                    = 0.000100
4_CurrentNominal                = 0.000500
4_CurrentBound                  = 0
                                
6_Name                          = sipm
6_Number                        = 4
6_VoltageSet                    = 65.6
6_VoltageNominal                = 100
6_VoltageBound                  = 5
6_CurrentSet                    = 0.0005
6_CurrentNominal                = 0.0005
6_CurrentBound                  = 0
                                
# The veto paddle scintillator is commented out, as it was supplied
# with HV by an external CAEN HV power supply.
# 5_Name                        = szintillator
# 5_Number                      = 11
# #5_VoltageSet                 = 1300
# 5_VoltageSet                  = 0
# 5_VoltageNominal              = 2500
# 5_VoltageBound                = 5
# 5_CurrentSet                  = 0.002
# 5_CurrentNominal              = 0.002
# 5_CurrentBound                = 0

[Fadc] # FADC Settings
fadcTriggerType                 = 3 
fadcFrequency                   = 2
fadcPosttrig                    = 80
fadcPretrig                     = 15000
# was 2033 before, 1966 corresponds to -40 mV
fadcTriggerThresholdRegisterAll = 1966 
# run time of a single pedestal run for the FADC in ms
fadcPedestalRunTime             = 100
# number of acquisition runs done for each pedestal calibration
fadcPedestalNumRuns             = 10
# using channel 0 on FADC as trigger source, thus bit 0  1!
fadcChannelSource               = 1
# set FADC mode register (mainly to enable 14-bit readout)
fadcModeRegister                = 0b000

[Temperature] # temperature related parameters
safeUpperTempIMB                = 61
safeUpperTempSeptem             = 61
safeLowerTempIMB                = 0
safeLowerTempSeptem             = 0
#+end_src



** Calibrations

*** Septemboard calibration

Show all calibrations for each of the runs.

That means, for all chips:
- THS optimization & equalization bits
- equalized matrix of all pixels  
- ToT calibration
- S-curves
- fit to 50% point of S-curves to get #electrons / THL DAC value    

*** Calibration measurements of the veto scintillator paddle

The following is a set of notes taken when calibrating the
scintillator paddle in the laboratory of the RD51 group at CERN. It is
reproduced here for transparency and completeness.

**** Scintillator paddle calibrations [0/2]

This document contains the data for the calibration of the MM veto
scintillator. It is a 'report' created while data taking and thus may
contain conflicting information. Not to be understood as a simple
reference protocol.

The scintillator has a Canberra 2007 base, which accepts positive
HV. The PMT is a Bicron Corp. 31.49x15.74M2BC408/2-X, where the first
two numbers are the scintillators dimensions in inch.

=For calibration we're using $\SI{1400}{\volt}$, while Juanan
mentioned in his mail to use $\SI{1200}{\volt}$ during data taking.=

For calibration we're using an Ortec 9302 amplifier after the PMT with
a gain of 20. This is fed into an LRS 621CL discriminator. The PMT and
base are used at a HV of $+\SI{1200}{\volt}$.

Scintillator is of size $\SI{42}{\cm}$ times $\SI{82}{\cm}$. Which is
an area of
#+BEGIN_SRC nim
let x = 0.42
let y = 0.82
echo x * y 
#+END_SRC

#+RESULTS:
: 0.3444

- [ ] *TODO: CROSS CHECK THESE NUMBERS HERE*

At a cosmic muon rate of $\sim\SI{100}{\hertz \per \meter \squared
\steradian}$, the expected signal rate of munons is thus $\sim
\SI{33}{\hertz}$.

#+BEGIN_SRC nim
let area = 0.34
let total_muons = 60000.0
echo area * total_muons
#+END_SRC

#+RESULTS:
: 20400.0

- [ ] *UPDATE*: Muon rate about $\SI{1}{cm^{-2}.min^{-1}} \approx \SI{166.67}{m^{-2}.s^{-1}}$

***** Calibration
:PROPERTIES:
:ORDERED:  t
:END:

Threshold values are scaled by a factor of 10. Coincedence using
Theodoros 2 scintillator paddles in RD51 lab. 
- upper scinti: $\SI{-2070}{\volt}$
- lower scinti: $\SI{-2050}{\volt}$

Measurement time for each value: $\SI{10}{\minute}$

Note: The reason the coincidences are much lower than the single
scintillator counts is of course due to the much smaller coincidence
area of the small scintillators used for the measurement.

| Threshold / mV | Counts Szinti | Counts Coincedence |
|----------------+---------------+--------------------|
|         -301.9 |         24062 |                760 |
|           -399 |         13332 |                496 |
|           -498 |          6584 |                300 |
|           -603 |          3363 |                167 |
|           -699 |          1900 |                104 |
|           -802 |          1087 |                 83 |
|           -901 |           651 |                 54 |
|          -1005 |           523 |                 50 |
|          -1104 |           361 |                 32 |
|          -1203 |           231 |                 32 |
|          -1305 |           189 |                 38 |
|          -1400 |           151 |                 23 |
|          -1502 |            96 |                 14 |
|          -1602 |            78 |                 15 |
|          -1703 |            72 |                 10 |
|          -1802 |            58 |                 11 |
|                |               |                    |

Second set of measurements around interesting point of
$\SI{1000}{\milli\volt}$

| Threshold / mV | Counts Szinti | Counts Coincedence |
|----------------+---------------+--------------------|
|          -1200 |           259 |                 35 |
|          -1100 |           350 |                 34 |
|          -1000 |           456 |                 48 |
|           -900 |           774 |                 42 |

A third measurement using an amplifier after the PMT, since the output
signal of the PMT is so small (see mail of JuanAn). Now the HV was
lowered to $\SI{1200}{\volt}$ again, since it is not necessary.

| Threshold / mV | Counts Szinti | Counts Coincedence |
|----------------+---------------+--------------------|
|           -598 |         31221 |                634 |
|           -700 |         30132 |                674 |
|           -804 |         28893 |                635 |
|           -903 |         28076 |                644 |
|          -1005 |         27012 |                684 |
|          -1103 |         25259 |                566 |
|          -1200 |         22483 |                495 |
|          -1303 |         19314 |                437 |
|          -1403 |         16392 |                356 |
|          -1505 |         13677 |                312 |
|          -1600 |         11866 |                267 |
|          -1701 |         10008 |                243 |
|                |               |                    |

|           -900 |         28263 |                892 |
|          -1000 |         26789 |                991 |



Export this table using org-table-export to
[[file:data/veto_szinti_counts.txt]]. Then remove unnecessary last line
and add # to beginning of first line.

- [ ] *REWRITE TO USE AN INLINE GGPLOTNIM PLOTTING AND SHOW DATA*

Then use [[file:PyS_mm_veto_szinti_calib.py]] to plot the data.

A threshold of $\SI{-110}{\milli\volt} was selected, after analysis.
