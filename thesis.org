#+LATEX_CLASS: book-noparts
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage{shellesc}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{longtable}
#+LaTeX_HEADER: \usepackage{pdfpages}
# #+LaTeX_HEADER: \usepackage{tikz}

# 'externalize' all TikZ plots, i.e. cache them
# #+LaTeX_HEADER: \usepackage{pgfplots}
# #+LaTeX_HEADER: \usepgfplotslibrary{external} 
# #+LaTeX_HEADER: \tikzexternalize[prefix=cache/]

#+LATEX_HEADER: % main document, called main.tex
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{external}
#+LATEX_HEADER: \tikzexternalize[prefix=cache/] % activate!

# got an error suddenly with the 'externalize' section above
# https://tex.stackexchange.com/questions/365777/cannot-run-tikz-externalize-with-lualatex-but-it-used-to-work

# for mini table of contents for each chapter
#+LATEX_HEADER: \usepackage{minitoc}

#+LATEX_HEADER: \usepackage{siunitx}
#+LATEX_HEADER: \sisetup{mode=text,range-phrase = {\text{~to~}}}

# font handling

# font handling
#+LATEX_HEADER: \usepackage{fontspec,minted}
#+LATEX_HEADER: \setmonofont{Fira Code} % suports all unicode we care about in code
#+LATEX_HEADER: \setmainfont{DejaVu Serif} % supports all unicode we care about as serif font

# STIX looks nice, but we have to set up the other versions (bold
# etc.) and decide on a good line spacing.
# #+LATEX_HEADER: \setmainfont[Path = "/usr/share/fonts/stix/static_otf/", Extension = ".otf"]{"STIXTwoText-Regular"}
# #+LATEX_HEADER:   #UprightFont    =  ,
# #+LATEX_HEADER:   #BoldFont       = *-Bold ,
# #+LATEX_HEADER:   #ItalicFont     = *-Italic ,
# #+LATEX_HEADER:   #BoldItalicFont = *-BoldItalic
# #+LATEX_HEADER: ]{"STIXTwoText-Regular"}


# The following is the approach using `ucharclasses` but that ruins
# code blocks of minted...
#   #+LATEX_HEADER: \usepackage{fontspec}
#   #+LATEX_HEADER: \usepackage[Latin,Mathematics,Punctuation,Symbols]{ucharclasses}
#
#   #+LATEX_HEADER: \newfontfamily{\mydefaultfont}{DejaVuSans}
#   #+LATEX_HEADER: \newfontfamily{\mymainfont}{CMU Serif}
#
#   #+LATEX_HEADER: \setTransitionsForPunctuation{\mymainfont}{\mydefaultfont}
#   #+LATEX_HEADER: \setTransitionsForLatin{\mymainfont}{\mydefaultfont}
#   #+LATEX_HEADER: \setTransitionsForSymbols{\mydefaultfont}{\mymainfont}
#   #+LATEX_HEADER: \setTransitionsForMathematics{\mydefaultfont}{\mymainfont}

# package that allows inserting unicode characters in math environment
#+LATEX_HEADER: \usepackage{unicode-math}

#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{mhchem}
#+LATEX_HEADER: \usepackage{subcaption}

# make the margin on the sides smaller
#+LATEX_HEADER: \usepackage[margin=2.5cm]{geometry}

# ##############################
# change output of code blocks to use monokai
# ##############################
#+LaTeX_HEADER: \usemintedstyle{monokai}

#+LATEX_HEADER: \definecolor{monokai_bg}{RGB}{39, 40, 34}
# #+LATEX_HEADER: \definecolor{monokai_bg}{RGB}{27, 28, 27}
# #+LATEX_HEADER: \definecolor{monokai_fg}{RGB}{241, 235, 235}
#+LATEX_HEADER: \definecolor{monokai_0}{RGB}{72,72,62}
#+LATEX_HEADER: \definecolor{monokai_1}{RGB}{220,37,102}
#+LATEX_HEADER: \definecolor{monokai_3}{RGB}{212,201,110}
#+LATEX_HEADER: \definecolor{monokai_4}{RGB}{85,188,206}

# color commands
#+LATEX_HEADER: \definecolor{monokai_orange}{RGB}{253, 151, 31}
#+LATEX_HEADER: \newcommand{\orange}{\textcolor{monokai_orange}}
#+LATEX_HEADER: \newcommand{\green}{\textcolor{green}}
#+LATEX_HEADER: \newcommand{\red}{\textcolor{red}}
#+LATEX_HEADER: \DeclareSIUnit\year{yr}

# custom commands for convenience
#+LATEX_HEADER: \newcommand{\ccsini}{$\mathrm{Si}₃\mathrm{N}₄$}
# \def\si3n4{$\mathrm{Si}₃\mathrm{N}₄$}

#+LATEX_HEADER: \usepackage[backend=biber]{biblatex}
#+LATEX_HEADER: \addbibresource{references.bib}


# With Dejavu Serif a linespacing of 1.2 is too tight. 1.5 looks nice,
# maybe 1.4 is optimal? 
#+LATEX_HEADER: \linespread{1.5} % change line spacing to be a bit larger. TODO: find good value!

# HTML Export
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="nimdoc.css" />
#+OPTIONS: html-style:nil

#+OPTIONS: toc:nil # turn off Table of Contents here and place it elsewhere

#+LATEX: \dominitoc % initialize the package

#+EXCLUDE_TAGS: noexport


\begin{titlepage}

\begin{center}
  \huge Search for solar axions using a 7-GridPix IAXO prototype detector at CAST

  \vspace{2cm}
  \Large Sebastian Michael Schmidt
\end{center}

place funny logos and stuff

Doktorgrad
erworben 2021
Solingen


\end{titlepage}

#+TOC: headlines 2


# Part 0: Introduction

* Compile                                                          :noexport:

Compilation at the moment is still a bit broken due to =biber=.

We need to generate the TeX file from Org =C-c C-e l l= to generate
the TeX file.

Then in terminal:
#+begin_src sh
lualatex --shell-escape thesis.tex
biber thesis
lualatex --shell-escape thesis.tex
#+end_src

Or better yet, let =latexmk= take care of it:
#+begin_src
latexmk -pvc -pdf -view=none -shell-escape -pdflatex=lualatex thesis.tex
#+end_src

it watches the file and automatically recompiles if the file changed
on disc.

* Start me                                                         :noexport:

#+begin_src emacs-lisp
(add-to-list 'org-latex-classes
             '("book-noparts"
               "\\documentclass{book}"
               ("\\chapter{%s}" . "\\chapter*{%s}")
               ("\\section{%s}" . "\\section*{%s}")
               ("\\subsection{%s}" . "\\subsection*{%s}")
               ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
               ("\\paragraph{%s}" . "\\paragraph*{%s}")
               ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+end_src


* Introduction                                                        :Intro:

Bla..


After a short side note about this thesis as a document in chapter
[[About this thesis (structure)]], we introduce the theoretical foundation
of axion physics in chapter [[Theory of axions]]. From a historical
standpoint as to why axions were invented in the first place to the
avenues of detection and related the expected solar axion fluxes.

This leads to chapter [[Axion helioscopes]], which introduces the concept
of an axion helioscope as a way to potentially detect axions of a
solar origin. Other possible approaches will be shortly mentioned.

With an understanding of possible detection mechanisms for axions, we
will focus next on the required hardware to actually measure axions
indirectly, i.e. via gaseous detectors for X-ray detection in chapter
[[Gaseous detectors principles]].

As we finally wish to compute a limit on different axion coupling
constants, an understanding of basic statistics for limit calculations
is required. This we will cover in chapter [[Statistics & limit
calculations]].

Next we introduce our detector, the Septemboard based GridPix
detector, in chapter [[Septemboard detector]]. Here we will discuss both
the motivation behind why such a detector was built, the different
features of the detector and basic calibration principles as well as
covering the setup and software used to run the detector.

Stopping at the software running the detector, we will then transfer
over to the software suite built to analyze the data in chapter
[[Software]].

A further chapter about the analysis principles follows, which
explains the ideas of how the data reconstruction works, what kind of
calibrations are applied to the data and how it all fits together to
compute a background rate and limit. This is chapter [[Chapter about
analysis principle]].

Raytracing chapter will be moved somehow.

What follows in chapter [[Detector preparation / study /
characterization etc.]] is the explanation of all characterization
measurements, an introduction to the $^55\text{Fe}$ calibration
measurements and how the energy calibration works.

From there we go to the actual deployment of the detector at CAST in
chapter [[Detector installation at CAST & data taking]], in which we
describe the physical setup and give an overview over the different
data taking periods.

With the description of the data periods out of the way, we can make
use of the data to compute the background rate of the detector for
different cases in chapter [[Background rate computation]].

These background rates are combined with the expected signals from
chapter *TODO which one Raytracing + theory?* and the measured
candidates during tracking time to compute a limit in chapter [[Limit
calculation]].

As a final part we will give an outlook of what a future Timepix3
based detector might achieve in chapter [[Outlook]].

Afterwards we finally conclude in chapter [[Summary & conclusion]].

* About this thesis (structure)                                       :Intro:

*TODO:* (maybe) insert the essay written on my phone one night here
(into the full version of the thesis at least) 

Explanation about the thesis structure and introduction of the "full
thesis document".

The thesis you are reading right now is a shortened version of the
full document it is part of. To conform to the expectations of a PhD
thesis many parts are removed that are irrelevant for the basic
presentation of the work done during the thesis.

However, a fellow researcher who wishes to understand all the details,
in particular in terms of reproducibility of the results, the full
document should be read instead. If possible a PhD thesis should be a
tome of knowledge about the topic that allows the interested reader to
absorb as much of the authors knowledge as possible to help with the
continuation of the research.

Furthermore, every thesis, especially those relying on large pieces of
software, contains mistakes, bugs, wrong assumptions and more. Most of
these are not known to the researcher, possibly due to lack of
knowledge in a specific topic. Other times shortcomings _are_ known,
but left out for convenience. This thesis is about one thing:
*transparency*. There are bugs in the referenced code that I'm not
aware of, bad assumptions about certain things, etc. Where I *am*
aware of sketchy choices, I will highlight them honestly. 

The full document is found at:

*TODO*: insert link, probably to GitHub as well as some other source

The main difference between the regular thesis document and the
extended version are the following. The extended version contains:
- either inline code or links to the code that produces *every plot*
  (that is created by me); inline code is used if the required code to
  generate the plot is less than a certain amount of lines.
  For non-inlined code the used code is referenced (link to the code +
  correct git commit)
- access to *all* raw and reconstructed data to reproduce the results
- additional chapters that were not relevant enough / polished enough
  for inclusion into the thesis. This includes additional plots,
  investigations of detector behavior etc., theoretical calculations
  and more.

In essence the idea is to provide a fully reproducible thesis. The
extended version should ideally be read as a mix of the generated PDF
and the real Org file behind it.

The extended version includes many source code blocks that can be
extracted using [[https://github.com/OrgTangle/ntangle][ntangle]]:
#+begin_src sh
ntangle thesis.org
#+end_src

Ideally, all results can be reproduced with a single:
#+begin_src sh
./generateResults.sh
#+end_src
call (we'll see how that will work out).

The package versions for the code used in the extended version will be
frozen at a specific time. The list of version numbers will be found
below.

*TODO*: Add version numbers of all packages used for final plots.

*TODO*: Have specific marking in (sub)sections if they contain more
information in extended version?

*TODO*: It would be sick if we could do something like
#+begin_src sh
curl -s <backblaze link> | sh foo.sh
#+end_src
to download and generate everything in one go. Seems a bit insane
though. But who knows.

*TODO*: In =noexport= sections, possibly have a "Skip this section
if:" introduction? So that readers know exactly why a certain section
might be of interest to them.


Further, this thesis does not attempt to cover *every* aspect of the
theoretical foundation required to understand every part. For example
we will not introduce the Standard Model or explain certain detector
features, if they are not of importance for the understanding of our
data.
Good references, if available, will however be given for an interested
reader / a reader attempting to fill in gaps in knowledge.

* TODO List of todos [0/9]                                   :Intro:noexport:

** TODO Have reference to Firmware used at CAST in each run

** TODO Run list (appendix)

** TODO Include exact results from Geometer measurements

Find in EDH and include, even if we don't use it. Referenced in X-ray
finger measurements.


** TODO fix up schematic of V6 Septemboard connections
** TODO fix up schematic of MM working principle

The existing schematic is not very clear. Change the drift gap
behavior and amplification gap one by reversing their drawing
style. Add some alpha to different regions to highlight amount of
electrons drifting. Add a text label with O(magnitude)

** TODO insert the first LaTeX + Vega-lite based plot

This gives us an idea of how this will work. For a start I'd say base
the Vega-lite plots on Github gists. That allows for easy replacement
for the time being.

** TODO implement nothing ⇒ background rate as reproducible build

This one will be a bit ambitious, but maybe it's a day of work.

*If* we get this working we're at a point where generating other plots
is just a simple shell command (call script X with args Y), as we will
have all =Calibration/DataRunsX_Y.h5= files ready somewhere.

Steps:
*** Setup Nim + all packages of fixed versions (take versions from a TOML file)
*** Have config file storing paths of raw data + output paths
*** run raw data, reco, ...
*** generate CDL datasets
*** compute logL files
*** plot background

** TODO find way to host the raw data

Can also just use Zenodo https://zenodo.org


B2 maybe as an alternative?

We could start by a simple Backblaze B2 hosting.

Pricing is competitive:
Hosting: 0.005 $/Month/GB
Download: 0.01 $/GB
https://www.backblaze.com/b2/cloud-storage-pricing.html

Which is 1.5$ for 300 GB and 3$ to download it. Certainly cheap enough
to try!

Data to store
*** All 2017/18 data runs
**** Run 2
**** Run 3
*** Detector calibration files for Run 2, Run 3
*** FADC pedestal run
*** X-ray finger runs
*** All our notes + thesis
*** Nim code?                                                     :pending:

** TODO use some package for abbreviations

** TODO update all links to code

Currently we use some links in footnotes to code on github.
1. replace the links to master branch by permalinks to a git tag for
   my thesis
2. add citations (*OR* find a way to add a "secondary" bibliography
   only for code references?)
   Apparently this is possible, either using biblatex directly or
   using a package called =multibib=
   https://www.overleaf.com/learn/latex/Questions/Creating_multiple_bibliographies_in_the_same_document

** TODO Adjust spacing in itemize etc. environments

Can be done using the ~enumitem~ package like here:
https://tex.stackexchange.com/questions/10684/vertical-space-in-lists

** TODO Use something like ~isodate~ to format dates

** Points of contention

At the moment <2021-07-31 Sat 11:36> my biggest point of uncertainty
is the whole detector calibration part + how this plays into a
software framework.

Difficult to come up with good layout at this point. Will be easier
once more notes are added in each part I think.

** Structure

I'm very lost <2022-08-22 Mon 13:53> about how to structure the thesis
at this point. :(

Maybe it's easier to think of the ingredients for the limit
calculation as tips of strands. Follow each back to its
introduction. But: should each of these simply be its own chapter?

E.g. axion image:
- raytracing
- solar axion flux
- axion models

So therefore have a chapter "Deriving the expected axion image" that
starts from:
- pick a solar model & axion model
- compute expected flux
- use raytracing, explain, to compute the image?
- but: needs average absorption depth to know at what point to even
  compute something!
  Well, this _can_ work, as long as the setup & detector are explained
  _before_ this chapter.

However: none of that makes any sense without the context of the
limit calculation! Why else would one need to compute such an image
etc?

Instead could also start part 2 (or whatever) of the thesis as "limit
calculation" and have this be a huge part that first introduces the
math of what & how to compute a limit, and *then* introduces how one
ends up at the necessary inputs?

If I do it this way, then the first part of the thesis is purely:
- axion theory generically
- axion helioscopes  
- gaseous detector physics & micromegas
- the septemboard detector
- deployment at CAST
- data analysis to an extent? to what extent though?

Part 2:
limit calculation
- how to compute limit, method
- ingredients, show them.
- then: each ingredient, how to derive it
- finally:
  - put all ingredients together, short overview
  - compute
  
** Current thoughts about structure

<2022-11-03 Thu 10:32>:
So, as I'm currently finishing up the chapter about TOS and the
Timepix calibrations, I'm unclear about how to structure the next
steps:

- real detector calibrations used, Septemboard FSRs, Thresholds
  etc. When performed and link to appendix containing all of them.
- scintillator calibrations
- FADC pedestal runs

- Data reconstruction must have an introduction that motivates why we
  even compute geometric properties and so on. Comparison of events
  etc.

- reconstruction before deployment at CAST?

- 


** DONE Use ~booktabs~ everywhere

Simply done by adding ~:booktabs t~ to the ~#+ATTR_LATEX:~ above a
table!

https://orgmode.org/manual/Tables-in-LaTeX-export.html

(Note that it isn't really clear from the documentation that it needs
an argument, as it is otherwise interpreted as receiving ~nil~ I presume)

* Theory of axions                                                   :Theory:
#+LATEX: \minitoc

*ADD SENTENCE ABOUT CPT INVARIANCE OF SM*

The standard model of particle physics at low energies can be
described by a combination of three different forces, the
electromagnetic, the weak and the strong force. These can be
represented mathematically by an internal group structure of
$\mathrm{U}(1) \times \mathrm{SU}(2) \times \mathrm{SU}(3)$,
respectively. [fn:groups] The weak force, represented by
$\mathrm{SU}(2)$, has long since been known to exhibit a
$CP$-violation [fn:cp_violation] *CITE REFERENCE WEAK CP PROBLEM*. Due
to the similar structure between the weak and the strong force
($\mathrm{SU}(2)$ vs. $\mathrm{SU}(3)$) many parallels exist between
the mathematical descriptions of the two forces in the standard
model. *CITE t'HOOFT QCD VACUUM STRUCTURE* In particular the
Lagrangian term giving rise to the weak $CP$-violation can be written
down equivalently for the strong force, implying an expected
$CP$-violation in the strong force. Peculiarly, any effect expected
from this has still _not_ been observed. One such effect is for
example an expected electric dipole moment of the neutron
\cite{CREWTHER_NEDM, CREWTHER_NEDM_ERRATA, Baluni_NEDM}. Such a dipole
moment may naively be expected plainly from the fact that the
constituent quarks of a neutron are charged after all. However, very
stringent limits place an extremely low upper bound on it at
\cite{NEDM_Limit, Revised_NEDM_Limit}

*SHOW WEAK CP VIOLATING TERM*
*GET BEST CURRENT LIMIT ON NEDM*
*WRITE THETA TERM HERE TO REFERENCE IT IN QUINN PECCEI*

\[
d_{\text{NEDM}} \leq \SI{3e-26}{\elementarycharge \cm},
\]

where $e$ is the electron charge. Nature's deviation from our
expectation in this context is coined the _strong $CP$-problem_ of
particle physics. While it is possible that our universe is simply one
in which the effect of the strong $CP$-violation is suppressed (or
even exactly zero) "by chance", Helen Quinn and Roberto Peccei
realized in 1977 \cite{PecceiQuinn1977_1, PecceiQuinn1977_2} that this
behavior can be explained in the presence of an additional scalar
field. Shortly after both Weinberg and Wilczek \cite{AxionWeinberg,
AxionWilczek} realized the implication of such an additional field,
namely a pseudo Nambu-Goldstone boson, which *WILCZEK OR WEINBERG??*
named the _axion_, after a washing detergent, as it washes the
standard model clean of the strong $CP$-problem. While the most
straight forward axion model based on the work by Wilczek and Weinberg
yields a coupling of the axion to matter that is already excluded
*CITE SEE LANDSCAPE*, models for an 'invisible axion' manage to unify
the solution to the strong $CP$-problem with the current lack of
experimental evidence for an axion-like particle. There are two main
models for the invisible axion, the KSVZ
(Kim-Shifman-Vainshtein-Zakharov) and the DFSZ
(Dine-Fischler-Srednicki-Zhitnitskii) models.

For the most comprehensive overview of the theory of axions, overview
of models, best bounds on different axion models and general axion
reference, make sure to look into the aptly named "landscape of QCD
axions" \cite{DILUZIO20201}!

*LANDSCAPE OF QCD AXION* shows nice explanation of visible vs
invisible models.

*FIND REFERENCE TO ORIGINAL AXION BEING VISIBLE*
*FIND REFERENCE TO INVISIBLE AXION*

*ADD REMARKS ABOUT*:
- theta term
- axion mass
- axion coupling constants    

[fn:groups] $\mathrm{U}(1)$ refers to the "circle group", i.e. the
group that describes rotations on a unit circle (consider a phase
shift on the complex plane). The group operation as such can be
considered as multiplication by a complex phase. $\mathrm{SU}(n)$ is
the special unitary group, which means the group of unitary matrices
of rank $n$ with determinant 1, where the group operation is matrix
multiplication of these matrices (for $\mathrm{SU}(2)$ the Pauli
matrices multiplied by $\frac{i}{2}$ are a possible set of
infinitesimal generators for example).

[fn:cp_violation] $C$ refers to the discrete transformation of charge
conjugation and $P$ for parity transformation. Both refer to the
idea of studying a physical system with either (or both) of these
transformations applied. A $CP$ conserving theory (or system) would
behave exactly the same under the combined transformation. The
standard model is mathematically $CPT$ invariant ($T$ being time
reversal). As such, if a system exhibits different behavior under time
reversal it implies a violation of $CP$ to achieve a combined $CPT$
invariance.



From a historical standpoint including the strong CP problem, we go
over to the Peccei-Quinn solution. Another way to look at it is from a
modern standpoint asking why does the neutron not have a dipole
moment?

*Take a look at lectures for Axion School*
*QCD AXION LANDSCAPE PAPER*
*PAPER RINGWALD LIKED SO MUCH*


[fn:axion_overview] To be brutally honest, as a combination of the
significant growth of the axion community (both experimentally and
theoretically) and my lack of theory work in the last years, I cannot
do an overview of axion theory justice. Fortunately, there are a huge
number of amazing reviews of the current axion landscape out there! In
particular "landscape of QCD axion models".


*NOTE*: I think after introducing the axion the way I've done up there
now, maybe it's a good idea to just review the relevant parts that
will show up in the thesis? Mass, coupling, etc?

** Historical origins

From electroweak theory we know about CP violation. Standard model for
strong force is just SU(3) vs. SU(2) for electroweak.

Lagrangian allows mostly the same terms for both forces. This implies
there should be a strong CP violation. This isn't observed and even
today theh neutron electric dipole moment is restricted to values
smaller $d_N \leq 1e-26 \text{? some units}$.

Merge the next section into this one and change title?

** Strong CP problem

Use the schematic I created for Hendrik's presentation?

** Peccei-Quinn solution

Main Peccei-Quinn paper citation.

Solution by introducing another global U(1) symmetry that is
spontaneously broken below some energy scale. 

** The axion

Leads to a pseudo Nambu-Goldstone boson that Wilzcek named the Axion
(ref a pic of axion detergent), as it washes the standard model clean
of an ugly stain.

** DFSZ & KSVZ axion models

Further developments lead to more complex axion models that better fit
with our understanding.

Two main types of models emerged.

** Implications for axion interactions

Axions are apparently not interacting a whole lot, otherwise we'd know
about them already. Very weak interaction

Main interaction arises due to anomalies in standard model that allow
for a Fermion loop diagram. That allows for coupling to
gluons. Effective photon coupling is the result, equivalent to
Primakoff effect for pions (also an effective coupling!).

Write down effective Lagrangian.

*COHERENCE CONDITION*
*VACUMM VS GAS*

** Solar axion flux

Important for us? How do we detect them.

Have a simple derivation from KG equation? Take a look at Biljana &
Kreso for simple overview and simplify.

Take KG equation and derive interaction.

Interaction tells us conversion is proportional to B and L. Where are
strong Bs for long Ls? Solar core.
Take modern solar model to plot the density profile & especially
temperature. Density + temperature allows us to compute:
- number of photons
- at various photon energies

By wrapping blackbody radiation (ref, 3 sentences about it) present in
solar core with Primakoff coupling, we get an effective axion flux
equivalent to:

$dΦ/dE ∝ g_{aγ}² · \text{black body radiation}$

*CHECK CAST PHASE I RESULT PAPER FOR OVERVIEW* (contains physics +
integration over solar model!)
Refer to that paper in particular to answer the question: "do axions
escape from the sun?"

*BIBBER* \cite{PhysRevD.39.2089} contains derivation of axion flux based
on black body radiation. First CAST paper bases their flux on this,
with a modification from some other paper & a newer solar model from
2001 ("reference" 15 in that CAST paper). This reference *also*
contains a derivation of axion equations of motion etc. via KG equation.

*** Primakoff flux

Including analytical equation for flux... :)

#+begin_src nim :tangle /tmp/solar_axion_flux.nim :results silent
import unchained, ggplotnim, math, chroma, ginger
defUnit(keV⁻¹•m⁻²•yr⁻¹)
defUnit(keV⁻¹•cm⁻²•s⁻¹)
defUnit(GeV⁻¹)

proc axionFluxPrimakoff(E_a: keV, g_aγ: GeV⁻¹): keV⁻¹•cm⁻²•s⁻¹ =
  ## dΦ_a/dE taken from paper about first CAST results \cite{PhysRevLett.94.121301}
  let g₁₀ = g_aγ / 1e-10.GeV⁻¹ # * 10e10.GeV¹ #
  result = g₁₀^2 * 3.821e10.cm⁻²•s⁻¹•keV⁻¹ * (E_a / 1.keV)^3 / (exp(E_a / (1.103.keV)) - 1)

proc axFluxPerYear(E_a: keV, g_aγ: GeV⁻¹): keV⁻¹•m⁻²•yr⁻¹ =
  result = axionFluxPrimakoff(E_a, g_aγ).to(keV⁻¹•m⁻²•yr⁻¹)

proc axionFluxPrimakoffMasterThesis(ω: keV, g_ay: GeV⁻¹): keV⁻¹•m⁻²•yr⁻¹ =
  # axion flux produced by the Primakoff effect
  # in units of m^(-2) year^(-1) keV^(-1)
  result = 2.0 * 1e18.keV⁻¹•m⁻²•yr⁻¹ * (g_ay / 1e-12.GeV⁻¹)^2 * pow(ω / 1.keV, 2.450) * exp(-0.829 * ω / 1.keV)

let E = linspace(1e-3, 14.0, 1000)
let df = seqsToDf(E)
  .mutate(f{float: "Flux" ~ axionFluxPrimakoff(`E`.keV, 1e-11.GeV⁻¹).float})
  .mutate(f{float: "FluxYr" ~ axFluxPerYear(`E`.keV, 1e-11.GeV⁻¹).float})
  .mutate(f{float: "FluxMSc" ~ axionFluxPrimakoffMasterThesis(`E`.keV, 1e-11.GeV⁻¹).float})    
ggplot(df, aes("E", "Flux")) +
  geom_line() +
  #geom_line(aes = aes(y = "FluxMSc"), color = some(parseHex("0000FF"))) + 
  ggtitle("Solar axion flux due to Primakoff production, g_aγ = 10⁻¹¹·GeV⁻¹") +
  xlab("Energy [keV]") +
  #ylab("Axion flux [keV⁻¹·cm⁻²·s⁻¹]") +
  ylab("Axion flux [keV⁻¹·m⁻²·yr⁻¹]") +  
  ggsave("/tmp/primakoff_axion_flux.pdf")

ggplot(df.mutate(f{"Flux" ~ `Flux` / 1e8}), aes("E", "Flux")) +
  geom_line() +
  #xlab("Energy [keV]", tickFont = font(12.0), margin = 1.5) +
  xlab(r"\fontfamily{lmss}\selectfont Energy [$\si{\keV}$]", margin = 2.0, font = font(16.0),
       tickFont = font(16.0)) +
  xlim(0, 14) + 
  #ylab("Axion flux [10¹⁰ keV⁻¹·cm⁻²·s⁻¹]", margin = 1.5) +
  ylab(r"\fontfamily{lmss}\selectfont Axion flux [\SI[print-unity-mantissa=false]{1e11}{\keV^{-1} \cm^{-2} \second^{-1}}]",
       margin = 2.0,
       font = font(16.0)) + 
  #     tickFont = font(12.0)) +
  #ggtitle(r"Expected solar axion flux, g_aγ = 10⁻¹⁰ GeV⁻¹", titleFont = font(12.0)) +
  annotate(r"\fontfamily{lmss}\selectfont Expected solar axion flux" &
    r"\\$g_{aγ} = \SI[print-unity-mantissa=false]{1e-11}{\GeV^{-1}}$", #10⁻¹⁰ GeV⁻¹",
           x = 6.2, y = 6.2, 
           font = font(16.0),
           backgroundColor = transparent) +
  #ggtitle(r"Expected solar axion flux, $g_{aγ} = \SI{1e-11}{\GeV^{-1}}$", titleFont = font(12.0)) + 
  #ggsave("/tmp/cristina_primakoff_axion_flux.pdf", width = 400, height = 300) #, useTeX = true, standalone = true)
  ggsave("/tmp/cristina_primakoff_axion_flux.pdf", useTeX = true, standalone = true)
  

defUnit(m⁻²•yr⁻¹)  
echo 1.cm⁻²•s⁻¹.to(m⁻²•yr⁻¹)
#+end_src

There are different analytical expressions for the solar axion flux
for Primakoff production. These stem from the fact that a solar model
is used to model the internal density, temperature, etc. in the Sun to
compute the photon distribution (essentially the blackbody radiation)
near the core. From it (after converting via the Primakoff effect) we
get the axion flux.

Different solar models result in different expressions for the
flux. The first one uses an older model, while the latter ones use
newer models.

*** Axion-electron flux

*citations*: Redondo 2013, maybe (Johanna + Sebastian Hoof something?)
*Keep in mind errors in Redondo 2013*! *possibly write a mail to Sebastian Hoof*

Expected axion flux combined.

Reference to file storing the results for specific coupling constants.

Much more complicated.

ABC components.

B and C can be expressed analytically.

A cannot, needs opacity project.

Show plot of differential axion flux.

For a derivation of this, consider section about ray tracing. Custom
computation of A done by Johanna in code developed by her & me in
*LINK*.

** TODO possibly add chameleons?

?? will depend on whether we do a chameleon limit (which we should, as
our detector is much better here!)

Should be easy after all, as everything is the same as for axions,
except different flux, raytracing and thus limit calc (from a number
perspective; concept is the same).

** Current bounds on axion couplings

The field of axion searches is expanding rapidly in recent years,
especially in haloscope experiments.

A haloscope is a type of axion experiment consisting of a (typically
microwave) cavity placed in a magnetic field. It intends to detect
axions of the dark matter halo of our galaxy. Axions that are part of
the dark matter component are necessarily very low energy as they
decoupled long ago and underwent cooling ever since. Thus, their
energies are in the microwave range. If a cavity has a resonance
frequency matching the axion mass (the kinetic energy is negligible,
so the majority of the energy is in the mass), the conversion probability is
enhanced by the quality factor $Q$ of the cavity (effectively the
number of reflections in the cavity). The upside of such experiments
are the strong enhancements possible, which allow to reach very low
coupling constants. However, a cavity has a single resonance
frequency, limiting the mass range to be studied to a very narrow
range. Most experiments use cavities that can be tuned to expand the
mass range. At each tuned frequency data is taken for a fixed amount
of time to reach a certain coupling constant. As such a tunable cavity
experiment can scan a narrow band of axion masses over the course of
its data taking campaign. Due to the simplicity of the setup these
type of experiments are very popular nowadays.

Astronomical axion bounds.

Cavity bounds.

Helioscope bounds.

(what else?)

*TODO*: include newest Chandra results for coupling constant

*TODO*: include Xenon-1T results 

* Axion helioscopes                                                  :Theory:
:PROPERTIES:
:CUSTOM_ID: sec:helioscopes
:END:

#+LATEX: \minitoc
Introduce axion helioscopes as one of the types of experiments
proposed by Sikivie in his paper. *CITE SIKIVIE*

Maybe shortly mention other experiments.

As discussed in the previous chapter in section [[Solar axion flux]],
stars are expected to produce significant excess of axions. In 1983
Pierre Sikivie proposed multiple methods to potentially detect
axions, one of these making use of this solar axion production. 

From the theory on axions (ref. section [[Implications for axion
interactions]]) we know there is an effective coupling to the photon
$g_{aγ}$. This coupling is an equivalent to the Primakoff effect,
which describes a resonant production of mesons via a Fermion loop in
strong electromagnetic fields when interacting with a nucleus. In the
Primakoff effect two photons are present, an incoming real photon and
a virtual photon of the electromagnetic interaction of the
nucleus. Axions can take the place of the physical photon, either in
the initial state or in the final state. In the former case we have an
axion to photon conversion and in the latter a photon to axion
conversion.

*DIFFERENTIATE BETWEEN PRIMAKOFF AND INVERSE PRIMAKOFF*

*PUT PRIMAKOFF FEYNMAN DIAGRAM*
*POSSIBLY MOVE TO THEORY ITSELF AND REFERENCE*

As it turns out, the relevant aspect for the Primakoff effect is not
the presence of a nucleus, but simply the fact that the nucleus
provides an electromagnetic field. This means the nucleus can also be
replaced by - for example - a transverse, constant magnetic field.

*EXPLAIN WHY TRANSVERSE MAGNETIC FIELD IN THEORY*

This fact is the foundation of the helioscope idea. By pointing a
magnet at the Sun one expects a small fraction of the axions produced
in the Sun to reconvert to photons in the presence of the magnetic
field via the inverse Primakoff effect. These photons will carry the
energy of the original photons that produced the axions, namely the
energy of photons in the solar core. Essentially black body radiation
of $\sim\mathcal{O}(\SI{15}{\mega\kelvin}$.

*INSERT FIG BLACKBODY HERE OR IN SOLAR AXION FLUX SECTION*

This means the reconverted photons are mostly in the soft X-ray range
between \SIrange{1}{7}{\keV}. The first implementation of the
helioscope idea was the Rochester-Brookhaven-Florida experiment
\cite{PhysRevD.39.2089,PhysRevLett.69.2333}.  It was followed by the
SUMICO experiment in Tokyo
\cite{MORIYAMA1998147,INOUE200218,INOUE200893}. The third and only
still running helioscope is the CERN Axion Solar Telescope (CAST),
which we will present in more detail in section [[CERN Axion Solar
Telescope (CAST)]]. In the final section we will introduce the next
generation of axion helioscopes, the International AXion Observatory
(IAXO), section [[International AXion Observatory (IAXO)]].

** Black body radiation in solar core                             :noexport:

Let's compute the black body radiation for the solar core and see if
it matches the energy spectrum we expect for axions.

Planck's law is defined as *CITE SOMETHING*:

\[
B_ν(ν, T) = \frac{2hν³}{c²} \frac{1}{e^{hν/kT} - 1}
\]

where $ν$ is the frequency of the photon and $T$ the temperature in
Kelvin. $k$ is of course the Boltzmann constant and $h$ the Planck
constant. Let's see what this looks like for $T =
\SI{15}{\mega\kelvin}$.

#+begin_src nim :tangle /home/basti/phd/code/black_body_sun_core.nim
import ggplotnim, unchained, sequtils

#defUnit(s⁻¹)
#defUnit(μs⁻¹)
defUnit(Watt•Steradian⁻¹•Meter⁻²•NanoMeter⁻¹)
defUnit(Joule•Meter⁻²•Steradian⁻¹)

let T_sun = 15.MegaKelvin.to(Kelvin)

proc blackBody(ν: s⁻¹, T: Kelvin): Joule•Meter⁻²•Steradian⁻¹ =
  result = (2 * hp * ν^3 / c^2 / (exp(hp * ν / (k_B * T)) - 1)).to(Joule•Meter⁻²•Steradian⁻¹)

proc xrayEnergyToFreq(E: keV): s⁻¹ = 
  ## converts the input energy in keV to a correct frequency
  result = E.to(Joule) / hp
echo 1.keV.xrayEnergyToFreq

echo blackBody(1.μHz.to(Hz), T_sun)
echo blackBody(1.keV.xrayEnergyToFreq, T_sun)

let energies = linspace(0.01, 16.0, 1000)
let radiance = energies.mapIt(blackBody(it.keV.xrayEnergyToFreq, T_sun).float)
let df = seqsToDf(energies, radiance)
ggplot(df, aes("energies", "radiance")) + 
  geom_line() + 
  ggtitle("Black body radiation @ T = 15 Mio. K") +
  xlab("Energy [keV]") + ylab("Radiance [J•m⁻²•sr⁻¹]") + 
  ggsave("/tmp/blackbody_sun.pdf")
#+end_src

#+RESULTS:
| 2.41799e+17 Hertz                 |
| inf Meter⁻²•Joule•Steradian⁻¹     |
| 178.526 Meter⁻²•Joule•Steradian⁻¹ |


** TODO small section about other kinds of experiment?

** CERN Axion Solar Telescope (CAST)

The CERN Axion Solar Telescope (CAST) was proposed in 1999
\cite{ZIOUTAS1999480} and started data taking in 2003
\cite{PhysRevLett.94.121301}. 

*PICTURE OF CAST*

Using a \SI{9.26}{m} long LHC dipole magnet that was available from
the developments for the LHC, CAST features a \SI{9}{\tesla} strong
transverse magnetic field for axion-photon conversion produced by a
current of \SI{13}{\kilo\ampere} in the superconducting wires
*MATERIAL EXPLICIT* at \SI{1.8}{\kelvin}. It is placed on a movable
platform that allows for solar tracking both during sunrise as well as
sunset. The vertical range of movement is in principle
$\sim\pm\ang{8}$, but is slightly reduced in the last years of data
taking since 2019 (*CHECK NUMBER ASK THEODOROS*). This range of motion
allows for solar tracking of approximately \SI{90}{\minute} each day,
the exact duration depending on time of the year. Due to their
incredibly feeble interactions solar tracking can already start before
sunrise / stop after sunset as axions easily traverse through large
distances of Earth's mantle.

*NAME SUPERCONDUCTING MATERIAL OF THESE MAGNETS*

*CROSS SECTION OF LHC DIPOLE MAGNET*

An LHC dipole magnet has two bores for the two proton beams running in
reverse order. Being a prototype magnet it is *not* bent to the
curvature required by the LHC. A cross section can be seen in
fig. *INSERT ME*. These two bores have a diameter of \SI{4.3}{cm}
*CITE NUMBER* \cite{ZIOUTAS1999480} *SAYS 42.5mm*. In total then two
bores on each side allow for 4 experiments to be installed at CAST,
two for data taking during sunrise and two during sunset. 
#+begin_export latex
\footnote{There is some confusion about the diameter and length of the
magnet. The original CAST proposal \cite{ZIOUTAS1999480} talks about
the prototype dipole magnets as having a bore diameter of
\SI{42.5}{mm} and a length of \SI{9.25}{m}. However, ever CAST
publication afterwards uses the numbers \SI{43}{mm} and
\SI{9.26}{m}. Digging into references about the prototype dipole
magnets is inconclusive. For better compatibility with all other CAST
related publications, we will use the same \SI{43}{mm} and
\SI{9.26}{m} values in this thesis.}
#+end_export

The first data taking period (often referred to as 'phase I') took
place in 2003 for 6 months between May and November and was a pure
vacuum run with 3 different detectors. On the side observing during
sunset was a Time Projection Chamber (TPC) that covered both bores. On
the 'sunrise' side a Micromegas (Micromesh Gaseous Detector) detector
and a Charged Coupled Device (CCD) detector were installed. The CCD
was further behind a still in place X-ray telescope originally
designed for the ABRIXAS X-ray space telescope
\cite{ABRIXAS}. \cite{PhysRevLett.94.121301}

The full first phase I data taking period comprises of data taken in
2003 and 2004 and achieved a best limit of $g_{aγ} <
\SI{8.8e-11}{\GeV^{-1}}$ \cite{Andriamonje_2007}.

In what is typically referred to as 'phase II' of the CAST data
taking, the magnet was filled with helium as a buffer gas. First
between late 2005 and early 2007 with $^4\text{He}$. From March 2008 a
run with $^3\text{He}$ was started, which ran until 2011
\cite{Arik_2009, PhysRevD.92.021101}. In 2012 another $^4\text{He}$
data run took place \cite{PhysRevD.92.021101}. 

From 2013 on the CAST experiment has only taken data using vacuum
\cite{cast_nature}. Further, the physics scope has been extended
to include searches for chameleons *CITE CHRISTOPH, SDD, KWISP*, and
axions in the galactic halo via cavity experiments *CITE SERGIO,
CAPP*. 

In addition, with the MicroMegas dataset taken in *CHECK EXACT* phase I a
limit on the axion electron coupling was computed *CITE 2013*.

*160 STEPS WERE PERFORMED WITH BUFFER GAS* \cite{Arik_2009}

*BETTER SEPARATE X-ray OPTICS*

*MENTION COHERENCE CONDITION* (here or in theory?)

*2 ANNOTATED PICTURES OF CAST W/ HIGHLIGHT OF SUNRISE, SUNSET,
AIRPORT, JURA* 
*INTRODUCE THESE IN TEXT*

*CAST PROPOSAL MENTIONS 9.25m and 42.5mm DIAMETER!! CHECK*

Basic data.

Data taking periods.

*INSERT VIDEO IN FOOTNOTE*

*** CAST X-ray optics

The first X-ray telescope used at CAST as a focusing optics for the
expected axion induced X-ray flux was a Wolter I type X-ray telescope
\cite{wolter_1_type} originally built for a proposed German space
based X-ray telescope mission, ABRIXAS \cite{ABRIXAS}. The telescope
consists of 27 gold coated parabolic and hyperbolic shells and has a
focal length of \SI{1.6}{m}. Due to the small size of the dipole
magnet's bores of only \SI{42.5}{mm} only a single section of the
telescope can be exposed. The telescope is thus placed off-axis from
the magnet bore to expose a single mirror section. An image of the
mirror system with a rough indication of the exposed section is shown
in fig. [[CAST_abrixas_mirror_system]]. 

The telescope is owned by the Max Planck Institut für
extraterrestrische Physik in Garching. For that reason it will often
be referred to as the 'MPE telescope' in the rest of the thesis.

The efficiency of the telescope reaches about \SI{48}{\%} as the peak
at around \SI{1.5}{\keV}, drops sharply at around \SI{2.3}{\keV} to
only about \SI{30}{\%} up to about \SI{7}{\keV}. From there it
continues to drop until about \SI{5}{\%} efficiency at
\SI{10}{\keV}. The efficiency is shown in a comparison with the LLNL
telescope in the next section [[Lawrence Livermore National Laboratory
(LLNL) telescope]] in fig. [[telescope_efficiency_comparison_mpe_llnl]].

A picture of the telescope installed at CAST behind the magnet on the
'sunrise' side of the magnet is shown in fig. [[CAST_abrixas_telescope_installed]]. 

This telescope was used for the data taking campaign in 2014 and 2015 using a GridPix
based detector discussed in \cite{krieger2018search} and serves as a
comparison for certain aspects in this thesis.

#+begin_center
#+CAPTION: Image of the CAST Abrixas installed at CAST on the sunrise side.
#+CAPTION: The image is taken from \cite{CAST_telescope_ccd} as it provides a 
#+CAPTION: relatively clear image of the telescope, which is hard to take nowadays.
#+NAME: CAST_abrixas_telescope_installed
[[~/org/Figs/thesis/CAST/cast_abrixas_telescope_image_clear.png]]
#+end_center

#+begin_center
#+CAPTION: Image of the CAST Abrixas telescope mirror system. The different shells of the 
#+CAPTION: Wolter I type telescope system are visible. One section is exposed to the 
#+CAPTION: magnet bore, the white line indicating roughly the extent of the bore. The 
#+CAPTION: sproke like structure is the support for the mirror shells.
#+CAPTION: Image taken from \cite{CAST_telescope_ccd}.
#+NAME: CAST_abrixas_mirror_system
[[~/org/Figs/thesis/CAST/abrixas_cast_telescope_system.png]]
#+end_center

*** Lawrence Livermore National Laboratory (LLNL) telescope
:PROPERTIES:
:CUSTOM_ID: sec:helioscopes:llnl_telescope
:END:

Up to 2014 there was only a single X-ray telescope in use at CAST. In
August 2014 a second X-ray optics was installed on the second bore
next to the ABRIXAS telescope. This telescope using technologies
originally developed for the space based NuSTAR telescope by NASA
\cite{Harrison_2013, Harrison2006, nustar_design_performance, nustar_fabrication, nustar_overview_status}, 
but purpose built for
axion searches and in particular the CAST experiment. Contrary to the
ABRIXAS telescope only a single telescope section of the Wolter I type
geometry was built as the small bore cannot expose more area. It
consists of 13 platinum / carbon coated glass shells in sections for a
total of 26 mirrors. Further the focal length was shortened to
\SI{1.5}{m} and the focal point is slightly angled away from the
straight continuation of the bore to make more room for the
installation of the detectors. This can be seen in the render of the
2017/18 detector setup in
fig. [[llnl_telescope_setup_2017_render]]. \cite{llnl_telescope_first_cast_results}

*BETTER INTRODUCE 2 LENGTH WISE SECTION THING OF WOLTER TELESCOPES*

#+begin_center
#+CAPTION: Render of the setup of the GridPix septemboard detector in 2017/18 showing the 
#+CAPTION: LLNL telescope on the left side. The diversion away from the extension of the
#+CAPTION: bore is visible, to have more space for detector installation, in particular the
#+CAPTION: lead shielding that is not shown in the render.
#+CAPTION: *ANNOTATE THE RENDER*
#+NAME: llnl_telescope_setup_2017_render
[[~/org/Figs/rayTracing/llnl_cast_gridpix_render_small.png]]
#+end_center

Part of the master thesis of Johanna von Oy in this group was a ray
tracing simulation for this optics. A comparison of the ray tracing
simulation is part of a more detailed introduction to the ray tracing
in chapter [[Raytracing - where does this belong?]]. *CITE JOHANNA*

#+begin_center
#+CAPTION: Comparison of the efficiency between the two telescopes, the MPE (ABRIXAS) as the 
#+CAPTION: original CAST telescope and the LLNL telescope purpose built for axion searches.
#+CAPTION: The LLNL telescope has superior efficiency in the energy range where the axion
#+CAPTION: flux is assumed to dominate, but falls off sharper at high energies.
#+CAPTION: The data for the LLNL telescope is extracted from fig. 3 in \cite{llnl_telescope_first_cast_results},
#+CAPTION: whereas for the ABRIXAS telescope it is extracted from the red line in fig. 4
#+CAPTION: of \cite{CAST_telescope_ccd}.
#+CAPTION: *FIX ME (REPLACE BY DATA FROM 0 TO 10 AND THINK ABOUT TRANSMISSION VS EFFICIENCY*
#+NAME: telescope_efficiency_comparison_mpe_llnl
[[~/org/Figs/statusAndProgress/llnl_mpe_transmission_comparison.pdf]]
#+end_center

#+begin_comment
Note: Refer to DTU thesis
[[/home/basti/org/Papers/llnl_telescope_optimizations_phdthesis_for_DTU_orbit.pdf]]
around page 65 (and shortly before for effective area definition; and
another eff area def on page 7). 
#+end_comment

*** Best limits

In the many years of data taking and countless detectors taking data
at the CAST experiment, it has put the most stringent limits on
different coupling constants over the years.

Specifically, CAST sets the current best limits on the:
- Axion-photon coupling $g_{aγ}$
- Axion-electron coupling $g_{ae}$
- Chameleon-photon coupling $β_γ$

For the axion-photon coupling the best limit is from
\cite{cast_nature} in 2017 based on the full MicroMegas dataset
including the data behind the LLNL telescope and constricts the coupling to $g_{aγ} <
\SI{6.6e-11}{\GeV^{-1}}$. 

For the axion-photon coupling the best limit is still from 2013 in
\cite{Barth_2013} using the theoretical calculations for an expected
solar axion flux done by J. Redondo in \cite{Redondo_2013} for a limit
on the product of the axion-electron and axion-photon coupling of
$g_{ae} g_{aγ} < \SI{8.1e-23}{\GeV^{-1}}$. The limit calculation was
based on data taken in CAST phase I in 2003 - 2005 with a pn-CCD
detector behind the MPE telescope.

For the chameleon search the best current limit on the
chameleon-photon coupling is based on a single GridPix based detector
with data taken in 2014 and 2015 by C. Krieger in
\cite{krieger2018search}, limiting the coupling to $β_γ <
\num{5.74e10}$, which is the first limit below the solar luminosity
bound. *CHECK CORRECT TERM*.

*Mention the limit method with foreshadowing to statistics chapter
that we will use the same?*

*** Subsection about gaseous phase, affecting conversion :noexport:

Extract parts of the axionMass.org file and place it here. Essentially
the:
- conversion probability in gas
- how to compute that
- one step showing conversion prob outside coherent condition

** International AXion Observatory (IAXO)

Barring a revolution in detector development or a lucky find of a non
QCD axion, the CAST experiment was unlikely to detect any signals. A
fourth generation axion helioscope to possibly reach towards the QCD
band in the mass-coupling constant phase space is a natural idea.

The first proposal for a next generation axion helioscope was
published in 2011 \cite{Irastorza_2011}, with the name International AXion
Observatory (IAXO) first appearing in 2013 \cite{vogel2013iaxo}. A
conceptual design report was further published in 2014
\cite{Armengaud_2014}. 

The proposed experiment is supposed to have a total magnet length of \SI{25}{m}
length with \num{8} \SI{60}{\cm} bores with an average transverse
magnetic field of \SI{2.5}{\tesla}. With a cryostat and magnet design
specifically built for the experiment, much larger tilting angles of
the magnet of about $\pm\ang{25}$ are proposed to allow for solar
tracking for \SI{12}{\hour} per day for a 1:1 data split between
tracking and background data. \cite{Armengaud_2014}

A schematic of the proposed design can be seen in fig. *IAXO FIG*.

Given the comparatively large budget requirements for such an
experiment, a compromise was envisioned to prove the required
technologies. This intermediate experiment called BabyIAXO will be
discussed in the next section, [[BabyIAXO]].

Make use of PRC (?) mainly for data, citation both that and first
proposal.

*MAYBE PICTURE OF IAXO LEFT, BABYIAXO RIGHT*

*** BabyIAXO

The major difference between full grown IAXO and BabyIAXO is
restricting the setup to 2 bores instead of 8 with a magnet length of
only \SI{10}{\m} to prove the magnet design works, before building a
larger version of said design.

Since the first conceptual design of IAXO \cite{Armengaud_2014} the
bore diameter for the two bores of BabyIAXO has increased from
\SI{60}{\cm} to \SI{70}{\cm}. \cite{abeln2021conceptual}

The BabyIAXO design was approved by the Deutsches
Elektronen-Synchrotron (DESY) for construction onsite, possibly
starting 2022 *CHECK*. As of writing the thesis the final construction
site is still undecided.
*WHEN CONSTRUCTION START UNCLEAR, WHAT TO WRITE HERE*

A schematic of the BabyIAXO design can be seen in fig. *BABYIAXO*.

*FIGURE OF MERIT*

*EXPECTED LIMIT for IAXO / BabyIAXO*


* Gaseous detectors principles                                       :Theory:
:PROPERTIES:
:CUSTOM_ID: sec:theory_detector
:END:

#+LATEX: \minitoc

Gaseous detectors, keep a bit short. Before writing properly read
Lucian. Best if read Lucian and then write a couple of weeks later.

This chapter will be kept reasonably short. Instead of introducing all
physics relevant for gaseous detectors, we will focus on the things
that are relevant for the understanding in the context of the
thesis. For better general overview of the physics of gaseous
detectors, read some of the following references: *Lucian, Markus MSc;
Lupberger, Krieger PhD, Elisa PhD, PDG, some book?...*

*Highlight which reference for what*

The theory sections covered in the following parts all have in common
that their understanding is required to make certain assumptions in
the data analysis or *???* 

It should be noted though that no part will be thorough enough to
stand on its own. Further reading is required in many places. This
theory section is supposed to serve as a reference for the later parts
of the thesis.

Of particular interest are all sections that give the theoretical
foundation for different kinds of background we might measure or the
understanding of our calibration data.

** Particle interactions with matter

We will now describe a few of the laws governing how particles
interact with matter, to the extent as it will be useful in the
context of the rest of this thesis.

*WRITE SUMMARY*

On the one hand we will discuss how X-rays interact with matter. Both
in terms of solids as well as gases, focused on their attenuation,
because this is required to describe signal attenuation due to a
detector window of a gaseous detector as well as for the absorption of
X-rays in the detector gas. In addition, X-ray reflectivity will be
discussed briefly as it is of interest for the behavior of X-ray
telescopes.

On the other hand the interaction of highly energetic charged
particles with matter will be discussed, its relation to cosmic
radiation as a source of background for an axion helioscope.

Finally, X-ray fluorescence will be covered as it is another major
source of background in an axion helioscope experiment, in particular
for gaseous detectors.

*** X-rays through matter & gases
:PROPERTIES:
:CUSTOM_ID: sec:theory:xray_matter_gas
:END:


*FIND REFERENCE TO MODERN LAW IN SOMETHING LIKE DEMTRÖDER*

Lambert-Beer's law \cite{bouguer1729essai, lambert1760photometria, beer1852bestimmung}

\[
I(z) = I_0 e^{-μz},
\]

gives the intensity of radiation $I(z)$ after traversing through a
medium with constant attenuation $μ$ of length $z$, given a starting
intensity of $I_0$. Directly related is of course the absorption
length $l_{\text{abs}} = 1/μ$ (or mean free path), which is a useful
property when considering typical absorption depths.

This law is of vital importance for the behavior of X-rays traversing
through matter, which is needed to compute the efficiency of a gaseous
detector with an entrance window.

In addition it is also related to the mean free path of X-rays in a
gas, which is an important parameter in gaseous detectors to
understand the absorption efficiency of X-rays of different energies
and the resulting expected diffusion.

For a more detailed overview of the remaining section, see the X-ray data
booklet \cite{williams2001x}.

In the context of X-rays the factor $μ$ is typically rewritten via the
'mass attenuation coefficient' $μ_m = μ · ρ$ with $ρ$ the density of
the material, commonly in \si{g cm^{-3}}. $μ_m$ is then defined by

\[
μ_m = \frac{N_A}{M} σ_A,
\]

where $N_A$ is Avogadro's number, $M$ the molar mass of the medium in
units of \si{g\per\mol} and $σ_A$ is the photoabsorption cross section
in units of \si{cm^2}. Thus, the mass attenuation coefficient is
usually given in $\si{cm^2 g^{-1}}$ such that $μ = μ_m · ρ$ is of inverse length
as expected. Further, the photoabsorption cross section can be
described via the scattering factor $f₂$

\[
σ_A = 2 r_e λ f₂,
\]

where $r_e$ is the classical electron radius and $λ$ the wavelength of
the X-ray. $f₂$ is the imaginary part of the forward scattering factor
$f$

\[
f = f₁ - i f₂
\]

which itself is the simplification of the general atomic scattering
factor that describes the atom specific part of the scattering cross
section.

This way of expressing it has the nice property of relying on a well
tabulated parameter $f₂$. Together with $f₁$ these tabulated values
can be used to compute everything from the refractive index at a
specific X-ray energy of a compound to the attenuation coefficient and
even reflectivity of a multi layer substrate.

It generalizes from single element to compounds easily by

\[
μ_m = \frac{N_A}{M_c} \sum_i n_i σ_{A,i},
\]

with $M_c$ the molar weight of the compound and $n_i$ the number of
atoms of kind $i$.

There is an online calculator for calculations of X-ray transmission
found under [fn:henke_gov] \cite{henke1993x}, as well as a library
implementation developed during the course of this thesis
under [fn:scinim_xrayAttenuation] \cite{Schmidt_xrayAttenuation_2022}. 

[fn:henke_gov] https://henke.lbl.gov/optical_constants/ 

[fn:scinim_xrayAttenuation] https://github.com/SciNim/xrayAttenuation



Fig. [[fig:theory:trasmission_examples]] shows an example of X-ray
transmission through a \SI{300}{nm} thick layer of \ccsini as well as
transmission through \SI{3}{cm} of argon at \SI{1}{atm}. All
information about the absorption lines and general transmission is
encoded in $f₂$.

#+CAPTION: X-ray transmission through a \SI{300}{nm} thick layer of \ccsini
#+CAPTION: and \SI{3}{cm} of argon calculated with \cite{Schmidt_xrayAttenuation_2022}. 
#+CAPTION: Calculation of the transmission based on tabulated scattering form factors.
#+NAME: fig:theory:transmission_examples
[[~/phd/Figs/theory/transmission_example.pdf]]

Mean free path of photons in gas. (for point of absorption in
detector + diffusion distance)

*EXAMPLE of ?*

**** Generation of \ccsini transmission figure                 :noexport:

Let's compute an example transmission plot using the Lambert-Beer law
as presented above based on =xrayAttenuation= now, on the one hand for
\ccsini as well as argon (common detector gas).

*TODO*: update ginger to use =-output-directory= to put the plot in
the right path & turn it into a TikZ plot.

#+begin_src nim :tangle /home/basti/phd/code/transmission_example.nim
import std / strutils
import xrayAttenuation, ggplotnim
# generate a compound of silicon and nitrogen with correct number of atoms
let Si₃N₄ = compound((Si, 3), (N, 4))
# instantiate an Argon instance
let ar = Argon.init()
# compute the density using ideal gas law at 1 atm
let ρ_Ar = density(1013.mbar.to(Pascal), 293.K, ar.molarMass)

# define energies in which to compute the transmission
# (we don't start at 0, as at 0 energy the parameters are not well defined)
let energies = linspace(1e-2, 10.0, 1000)

proc compTrans[T: AnyCompound](el: T, ρ: g•cm⁻³, length: Meter): DataFrame =
  result = toDf({ "Energy [keV]" : energies })
    .mutate(f{float: "μ" ~ el.attenuationCoefficient(idx("Energy [keV]").keV).float},
            f{float: "Trans" ~ transmission(`μ`.cm²•g⁻¹, ρ, length).float},
            f{"Compound" <- el.name})
var df = newDataFrame()
# compute transmission for Si₃N₄ (known density and desired length)
df.add Si₃N₄.compTrans(3.44.g•cm⁻³, 300.nm.to(Meter))
# and for argon 
df.add ar.compTrans(ρ_Ar, 3.cm.to(Meter))
# create a plot for the transmissions
echo df
let dS = pretty(300.nm, 3, short = true)
let dA = pretty(3.cm, 1, short = true)
let si = r"$\mathrm{Si}₃\mathrm{N}₄$"
ggplot(df, aes("Energy [keV]", "Trans", color = "Compound")) +
  geom_line() +
  xlab("Energy [keV]") + ylab("Transmission") +
  ggtitle("Transmission examples of $# $# and $# Argon" % [dS, si, dA]) +
  ggsave("/home/basti/phd/Figs/theory/transmission_example.pdf",
         #width = 800, height = 600,
         useTex = true, standalone = true) 
#+end_src

#+RESULTS:

*** X-ray reflectivity & scattering

The same atomic scattering factors $f₁$ and $f₂$ introduced in section
[[#sec:theory:xray_matter_gas]] for the attenuation can also be used to
compute the reflectivity of X-rays under shallow angles.

By defining the combined scattering factor

\[
f(E) = f₁(E) + i f₂(E)
\]

at energy $E$, the refractive index $n$ of a medium can be computed using

\[
n(E) = 1 - r_e \frac{λ²}{2π} \sum_i n_{ai} f_i(E)
\]

where $n_{ai}$ is the number density of the $i$-th compound of the
medium.

Then, in what is essentially an application of Snell's law, the
reflectivity can be expressed as

*TODO: FIX THIS UP LIKELY TO INCLUDE SURFACE ROUGHNESS. ALSO LOOK AT
XRAY DATA BOOKLET FOR IT AGAIN*

\[
R = \left| \frac{k_m - k_p}{k_m + k_p} \right|²
\]

where $k_m$ and $k_p$ are

\[
k_m = \sqrt{k² - (k \cos{θ})²}
\]

and

\[
k_p = \sqrt{ k² n² - (k \cos{θ})² }
\]

defined via the wave number $k$, which itself is computed via

\[
k = 2π \sin{θ} / λ.
\]

This can be generalized to multiple layers of material on a substrate
and including a surface roughness. Combined these provide the essence
for a realistic computation of the efficiency of an X-ray telescope
mirror shell.

This is also implemented in [fn:scinim_xrayAttenuation]
\cite{Schmidt_xrayAttenuation_2022} and [fn:henke_gov]
\cite{henke1993x} also provides an online calculator for such
reflectivities. 


[fn:henke_gov] https://henke.lbl.gov/optical_constants/ 

[fn:scinim_xrayAttenuation] https://github.com/SciNim/xrayAttenuation
Note: at the time of writing this, multi layers are not yet
implemented and the reflectivity code still has to be cleaned up.


*** Bethe-Bloch equation
:PROPERTIES:
:CUSTOM_ID: sec:theory:bethe_bloch
:END:

Another relevant aspect for gaseous detectors is the energy deposition
of charged particles. In particular for experiments that sit near the
surface, a major source of background is due to cosmic radiation, with
cosmic muons making up more than \SI{95}{\percent} \cite{Zyla:2020zbs}
of radiation (aside from neutrinos) at the surface, see
sec. [[#sec:theory:cosmic_radiation]].

These muons lose energy according to the Bethe-Bloch equation, which
describes the average energy loss per distance for a charged particle
with charge $z$ in a homogeneous medium with charge carriers $Z$. \cite{Zyla:2020zbs}

\begin{equation}
  \label{eq:theory:bethe_bloch_eq}
  \left\langle -\frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle = 
    K z² \frac{Z}{A} \frac{1}{β²} \left[ 
      \frac{1}{2} \ln\frac{2m_e c² β² γ² W_{\text{max}}}{I²} - β² - \frac{δ(βγ)}{2} 
    \right]
\end{equation}
where the different variables are as follows: 
*TURN INTO TABLE?*
- $K = 4π N_A r_e² m_e c² = \SI{0.307075}{\MeV \mol^{-1} \cm²}$
- $N_A = \SI{6.022 140 857(74)e23}{\mol^{-1}}$: Avogadro's number
- $r_e = e² / 4π ε_0 m_e c² = \SI{2.817 940 3227(19)}{fm}$: classical
  electron radius
- $m_e = \SI{9.1093837015(28)e-31}{\kg}$: electron mass
- $c = \SI{299792458}{\meter\per\second}$: speed of light in vacuum
- $z$: charge number of incident particle
- $Z$: atomic number of absorber material
- $A$: atomic mass of absorber material
- $β = \frac{v}{c}$: speed of incident particle
- $γ = \frac{1}{\sqrt{1 - β²}}$: Lorentz factor
- $W_{\text{max}}$: Maximum possible energy transfer to an electron in
  a single interaction
- $I$: mean excitation energy of the absorber material in \si{\eV}
- $δ(βγ)$: density-effect correction to energy loss

This interaction behavior of muons leads to a specific, expected
energy loss per distance. For argon gas at normal conditions (1 bar,
20°C, ...) this is shown in
fig. *FIG BETHE*. 

*CITE PDG*
There are multiple different representations of the Bethe-Bloch
equation mention multiple different ways to write formula.

As the Bethe formula was derived from quantum mechanical perturbation
theory, higher order corrections can be computed. For our purposes
here the leading order is enough. The next corrections proportional to
$Z³$ and $Z⁴$ are called /??/ and /shell correction/ respectively. 
At higher energies also the density correction by Fermi *CITE* needs
to be accounted for. These higher order corrections are mainly
relevant for very low energies. *SEE PDG "Energy loss at low energies" section*
*SHOW WITH OR WITHOUT. EQUATION WITH, BUT DROP IN CALCS*

It is important to keep in mind that the Bethe-Bloch equation gives
the *mean energy* per distance. When considering short distances as
typically encountered in particle detectors, this mean is skewed by
rare interactions that deposit large amounts of energy (towards
$W_{\text{max}}$). The energy deposition along short distances is
typically described by a Landau-Vavilov distribution (similar, but
different from a normal Landau distribution) \cite{Zyla:2020zbs,
BICHSEL2006154}. The most probable energy loss is often a more
appropriate number to look at. It can be expressed as

\begin{equation}
\label{eq:theory:most_probable_loss}
Δ_p = ξ \left[ \ln{ \frac{2 m_e c² β² γ²}{I}} + \ln{\frac{ξ}{I}} + j -
β² - δ(βγ) \right],
\end{equation}

where $ξ$ is

\[
ξ = \frac{1}{2} K z² \left\langle \frac{Z}{A} \right\rangle
\frac{x}{β²} \, \si{MeV},
\]

for a detector in which the material column the particle
travels through is expressed as $x = d · ρ$ of a distance $d$ in \si{g
cm^{-2}}. $j = \num{0.200}$ is an empirical constant
\cite{Zyla:2020zbs, bichsel1988straggling}. Further, $\langle Z / A
\rangle$ is simply the average $Z/A$ for a material compound $\langle
Z/A \rangle = \sum_i w_i Z_i / A_i$. 

The large difference typically encountered between the most probable
and the mean value for the energy loss in particle detectors, makes
studying the expected signals a complicated topic. For a detailed
description relevant for thin gaseous detectors, see especially
\cite{BICHSEL2006154}. 

Fig. [[fig:theory:muon_argon_3cm_bethe_loss]] shows the comparison of the
most probable energy loss via equation [[eq:theory:most_probable_loss]]
and the mean energy loss via the Bethe-Bloch equation
[[eq:theory:bethe_bloch_eq]] for muons of different energies traversing
$\SI{3}{cm}$ of argon gas.

*TODO: ADD MOST PROBABLE LOSS TO PLOT BELOW!*

*REPHRASE* instead focus on fact that they lose > 2 GeV instead of
talking about typical muon energies.

Muons arriving at the surface have energies typically above
\SI{100}{\MeV}. For that reason the higher order corrections are not
of importance for the study of muons in gaseous detectors.

At each point the formula gives the *expectation value* for the energy
loss after a distance large enough to include many interactions. In
each interaction the particle loses energy according to a Landau
distribution *CITE WHAT*, shown in fig. *LANDAU PLOT*. 
*EXPLANATION NOT QUITE CORRECT*

*MOVE FOLLOWING TO SEPARATE SECTION LATER (noexport about muon studies?)*
By taking into account the Bethe formula and a Landau distribution for
each point, we can compute an expectation for the energy loss for
muons under typical conditions met in a gaseous detector.

Landau distribution!

Also check out this $f$ function that is mentioned here:
https://doi.org/10.1016/j.nima.2006.03.009

as a better way to compute the actual energy loss per distance?

Also: read again PDG part about PDG and later in chapter the average
energy loss. Of course cannot take the mean of the Landau distribution
due to the long tail. We don't really do that in our muon simulation
though. 

\input{~/phd/Figs/muonStudies/ar_energy_loss_cast.tex}

**** Bethe equation for muons traversing \SI{3}{\cm} of argon gas :noexport:

We will now compute the energy loss for muons traversing the
\SI{3}{\cm} of argon gas that are seen by a muon traversing
orthogonally to the readout plane (i.e. such that it may look like a
photon).

#+begin_src nim :results silent :tangle /home/basti/phd/code/bethe_bloch.nim
import math, macros, unchained, ggplotnim, sequtils, strformat, strutils
import thesisHelpers
import ggplotnim / ggplot_vegatex

let K = 4 * π * N_A * r_e^2 * m_e * c^2 # usually in: [MeV mol⁻¹ cm²]

defUnit(cm³•g⁻¹)
defUnit(J•m⁻¹)
defUnit(cm⁻³)
defUnit(g•mol⁻¹)
defUnit(MeV•g⁻¹•cm²)
defUnit(mol⁻¹)
defUnit(keV•cm⁻¹)
defUnit(g•cm⁻³)
defUnit(g•cm⁻²)

proc I[T](z: float): T =
  ## use Bloch approximation for all but Argon (better use tabulated values!)
  result = if z == 18.0: 188.0.eV.to(T) 
           else: (10.eV * z).to(T)

proc calcβ(γ: UnitLess): UnitLess =
  result = sqrt(1.0 - 1.0 / (γ^2))

proc betheBloch(z, Z: UnitLess, A: g•mol⁻¹, γ: UnitLess, M: kg): MeV•g⁻¹•cm² =
  ## result in MeV cm² g⁻¹ (normalized by density)
  ## z: charge of particle
  ## Z: charge of particles making up medium
  ## A: atomic mass of particles making up medium
  ## γ: Lorentz factor of particle
  ## M: mass of particle in MeV (or same mass as `m_e` defined as)
  let β = calcβ(γ)
  let W_max = 2 * m_e * c^2 * β^2 * γ^2 / (1 + 2 * γ * m_e / M + (m_e / M)^2)
  let lnArg = 2 * m_e * c^2 * β^2 * γ^2 * W_max / (I[Joule](Z)^2)
  result = (K * z^2 * Z / A * 1.0 / (β^2) * (
   0.5 * ln(lnArg) - β^2
  )).to(MeV•g⁻¹•cm²)

proc mostProbableLoss(z, Z: UnitLess, A: g•mol⁻¹, γ: UnitLess,
                      x: g•cm⁻²): keV =
  ## Computes the most probable value, corresponding to the peak of the Landau
  ## distribution, that gives rise to the Bethe-Bloch formula.
  ##
  ## Taken from PDG chapter 'Passage of particles through matter' equation
  ## `34.12` in 'Fluctuations in energy loss', version 2020).
  ##
  ## `x` is the "thickness". Density times length, `x = ρ * d`. The other parameters
  ## are as in `betheBloch` above.
  let β = calcβ(γ)
  let ξ = K / 2.0 * Z / A * z*z * (x / (β*β))
  const j = 0.200
  let I = I[Joule](Z)
  result = (ξ * ( ln((2 * m_e * c^2 * β^2 * γ^2).to(Joule) / I) + ln(ξ.to(Joule) / I) + j - β^2)).to(keV) # - δ*(β*γ)

proc density(p: mbar, M: g•mol⁻¹, temp: Kelvin): g•cm⁻³ =
  ## returns the density of the gas for the given pressure.
  ## The pressure is assumed in `mbar` and the temperature (in `K`).
  ## The default temperature corresponds to BabyIAXO aim.
  ## Returns the density in `g / cm^3`
  let gasConstant = 8.314.J•K⁻¹•mol⁻¹ # joule K^-1 mol^-1
  let pressure = p.to(Pa) # pressure in Pa
  result = (pressure * M / (gasConstant * temp)).to(g•cm⁻³)

proc E_to_γ(E: GeV): UnitLess =
  result = E.to(Joule) / (m_μ * c^2) + 1

type
  Element = object
    name: string
    Z: UnitLess
    M: g•mol⁻¹
    A: UnitLess # numerically same as `M`
    ρ: g•cm⁻³

proc initElement(name: string, Z: UnitLess, M: g•mol⁻¹, ρ: g•cm⁻³): Element =
  Element(name: name, Z: Z, M: M, A: M.UnitLess, ρ: ρ)

let M_Ar = 39.95.g•mol⁻¹ # molar mass. Numerically same as relative atomic mass
#let ρAr = density(1050.mbar, M_Ar, temp = 293.15.K)
let ρAr = density(1013.mbar, M_Ar, temp = 293.15.K)
let Argon = initElement("ar", 18.0.UnitLess, 39.95.g•mol⁻¹, ρAr)

proc intBethe(e: Element, d_total: cm, E0: eV, dx = 1.μm): eV =
  ## integrated energy loss of bethe formula after `d` cm of matter
  ## and returns the energy remaining
  var γ: UnitLess = E_to_γ(E0.to(GeV))
  var d: cm
  result = E0
  var totalLoss = 0.eV
  while d < d_total and result > 0.eV:
    let E_loss: MeV = betheBloch(-1, e.Z, e.M, γ, m_μ) * e.ρ * dx
    result = result - E_loss.to(eV)
    γ = E_to_γ(result.to(GeV))
    d = d + dx.to(cm)
    totalLoss = totalLoss + E_loss.to(eV)
  result = max(0.float, result.float).eV

func argonLabel(): string = "fig:theory:muon_argon_3cm_bethe_loss"

## TODO: add in the most probable value calc!  
func argonCaption(): string = 
  result = r"Mean energy loss via Bethe-Bloch (red) equation of muons in \SI{3}{\cm} of argon at " &
    r"conditions in use in GridPix detector at CAST. \SI{1050}{mbar} of chamber pressure at room " &
    r"temperature. Note that the mean is skewed by events that transfer a large amount of energy, " &
    r"but are very rare! As such care must be taken interpreting the numbers. Blue shows the most " &
    r"probable energy loss, based on the peak of the Landau-Vavilov distribution underlying the " &
    r"Bethe-Bloch mean value." &
    interactiveVega(argonLabel())

proc plotDetectorAbsorption(element: Element) =
  let E_float = logspace(-2, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  let E_loss = energies.mapIt((it.to(eV) - intBethe(element, 3.cm, it.to(eV))).to(keV).float)
  let E_lossMP = energies.mapIt(mostProbableLoss(-1, element.Z, element.M, E_to_γ(it), ρ_Ar * 3.cm).float)
  let df = seqsToDf({E_float, "Bethe-Bloch (BB)" : E_loss, "Most probable (MP)" : E_lossMP})
    .gather(["Bethe-Bloch (BB)", "Most probable (MP)"], "Type", "Value")
  ggplot(df, aes("E_float", "Value", color = "Type")) +
    geom_line() +
    #xlab(r"μ Energy [\si{\GeV}]") + ylab(r"$-\left\langle \frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle$ [\si{\keV}]") +
    xlab(r"μ Energy [\si{\GeV}]") +
    ylab(r"$-\left\langle \frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle$ (BB), $Δ_p$ (MP) [\si{\keV}]") +
    scale_x_log10() + scale_y_log10() +
    theme_latex() + 
    ggtitle(r"Energy loss of Muons in \SI{3}{\cm} " & &"{element.name.capitalizeAscii} at CAST conditions") +
    #ggsave(&"/home/basti/phd/Figs/muonStudies/{element.name}_energy_loss_cast.pdf", useTeX = true, standalone = true)
    ggvegatex(&"/home/basti/phd/Figs/muonStudies/{element.name}_energy_loss_cast",
              caption = argonCaption(),
              label = argonLabel())
plotDetectorAbsorption(Argon)

proc plotMostProbable(e: Element) =
  let E_float = logspace(-1.5, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  let E_loss = energies.mapIt(mostProbableLoss(-1, e.Z, e.M, E_to_γ(it), ρ_Ar * 3.cm))
  let df = toDf({"E_loss" : E_loss.mapIt(it.float), E_float})
  ggplot(df, aes("E_float", "E_loss")) +
    geom_line() +
    scale_x_log10() + 
    xlab("Energy [GeV]") + ylab("Most probable loss [keV]") +
    ggsave("/tmp/most_probable_loss.pdf")
plotMostProbable(Argon)
#+end_src

*** X-ray fluorescence
:PROPERTIES:
:CUSTOM_ID: sec:theory:xray_fluorescence
:END:

Cosmic muons in their interactions with matter can ionize atoms,
leading to the possible emission of X-rays if the removed electron is
part of an inner shell, mostly K (and some L) shell electrons. This
leads to a form of background based on real X-rays and thus represents
a kind of background that is impossible to distinguish from any kind
of axion signal unless external scintillator based vetoes are used.
*TOO MUCH DETAIL HERE?* *CHECK THE SHELL STUFF, GIVE A MINI TABLE OF
IMPORTANT ATOMIC LINES!*

Important for our 3 keV Argon line + 8 keV copper line mainly.

Different lines of different materials are listed in
tab. [[tab_all_xray_fluorescence]], with a focus on elements that are
likely to be present in or around a detector.

Of course to be relevant as a form of detector background the material
must be close to the detector, as the X-rays will otherwise be
absorbed. This makes the detector material, the gas itself and all
material in the direction of the detectors' sensitivity a candidate
for X-ray fluorescence background.

Tab. *TABLE INSERT* contains the different lines of plausible
materials used for detector construction / etc. *...*
*ASK TOBI IF TO ADD SOME MATERIAL*

- [ ] *HOW DOES THIS CORRESPOND TO AUGER ELECTRONS?*

- [ ] *ADD RELEVANT TABLE FOR BINDING ENERGY AS WELL!*  
- [ ] *TODO: REMOVE UNNECESSARY LINES*

#+NAME: tab_all_xray_fluorescence
#+CAPTION: Photon energies of K, L and M emission lines for different elements in \si{eV}. 
#+CAPTION: Taken from \cite{williams2001x}, specifically https://xdb.lbl.gov/Section1/Table_1-2.pdf.
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  3 | Li      | 54.3      |           |          |          |           |          |          |          |         |
|  4 | Be      | 108.5     |           |          |          |           |          |          |          |         |
|  5 | B       | 183.3     |           |          |          |           |          |          |          |         |
|  6 | C       | 277       |           |          |          |           |          |          |          |         |
|  7 | N       | 392.4     |           |          |          |           |          |          |          |         |
|  8 | O       | 524.9     |           |          |          |           |          |          |          |         |
|  9 | F       | 676.8     |           |          |          |           |          |          |          |         |
| 10 | Ne      | 848.6     | 848.6     |          |          |           |          |          |          |         |
| 11 | Na      | 1,040.98  | 1,040.98  | 1,071.1  |          |           |          |          |          |         |
| 12 | Mg      | 1,253.60  | 1,253.60  | 1,302.2  |          |           |          |          |          |         |
| 13 | Al      | 1,486.70  | 1,486.27  | 1,557.45 |          |           |          |          |          |         |
| 14 | Si      | 1,739.98  | 1,739.38  | 1,835.94 |          |           |          |          |          |         |
| 15 | P       | 2,013.7   | 2,012.7   | 2,139.1  |          |           |          |          |          |         |
| 16 | S       | 2,307.84  | 2,306.64  | 2,464.04 |          |           |          |          |          |         |
| 17 | Cl      | 2,622.39  | 2,620.78  | 2,815.6  |          |           |          |          |          |         |
| 18 | Ar      | 2,957.70  | 2,955.63  | 3,190.5  |          |           |          |          |          |         |
| 19 | K       | 3,313.8   | 3,311.1   | 3,589.6  |          |           |          |          |          |         |
| 20 | Ca      | 3,691.68  | 3,688.09  | 4,012.7  | 341.3    | 341.3     | 344.9    |          |          |         |
| 21 | Sc      | 4,090.6   | 4,086.1   | 4,460.5  | 395.4    | 395.4     | 399.6    |          |          |         |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
| 22 | Ti      | 4,510.84  | 4,504.86  | 4,931.81 | 452.2    | 452.2     | 458.4    |          |          |         |
| 23 | V       | 4,952.20  | 4,944.64  | 5,427.29 | 511.3    | 511.3     | 519.2    |          |          |         |
| 24 | Cr      | 5,414.72  | 5,405.509 | 5,946.71 | 572.8    | 572.8     | 582.8    |          |          |         |
| 25 | Mn      | 5,898.75  | 5,887.65  | 6,490.45 | 637.4    | 637.4     | 648.8    |          |          |         |
| 26 | Fe      | 6,403.84  | 6,390.84  | 7,057.98 | 705.0    | 705.0     | 718.5    |          |          |         |
| 27 | Co      | 6,930.32  | 6,915.30  | 7,649.43 | 776.2    | 776.2     | 791.4    |          |          |         |
| 28 | Ni      | 7,478.15  | 7,460.89  | 8,264.66 | 851.5    | 851.5     | 868.8    |          |          |         |
| 29 | Cu      | 8,047.78  | 8,027.83  | 8,905.29 | 929.7    | 929.7     | 949.8    |          |          |         |
| 30 | Zn      | 8,638.86  | 8,615.78  | 9,572.0  | 1,011.7  | 1,011.7   | 1,034.7  |          |          |         |
| 31 | Ga      | 9,251.74  | 9,224.82  | 10,264.2 | 1,097.92 | 1,097.92  | 1,124.8  |          |          |         |
| 32 | Ge      | 9,886.42  | 9,855.32  | 10,982.1 | 1,188.00 | 1,188.00  | 1,218.5  |          |          |         |
| 33 | As      | 10,543.72 | 10,507.99 | 11,726.2 | 1,282.0  | 1,282.0   | 1,317.0  |          |          |         |
| 34 | Se      | 11,222.4  | 11,181.4  | 12,495.9 | 1,379.10 | 1,379.10  | 1,419.23 |          |          |         |
| 35 | Br      | 11,924.2  | 11,877.6  | 13,291.4 | 1,480.43 | 1,480.43  | 1,525.90 |          |          |         |
| 36 | Kr      | 12,649    | 12,598    | 14,112   | 1,586.0  | 1,586.0   | 1,636.6  |          |          |         |
| 37 | Rb      | 13,395.3  | 13,335.8  | 14,961.3 | 1,694.13 | 1,692.56  | 1,752.17 |          |          |         |
| 38 | Sr      | 14,165    | 14,097.9  | 15,835.7 | 1,806.56 | 1,804.74  | 1,871.72 |          |          |         |
| 39 | Y       | 14,958.4  | 14,882.9  | 16,737.8 | 1,922.56 | 1,920.47  | 1,995.84 |          |          |         |
| 40 | Zr      | 15,775.1  | 15,690.9  | 17,667.8 | 2,042.36 | 2,039.9   | 2,124.4  | 2,219.4  | 2,302.7  |         |
| 41 | Nb      | 16,615.1  | 16,521.0  | 18,622.5 | 2,165.89 | 2,163.0   | 2,257.4  | 2,367.0  | 2,461.8  |         |
| 42 | Mo      | 17,479.34 | 17,374.3  | 19,608.3 | 2,293.16 | 2,289.85  | 2,394.81 | 2,518.3  | 2,623.5  |         |
| 43 | Tc      | 18,367.1  | 18,250.8  | 20,619   | 2,424    | 2,420     | 2,538    | 2,674    | 2,792    |         |
| 44 | Ru      | 19,279.2  | 19,150.4  | 21,656.8 | 2,558.55 | 2,554.31  | 2,683.23 | 2,836.0  | 2,964.5  |         |
| 45 | Rh      | 20,216.1  | 20,073.7  | 22,723.6 | 2,696.74 | 2,692.05  | 2,834.41 | 3,001.3  | 3,143.8  |         |
| 46 | Pd      | 21,177.1  | 21,020.1  | 23,818.7 | 2,838.61 | 2,833.29  | 2,990.22 | 3,171.79 | 3,328.7  |         |
| 47 | Ag      | 22,162.92 | 21,990.3  | 24,942.4 | 2,984.31 | 2,978.21  | 3,150.94 | 3,347.81 | 3,519.59 |         |
| 48 | Cd      | 23,173.6  | 22,984.1  | 26,095.5 | 3,133.73 | 3,126.91  | 3,316.57 | 3,528.12 | 3,716.86 |         |
| 49 | In      | 24,209.7  | 24,002.0  | 27,275.9 | 3,286.94 | 3,279.29  | 3,487.21 | 3,713.81 | 3,920.81 |         |
| 50 | Sn      | 25,271.3  | 25,044.0  | 28,486.0 | 3,443.98 | 3,435.42  | 3,662.80 | 3,904.86 | 4,131.12 |         |
| 51 | Sb      | 26,359.1  | 26,110.8  | 29,725.6 | 3,604.72 | 3,595.32  | 3,843.57 | 4,100.78 | 4,347.79 |         |
| 52 | Te      | 27,472.3  | 27,201.7  | 30,995.7 | 3,769.33 | 3,758.8   | 4,029.58 | 4,301.7  | 4,570.9  |         |
| 53 | I       | 28,612.0  | 28,317.2  | 32,294.7 | 3,937.65 | 3,926.04  | 4,220.72 | 4,507.5  | 4,800.9  |         |
| 54 | Xe      | 29,779    | 29,458    | 33,624   | 4,109.9  | —         | —        | —        | —        |         |
| 55 | Cs      | 30,972.8  | 30,625.1  | 34,986.9 | 4,286.5  | 4,272.2   | 4,619.8  | 4,935.9  | 5,280.4  |         |
| 56 | Ba      | 32,193.6  | 31,817.1  | 36,378.2 | 4,466.26 | 4,450.90  | 4,827.53 | 5,156.5  | 5,531.1  |         |
| 57 | La      | 33,441.8  | 33,034.1  | 37,801.0 | 4,650.97 | 4,634.23  | 5,042.1  | 5,383.5  | 5,788.5  | 833     |
| 58 | Ce      | 34,719.7  | 34,278.9  | 39,257.3 | 4,840.2  | 4,823.0   | 5,262.2  | 5,613.4  | 6,052    | 883     |
| 59 | Pr      | 36,026.3  | 35,550.2  | 40,748.2 | 5,033.7  | 5,013.5   | 5,488.9  | 5,850    | 6,322.1  | 929     |
| 60 | Nd      | 37,361.0  | 36,847.4  | 42,271.3 | 5,230.4  | 5,207.7   | 5,721.6  | 6,089.4  | 6,602.1  | 978     |
| 61 | Pm      | 38,724.7  | 38,171.2  | 43,826   | 5,432.5  | 5,407.8   | 5,961    | 6,339    | 6,892    | —       |
| 62 | Sm      | 40,118.1  | 39,522.4  | 45,413   | 5,636.1  | 5,609.0   | 6,205.1  | 6,586    | 7,178    | 1,081   |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
| 63 | Eu      | 41,542.2  | 40,901.9  | 47,037.9 | 5,845.7  | 5,816.6   | 6,456.4  | 6,843.2  | 7,480.3  | 1,131   |
| 64 | Gd      | 42,996.2  | 42,308.9  | 48,697   | 6,057.2  | 6,025.0   | 6,713.2  | 7,102.8  | 7,785.8  | 1,185   |
| 65 | Tb      | 44,481.6  | 43,744.1  | 50,382   | 6,272.8  | 6,238.0   | 6,978    | 7,366.7  | 8,102    | 1,240   |
| 66 | Dy      | 45,998.4  | 45,207.8  | 52,119   | 6,495.2  | 6,457.7   | 7,247.7  | 7,635.7  | 8,418.8  | 1,293   |
| 67 | Ho      | 47,546.7  | 46,699.7  | 53,877   | 6,719.8  | 6,679.5   | 7,525.3  | 7,911    | 8,747    | 1,348   |
| 68 | Er      | 49,127.7  | 48,221.1  | 55,681   | 6,948.7  | 6,905.0   | 7,810.9  | 8,189.0  | 9,089    | 1,406   |
| 69 | Tm      | 50,741.6  | 49,772.6  | 57,517   | 7,179.9  | 7,133.1   | 8,101    | 8,468    | 9,426    | 1,462   |
| 70 | Yb      | 52,388.9  | 51,354.0  | 59,370   | 7,415.6  | 7,367.3   | 8,401.8  | 8,758.8  | 9,780.1  | 1,521.4 |
| 71 | Lu      | 54,069.8  | 52,965.0  | 61,283   | 7,655.5  | 7,604.9   | 8,709.0  | 9,048.9  | 10,143.4 | 1,581.3 |
| 72 | Hf      | 55,790.2  | 54,611.4  | 63,234   | 7,899.0  | 7,844.6   | 9,022.7  | 9,347.3  | 10,515.8 | 1,644.6 |
| 73 | Ta      | 57,532    | 56,277    | 65,223   | 8,146.1  | 8,087.9   | 9,343.1  | 9,651.8  | 10,895.2 | 1,710   |
| 74 | W       | 59,318.24 | 57,981.7  | 67,244.3 | 8,397.6  | 8,335.2   | 9,672.35 | 9,961.5  | 11,285.9 | 1,775.4 |
| 75 | Re      | 61,140.3  | 59,717.9  | 69,310   | 8,652.5  | 8,586.2   | 10,010.0 | 10,275.2 | 11,685.4 | 1,842.5 |
| 76 | Os      | 63,000.5  | 61,486.7  | 71,413   | 8,911.7  | 8,841.0   | 10,355.3 | 10,598.5 | 12,095.3 | 1,910.2 |
| 77 | Ir      | 64,895.6  | 63,286.7  | 73,560.8 | 9,175.1  | 9,099.5   | 10,708.3 | 10,920.3 | 12,512.6 | 1,979.9 |
| 78 | Pt      | 66,832    | 65,112    | 75,748   | 9,442.3  | 9,361.8   | 11,070.7 | 11,250.5 | 12,942.0 | 2,050.5 |
| 79 | Au      | 68,803.7  | 66,989.5  | 77,984   | 9,713.3  | 9,628.0   | 11,442.3 | 11,584.7 | 13,381.7 | 2,122.9 |
| 80 | Hg      | 70,819    | 68,895    | 80,253   | 9,988.8  | 9,897.6   | 11,822.6 | 11,924.1 | 13,830.1 | 2,195.3 |
| 81 | Tl      | 72,871.5  | 70,831.9  | 82,576   | 10,268.5 | 10,172.8  | 12,213.3 | 12,271.5 | 14,291.5 | 2,270.6 |
| 82 | Pb      | 74,969.4  | 72,804.2  | 84,936   | 10,551.5 | 10,449.5  | 12,613.7 | 12,622.6 | 14,764.4 | 2,345.5 |
| 83 | Bi      | 77,107.9  | 74,814.8  | 87,343   | 10,838.8 | 10,730.91 | 13,023.5 | 12,979.9 | 15,247.7 | 2,422.6 |
| 84 | Po      | 79,290    | 76,862    | 89,800   | 11,130.8 | 11,015.8  | 13,447   | 13,340.4 | 15,744   | —       |
| 85 | At      | 81,520    | 78,950    | 92,300   | 11,426.8 | 11,304.8  | 13,876   | —        | 16,251   | —       |
| 86 | Rn      | 83,780    | 81,070    | 94,870   | 11,727.0 | 11,597.9  | 14,316   | —        | 16,770   | —       |
| 87 | Fr      | 86,100    | 83,230    | 97,470   | 12,031.3 | 11,895.0  | 14,770   | 14,450   | 17,303   | —       |
| 88 | Ra      | 88,470    | 85,430    | 100,130  | 12,339.7 | 12,196.2  | 15,235.8 | 14,841.4 | 17,849   | —       |
| 89 | Ac      | 90,884    | 87,670    | 102,850  | 12,652.0 | 12,500.8  | 15,713   | —        | 18,408   | —       |
| 90 | Th      | 93,350    | 89,953    | 105,609  | 12,968.7 | 12,809.6  | 16,202.2 | 15,623.7 | 18,982.5 | 2,996.1 |
| 91 | Pa      | 95,868    | 92,287    | 108,427  | 13,290.7 | 13,122.2  | 16,702   | 16,024   | 19,568   | 3,082.3 |
| 92 | U       | 98,439    | 94,665    | 111,300  | 13,614.7 | 13,438.8  | 17,220.0 | 16,428.3 | 20,167.1 | 3,170.8 |
| 93 | Np      | —         | —         | —        | 13,944.1 | 13,759.7  | 17,750.2 | 16,840.0 | 20,784.8 | —       |
| 94 | Pu      | —         | —         | —        | 14,278.6 | 14,084.2  | 18,293.7 | 17,255.3 | 21,417.3 | —       |
| 95 | Am      | —         | —         | —        | 14,617.2 | 14,411.9  | 18,852.0 | 17,676.5 | 22,065.2 | —       |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|

X-Ray Data Booklet Table 1-1. Electron binding energies, in electron
volts, for the elements in their natural forms.  
https://xdb.lbl.gov/Section1/Table_1-1.pdf

#+CAPTION: Electron binding energies of all elements up to uranium in \si{eV}.
#+CAPTION: Taken from the X-ray data book \cite{williams2001x},
#+CAPTION: specifically https://xdb.lbl.gov/Section1/Table_1-1.pdf.
#+NAME: tab_all_atomic_binding_energies
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element |     K 1s | L1 2s    | L2 2p1/2 | L3 2p3/2 | M1 3s   | M2 3p1/2 | M3 3p3/2 | M4 3d3/2 | M5 3d5/2 | N1 4s  | N2 4p1/2 | N3 4p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  1 | H       |     13.6 |          |          |          |         |          |          |          |          |        |          |          |
|  2 | He      |    24.6* |          |          |          |         |          |          |          |          |        |          |          |
|  3 | Li      |    54.7* |          |          |          |         |          |          |          |          |        |          |          |
|  4 | Be      |   111.5* |          |          |          |         |          |          |          |          |        |          |          |
|  5 | B       |     188* |          |          |          |         |          |          |          |          |        |          |          |
|  6 | C       |   284.2* |          |          |          |         |          |          |          |          |        |          |          |
|  7 | N       |   409.9* | 37.3*    |          |          |         |          |          |          |          |        |          |          |
|  8 | O       |   543.1* | 41.6*    |          |          |         |          |          |          |          |        |          |          |
|  9 | F       |   696.7* |          |          |          |         |          |          |          |          |        |          |          |
| 10 | Ne      |   870.2* | 48.5*    |    21.7* |    21.6* |         |          |          |          |          |        |          |          |
| 11 | Na      |  1070.8† | 63.5†    |    30.65 |    30.81 |         |          |          |          |          |        |          |          |
| 12 | Mg      |  1303.0† | 88.7     |    49.78 |    49.50 |         |          |          |          |          |        |          |          |
| 13 | Al      |   1559.6 | 117.8    |    72.95 |    72.55 |         |          |          |          |          |        |          |          |
| 14 | Si      |     1839 | 149.7*b  |    99.82 |    99.42 |         |          |          |          |          |        |          |          |
| 15 | P       |   2145.5 | 189*     |     136* |     135* |         |          |          |          |          |        |          |          |
| 16 | S       |     2472 | 230.9    |   163.6* |   162.5* |         |          |          |          |          |        |          |          |
| 17 | Cl      |   2822.4 | 270*     |     202* |     200* |         |          |          |          |          |        |          |          |
| 18 | Ar      |  3205.9* | 326.3*   |   250.6† |   248.4* | 29.3*   | 15.9*    | 15.7*    |          |          |        |          |          |
| 19 | K       |  3608.4* | 378.6*   |   297.3* |   294.6* | 34.8*   | 18.3*    | 18.3*    |          |          |        |          |          |
| 20 | Ca      |  4038.5* | 438.4†   |   349.7† |   346.2† | 44.3    | †        | 25.4†    | 25.4†    |          |        |          |          |
| 21 | Sc      |     4492 | 498.0*   |   403.6* |   398.7* | 51.1*   | 28.3*    | 28.3*    |          |          |        |          |          |
| 22 | Ti      |     4966 | 560.9†   |   460.2† |   453.8† | 58.7†   | 32.6†    | 32.6†    |          |          |        |          |          |
| 23 | V       |     5465 | 626.7†   |   519.8† |   512.1† | 66.3†   | 37.2†    | 37.2†    |          |          |        |          |          |
| 24 | Cr      |     5989 | 696.0†   |   583.8† |   574.1† | 74.1†   | 42.2†    | 42.2†    |          |          |        |          |          |
| 25 | Mn      |     6539 | 769.1†   |   649.9† |   638.7† | 82.3†   | 47.2†    | 47.2†    |          |          |        |          |          |
| 26 | Fe      |     7112 | 844.6†   |   719.9† |   706.8† | 91.3†   | 52.7†    | 52.7†    |          |          |        |          |          |
| 27 | Co      |     7709 | 925.1†   |   793.2† |   778.1† | 101.0†  | 58.9†    | 59.9†    |          |          |        |          |          |
| 28 | Ni      |     8333 | 1008.6†  |   870.0† |   852.7† | 110.8†  | 68.0†    | 66.2†    |          |          |        |          |          |
| 29 | Cu      |     8979 | 1096.7†  |   952.3† |    932.7 | 122.5†  | 77.3†    | 75.1†    |          |          |        |          |          |
| 30 | Zn      |     9659 | 1196.2*  |  1044.9* |  1021.8* | 139.8*  | 91.4*    | 88.6*    | 10.2*    | 10.1*    |        |          |          |
| 31 | Ga      |    10367 | 1299.0*b |  1143.2† |  1116.4† | 159.5†  | 103.5†   | 100.0†   | 18.7†    | 18.7†    |        |          |          |
| 32 | Ge      |    11103 | 1414.6*b | 1248.1*b | 1217.0*b | 180.1*  | 124.9*   | 120.8*   | 29.8     | 29.2     |        |          |          |
| 33 | As      |    11867 | 1527.0*b | 1359.1*b | 1323.6*b | 204.7*  | 146.2*   | 141.2*   | 41.7*    | 41.7*    |        |          |          |
| 34 | Se      |    12658 | 1652.0*b | 1474.3*b | 1433.9*b | 229.6*  | 166.5*   | 160.7*   | 55.5*    | 54.6*    |        |          |          |
| 35 | Br      |    13474 | 1782*    |    1596* |    1550* | 257*    | 189*     | 182*     | 70*      | 69*      |        |          |          |
| 36 | Kr      |    14326 | 1921     |  1730.9* |  1678.4* | 292.8*  | 222.2*   | 214.4    | 95.0*    | 93.8*    | 27.5*  | 14.1*    | 14.1*    |
| 37 | Rb      |    15200 | 2065     |     1864 |     1804 | 326.7*  | 248.7*   | 239.1*   | 113.0*   | 112*     | 30.5*  | 16.3*    | 15.3*    |
| 38 | Sr      |    16105 | 2216     |     2007 |     1940 | 358.7†  | 280.3†   | 270.0†   | 136.0†   | 134.2†   | 38.9†  | 21.3     | 20.1†    |
| 39 | Y       |    17038 | 2373     |     2156 |     2080 | 392.0*b | 310.6*   | 298.8*   | 157.7†   | 155.8†   | 43.8*  | 24.4*    | 23.1*    |
| 40 | Zr      |    17998 | 2532     |     2307 |     2223 | 430.3†  | 343.5†   | 329.8†   | 181.1†   | 178.8†   | 50.6†  | 28.5†    | 27.1†    |
| 41 | Nb      |    18986 | 2698     |     2465 |     2371 | 466.6†  | 376.1†   | 360.6†   | 205.0†   | 202.3†   | 56.4†  | 32.6†    | 30.8†    |
| 42 | Mo      |    20000 | 2866     |     2625 |     2520 | 506.3†  | 411.6†   | 394.0†   | 231.1†   | 227.9†   | 63.2†  | 37.6†    | 35.5†    |
| 43 | Tc      |    21044 | 3043     |     2793 |     2677 | 544*    | 447.6    | 417.7    | 257.6    | 253.9*   | 69.5*  | 42.3*    | 39.9*    |
| 44 | Ru      |    22117 | 3224     |     2967 |     2838 | 586.1*  | 483.5†   | 461.4†   | 284.2†   | 280.0†   | 75.0†  | 46.3†    | 43.2†    |
| 45 | Rh      |    23220 | 3412     |     3146 |     3004 | 628.1†  | 521.3†   | 496.5†   | 311.9†   | 307.2†   | 81.4*b | 50.5†    | 47.3†    |
| 46 | Pd      |    24350 | 3604     |     3330 |     3173 | 671.6†  | 559.9†   | 532.3†   | 340.5†   | 335.2†   | 87.1*b | 55.7†a   | 50.9†    |
| 47 | Ag      |    25514 | 3806     |     3524 |     3351 | 719.0†  | 603.8†   | 573.0†   | 374.0†   | 368.3    | 97.0†  | 63.7†    | 58.3†    |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element |     K 1s | L1 2s    | L2 2p1/2 | L3 2p3/2 | M1 3s   | M2 3p1/2 | M3 3p3/2 | M4 3d3/2 | M5 3d5/2 | N 4s   | N2 4p1/2 | N3 4p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 48 | Cd      |    26711 | 4018     |     3727 |     3538 | 772.0†  | 652.6†   | 618.4†   | 411.9†   | 405.2†   | 109.8† | 63.9†a   | 63.9†a   |
| 49 | In      |    27940 | 4238     |     3938 |     3730 | 827.2†  | 703.2†   | 665.3†   | 451.4†   | 443.9†   | 122.9† | 73.5†a   | 73.5†a   |
| 50 | Sn      |    29200 | 4465     |     4156 |     3929 | 884.7†  | 756.5†   | 714.6†   | 493.2†   | 484.9†   | 137.1† | 83.6†a   | 83.6†a   |
| 51 | Sb      |    30491 | 4698     |     4380 |     4132 | 946†    | 812.7†   | 766.4†   | 537.5†   | 528.2†   | 153.2† | 95.6†a   | 95.6†a   |
| 52 | Te      |    31814 | 4939     |     4612 |     4341 | 1006†   | 870.8†   | 820.0†   | 583.4†   | 573.0†   | 169.4† | 103.3†a  | 103.3†a  |
| 53 | I       |    33169 | 5188     |     4852 |     4557 | 1072*   | 931*     | 875*     | 630.8    | 619.3    | 186*   | 123*     | 123*     |
| 54 | Xe      |    34561 | 5453     |     5107 |     4786 | 1148.7* | 1002.1*  | 940.6*   | 689.0*   | 676.4*   | 213.2* | 146.7    | 145.5*   |
| 55 | Cs      |    35985 | 5714     |     5359 |     5012 | 1211*b  | 1071*    | 1003*    | 740.5*   | 726.6*   | 232.3* | 172.4*   | 161.3*   |
| 56 | Ba      |    37441 | 5989     |     5624 |     5247 | 1293*b  | 1137*b   | 1063*b   | 795.7†   | 780.5*   | 253.5† | 192      | 178.6†   |
| 57 | La      |    38925 | 6266     |     5891 |     5483 | 1362*b  | 1209*b   | 1128*b   | 853*     | 836*     | 274.7* | 205.8    | 196.0*   |
| 58 | Ce      |    40443 | 6549     |     6164 |     5723 | 1436*b  | 1274*b   | 1187*b   | 902.4*   | 883.8*   | 291.0* | 223.2    | 206.5*   |
| 59 | Pr      |    41991 | 6835     |     6440 |     5964 | 1511    | 1337     | 1242     | 948.3*   | 928.8*   | 304.5  | 236.3    | 217.6    |
| 60 | Nd      |    43569 | 7126     |     6722 |     6208 | 1575    | 1403     | 1297     | 1003.3*  | 980.4*   | 319.2* | 243.3    | 224.6    |
| 61 | Pm      |    45184 | 7428     |     7013 |     6459 | ---     | 1471     | 1357     | 1052     | 1027     | ---    | 242      | 242      |
| 62 | Sm      |    46834 | 7737     |     7312 |     6716 | 1723    | 1541     | 1420     | 1110.9*  | 1083.4*  | 347.2* | 265.6    | 247.4    |
| 63 | Eu      |    48519 | 8052     |     7617 |     6977 | 1800    | 1614     | 1481     | 1158.6*  | 1127.5*  | 360    | 284      | 257      |
| 64 | Gd      |    50239 | 8376     |     7930 |     7243 | 1881    | 1688     | 1544     | 1221.9*  | 1189.6*  | 378.6* | 286      | 271      |
| 65 | Tb      |    51996 | 8708     |     8252 |     7514 | 1968    | 1768     | 1611     | 1276.9*  | 1241.1*  | 396.0* | 322.4*   | 284.1*   |
| 66 | Dy      |    53789 | 9046     |     8581 |     7790 | 2047    | 1842     | 1676     | 1333     | 1292.6*  | 414.2* | 333.5*   | 293.2*   |
| 67 | Ho      |    55618 | 9394     |     8918 |     8071 | 2128    | 1923     | 1741     | 1392     | 1351     | 432.4* | 343.5    | 308.2*   |
| 68 | Er      |    57486 | 9751     |     9264 |     8358 | 2207    | 2006     | 1812     | 1453     | 1409     | 449.8* | 366.2    | 320.2*   |
| 69 | Tm      |    59390 | 10116    |     9617 |     8648 | 2307    | 2090     | 1885     | 1515     | 1468     | 470.9* | 385.9*   | 332.6*   |
| 70 | Yb      |    61332 | 10486    |     9978 |     8944 | 2398    | 2173     | 1950     | 1576     | 1528     | 480.5* | 388.7*   | 339.7*   |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element | N4 4d3/2 | N5 4d5/2 | N6 4f5/2 | N7 4f7/2 | O1 5s   | O2 5p1/2 | O3 5p3/2 | O4 5d3/2 | O5 5d5/2 | P1 6s  | P2 6p1/2 | P3 6p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 48 | Cd      |    11.7† | l0.7†    |          |          |         |          |          |          |          |        |          |          |
| 49 | In      |    17.7† | 16.9†    |          |          |         |          |          |          |          |        |          |          |
| 50 | Sn      |    24.9† | 23.9†    |          |          |         |          |          |          |          |        |          |          |
| 51 | Sb      |    33.3† | 32.1†    |          |          |         |          |          |          |          |        |          |          |
| 52 | Te      |    41.9† | 40.4†    |          |          |         |          |          |          |          |        |          |          |
| 53 | I       |     50.6 | 48.9     |          |          |         |          |          |          |          |        |          |          |
| 54 | Xe      |    69.5* | 67.5*    |      --- |      --- | 23.3*   | 13.4*    | 12.1*    |          |          |        |          |          |
| 55 | Cs      |    79.8* | 77.5*    |      --- |      --- | 22.7    | 14.2*    | 12.1*    |          |          |        |          |          |
| 56 | Ba      |    92.6† | 89.9†    |      --- |      --- | 30.3†   | 17.0†    | 14.8†    |          |          |        |          |          |
| 57 | La      |   105.3* | 102.5*   |      --- |      --- | 34.3*   | 19.3*    | 16.8*    |          |          |        |          |          |
| 58 | Ce      |     109* | ---      |      0.1 |      0.1 | 37.8    | 19.8*    | 17.0*    |          |          |        |          |          |
| 59 | Pr      |   115.1* | 115.1*   |      2.0 |      2.0 | 37.4    | 22.3     | 22.3     |          |          |        |          |          |
| 60 | Nd      |   120.5* | 120.5*   |      1.5 |      1.5 | 37.5    | 21.1     | 21.1     |          |          |        |          |          |
| 61 | Pm      |      120 | 120      |      --- |      --- | ---     | ---      | ---      |          |          |        |          |          |
| 62 | Sm      |      129 | 129      |      5.2 |      5.2 | 37.4    | 21.3     | 21.3     |          |          |        |          |          |
| 63 | Eu      |      133 | 127.7*   |        0 |        0 | 32      | 22       | 22       |          |          |        |          |          |
| 64 | Gd      |      --- | 142.6*   |     8.6* |     8.6* | 36      | 28       | 21       |          |          |        |          |          |
| 65 | Tb      |   150.5* | 150.5*   |     7.7* |     2.4* | 45.6*   | 28.7*    | 22.6*    |          |          |        |          |          |
| 66 | Dy      |   153.6* | 153.6*   |     8.0* |     4.3* | 49.9*   | 26.3     | 26.3     |          |          |        |          |          |
| 67 | Ho      |     160* | 160*     |     8.6* |     5.2* | 49.3*   | 30.8*    | 24.1*    |          |          |        |          |          |
| 68 | Er      |   167.6* | 167.6*   |      --- |     4.7* | 50.6*   | 31.4*    | 24.7*    |          |          |        |          |          |
| 69 | Tm      |   175.5* | 175.5*   |      --- |      4.6 | 54.7*   | 31.8*    | 25.0*    |          |          |        |          |          |
| 70 | Yb      |   191.2* | 182.4*   |     2.5* |     1.3* | 52.0*   | 30.3*    | 24.1*    |          |          |        |          |          |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element |     K 1s | L1 2s    | L2 2p1/2 | L3 2p3/2 | M1 3s   | M2 3p1/2 | M3 3p3/2 | M4 3d3/2 | M5 3d5/2 | N1 4s  | N2 4p1/2 | N3 4p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 71 | Lu      |    63314 | 10870    |    10349 |     9244 | 2491    | 2264     | 2024     | 1639     | 1589     | 506.8* | 412.4*   | 359.2*   |
| 72 | Hf      |    65351 | 11271    |    10739 |     9561 | 2601    | 2365     | 2108     | 1716     | 1662     | 538*   | 438.2†   | 380.7†   |
| 73 | Ta      |    67416 | 11682    |    11136 |     9881 | 2708    | 2469     | 2194     | 1793     | 1735     | 563.4† | 463.4†   | 400.9†   |
| 74 | W       |    69525 | 12100    |    11544 |    10207 | 2820    | 2575     | 2281     | 1872     | 1809     | 594.1† | 490.4†   | 423.6†   |
| 75 | Re      |    71676 | 12527    |    11959 |    10535 | 2932    | 2682     | 2367     | 1949     | 1883     | 625.4† | 518.7†   | 446.8†   |
| 76 | Os      |    73871 | 12968    |    12385 |    10871 | 3049    | 2792     | 2457     | 2031     | 1960     | 658.2† | 549.1†   | 470.7†   |
| 77 | Ir      |    76111 | 13419    |    12824 |    11215 | 3174    | 2909     | 2551     | 2116     | 2040     | 691.1† | 577.8†   | 495.8†   |
| 78 | Pt      |    78395 | 13880    |    13273 |    11564 | 3296    | 3027     | 2645     | 2202     | 2122     | 725.4† | 609.1†   | 519.4†   |
| 79 | Au      |    80725 | 14353    |    13734 |    11919 | 3425    | 3148     | 2743     | 2291     | 2206     | 762.1† | 642.7†   | 546.3†   |
| 80 | Hg      |    83102 | 14839    |    14209 |    12284 | 3562    | 3279     | 2847     | 2385     | 2295     | 802.2† | 680.2†   | 576.6†   |
| 81 | Tl      |    85530 | 15347    |    14698 |    12658 | 3704    | 3416     | 2957     | 2485     | 2389     | 846.2† | 720.5†   | 609.5†   |
| 82 | Pb      |    88005 | 15861    |    15200 |    13035 | 3851    | 3554     | 3066     | 2586     | 2484     | 891.8† | 761.9†   | 643.5†   |
| 83 | Bi      |    90524 | 16388    |    15711 |    13419 | 3999    | 3696     | 3177     | 2688     | 2580     | 939†   | 805.2†   | 678.8†   |
| 84 | Po      |    93105 | 16939    |    16244 |    13814 | 4149    | 3854     | 3302     | 2798     | 2683     | 995*   | 851*     | 705*     |
| 85 | At      |    95730 | 17493    |    16785 |    14214 | 4317    | 4008     | 3426     | 2909     | 2787     | 1042*  | 886*     | 740*     |
| 86 | Rn      |    98404 | 18049    |    17337 |    14619 | 4482    | 4159     | 3538     | 3022     | 2892     | 1097*  | 929*     | 768*     |
| 87 | Fr      |   101137 | 18639    |    17907 |    15031 | 4652    | 4327     | 3663     | 3136     | 3000     | 1153*  | 980*     | 810*     |
| 88 | Ra      |   103922 | 19237    |    18484 |    15444 | 4822    | 4490     | 3792     | 3248     | 3105     | 1208*  | 1058     | 879*     |
| 89 | Ac      |   106755 | 19840    |    19083 |    15871 | 5002    | 4656     | 3909     | 3370     | 3219     | 1269*  | 1080*    | 890*     |
| 90 | Th      |   109651 | 20472    |    19693 |    16300 | 5182    | 4830     | 4046     | 3491     | 3332     | 1330*  | 1168*    | 966.4†   |
| 91 | Pa      |   112601 | 21105    |    20314 |    16733 | 5367    | 5001     | 4174     | 3611     | 3442     | 1387*  | 1224*    | 1007*    |
| 92 | U       |   115606 | 21757    |    20948 |    17166 | 5548    | 5182     | 4303     | 3728     | 3552     | 1439*b | 1271*b   | 1043†    |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
|  Z | Element | N4 4d3/2 | N5 4d5/2 | N6 4f5/2 | N7 4f7/2 | O1 5s   | O2 5p1/2 | O3 5p3/2 | O4 5d3/2 | O5 5d5/2 | P1 6s  | P2 6p1/2 | P3 6p3/2 |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|
| 71 | Lu      |   206.1* | 196.3*   |     8.9* |     7.5* | 57.3*   | 33.6*    | 26.7*    |          |          |        |          |          |
| 72 | Hf      |   220.0† | 211.5†   |    15.9† |    14.2† | 64.2†   | 38*      | 29.9†    |          |          |        |          |          |
| 73 | Ta      |   237.9† | 226.4†   |    23.5† |    21.6† | 69.7†   | 42.2*    | 32.7†    |          |          |        |          |          |
| 74 | W       |   255.9† | 243.5†   |    33.6* |    31.4† | 75.6†   | 45.3*b   | 36.8†    |          |          |        |          |          |
| 75 | Re      |   273.9† | 260.5†   |    42.9* |    40.5* | 83†     | 45.6*    | 34.6*b   |          |          |        |          |          |
| 76 | Os      |   293.1† | 278.5†   |    53.4† |    50.7† | 84*     | 58*      | 44.5†    |          |          |        |          |          |
| 77 | Ir      |   311.9† | 296.3†   |    63.8† |    60.8† | 95.2*b  | 63.0*b   | 48.0†    |          |          |        |          |          |
| 78 | Pt      |   331.6† | 314.6†   |    74.5† |    71.2† | 101.7*b | 65.3*b   | 51.7†    |          |          |        |          |          |
| 79 | Au      |   353.2† | 335.1†   |    87.6† |     84.0 | 107.2*b | 74.2†    | 57.2†    |          |          |        |          |          |
| 80 | Hg      |   378.2† | 358.8†   |   104.0† |    99.9† | 127†    | 83.1†    | 64.5†    | 9.6†     | 7.8†     |        |          |          |
| 81 | Tl      |   405.7† | 385.0†   |   122.2† |   117.8† | 136.0*b | 94.6†    | 73.5†    | 14.7†    | 12.5†    |        |          |          |
| 82 | Pb      |   434.3† | 412.2†   |   141.7† |   136.9† | 147*b   | 106.4†   | 83.3†    | 20.7†    | 18.1†    |        |          |          |
| 83 | Bi      |   464.0† | 440.1†   |   162.3† |   157.0† | 159.3*b | 119.0†   | 92.6†    | 26.9†    | 23.8†    |        |          |          |
| 84 | Po      |     500* | 473*     |     184* |     184* | 177*    | 132*     | 104*     | 31*      | 31*      |        |          |          |
| 85 | At      |     533* | 507      |     210* |     210* | 195*    | 148*     | 115*     | 40*      | 40*      |        |          |          |
| 86 | Rn      |     567* | 541*     |     238* |     238* | 214*    | 164*     | 127*     | 48*      | 48*      | 26     |          |          |
| 87 | Fr      |     603* | 577*     |     268* |     268* | 234*    | 182*     | 140*     | 58*      | 58*      | 34     | 15       | 15       |
| 88 | Ra      |     636* | 603*     |     299* |     299* | 254*    | 200*     | 153*     | 68*      | 68*      | 44     | 19       | 19       |
| 89 | Ac      |     675* | 639*     |     319* |     319* | 272*    | 215*     | 167*     | 80*      | 80*      | ---    | ---      | ---      |
| 90 | Th      |   712.1† | 675.2†   |   342.4† |   333.1† | 290*a   | 229*a    | 182*a    | 92.5†    | 85.4†    | 41.4†  | 24.5†    | 16.6†    |
| 91 | Pa      |     743* | 708*     |     371* |     360* | 310*    | 232*     | 232*     | 94*      | 94*      | ---    | ---      | ---      |
| 92 | U       |   778.3† | 736.2†   |   388.2* |   377.4† | 321*ab  | 257*ab   | 192*ab   | 102.8†   | 94.2†    | 43.9†  | 26.8†    | 16.8†    |
|----+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+--------+----------+----------|


*** Bremsstrahlung

Talk about Bremsstrahlung as a requirement for the CDL data?

** Cosmic rays
:PROPERTIES:
:CUSTOM_ID: sec:theory:cosmic_radiation
:END:

Cosmic rays, or cosmic radiation refers to two aspects of a related
phenomenon. Primary cosmic radiation is the radiation arriving at
Earth from the Sun, galactic and extragalactic sources. The main
contribution are highly energetic protons, but other long lived
elementary particles and nuclei also contribute to a lesser
extent. Cosmic rays are isotropic at most energies, because of the
influence of galactic magnetic fields. Their energies range from
$\SI{1e9}{eV}$ up to $\SI{1e21}{eV}$. It is generally assumed that
particles below \SI{1e18}{eV} are of mainly galactic origin, whereas
the above is dominated by extragalactic sources. The flux of the
primary cosmic rays generally follows a power law
distribution. Different contributions follow a generally similar power
law. \cite{Zyla:2020zbs} (chapter on cosmic rays)

When cosmic rays interact with the molecules of Earth's atmosphere,
mesons are produced, mainly pions. Neutral pions generate showers of
photons and electron-positron pairs. Charged pions on the other hand
decay into muons and anti muon-neutrinos. Muons are produced over
electrons in this case, due to chirality. As they are more massive
than electrons they have a larger component of the opposite chirality
than their neutrino partner, which is necessary for this 'forbidden'
decay due to angular momentum conservation.

They are produced at an altitude of roughly $\SI{15}{km}$. A large
fraction of them reaches Earth's surface as they are highly
relativistic. Their spectrum is described by a convolution of the
production energy, their energy loss due to ionization in the
atmosphere and possible decay.

Muons are of interest in the context of helioscope experiments, as
they present a dominant source of background, especially in gaseous
detectors (directly and indirectly due to fluorescence). And because
current helioscope experiments are built near the surface, little
attenuation of muon flux happens. Therefore, a good understanding of
the expected muon flux is required.

Above $\SI{100}{GeV}$ muon decay is negligible. At those energies the
muon flux at the surface strictly follows the same power law as the
primary cosmic ray flux. Following Gaisser \cite{gaisser2016cosmic},
in this regime it can be described by

#+NAME: eq:theory:muon_flux_gaisser
\begin{equation}
\frac{\mathrm{d}N_μ}{\mathrm{d}E_μ \mathrm{d}Ω} \approx \frac{0.14
E_μ^{-2.7}}{\si{\centi\meter\squared \second \steradian \giga\electronvolt}} \times \left[ \frac{1}{1 + \frac{1.1
E_μ \cos ϑ}{\SI{115}{GeV}}} + \frac{0.054}{1 + \frac{1.1 E_μ \cos
ϑ}{\SI{850}{GeV}}} \right]
\end{equation}

where the first term in parenthesis is the pion and the second the
kaon contribution.

For lower energies, \cite{doi:10.1142/S0217751X18501750} provide a set
of fitted functions based on [[#eq:theory:muon_flux_gaisser]] with a
single power law

\[
I(E, θ) = I_0 N (E_0 + E)^{-n} \left(1 + \frac{E}{ε}\right)^{-1} D(θ)^{-(n - 1)},
\]

where $I_0$, the intensity under zenith angle, and
$ε$ is another fit parameter for the replacement of the separate meson
masses in eq. [[#eq:theory:muon_flux_gaisser]]. $D(θ)$ is the path length
through the atmosphere under an angle $θ$ from the zenith. $N$ is a
normalization constant given by

\[
N = (n - 1) (E_0 + E_c)^{n-1},
\]

where $n$ corresponds to the effective power of the cosine behavior
and is the final fit parameter. $E_0$ accounts for the energy loss due
to interactions in the atmosphere and $E_c$ is the lowest energy given
in a data set.

If the Earth is assumed flat, it is $D(θ) = 1/\cosθ$ (which is often
assumed for simplicity and is a reasonable approximation as long as
only angles close to $θ = 0$ are considered). To describe a trajectory
through Earth's curved atmosphere $D(θ)$ can be written as:

\[
D(θ) = \sqrt{
  \left(
    \frac{R²}{d²} \cos² θ + 2\frac{R}{d} + 1
  \right)
} -
  \frac{R}{d}\cos θ
\]
where $R$ is the Earth radius, $d$ the vertical path length (i.e. the
height at which the muon is created) and $θ$ the zenith angle.

While this parametrization is very useful to describe the few specific
datasets shown in \cite{doi:10.1142/S0217751X18501750} and provides a
way to fit any measured muon flux at a specific location, it is
limited in applicability to arbitrary locations, altitudes and
angles. For that an approach that does not require a fit to a dataset
is preferable, namely by utilizing the a combination of the
approximation by Gaisser, eq. [[#eq:theory:muon_flux_gaisser]], and the
interaction of muons with the atmosphere. As such, we modify the
equation for the intensity $I$ to the following:

\[
I(E, θ) = I_0 (n-1) (E_θ(E, θ) + E_c)^{n-1} (E_θ(E, θ) + E)^{-n} \left[ \frac{1}{1 + \frac{1.1
E_μ \cos ϑ}{\SI{115}{GeV}}} + \frac{0.054}{1 + \frac{1.1 E_μ \cos
ϑ}{\SI{850}{GeV}}} \right] D(θ)^{-(n - 1)},
\]

where we take $n = 3$ exactly. One could put in the best fit for the
general cosine behavior under zenith angles, $n = n_{\text{fit}} + 1$,
but for simplicity we just use 3 here. Take $E_θ(E, θ)$ to be the
energy of a muon left from initial energy $E$ at generation in the
upper atmosphere after transporting it through the atmosphere under
the angle $θ$. The transport must take into account the density change
using the barometric height formula of the atmosphere. Transport is
done using the Bethe-Bloch equation as introduced in
sec. [[#sec:theory:bethe_bloch]] assuming an atmosphere made up of
nitrogen, oxygen and argon. As such we remove all parameters except
an initial intensity $I_0$, which can be set to the best fit of the
integrated muon flux at the zenith angle at sea level. In the
following figures we simply use $I_0 = \SI{90}{\per\meter\squared
\per\steradian \per\second}$. Figure [[fig:theory:muon_flux_surface]]
shows the expected differential muon flux using these parameters for
different angles at sea level. On the left the initial energy of the
muons is shown before transporting through the atmosphere. For each
angle the lines cut off at the energy below which the muon would
likely stopped by the atmosphere according to its energy loss per
distance. On the right we see the same final energy of the same muons
at the surface. The lines are cut to the lowest muon energy that was
calculated for which more than \SI{1}{GeV} was left at the
surface. These numbers match reasonably well with different datasets
for different locations under different angles, but they should *not*
be considered as more than a starting point for a general expectation.

#+CAPTION: Differential muon flux at sea level for different zenith angles.
#+CAPTION: \ref{fig:theory:muon_flux_surface:initial} shows the initial energy of the muon. The cut-off corresponds to the
#+CAPTION: lowest energy transported through the atmosphere. \ref{fig:theory:muon_flux_surface:final} shows the
#+CAPTION: final muon energy at the surface, with the lowest computed value above
#+CAPTION: $\SI{1}{GeV}$ shown. 
#+NAME: fig:theory:muon_flux_surface
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\linewidth]{/home/basti/phd/Figs/muons/initial_energy_vs_flux_and_angle_cosmic_muons.pdf}
    \caption{Initial energy}
    \label{fig:theory:muon_flux_surface:initial}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\linewidth]{/home/basti/phd/Figs/muons/final_energy_vs_flux_and_angle_cosmic_muons.pdf}
    \caption{Final energy}
    \label{fig:theory:muon_flux_surface:final}
  \end{subfigure}
\end{figure}

Because of their large energies, muons behave as minimally ionizing
particles (MIPS), which means their mean energy loss is more or less
independent of the muon's energy. They are in the trough of the
Bethe-Bloch equation, see sec. [[#sec:theory:bethe_bloch]]. This means the
exact energy of each muon is irrelevant and for background studies
only the actual rate of muons is important.

*PLOT OF PRIMARY RADIATION*

*SECONDARY MUON PRODUCTION*

*MUON FLUX AT ZENITH*, *MUON FLUX UNDER ANGLE* (cos²)

*REFERENCE TO MUON CHIRALITY OVER ELECTRON PROD*


*** Calculation of muon angular / energy dependence at surface   :noexport:

The code here is directly based on code written in my notes
[[file:~/org/Doc/StatusAndProgress.org]] being tangled into a file
=/tmp/muon_flux.nim=. 

#+begin_src nim :results silent :tangle /home/basti/phd/code/muons.nim
import math, macros, unchained
import seqmath, ggplotnim, sequtils, strformat

let K = 4 * π * N_A * r_e^2 * m_e * c^2 # usually in: [MeV mol⁻¹ cm²]

defUnit(cm³•g⁻¹)
defUnit(J•m⁻¹)
defUnit(cm⁻³)
defUnit(g•mol⁻¹)
defUnit(MeV•g⁻¹•cm²)
defUnit(mol⁻¹)
defUnit(keV•cm⁻¹)
defUnit(g•cm⁻³)
defUnit(g•cm⁻²)

proc electronDensity(ρ: g•cm⁻³, Z, A: UnitLess): cm⁻³ =
  result = N_A * Z * ρ / (A * M_u.to(g•mol⁻¹))

proc I[T](z: float): T =
  ## use Bloch approximation for all but Argon (better use tabulated values!)
  # 188.0 eV from NIST table 
  result = if z == 18.0: 188.0.eV.to(T) 
           else: (10.eV * z).to(T)

proc calcβ(γ: UnitLess): UnitLess =
  result = sqrt(1.0 - 1.0 / (γ^2))

proc betheBloch(z, Z: UnitLess,
                   A: g•mol⁻¹,
                   γ: UnitLess,
                   M: kg): MeV•g⁻¹•cm² =
  ## result in MeV cm² g⁻¹ (normalized by density)
  ## z: charge of particle
  ## Z: charge of particles making up medium
  ## A: atomic mass of particles making up medium
  ## γ: Lorentz factor of particle
  ## M: mass of particle in MeV (or same mass as `m_e` defined as)
  let β = calcβ(γ)
  let W_max = 2 * m_e * c^2 * β^2 * γ^2 /
    (1 + 2 * γ * m_e / M + (m_e / M)^2)
  let lnArg = 2 * m_e * c^2 * β^2 * γ^2 * W_max / (I[Joule](Z)^2)
  result = (K * z^2 * Z / A * 1.0 / (β^2) * (
    0.5 * ln(lnArg) - β^2
  )).to(MeV•g⁻¹•cm²)

proc mostProbableLoss(z, Z: UnitLess, A: g•mol⁻¹, γ: UnitLess,
                      x: g•cm⁻²): keV =
  ## Computes the most probable value, corresponding to the peak of the Landau
  ## distribution, that gives rise to the Bethe-Bloch formula.
  ##
  ## Taken from PDG chapter 'Passage of particles through matter' equation
  ## `34.12` in 'Fluctuations in energy loss', version 2020).
  ##
  ## `x` is the "thickness". Density times length, `x = ρ * d`. The other parameters
  ## are as in `betheBloch` above.
  let β = calcβ(γ)
  let ξ = K / 2.0 * Z / A * z*z * (x / (β*β))
  const j = 0.200
  let I = I[Joule](Z)
  result = (ξ * ( ln((2 * m_e * c^2 * β^2 * γ^2).to(Joule) / I) + ln(ξ.to(Joule) / I) + j - β^2)).to(keV) # - δ*(β*γ)

proc density(p: mbar, M: g•mol⁻¹, temp: Kelvin): g•cm⁻³ =
  ## returns the density of the gas for the given pressure.
  ## The pressure is assumed in `mbar` and the temperature (in `K`).
  ## The default temperature corresponds to BabyIAXO aim.
  ## Returns the density in `g / cm^3`
  let gasConstant = 8.314.J•K⁻¹•mol⁻¹ # joule K^-1 mol^-1
  let pressure = p.to(Pa) # pressure in Pa
  # factor 1000 for conversion of M in g / mol to kg / mol
  result = (pressure * M / (gasConstant * temp)).to(g•cm⁻³)

proc E_to_γ(E: GeV): UnitLess =
  result = E.to(Joule) / (m_μ * c^2) + 1

proc γ_to_E(γ: UnitLess): GeV =
  result = ((γ - 1) * m_μ * c^2).to(GeV)

type
  Element = object
    Z: UnitLess
    M: g•mol⁻¹
    A: UnitLess # numerically same as `M`
    ρ: g•cm⁻³
proc initElement(Z: UnitLess, M: g•mol⁻¹, ρ: g•cm⁻³): Element =
  Element(Z: Z, M: M, A: M.UnitLess, ρ: ρ)

# molar mass. Numerically same as relative atomic mass
let M_Ar = 39.95.g•mol⁻¹
let ρAr = density(1050.mbar, M_Ar, temp = 293.15.K)
let Argon = initElement(18.0.UnitLess, 39.95.g•mol⁻¹, ρAr)

proc intBethe(e: Element, d_total: cm, E0: eV, dx = 1.μm): eV =
  ## integrated energy loss of bethe formula after `d` cm of matter
  ## and returns the energy remaining
  var γ: UnitLess = E_to_γ(E0.to(GeV))
  var d: cm
  result = E0
  var totalLoss = 0.eV
  while d < d_total and result > 0.eV:
    let E_loss: MeV = betheBloch(-1, e.Z, e.M, γ, m_μ) * e.ρ * dx
    result = result - E_loss.to(eV)
    γ = E_to_γ(result.to(GeV))
    d = d + dx.to(cm)
    totalLoss = totalLoss + E_loss.to(eV)
  result = max(0.float, result.float).eV

proc plotDetectorAbsorption() =
  let E_float = logspace(-2, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  let E_loss = energies.mapIt(
    (it.to(eV) - intBethe(Argon, 3.cm, it.to(eV))).to(keV).float
  )
  let df = toDf(E_float, E_loss)
  ggplot(df, aes("E_float", "E_loss")) +
    geom_line() +
    xlab("μ Energy [GeV]") + ylab("ΔE [keV]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle("Energy loss of Muons in 3 cm Ar at CAST conditions") +
    ggsave("/home/basti/phd/Figs/muons/ar_energy_loss_cast.pdf")
plotDetectorAbsorption()

let Atmosphere = @[(0.78084, initElement(7.0.UnitLess, 14.006.g•mol⁻¹, 1.2506.g•dm⁻³.to(g•cm⁻³))), # N2
                   (0.20964, initElement(8.0.UnitLess, 15.999.g•mol⁻¹, 1.429.g•dm⁻³.to(g•cm⁻³))),  # O2
                   (0.00934, initElement(18.0.UnitLess, 39.95.g•mol⁻¹, 1.784.g•dm⁻³.to(g•cm⁻³)))]  # Ar

proc plotMuonBethe() =
  let E_float = logspace(-2, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  var dEdxs = newSeq[float]()
  for e in energies:
    var dEdx = 0.0.MeV•g⁻¹•cm²
    for elTup in Atmosphere:
      let (w, element) = elTup
      let γ = E_to_γ(e)
      dEdx += w * betheBloch(-1, element.Z, element.M, γ, m_μ)
    dEdxs.add dEdx.float
  let df = toDf(E_float, dEdxs)
  ggplot(df, aes("E_float", "dEdxs")) +
    geom_line() +
    xlab("μ Energy [GeV]") + ylab("dE/dx [MeV•g⁻¹•cm²]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle("Energy loss of Muons in atmosphere") +
    ggsave("/home/basti/phd/Figs/muons/energy_loss_muons_atmosphere.pdf")  
plotMuonBethe()
#if true: quit()
import math, unchained, ggplotnim, sequtils

const R_Earth = 6371.km
func distanceAtmosphere(θ: Radian, d: KiloMeter = 36.6149.km): UnitLess =
  ## NOTE: The default value for `d` is not to be understood as a proper height. It.s an
  ## approximation based on a fit to get `R_Earth / d = 174`!
  result = sqrt((R_Earth / d * cos(θ))^2 + 2 * R_Earth / d + 1) - R_Earth / d * cos(θ)

defUnit(cm⁻²•s⁻¹•sr⁻¹)  
defUnit(m⁻²•s⁻¹•sr⁻¹)
proc muonFlux(E: GeV, θ: Radian, E₀, E_c: GeV,
              I₀: m⁻²•s⁻¹•sr⁻¹,
              ε: GeV): m⁻²•s⁻¹•sr⁻¹ =
  const n = 3.0
  let N = (n - 1) * pow((E₀ + E_c).float, n - 1)
  result = I₀ * N * pow((E₀ + E).float, -n) *
    #pow((1 + E / ε).float, -1) *
    ( ( 1.0 / (1 + 1.1 * E * cos(θ) / 115.GeV).float) + (0.054 / (1 + 1.1 * E * cos(θ) / 850.GeV).float) ) * 
    pow(distanceAtmosphere(θ), -(n - 1))

from numericalnim/integrate import simpson
proc plotE_vs_flux(θ: Radian, E₀, E_c: GeV, I₀: m⁻²•s⁻¹•sr⁻¹, ε: GeV,
                   suffix = "") =
  let energies = linspace(E_c.float, 100.0, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(it, θ, E₀, E_c, I₀, ε).float) # .to(cm⁻²•s⁻¹•sr⁻¹)
  let df = toDf(energies, flux)

  echo "Integrated flux: ", simpson(flux, energies)
  
  ggplot(df, aes("energies", "flux")) +
    geom_line() +
    xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle(&"Flux dependency on the energy of muons at θ = {θ.to(°)}{suffix}") +
    ggsave(&"/home/basti/phd/Figs/muons/energy_vs_flux_cosmic_muons{suffix}.pdf")
plotE_vs_flux(0.Radian,
              2.5.GeV, #4.29.GeV,
              0.5.GeV, 70.7.m⁻²•s⁻¹•sr⁻¹, 854.GeV)


let E₀ = 25.0.GeV
let I₀ = 90.0.m⁻²•s⁻¹•sr⁻¹
let E_c = 1.GeV
let ε = 2000.GeV

proc plotFlux_at_CAST() =
  let energies = linspace(0.5, 100.0, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(it, 88.0.degToRad.Radian, E₀, E_c, I₀, ε).float)
  let df = toDf(energies, flux)
  ggplot(df, aes("energies", "flux")) +
    geom_line() +
    xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
    scale_x_log10() + scale_y_log10() +
    ggtitle("Flux dependency on the energy at θ = 88° at CAST altitude") +
    ggsave("/home/basti/phd/Figs/muons/flux_at_cast_88_deg.pdf")
plotFlux_at_CAST()

proc computeMeanEnergyLoss() =
  let energies = linspace(0.5, 100.0, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(
    it, 88.0.degToRad.Radian, E₀, E_c, I₀, ε).float
  )
  let E_loss = E.mapIt(
    (it.to(eV) - intBethe(Argon, 3.cm, it.to(eV))).to(keV).float
  )
  let fluxSum = flux.sum
  let df = toDf(energies, E_loss, flux)
      .mutate(f{"flux" ~ `flux` / fluxSum},
              f{"AdjFlux" ~ `E_loss` * `flux`})
  echo "Mean energy loss: ", df["AdjFlux", float].sum
computeMeanEnergyLoss()

proc computeHeight(S: Meter, θ: Radian): KiloMeter =
  ## For given remaining distance distance along the path of a muon
  ## `S` (see fig. 1 in 1606.06907) computes the remaining height above
  ## ground. Formula is the result of inverting eq. 7 to `d` using quadratic
  ## formula. Positive result, because negative is negative.
  result = (-1.0 * R_Earth + sqrt(R_Earth^2 + S^2 + 2 * S * R_Earth * cos(θ)).m).to(km)

import algorithm
defUnit(K•m⁻¹)
proc barometricFormula(h: KiloMeter): g•cm⁻³ =
  let hs = @[0.0.km, 11.0.km]
  let ρs = @[1.225.kg•m⁻³, 0.36391.kg•m⁻³]
  let Ts = @[288.15.K, 216.65.K]
  let Ls = @[-1.0 * 0.0065.K•m⁻¹, 0.0.K•m⁻¹]
  let M_air = 0.0289644.kg•mol⁻¹
  let R = 8.3144598.N•m•mol⁻¹•K⁻¹
  let g_0 = 9.80665.m•s⁻²
  let idx = hs.mapIt(it.float).lowerBound(h.float) - 1
  case idx
  of 0:
    # in Troposphere, using regular barometric formula for denities
    let expArg = g_0 * M_air / (R * Ls[idx])
    result = (ρs[idx] * pow(Ts[idx] / (Ts[idx] + Ls[idx] * (h - hs[idx])), expArg)).to(g•cm⁻³)
  of 1:
    # in Tropopause, use equation valid for L_b = 0
    result = (ρs[idx] * exp(-1.0 * g_0 * M_air * (h - hs[idx]) / (R * Ts[idx]))).to(g•cm⁻³)
  else: doAssert false, "Invalid height! Outside of range!"

import random
randomize(43)
proc intBetheAtmosphere(E: GeV, θ: Radian, dx = 10.cm): eV =
  ## integrated energy loss using Bethe formula for muons generated at
  ## `15.km` under an angle of `θ` to the observer for a muon of energy
  ## `E`.
  # Main contributions in Earth's atmosphere
  const τ = 2.19618.μs # muon half life
  let elements = Atmosphere
  var γ: UnitLess = E_to_γ(E.to(GeV))
  result = E.to(eV)
  var totalLoss = 0.eV
  let h_muon = 15.km # assume creation happens in `15.km`
  let S = h_muon.to(m) * distanceAtmosphere(θ.rad, d = h_muon)
  var S_prime = S
  while S_prime > 0.m and result > 0.eV:
    let h = computeHeight(S_prime, θ)
    let ρ_at_h = barometricFormula(h)
    var E_loss = 0.0.MeV
    for eTup in elements: # compute the weighted contribution of the element fraction
      let (w, e) = eTup
      E_loss += w * betheBloch(-1, e.Z, e.M, γ, m_μ) * ρ_at_h * dx

    ## Add step for radioactive decay of muon.
    ## - given `dx` compute likelihood of decay
    ## - eigen time of muon: dx / v = dt. dτ = dt / γ
    ## - muon decay is λ = 1 / 2.2e-6s
    let β = calcβ(γ)
    # compute effective time in lab frame
    let δt = dx / (β * c)
    # compute eigen time
    let δτ = δt / γ
    # probability of a decay in this time frame
    let p = pow(1 / math.E, δτ / τ)
    # decay with likelihood `p`
    #echo "γ = ", γ, " yields ", p, " in δτ ", δτ, " for energy ", E
    if rand(1.0) < (1.0 - p):
      echo "Particle decayed after: ", S_prime
      return 0.eV
          
    result = result - E_loss.to(eV)
    S_prime = S_prime - dx
    γ = E_to_γ(result.to(GeV))
    totalLoss = totalLoss + E_loss.to(eV)
  echo "total Loss ", totalLoss.to(GeV)
  result = max(0.float, result.float).eV

block MuonLimits:
  let τ_μ = 2.1969811.μs
  # naively this means given some distance `s` the muon can
  # traverse `s = c • τ_μ` (approximating its speed by `c`) before
  # it has decayed with a 1/e chance
  # due to special relativity this is extended by γ
  let s = c * τ_μ
  echo s
  # given production in 15 km, means
  let h = 15.km
  echo h / s
  # so a reduction of (1/e)^22. So 0.
  # now it's not 15 km but under an angle `θ = 88°`.
  let R_over_d = 174.UnitLess
  let n = 3.0
  let E₀ = 25.0.GeV
  let I₀ = 90.0.m⁻²•s⁻¹•sr⁻¹
  let E_c = 1.GeV
  let ε = 2000.GeV

  # distance atmospher gives S / d, where `d` corresponds to our `h` up there
  let S = h * distanceAtmosphere(88.0.degToRad.rad)
  # so about 203 km
  # so let's say 5 * mean distance is ok, means we ned
  let S_max = S / 5.0
  # so need a `γ` such that `s` is stretched to `S_max`
  let γ = S_max / s
  echo γ
  # ouch. Something has to be wrong. γ of 61?

  # corresponds to an energy loss of what?
  let Nitrogen = initElement(7.0.UnitLess, 14.006.g•mol⁻¹, 1.2506.g•dm⁻³.to(g•cm⁻³))
  echo "================================================================================"
  echo "Energy left: ", intBethe(Nitrogen, S.to(cm), 6.GeV.to(eV), dx = 1.m.to(μm)).to(GeV)
  proc print(E: GeV, θ: Radian) =
    let left = intBetheAtmosphere(E, θ = θ).to(GeV)
    echo "E = ", E, ", θ = ", θ, ", Bethe = ", E - left
  print(6.GeV, 0.Radian)
  #print(200.GeV, 0.Radian)  
  #print(200.GeV, 88.°.to(Radian))
  #print(200.GeV, 75.°.to(Radian))

  let E_loss75 = 100.GeV - intBetheAtmosphere(100.GeV, 75.°.to(Radian)).to(GeV)
  plotE_vs_flux(75.°.to(Radian),
                E_loss75, #23.78.GeV, #25.GeV, #E_loss75,
                1.0.GeV,
                90.m⁻²•s⁻¹•sr⁻¹, #65.2.m⁻²•s⁻¹•sr⁻¹,
                2000.GeV, # 854.GeV,
                "_at_75deg")

  
  echo "S@75° = ", h * distanceAtmosphere(75.0.degToRad.rad, d = 15.0.km)
  echo "================================================================================"  
echo E_to_γ(4.GeV)
echo E_to_γ(0.GeV)

proc plotE_vs_flux_and_angles(E_c: GeV, I₀: m⁻²•s⁻¹•sr⁻¹, ε: GeV,
                              suffix = "") =
  ## Generates a plot of the muon flux vs energy for a fixed set of different
  ## angles.
  ##
  ## The energy loss is computed using a fixed 
  let energies = logspace(log10(E_c.float), 2.float, 100)
  let angles = linspace(0.0, 80.0, 9)
  block CalcLossEachMuon:
    var df = newDataFrame()
    for angle in angles:
      let E = energies.mapIt(it.GeV)
      let θ = angle.°.to(Radian)
      var flux = newSeq[float]()
      var E_initials = newSeq[float]()
      var E_lefts = newSeq[float]()
      for e in E:
        let E_left = intBetheAtmosphere(e, θ).to(GeV)
        if E_left <= 0.0.GeV:
          echo "Skipping energy : ", e, " as muon was lost in atmosphere"
          continue
        elif E_left <= E_c:
          echo "Skipping energy : ", e, " as muon has less than E_c = ", E_c, " energy left"
          continue
        let E₀ = e - E_left
        flux.add muonFlux(e, θ, E₀, E_c, I₀, ε).float
        E_initials.add e.float        
        E_lefts.add E_left.float
      let dfLoc = toDf({E_initials, E_lefts, flux, "angle [°]" : angle})
      df.add dfLoc
    ggplot(df, aes("E_initials", "flux", color = factor("angle [°]"))) +
      geom_line() +
      xlab("Initial energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
      scale_x_log10() + scale_y_log10() +
      ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
      ggsave(&"/home/basti/phd/Figs/muons/initial_energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")
  
    ggplot(df, aes("E_lefts", "flux", color = factor("angle [°]"))) +
      geom_line() +
      xlab("Energy at surface [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
      scale_x_log10() + scale_y_log10() +
      ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
      ggsave(&"/home/basti/phd/Figs/muons/final_energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")
  block StaticLoss:
    var df = newDataFrame()
    for angle in angles:
      let E = energies.mapIt(it.GeV)
      let θ = angle.°.to(Radian)
      let E₀ = 100.GeV - intBetheAtmosphere(100.GeV, 0.0.Radian).to(GeV)    
      let flux = E.mapIt(muonFlux(it, θ, E₀, E_c, I₀, ε).float)
      let dfLoc = toDf({energies, flux, "angle [°]" : angle})
      df.add dfLoc
    ggplot(df, aes("energies", "flux", color = factor("angle [°]"))) +
      geom_line() +
      xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
      scale_x_log10() + scale_y_log10() +
      ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
      ggsave(&"/home/basti/phd/Figs/muons/energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")


#proc plotE_vs_flux_and_angles(E_c: GeV, I₀: m⁻²•s⁻¹•sr⁻¹, ε: GeV,
#                              suffix = "") =
#  ## Generates a plot of the integrated muon flux vs angles for a fixed set of different
#  ## energies.
#  let angles = linspace(0.0, 90.0, 100)
#  var df = newDataFrame()
#  let energies = linspace(E_c.float, 100.0, 1000)
#  let E = energies.mapIt(it.GeV)
#  for angle in angles:
#    let θ = angle.°.to(Radian)
#    let E₀ = 100.GeV - intBetheAtmosphere(100.GeV, θ).to(GeV)
#    let flux = E.mapIt(muonFlux(it, θ, E₀, E_c, I₀, ε).float) 
#    let dfLoc = toDf({energies, flux, "angle [°]" : angle})
#    df.add dfLoc
#  ggplot(df, aes("energies", "flux", color = factor("angle [°]"))) +
#    geom_line() +
#    xlab("Energy [GeV]") + ylab("Flux [m⁻²•s⁻¹•sr⁻¹]") +
#    scale_x_log10() + scale_y_log10() +
#    ggtitle(&"Differential muon flux dependency at different angles{suffix}") +
#    ggsave(&"/home/basti/phd/Figs/muons/energy_vs_flux_and_angle_cosmic_muons{suffix}.pdf")

# different angles!      
#block MuonBehavior:
#  plotE_vs_flux_and_angles(1.0.GeV, 90.m⁻²•s⁻¹•sr⁻¹, 854.GeV)

proc unbinnedCdf(x: seq[float]): (seq[float], seq[float]) =
  ## Computes the CDF of unbinned data
  var cdf = newSeq[float](x.len)
  for i in 0 ..< x.len:
    cdf[i] = i.float / x.len.float
  result = (x.sorted, cdf)

import random, algorithm
proc sampleFlux(samples = 1_000_000): DataFrame =
  randomize(1337)
  let energies = linspace(0.1, 100.0, 100_000)
  #let energies = logspace(0, 2, 1000)
  let E = energies.mapIt(it.GeV)
  let flux = E.mapIt(muonFlux(it, 88.0.degToRad.Radian, E₀, E_c, I₀, ε).float)
  # given flux compute CDF
  let fluxCS = flux.cumSum()
  let fluxCS_sorted = flux.sorted.cumSum()
  let fluxCDF = fluxCS.mapIt(it / fluxCS[^1])
  let fluxCDF_sorted = fluxCS_sorted.mapIt(it / fluxCS_sorted[^1])

  let (data, cdf) = unbinnedCdf(flux)

  let dfX = toDf(energies, fluxCS, fluxCS_sorted, fluxCDF, fluxCDF_sorted)
  ggplot(dfX, aes("energies", "fluxCS")) +
    geom_line() +
    ggsave("/t/cumsum_test.pdf")
  ggplot(dfX, aes("energies", "fluxCDF")) +
    geom_line() +
    ggsave("/t/cdf_test.pdf")    
  ggplot(dfX, aes("energies", "fluxCS_sorted")) +
    geom_line() +
    ggsave("/t/cumsum_sorted_test.pdf")    
  ggplot(dfX, aes("energies", "fluxCDF_sorted")) +
    geom_line() +
    ggsave("/t/cdf_sorted_test.pdf")

  ggplot(toDf(data, cdf), aes("data", "cdf")) +
    geom_line() +
    ggsave("/t/unbinned_cdf.pdf")
  
  #if true: quit()
  var lossesBB = newSeq[float]()
  var lossesMP = newSeq[float]()
  var energySamples = newSeq[float]()

  let dedxmin = 1.519.MeV•cm²•g⁻¹
  echo "Loss = ", (dedxmin * Argon.ρ * 3.cm).to(keV)
  
  for i in 0 ..< samples:
    # given the fluxCDF sample different energies, which correspond to the
    # distribution expected at CAST
    let idx = fluxCdf.lowerBound(rand(1.0))
    let E_element = E[idx]
    # given this energy `E` compute the loss
    let lossBB = (E_element.to(eV) - intBethe(Argon, 3.cm, E_element.to(eV), dx = 50.μm)).to(keV).float
    lossesBB.add lossBB
    let lossMP = mostProbableLoss(-1, Argon.Z, Argon.M, E_Element.E_to_γ(), Argon.ρ * 3.cm)
    lossesMP.add lossMP.float
    #echo "Index ", i, " yields energy ", E_element, " and loss ", loss
    energySamples.add E_element.float
  let df = toDf(energySamples, lossesBB, lossesMP)
    .gather(["lossesBB", "lossesMP"], "Type", "Value")
  ggplot(df, aes("Value", fill = "Type")) +
    geom_histogram(bins = 300, hdKind = hdOutline, alpha = 0.5, position = "identity") +
    margin(top = 2) +
    xlim(5, 15) +
    ggtitle(&"Energy loss of muon flux at CAST based on MC sampling with {samples} samples") +
    ggsave("/home/basti/phd/Figs/muons/sampled_energy_loss.pdf")

  ggplot(df, aes("energySamples")) +
    geom_histogram(bins = 300) +
    margin(top = 2) +
    ggtitle(&"Sampled energies for energy loss of muon flux at CAST") +
    ggsave("/home/basti/phd/Figs/muons/sampled_energy_for_energy_loss.pdf")
  let (samples, bins) = histogram(energySamples, bins = 300)
  let dfH = toDf({"bins" : bins[0 ..< ^1], samples})
    .filter(f{`bins` > 0.0 and `samples`.float > 0.0})
  ggplot(dfH, aes("bins", "samples")) +
    geom_line() +
    scale_x_log10() + 
    margin(top = 2) +
    ggtitle(&"Sampled energies for energy loss of muon flux at CAST") +
    ggsave("/home/basti/phd/Figs/muons/sampled_energy_for_energy_loss_manual.pdf")

  ggplot(toDf(energies, flux), aes("energies", "flux")) +
    geom_line() +
    scale_x_log10() +
    ggsave("/tmp/starting_data_e_flux.pdf")

  ggplot(toDf(energies, flux), aes("energies", "flux")) +
    geom_line() +
    ggsave("/tmp/linear_starting_data_e_flux.pdf")
    

discard sampleFlux(samples = 1_000_000)
#+end_src


** Gaseous detector fundamentals

*HOW TO START CHAPTER / SECTION?*

Gaseous detectors consist of a volume filled with some kind of
gas. Usually a noble gas with a small amount of molecular gas. Some
kind of entrance window allows the particles to be detected to
enter. An electric field is applied over the gas volume, strong enough
to cause electron-ion pairs created by ionization of the incoming
particles to drift to opposite ends of the volume. At least on the
side of the anode (where the electrons arrive), a readout of some form
is installed to measure the time of arrival, amount of collected
charge and / or the position of the electrons. Depending on the
details, this in principle allows for a 3D reconstruction of the
initial event in the gas volume. The details of choice of detector
gas, applied electric fields, gas volume dimensions and types of
readout have a very large impact on the applications a detector is
useful for. In the following we will focus on the physics concepts
required for gaseous detectors with few \si{cm} long drift volumes and
high spatial resolution readouts.




Note: this section covers the basic fundamentals that will be later
referenced in the thesis. For a much more in-depth understanding of
these concepts, see references \cite{sauli2014gaseous} and
\cite{kolanoski2020particle} and to some extent the PDG
\cite{Zyla:2020zbs} (in particular chapters on particle detectors and
passage of particles through matter; chapter number varies by year).


Write a few general things about gaseous detectors here. I.e. contain
usually mainly a noble gas, with some quencher for rotational and
vibrational modes. These 'cool' the electrons down so that they are in
the Townsend minimum and effectively increases the drift velocity.

Electric fields should be strong enough to let electrons and ions
drift in opposite directions and have a fast enough drift velocity,
but low enough to not cause further ionization.

*** Gas mixtures and Dalton's law [/]
:PROPERTIES:
:CUSTOM_ID: sec:theory:daltons_law
:END:


Of common interest when dealing with gas mixtures is the notion of
partial pressures. In ideal gas theory, a mixture of gases at a
pressure $P$ can be considered to be the sum of the 'partial
pressures' of each gas species

\[
P = \sum_i p_i.
\]

The contribution of each gas only depends on the species' mole
fraction, which means given the mole fractions. Typically when
considering gas mixtures the fractions of each gas species is given as
a percentage. The percentage already refers to the mole fraction of
each species. As such, the partial pressure of a single species can be
expressed as:

\[
p_i = n_i P
\]

where $n_i$ is the mole fraction of species $i$.

This is an extremely valuable property when computing different
interactions of particles with gas mixtures. For example when
computing the absorption of X-rays after in propagating through a
certain distance of gas, as one can compute absorption for each
partial pressure independently and combine the contributions after
(whether they be added, multiplied or something else of course depends
on the considered process).

- [ ] *FIND GOOD REFERENCE FOR DALTON'S LAW*

*** Mean free path

*NOTE*: This is already explained for X-rays in the previous
section. Do we need this concept in some more detail? Otherwise we can
also remove it later. 

See photons above.

Of major importance for the detection of particles in a gaseous
detector is the mean free path. This is the mean length a particle
traverses in a medium before interactions. For charged particles it
yields the mean distance between individual interaction points,
whereas for a photon it gives the mean length the photon traverses
through the detector before interaction.

Especially for photons this value is of crucial importance, as it
tells us at what distance photons will likely convert depending on
their energy. This is described by the absorption length as mentioned
in section [[#sec:theory:xray_matter_gas]]. This is important as it
directly affects the possible drift distance and thus diffusion
available to the generated electrons.  *TOO MUCH DETAIL, AS WE HAVE
NOT INTRODUCED DETECTORS YET!!*

*** Ionization energy and average energy per electron-ion pair

*FIND GOOD REFERENCES* beyond these two. Better would be a primary
like reference. \cite{bronic1992relation, doi:10.1080/00223131.2014.974710} 

Why expect ~26 eV for argon

Talk about ionization energy vs. the actual mean energy loss for a
single ionization. Argon ionization energy is only like 15 eV or so,
but effective one is 26.

Leads to our 226 or so primary electrons for our 55Fe spectra.

In order to understand the signals detected by a gaseous detector the
average number of electrons created by an incident particle should be
known. Denoted by the $W$-value, it is defined by

\[
W = \frac{I}{\langle N \rangle} 
\]

where $I$ is the mean ionization energy of the gas and $\langle N
\rangle$ the average number of electron-ion pairs generated per
interaction. This number is usually smaller one, \numrange{0.6}{0.7}
for noble gases and even below \num{0.5} for molecular gases. Not all
energy of the incoming particle is always deposited in the form of
generation of, for example, a photoelectron. Other forms of energy
loss are possible. In molecular gases vibrational and rotational modes
offer even more possibilities, resulting in the smaller values.

The mean excitation energy of an element is the weighted combination
of the most likely energy levels the element is ionized from. The
exact values are dependent on the specific element and tabulated
values like from NIST \cite{hubbell1996nist}. Above some $Z$ a
rough approximation of $I = \SI{10}{eV} Z$ can be substituted,
developed by Bloch \cite{bloch1933bremsvermogen}.

The precise number for $W$ strongly depends on the used gas mixture
and typically requires experimental measurements to determine or Monte
Carlo based simulations. Tools for Monte Carlo simulations include
GEANT4 \cite{GEANT4:2002zbu} [fn:geant4] and MCNelectron
\cite{doi:10.1080/00223131.2014.974710} [fn:mcn_electron]. These are
based on atomic excitation cross sections, which are well tabulated in
projects like ENDF \cite{brown2018endf} (citation for latest data
release) [fn:endf_website] and LXCat \cite{pancheshnyi2012lxcat,
pitchford2017lxcat, carbone2021data} [fn:lxcat_website].

# Note: there is also MCNP6 https://mcnp.lanl.gov/ which I will
# conveniently *not* mention, as it is under ridiculous US export
# regulations and therefore the source code is not visible for non US
# citizens. Screw that.

[fn:geant4] [[https://geant4.cern.web.ch]]

[fn:mcn_electron] http://web.vu.lt/ff/a.poskus/mcnelectron/

[fn:endf_website] https://www.nndc.bnl.gov/endf-b8.0/index.html

[fn:lxcat_website] [[https://lxcat.net]]

[fn:w_value_fano_factor] Interestingly, there is an empirical somewhat
linear relationship between the W-value as shown here and the Fano
factor \cite{bronic1992relation}.
*NOTE*: Given how Fano discovered / described Fano noise, it's maybe
not quite surprising that this is related! 


*** Diffusion

*SEE Hilke2020 FOR OVERVIEW OF DIFFUSION MATH*

Diffusion is the process of the random walk of electrons either in
longitudinal or transverse (orthogonal to the electric field)
direction they exhibit, when drifting towards the readout. Depending
on the specific detector technology, some transverse diffusion may be
a desired property. For long drift distances, magnetic fields can be
used to significantly reduce the transverse diffusion.

For a point like source of multiple electrons, after diffusion of some
distance a 2 dimensional gaussian distribution will be expected.

Transverse diffusion depends, as one expects from a 2D random walk,
via the square root of the drift distance.

In general for precise numbers, numerical simulations using a tool
like Magboltz must be performed or measurements taken.

*EXPLAIN WHERE COMES FROM, COMES DOWN TO $D_t$ AND PARAMETER FROM MAGBOLTZ* 
\[
σ_t = D_t · \sqrt{x}
\]

*this is important as it relates to the 1.5 σ_transverse cut we do for
data cleaning!*

Describe diffusion based on gas. Needed to get expected photon size
based on conversion at specific height.

What effects affect diffusion?

Random walk + a force acting on particles.

*COMPUTE USING PYBOLTZ: https://github.com/UTA-REST/PyBoltz*

*** Drift velocity

*MENTION MOLECULAR GASES HAVE HIGHER DRIFT VELOCITY*

Talk about drift velocity of electrons for a given electric
field. Required to know time scales associated with e.g. muons + FADC,
time it takes for X-rays to drift (for random coincidences in long
frames etc.)

*USE FORMULA PDG*

The detector used in this thesis does not make use of magnetic
fields. Thus, all terms but the first are zero. Further, the electric
field is constant, leading to the following simplification:


Based on the so called 'friction force model' an analytical expression
for the drift velocity in an electromagnetic field can be written to:
\[
\vec{v} = \frac{e}{m_e} \frac{τ}{1 + ω²τ²}\left( \vec{E} + \frac{ωτ}{B}
(\vec{E} × \vec{B}) + \frac{ω²τ²}{B²}(\vec{E} · \vec{B}) \vec{B} \right)
\]
with the electron charge $e$ and mass $m_e$, in an electric field
$\vec{E}$ and magnetic field $\vec{B}$, given the Lamor frequency 
$ω = eB / m_e$ and the mean collision time $τ$. \cite{Zyla:2020zbs}

For the typical case in Micromegas detectors without a magnetic field
$B = 0, ω = 0$ and a constant, homogeneous electric field $E$, this
reduces to the Townsend expression:

\[
v = \frac{e E τ}{m_e}
\]

These can be computed using software packages like MAGBOLTZ (or its
Python port PyBoltz) that solve the underlying transport equation, the
Boltzmann equation:

\begin{align}
  \frac{∂f}{∂t} + \vec{v} \frac{∂}{∂\vec{r}}f + \frac{∂}{∂\vec{v}}\vec{g} &= Q(t) \\
  \vec{g} &= \left(\frac{e\vec{E}}{m} + \vec{ω} × \vec{v}\right) f
\end{align}
*FIX THIS*

*BOLTZMANN EQUATION: https://en.wikipedia.org/wiki/Boltzmann_equation*

*COMPUTE USING PYBOLTZ: https://github.com/UTA-REST/PyBoltz*

*** Gas amplification, avalanche effect [0/1]
:PROPERTIES:
:CUSTOM_ID: sec:theory:gas_gain_polya
:END:


*FIX TYPING OF POLYA DISTRIBUTION*

In order to turn the individual electrons into a measurable signal,
gaseous detectors use some kind of gas amplification stage. Details
vary, but it is usually a region in the gas volume close to the
readout with a very strong electric field (multiple $si{kV.cm^-1}$)
such that each electron causes many secondary ionizations, leading to
an avalanche effect. In case of the detectors described in this
thesis, amplification factors between \numrange{2000}{4500} are
desired.

The statistical distribution describing the number of electrons after
gas amplification is the Polya distribution

\[
p(x) = \frac{N}{G} \frac{(1 + θ)^{1 + θ}}{Γ(1 + θ)}
\left(\frac{x}{G}\right)^θ \exp{- \frac{(1 + θ) x}{G}}
\]

where $N$ is a normalization constant, $θ$ is another parameter
performing scaling of the distribution and $G$ is the effective gas
gain. $Γ$ refers to the gamma function. It is to note that the term
"polya distribution" in this context is different from other
mathematical definitions, in which polya distribution usually means a
negative binomial distribution. The above definition goes back to
Alkhazov \cite{alkhazov1970statistics} and in slight variations is
commonly used. Due to the complexity of this definition, care needs to
be taken when performing numerical fits to data with this function
(using bounded parameters and preferring more general non-linear
optimization routines instead of a normal Levenberg-Marquardt
approach).

The largest impacts on the expected gas amplification have the
electric field, the choice of gas and the temperature of the
gas. While the former two parameters are comparatively easy to
control, the temperature in the amplification region may vary and is
hard to measure. As such depending on the detector details and
application, gas gain variations are expected and corrections based on
a running gas gain value may be necessary.

If it fits here, Polya distribution to describe avalanche effect.

What gas properties affect the gas gain? Temperature, density etc.

Gas gain.

- [ ] *MENTION UV PHOTONS AND HENCE MOLECULAR GASES CALLED QUENCHER
  GAS*
- [ ] *ADD PLOT OF FUNCTION?*  

*** Energy resolution

Because of the statistical processes associated with the full
detection method used in gaseous detectors, even a perfect delta like
signal in energy, will lead to a natural spread of the measured
signal. The convolution of different ionization yields, potential
losses and gas gain variation all contribute to such a spread.



As such a typical measure of interest for gaseous detectors is the
energy resolution, which is commonly defined by

\[
ΔE = \frac{\text{FWHM}(E)}{E}
\]

which is to say the full-width-half maximum (FWHM) of the distribution
of a line at given energy $E$. Typical values for the energy
resolution are smaller than \SI{15}{\percent}.

If the absolute magnitude of the FWHM at a given energy is constant,
which at least is partially reasonable, as the width is not fully due
to energy dependent effects, the energy resolution is proportional to
$1/E$. 

*THINK ABOUT REPHRASING THIS / GIVING A VALUE FOR IDEAL RESOLUTION?*
(See Alkhazov paper maybe?)

The Fano factor, defined by the variance over the mean of a
distribution $F = σ² / μ$ (typically within some time window), helps
to improve the ideal energy resolution. It arises in the associated
statistical processes, because there are a finite number of possible
interactions, which limits the statistics. *CHECK IF SENTENCE
CORRECT!* In practice the energy
resolution of gaseous detectors is usually limited by other effects. 


What is energy resolution, definition.

E / σ_E or something like this.

Why important for our detector.

*WRITE SOMETHING FANO?* See Sauli about it. Section 7.5 on energy
resolution and section 3.6 about photo ionization of X-rays.

Fano factors are related to this! Theory and observation
disagree. Fano factor fixes this by doing a scaling. Related to the
fact that theory assumes a perfectly statistical process, but reality
has fixed number of possible interactions, hence not really perfect statistics.

*** Escape photons / peaks | 55Fe as a typical calibration source
:PROPERTIES:
:CUSTOM_ID: sec:theory:escape_peaks_55fe
:END:

Finally, gaseous detectors need to be calibrated, monitored and
tested. This is commonly done with a $^{55}\text{Fe}$
source. $^{55}\text{Fe}$ is a radioactive isotope of iron, which
decays under inverse beta decay to $^{55}\text{Mn}$. Due to the
required restructuring of the electronic shells, the manganese is in
an excited state. While the emission of an Auger electron with
$\SI{5.19}{keV}$ dominates with a probability of \SI{60}{\percent}, as
an X-ray source the $Kα₁$ and $Kα₂$ lines with combined energies of
about $\SI{5.9}{keV}$ are of note.

When using such a $^{55}\text{Fe}$ source as a calibration source for
an argon filled gaseous detector, the \SI{5.9}{keV} photons will
produce a photo-electron in argon. If this electron fully releases its
energy via further ionizations, the 'photopeak' will be observed at
around $\SI{5.9}{keV}$. If however another photon is produced with an
energy below the $K 1s$ energy of argon ($\SI{3.2}{keV}$) - for example
a photon produced via $Kα₁$ or $Kα₂$ fluorescence of argon, both at
about $\SI{2.95}{keV}$ - such a photon has a very long absorption
length in the gas volume
(cf. fig. [[fig:theory:transmission_examples]]). This can cause such a
photon to easily escape the active detection region, especially if the
sensitive region of the detector is comparatively small. The result is
a measured signal of $E_i - E_k = \SI{5.9}{keV} - \SI{2.95}{keV} \approx
\SI{2.9}{keV}$, called the 'escape peak'. \cite{sauli2014gaseous, kolanoski2020particle, hubbell1996nist}

*ADD CITATIONS*. For Sauli / Wermes & NIST for numbers.

Explain escape photons, escape peaks, how that gives us an escape peak
in the 55Fe spectra as well as a line at 3 keV in our background data.

Explain Fe ↦ Mn excited ↦ Mn + γ and what spectrum looks like

*INSERT EXAMPLE FIGURE OF SPECTRUM*


** Micromegas working principle

\textbf{Micro} \textbf{Me}sh \textbf{Ga}seous \textbf{S}tructures
(Micromegas) are a kind of \textbf{M}icro\textbf{p}attern
\textbf{G}aseous \textbf{D}etectors (MPGDs) first introduced in 1996
\cite{GIOMATARIS199629, GIOMATARIS1998239}. The modern Micromegas is
the Microbulk Micromegas \cite{Andriamonje_2010}.

Interestingly, the name Micromegas is based on the novella Micromégas
by Voltaire published in 1752 \cite{voltaire1752micromegas}, an early
example of a science fiction story. \cite{GIOMATARIS199629}

These detectors are - as the name implies - gaseous detectors
containing a 'micro mesh'. In the most basic form they are a made of a
closed detector volume that is filled with a suitable gas (often Argon
based gas mixtures are used; Xenon based detectors are in development
for certain applications) allowing ionization. The volume is split
into two different sections, a large drift volume typically
$\mathcal{O}(\text{few }\si{cm})$ and an amplification region, sized
$\mathcal{O}(\SIrange{50}{100}{μm})$. 

At the top of the volume is a cathode to apply an electric
field. Below the mesh is the readout area at the bottom of the
volume. In standard Micromegas detectors strips or pads are used as a
readout.

The electric field in the drift region is strong enough to avoid
recombination of the created electron-ion pairs and to provide
reasonably fast drift velocities $\mathcal{O}(\si{cm.μs⁻¹})$. 

The amplification gap on the other hand is precisely used to multiply
the primary electrons using an avalanche effect. Thus, the electric
field reaches values of $\mathcal{O}(\SI{50}{kV.cm⁻¹})$.

These drift and amplification volumes are achieved by an electric
field between a cathode and the mesh as well as the mesh and the
readout area. 

For a more detailed overview of Micromegas detectors and their
history, see *CITE WHAT?* 
# \cite{} 


#+begin_center
#+CAPTION: Working principle of a general Micromegas detector. An ionizing photon enters through the
#+CAPTION: detector window into the gas-filled detector body. After a certain distance it produces
#+CAPTION: a photo electron, which ionizes further gas molecules for a specific number of primary
#+CAPTION: electrons (depending on the incoming photon's energy) and gas mixture. The primary electrons
#+CAPTION: drift towards the micromesh due to the drift voltage, thereby experiencing diffusion. 
#+CAPTION: In the much higher voltage in the amplification gap an avalanche of electrons is produced, 
#+CAPTION: enough to trigger the readout electronics (strips or pads).
#+CAPTION: Note that the numbers shown in the figure are exemplary and vary between individual
#+CAPTION: detectors.
#+NAME: micromegas_schematic
[[~/org/Figs/thesis/detectors/micromegas_schematic.pdf]]
#+end_center


** Timepix ASIC

The Timepix ASIC (Application Specific Integrated Circuit) is a $256 ×
256$ pixel ASIC (\SI{55}{\micro\meter} pitch), based on the Medipix
ASIC developed for medical imaging applications by the Medipix
Collaboration \cite{medipix}. The pixels are distributed over an
active area of $\num{1.4}\times\SI{1.4}{\cm^2}$. Each pixel contains a charge
sensitive amplifier, a single threshold discriminator and a
$\SI{14}{bit}$ pseudo random counting logic. It requires use of an
external clock, in the range of \SIrange{10}{150}{MHz}, with
\SI{40}{MHz} being typical clock frequency for the use cases described
in this thesis.

A picture of a Timepix ASIC is shown in
fig. [[fig:detector:timepix_asic]].

#+CAPTION: Picture of a Timepix ASIC
#+NAME: fig:detector:timepix_asic
#+ATTR_LATEX: :width 0.4\textwidth
[[~/phd/Figs/timepix_gold.png]]

*INSERT TIMEPIX FIGURE?*

- [ ] *CITE LUPBERGER AS REFERENCE FOR THOROUGH TIMEPIX OVERVIEW*

The Timepix uses a shutter based readout, either with a fixed shutter
time or using an external trigger to close a frame. Each pixel further
can work in four different modes:

- hit counting mode / single hit mode: simply counts the number of
  times the threshold of a pixel was crossed (or whether a pixel was
  activated once in single hit mode).
- \textbf{T}ime \textbf{o}ver \textbf{T}hreshold (ToT): In the ToT
  mode the counter of a pixel will count the number of clock cycles
  that the charge on the pixel exceeds the set threshold, which is set
  by an $\SI{8}{bit}$ \textbf{D}igital to \textbf{A}nalog
  \textbf{C}onverter (DAC) while the shutter is open. ToT is
  equivalent to the collected charge of each pixel.
- \textbf{T}ime \textbf{o}f \textbf{A}rrival (ToA): The ToA mode
  records the number of clock cycles from

  *DOES TOA IN TPX1 START FROM SHUTTER OPEN OR START FROM PIXEL HIT?*

  - [ ] *LUPBERGER THESIS EXPLAINS IT*
  - [ ] *PIXELS COUNT TO MAX 11810 AS WELL OF COURSE. THAT'S THE TIME
    LIMIT. AT 40 MHZ THIS IS ABOUT 295 μs TIME*
    
  
  starts counting the clock cycles from the first time the charge
  exceeds the set threshold until the shutter closes. Thus, it allows
  to calculate the time at which the pixel first crossed the
  threshold.

After the shutter is closed in the Timepix, the readout is performed
during which the detector is effectively dead. For a single Timepix
the readout takes about *HOW MANY?* ms. 


Check Lucian's master thesis for information about Timepix & gaseous
detector physics. :)

*TALK HERE ABOUT DIFFERENT TOS CALIBRATIONS?*

*ADD ALL USED DETECTOR CALIBRATIONS IN FULL TO APPENDIX. INCLUDE THE
PLOTS FOR TOT. TABLE OF TOT FIT PARAMETERS ETC*

*** Timepix3

The successor of the Timepix, the Timepix3 already exists. It is
generally similar to the Timepix, but provides 3 important advantages
for the applications in this thesis:
- clock rates of up to \SI{300}{MHz} for higher possible data rates
  (less interesting for data taking in an axion helioscope)
- a stream based data readout. This means no fixed shutter times and
  no dead time during readout. Instead data is sent out when it is
  recorded in parallel.
- each pixel can record ToT *and* ToA at information at the same
  time. This allows to record the charge recorded by a pixel as well
  as the time it was activated, yielding 3D event reconstruction with
  precise charge information.

An open source readout was developed by the University of Bonn and is
available under \cite{tpx3-daq} [fn:detector:tpx3_daq]. A gaseous
detector based on this is currently in the prototyping phase, see the
upcoming \cite{shiffer_phd_thesis}.


[fn:detector_tpx3_daq] [[https://github.com/SiLab-Bonn/tpx3-daq]] 




Introduce as something for which readout etc. is currently in
development. Mention improvements so that we can refer back to them in
our conclusion that having time information would be great.

Further out, the Timepix4 is also already finalized. No work on a
readout for these applications has been started yet. 

** GridPix

First experiments of combining a Micromegas with a Timepix readout
were done in 2005 \cite{campbell2005detection} by using classical
approaches to place a micromesh on top of the Timepix, at the time
still called /TimePixGrid/. While this worked in principle, it showed
a Moiré pattern, due to slight misalignment between the holes of the
micromesh and the pixels of the Timepix. Shortly after, an approach
based on photolithographic post-processing was developed to perfectly
align the Timepix pixels each with a hole of a micromesh
\cite{CHEFDEVILLE2006490}, called the /InGrid/ (integrated grid). The
commonly used name for a gaseous detector using an InGrid nowadays is
GridPix. For an overview of the process as it is performed nowadays to
produce InGrids, see \cite{lucianMsc}. *NOTE: ASK LUCIAN IF HE STILL
RECOMMNENDS HIS OWN THESIS FOR THIS*.

The InGrid consists of a \SI{1}{μm} thick aluminum grid, resting on
small pillars \SI{50}{μm} above the Timepix. A silicon-nitride
\ce{Si_x N_y} layer protects the Timepix from direct exposure to the
amplification processes. The main advantage over previous Micromegas
technologies of the GridPix is its ability to detect single electrons.
As long as the diffusion distance is long enough to avoid multiple
electrons entering a single hole of the InGrid, each primary electron
produced during the initial ionization event is recorded.

Fig. [[fig:detector:ingrid_explanation]] shows an image of such an InGrid.

#+CAPTION: Image of an InGrid, which was partially cut for inspection under an
#+CAPTION: electron microscope. The pillars seen support the micromesh and
#+CAPTION: have a height of \SI{50}{μm}. Each hole is perfectly aligned with
#+CAPTION: a pixel of the Timepix below. Typical voltages applied between
#+CAPTION: the grid and the Timepix are shown
#+NAME: fig:detector:ingrid_explanation
[[~/org/Figs/ingrid_principle.pdf]]

Production nowadays in Berlin IZM. Show sketch of production process?
Imo should be enough to refer to Lucian's thesis for production
process. Is there a paper about IZM process? Ask Yevgen & Lucian.

\SI{50}{\micro\meter} pillars (amplification gap). Typical gas gains
of 2000-5000. 

Polya plot.

Important: single electron detection efficiency. 

*** Caveats

E.g. things like charge up effects etc. discussed in other theses.

** 2014 / 2015 GridPix detector [/]
:PROPERTIES:
:CUSTOM_ID: sec:detector:detector_2014_15
:END:

In the course of \cite{krieger2018search} a first GridPix based
detector for usage at an axion helioscope, CAST, was developed. While
the main result was on the coupling constant of the chameleon
particle, an axion-electron coupling result was computed in
\cite{SchmidtMaster}.

The detector consists of a single GridPix in a \SI{78}{mm} diameter
gas volume and a drift distance of \SI{3}{cm}. The detector has a
\SI{2}{μm} Mylar entrance window X-rays. This detector serves as the
foundation for the detector used in the course of this thesis. See
fig. [[fig:detector:exploded_schematic]] for an exploded schematic of the
detector. Further, fig. [[fig:detector:background_rate_2014]] shows the
achieved background rate of this detector in the center $\num{5}
\times \SI{5}{mm^2}$ region of the detector. The background rate shows
the copper $Kα$ line near \SI{8}{keV}, possibly overlaid with a muon
contribution as well as the expected argon $Kα$ lines at
\SI{3}{keV}. Below \SI{2}{keV} the background starts to rise more and
more the lower the energy becomes, likely due to background and signal
like events being less geometrically different at low energies (fewer
pixels). The average background rate in the range from
\SIrange{0}{8}{keV} is \SI{2.8793e-05}{keV^{-1}.cm^{-2}.s^{-1}}.

- [ ] *WHICH COPPER LINE? AND WHICH ARGON?*

#+CAPTION: Exploded view of the GridPix detector used during the 2014/15 data taking campaign
#+CAPTION: at CAST. Consists of a \SI{3}{cm} drift volume with a \SI{78}{mm} inner diameter
#+CAPTION: and a single GridPix at the center.
#+NAME: fig:detector:exploded_schematic
[[~/org/Figs/ingrid_detector_exploded_krieger_thesis.png]]

#+CAPTION: Background rate in the center $\num{5} \times \SI{5}{mm^2}$ for the GridPix used in
#+CAPTION: 2014/15 at CAST. It corresponds to a background rate of \SI{2.8793e-05}{keV^{-1}.cm^{-2}.s^{-1}}
#+CAPTION: in the range from \SIrange{0}{8}{keV}. *INSERT INTERACTIVE VEGA-LITE VERSION*
#+NAME: fig:detector:background_rate_2014
[[~/phd/Figs/background_rate_2014_gold.pdf]]

As an example and a reference shown here. The foundation of what is
done in this thesis.

Not sure if this section is the right place. But: Could add background
rate achieved by that detector here?
*YES*
- background rate
- background over chip (latter comes later??)

- [ ] *ADD AVERAGE BACKGROUND RATE IN TEXT*.  

*** Create background rate plot for 2014 data                    :noexport:

We simply generate the code with our background rate plotting script,
as the 2014/15 dataset background rate is stored in our resources of
the TPA repository:
#+begin_src sh
plotBackgroundRate --show2014 --xMax 10.0 \
  --title "Background rate in center 5·5 mm² for GridPix 2014/15 CAST data"
#+end_src
(Note: the half space between numbers and unit for the gold area)

which also outputs the integrated background rates:

#+begin_src
-xMax 10.0 --title "Background rate in center 5·5 mm² for GridPix 2014/15 CAST data"
Dataset: 2014/15
         Integrated background rate in range: 0.0 .. 12.0: 3.0372e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.0 .. 12.0: 2.5310e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.5 .. 2.5: 8.4056e-05 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.5 .. 2.5: 4.2028e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.5 .. 5.0: 1.4269e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.5 .. 5.0: 3.1708e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.0 .. 2.5: 1.2016e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.0 .. 2.5: 4.8065e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 4.0 .. 8.0: 5.7818e-05 cm⁻² s⁻¹
         Integrated background rate/keV in range: 4.0 .. 8.0: 1.4454e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 0.0 .. 8.0: 2.3034e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 0.0 .. 8.0: 2.8793e-05 keV⁻¹·cm⁻²·s⁻¹
Dataset: 2014/15
         Integrated background rate in range: 2.0 .. 8.0: 1.1610e-04 cm⁻² s⁻¹
         Integrated background rate/keV in range: 2.0 .. 8.0: 1.9350e-05 keV⁻¹·cm⁻²·s⁻¹
#+end_src

* Septemboard detector                                             :Detector:
#+LATEX: \minitoc
The detector in use in the 2014 / 2015 data taking campaign, presented
in section [[#sec:detector:detector_2014_15]] had a few significant
drawbacks for more sensitive searches, in particular for searches at
low energies $\lesssim\SI{2}{\keV}$ and/or searches requiring low
backgrounds over larger areas on the chip (for example the chameleon
search done in \cite{krieger2018search}).

All detector upgrades were done to alleviate one or more of these
drawbacks. We will now go through each of the new detector features
and highlight the aspects it is intended to improve on.

Section [[#sec:detector:scintillators]] introduces two new scintillators as
vetoes. These require the addition of an external shutter for the
Timepix, which is realized by usage of a flash ADC (FADC), see section
[[#sec:detector:fadc]]. Further, an independent but extremely important addition is
the replacement of the Mylar window by a silicon nitride window,
section [[#sec:detector:sin_window]]. Another aspect is the addition of another 6
GridPixes around the central GridPix, the 'Septemboard' introduced in
section [[#sec:detector:septemboard]]. 

The full detector is presented in section [[#sec:detector:detector_overview]]





Why do we build such a 'complicated' detector?

Background increases to edges, esp. corners.

Background rate has known peaks. 3 keV for the Argon escape
peak. Can't do anything about that in current iteration.

Peak at 8-9 keV. A mix of a copper peak and orthogonal muons, which
are expected to emit about 8 keV through 3 cm. More on this later in
[[Background rate]].

Window doesn't transmit at < 2 keV


The first section introduces the reasoning behind building a more
complicated detector. Existing detector has multiple downsides, seen
in background rate & detector efficiency.

In the further sections we discuss each additional detector feature in
detail and explain why it was added / what drawback of the previous
detector should be improved on.

After we have introduced the detector as a whole we talk about the
calibrations that are necessary to perform sensible measurements.

*IN EACH SUBSECTION START WITH WHAT IT'S SUPPOSED TO HELP WITH?*

** Scintillator vetoes [2/9]
:PROPERTIES:
:CUSTOM_ID: sec:detector:scintillators
:END:

The first general improvement is the addition of two scintillators for
veto purposes. While both have slightly different goals, each is there
to help with the removal of muon signals in the detector or muon
induced events (for example X-ray fluorescence). Given that cosmic
muons (ref. section [[#sec:theory:cosmic_radiation]]) dominate the background by
flux, statistically there is a high chance of muons creating X-ray
like signatures in the detector (more on that below). By tagging muons
before they interact near the detector, these can be correlated with
events seen on the GridPix and thus possibly be vetoed if precise time
information is available.

- [ ] *REPHRASE*

The first scintillator is a large paddle installed above the detector
installation, aiming to tag a large fraction of cosmic muons
traversing in the area around the detector. It has a Canberra 2007
base, which accepts positive HV. The PMT is a Bicron
Corp. 31.49x15.74M2BC408/2-X, where the first two numbers are the
scintillators dimensions in inches. The full outer dimensions of the
scintillator paddle are closer to $\SI{42}{cm} \times \SI{82}{cm}$. It
is the same scintillator paddle used during the Micromegas data taking
behind the LLNL telescope prior and after the data taking campaign
with the detector described in this thesis.

For this scintillator, muons which traverse through this scintillator
and the gaseous detector volume are not the main use case. They can be
easily identified by the geometric properties of the induced tracks
(their zenith angles are relatively small, resulting in track like
signatures as the GridPix readout is orthogonal to the zenith
angle). There is a small chance however that a muon can excite an atom
of the detector material, which may emit an X-ray upon
deexcitation. One particular source of background can be attributed to
the presence of copper whose $Kα$ lines are at $\sim\SI{8.04}{\keV} as
well as fluorescence of the argon gas with its $Kα$ lines at
$\sim\SI{2.95}{keV}$ (see. table [[tab_all_xray_fluorescence]] in
sec. [[#sec:theory:xray_fluorescence]]).

The second scintillator is a small silicon photomultiplier (SiPM)
installed on the underside of the PCB on which the septemboard is
installed. This scintillator was calibrated and set up as part of
\cite{JannesBSc}. We are interested in tagging precisely those muons,
which enter the detector orthogonally to the readout plane. This
implies zenith angles of almost \SI{90}{\degree} such that the
elongation in the transverse direction of the muon track is small
enough to result in a small eccentricity. From the Bethe equation we
commonly expect muons to deposit about \SI{8}{\keV} along the
\SI{3}{\cm} of drift volume in the detector, assuming the conditions
as used in the detector at CAST (see
fig. [[fig:theory:muon_argon_3cm_bethe_loss]] for the energy loss). This
coincides with the copper Kα lines and should lead to another source
of background in this energy range. Although the muon background will
have a much wider distribution than the copper lines.

- [ ] *REFERENCE SECTION ON MUON LOSSES*

- [X] *REFERENCE JANNES BSC THESIS FOR SIPM*

- [ ] *GIVE NAME OR WHATEVER OF SIPM*
- [X] *GIVE NAME OR WHATEVER OF BIG PADDLE*  

- [ ] *CONSIDER REPHRASING SENTENCE ABOUT BETHE EQ GIVING US 8 KEV*

- [ ] *ADD NOEXPORT OF CALCULATIONS OF MUON ANGLES POSSIBLE*

- [ ] *SCHEMATIC OF MUON IONIZATION*

- [ ] *NOTE: MAYBE INSTEAD START WITH SEPTEMBOARD? THEN IN OTHER FEATURES
CAN MENTION THAT THINGS ARE ONLY FOR CENTER CHIP EG*

** FADC [0/4]
:PROPERTIES:
:CUSTOM_ID: sec:detector:fadc
:END:

As the Timepix is read out in a shutter based fashion and typical
shutter lengths for low rate experiments are long compared to the rate
of cosmic muons, the scintillators introduced in previous section
require an external trigger to close the Timepix shutter early if a
signal is measured on the Timepix. This is one the main purposes of
the \text{f}lash \textbf{a}nalog to \textbf{d}igital
\textbf{c}onverter (FADC) that is part of the detector.

The specific FADC used for the detector is an Caen V1792a *WHICH
REVISION?*. It runs at an internal \SI{50}{MHz} or \SI{100}{MHz} clock
and utilizes virtual frequency multiplication to achieve sampling
rates of \SI{1}{GHz} or \SI{2}{GHz}, respectively. It has 4 channels,
each with a cyclic register of \num{2560} channels. At an operating
clock frequency of $\SI{1}{GHz}$ that means each channel covers the
last $\sim\SI{2.5}{\micro\second}$ at any time. \cite{fadc_manual}

The raw signal decoupled from the grid is first fed into an Ortec 142
B pre-amplifier, which then feeds into an Ortec 474 shaping amplifier,
which integrates and shapes the signal as well as amplifies it. For a
detailed introduction to this FADC system, see the thesis of
A. Deisting \cite{Deisting} and \cite{SchmidtMaster} for further work
integrating it into this detector. In addition see the FADC manual
\cite{fadc_manual} [fn:fadc_manual] for a deep explanation of the
working principle of this FADC.

- [ ] *HAVE PRE AMPLIFIER BEFORE FADC. ORTEC*
- [ ] *SHOW IMAGE OF FADC AND SHAPING AMPLIFIER*

#+CAPTION: Schematic of the setup to decouple signals induced on the grid of the
#+CAPTION: InGrid. The signal is decoupled in the sense that the capacitor essentially
#+CAPTION: acts as a low pass filter, thus removing the constant HV. Only the
#+CAPTION: high frequency components of the induced signals on top of the HV pass
#+CAPTION: into the branch leading to the FADC. In the detector of this thesis, 
#+CAPTION: a capacitance of \SI{10}{nF} was used instead. The decoupling is implemented 
#+CAPTION: on the intermediate board. Schematic taken from \cite{Deisting}. 
#+NAME: fig:detector:fadc_circuit
[[~/phd/Figs/decouple_fadc.pdf]]

The analogue signal measured by the FADC is the induced signal on the
grid of the central GridPix (introduced in detail in section
[[#sec:septemboard]]) via a small $C_{\text{dec}} = \SI{10}{nF}$ capacitor
in parallel to the high voltage line. For a schematic of the circuit
see fig. [[fig:detector:fadc_circuit]]. When a primary electron traverses
through a hole in the grid and is amplified, the back flowing ions
induce a small voltage spike on top of the constant high voltage
applied to the grid. The parallel capacitor filters out the constant
high voltage and only transmits the time varying induced signals. Such
signals - the envelope of possibly many primary electrons - are
measured by the FADC.

#+CAPTION: Schematic showing how the FADC and scintillators are used together
#+CAPTION: to tag possible coincidence events and close the shutter early to
#+CAPTION: reduce the likelihood of multi-hit events. If the scintillator
#+CAPTION: triggers when the shutter is open, a clock starts counting up to
#+CAPTION: 4096 clock cycles. On every new trigger this clock is reset. If
#+CAPTION: the FADC triggers, the scintillator clock values are read out and
#+CAPTION: can be used to correlate events in the scintillator with FADC and
#+CAPTION: GridPix information. Further, the FADC trigger is used to close the
#+CAPTION: Timepix shutter \SI{50}{μs} after the trigger.
#+NAME: fig:detector:scintillator_fadc_shutter_close
[[~/phd/Figs/scintillator_fadc_shutter_close.pdf]]

This signal can be used for two distinct things:
1. it may be used as a trigger to close the shutter of the ongoing
   event. Ideally, we want to only measure a single physical event
   within one shutter window. A long shutter time can statistically
   result in multiple events happening, which the FADC trigger helps
   to alleviate.
2. By nature of the signal production & drift properties of the
   primary electrons before they reach the grid, the signal shape can
   theoretically be used to determine a rough longitudinal shape of
   the event. The length of the FADC event should be proportional to
   the size of the primary electron cloud distribution along the
   'vertical' detector axis. 

The former allows us to reduce the number of events with multiple
physical events and acts as a trigger for the scintillators. This in
turn means possible muon induced X-ray fluorescence can be vetoed. The
latter potentially allows to differentiate between a muon traversing
orthogonally through the readout plane and an X-ray due to their
longitudinal shape difference.

The working principle of how the FADC and the scintillators can be
used together to remove certain kinds of background by correlating
events in the scintillators, the FADC and the GridPix is shown in
fig. [[fig:detector:scintillator_fadc_shutter_close]].

- [ ] *PICTURE OF FADC*

- [ ] *COPY OVER SECTION ABOUT MUONS / TOA INFO FROM IAXO TDR TEXT?*

[fn:fadc_manual] A PDF version is available at: https://archive.org/details/manualzilla-id-5646050/

** SiN window [/]
:PROPERTIES:
:CUSTOM_ID: sec:detector:sin_window
:END:

Next up, a major limitation of the previous detector was its limited
combined efficiency below $\SI{2}{keV}$, due to its \SI{2}{μm} Mylar
window. Therefore, the next improvement for the new detector is an
ultra-thin silicon nitride \ce{Si_3 N_4} window of \SI{300}{nm}
thickness and \SI{14}{mm} diameter, developed by Norcada™ *WEBSITE*. A
strongback support structure consisting of 4 lines of \SI{200}{μm}
thick and \SI{500}{μm} wide \ce{Si_3 N_4}, helps to support a pressure
difference of up to \SI{1.5}{bar}. On the outer side a \SI{20}{nm}
thin layer of aluminum is coated to allow the window to be part of the
detector cathode. The strongback occludes about \SI{17}{\percent} of
the full window area. In reality it is slightly more, as the
strongbacks become somewhat wider towards the edges. In the center
most region they are straight and in the center $\num{5} \times
\SI{5}{mm²}$ area, they occlude \SI{22.2}{\percent}.

Fig. \subref{fig:detector:strongback_structure_mc} shows the idealized strongback
structure without a widening towards the edges of the
window. Fig. \subref{fig:detector:window_image} shows an image of one such
window under testing conditions in the laboratory, as it withstands a
pressure difference of \SI{1.5}{bar}.

*FIX REFERENCE TO INLINE LATEX LABELS!*

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/SiN_window_occlusion.png}
    \caption{Window strongback schematic}
    \label{fig:detector:strongback_structure_mc}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/300nm_SiN_holds.jpg}
    \label{fig:detector:window_image}
    \caption{Image}
  \end{subfigure}
  \label{fig:detector:window_image_and_strongback}
  \caption{\subref{fig:detector:strongback_structure_mc} shows an idealized schematic of the
    window strongback based on a simple MC simulation. \SI{22.2}{\percent} of the area inside the
    inner $\num{5} \times \SI{5}{mm^2}$ area (black square) are occluded.
    \subref{fig:detector:window_image} shows an image of one such window while testing in the
    laboratory, if it holds \SI{1.5}{\bar}.
  }
\end{figure}

- [ ] *POSSIBLY UPDATE IMAGE OF WINDOW*

As the main purpose is the increase of transmission at low energies,
let's compare the transmission between the mylar window of the old
detector and the new \ce{Si_3 N_4}
window. Fig. [[fig:detector:window_efficiency_comparison]] shows the
transmission of the two different window setups in the energy range
below \SI{3}{keV}. The \ce{Si_3 N_4} window shows a significant
increase in transmission below \SI{2}{keV}, which is very important
for the sensitivity in solar axion-electron and chameleon searches,
which both peak near \SI{1}{keV} in their solar flux. The window alone
significantly increases the signal to noise ratio of these physics searches.

#+CAPTION: Comparison of the transmission of a \SI{2}{μm} Mylar window and a
#+CAPTION: \SI{300}{nm} \ce{Si_3 N_4} window. The efficiency gains become
#+CAPTION: more and more pronounced the lower the energy is, aside from the
#+CAPTION: absorption edge of carbon at around \SI{250}{eV} and above about
#+CAPTION: \SI{1.75}{keV}. In the interesting range around \SI{1}{keV} significant
#+CAPTION: transmission gains are achieved.
#+NAME: fig:detector:window_efficiency_comparison
[[~/phd/Figs/detector/window_transmisson_comparison.pdf]]

*** Calculation of strongback window structure plot :noexport:

#+begin_src nim :tangle code/window_strongback.nim
## Super dumb MC sampling over the entrance window using the Johanna's code from `raytracer2018.nim`
## to check the coverage of the strongback of the 2018 window
##
## Of course one could just color areas based on the analytical description of where the
## strongbacks are, but this is more interesting and looks fun. The good thing is it also
## allows us to easily compute the fraction of pixels within and outside the strongbacks.
import ggplotnim, random, chroma
proc colorMe(y: float): bool =
  const
    stripDistWindow = 2.3  #mm
    stripWidthWindow = 0.5 #mm
  if abs(y) > stripDistWindow / 2.0 and
     abs(y) < stripDistWindow / 2.0 + stripWidthWindow or
     abs(y) > 1.5 * stripDistWindow + stripWidthWindow and
     abs(y) < 1.5 * stripDistWindow + 2.0 * stripWidthWindow:
    result = true
  else:
    result = false

proc sample() =
  randomize(423)
  const nmc = 5_000_000
  let black = color(0.0, 0.0, 0.0)
  var dataX = newSeqOfCap[float](nmc)
  var dataY = newSeqOfCap[float](nmc)
  var inside = newSeqOfCap[bool](nmc)
  for idx in 0 ..< nmc:
    let x = rand(-7.0 .. 7.0)
    let y = rand(-7.0 .. 7.0)
    if x*x + y*y < 7.0 * 7.0:
      dataX.add x
      dataY.add y
      inside.add colorMe(y)
  let df = toDf(dataX, dataY, inside)
  echo "A fraction of ", df.filter(f{`inside` == true}).len / df.len, " is occluded by the strongback"
  let dfGold = df.filter(f{abs(idx(`dataX`, float)) <= 2.25 and
                           abs(idx(`dataY`, float)) <= 2.25})
  echo "Gold region: A fraction of ", dfGold.filter(f{`inside` == true}).len / dfGold.len, " is occluded by the strongback"
  ggplot(df, aes("dataX", "dataY", fill = "inside")) +
    geom_point(size = 1.0) +
    # draw the gold region as a black rectangle
    geom_linerange(aes = aes(y = 0, x = 2.25, yMin = -2.25, yMax = 2.25), color = "black") +
    geom_linerange(aes = aes(y = 0, x = -2.25, yMin = -2.25, yMax = 2.25), color = "black") +
    geom_linerange(aes = aes(x = 0, y = 2.25, xMin = -2.25, xMax = 2.25), color = "black") +
    geom_linerange(aes = aes(x = 0, y = -2.25, xMin = -2.25, xMax = 2.25), color = "black") +
    xlab("x [mm]") + ylab("y [mm]") +
    ggtitle("Idealized schematic of the window layout. Strongback in red.") +
    ggsave("/home/basti/phd/Figs/SiN_window_occlusion.png", width = 1150, height = 1000)
sample()
#+end_src

#+RESULTS:

*** Calculation of transmission efficiency [0/0]                 :noexport:

Let's calculate the transmission for =Si₃N₄= and Mylar windows using
[[https://github.com/SciNim/xrayAttenuation][=xrayTransmission=]].

#+begin_src nim :tangle /home/basti/phd/code/window_transmission_comparison.nim
import std / strutils
import xrayAttenuation, ggplotnim
# generate a compound of silicon and nitrogen with correct number of atoms
let Si₃N₄ = compound((Si, 3), (N, 4))
#Si₃N₄.plotTransmission(3.44.g•cm⁻³, 300.nm.to(Meter))
# instantiate Mylar
let mylar = compound((C, 10), (H, 8), (O, 4))
# mylar.plotTransmission(1.4.g•cm⁻³, 2.μm.to(Meter), energyMax = 3.0)

echo mylar.name()
echo Si₃N₄.name()
# define energies in which to compute the transmission
# (we don't start at 0, as at 0 energy the parameters are not well defined)
let energies = linspace(1e-2, 3.0, 1000)

proc compTrans[T: AnyCompound](el: T, ρ: g•cm⁻³, length: Meter): DataFrame =
  result = toDf({ "Energy [keV]" : energies })
    .mutate(f{float: "μ" ~ el.attenuationCoefficient(idx("Energy [keV]").keV).float},
            f{float: "Trans" ~ transmission(`μ`.cm²•g⁻¹, ρ, length).float},
            f{"Compound" <- el.name()})
var df = newDataFrame()
# compute transmission for Si₃N₄ (known density and desired length)
df.add Si₃N₄.compTrans(3.44.g•cm⁻³, 300.nm.to(Meter))
# and for 2μm of mylar
df.add mylar.compTrans(1.4.g•cm⁻³, 2.μm.to(Meter))
# create a plot for the transmissions
echo df
let dS = r"$\SI{300}{nm}$" #pretty(300.nm, 3, short = true)
let dM = r"$\SI{2}{\micro\meter}$" #pretty(2.μm, 1, short = true)
let si = r"$\mathrm{Si}₃\mathrm{N}₄$"
ggplot(df, aes("Energy [keV]", "Trans", color = "Compound")) +
  geom_line() +
  xlab("Energy [keV]") + ylab("Transmission") +
  xlim(0.0, 3.0) + 
  ggtitle(r"Transmission examples of $# $# and $# Mylar" % [dS, si, dM]) +
  ggsave("/home/basti/phd/Figs/detector/window_transmisson_comparison.pdf",
         #width = 800, height = 600,
         useTex = true, standalone = true) 
#+end_src


** Septemboard - 6 GridPixes around a center one [0/7]
:PROPERTIES:
:CUSTOM_ID: sec:detector:septemboard
:END:

The main motivation for extending the readout area from a single chip
to a 7 chip readout is to reduce background towards the outer sides of
the chip, in particular in the corners. Against common intuition
however, it also plays a role for events, which have cluster centers
near the center of the readout. The latter is due to gas ionization
being a statistical process. In particular in lower energy events,
tracks may have gaps in them large enough to avoid being detected as a
single cluster for standard radii in cluster searching
algorithms. This is particularly of interest as different searches
produce an 'image' at different positions and sizes on the
detector. While the center chip is large enough to fully cover the
image for essentially all models, it may not be in the regions of
lowest background. Hence, improvements to larger areas are needed.

*REFERENCE PAPER ABOUT TRACKS IN TPCS. IONIZATION STATISTICAL AND SO ON*

*THE LATTER NEEDS MORE WORDING ELSEWHERE / CLUSTERING ALGORITHM EXPL /
SEPTEM VETO*

- [ ] *USE EXACT MEASURES OF THE TIMEPIX BASED ON TIMEPIX MANUAL*

The septemboard is implemented in such a way to optimize the loss of
active area due to bonding requirements and general manufacturing
realities. As the Timepix ASIC is a \SI{16.1}{mm} by \SI{14.1}{mm}
large chip (the bonding area adding \SI{2}{mm} on one side), the upper
two rows are installed such that they are inverted to another. The
bonding area is above the upper row and below the center row. The
bottom row again has its bonding area below. This way the top two rows
are as close together as realistically possible, with a decent gap on
the order of \SI{2}{mm} between the middle and bottom row. Any gap is
potentially problematic as it implies loss of signal in that area,
complicating the possible reconstruction methods.

All 7 GridPix are connected in a daisy-chained way. This means that in
particular for data readout, each chip is read out one after
another. The dead time for readouts therefore is approximately 7 times
the readout time of a single Timepix. A single Timepix has a readout
time of $\sim\SI{25}{ns}$ at a clock frequency of \SI{40}{MHz} (the
frequency used for this detector). This leads to an expected readout
time of the full septemboard of
\SI{175}{ns}. [fn:detector_readout_time] Such a long readout time
leads to a strong restriction of the possible applications for such a
detector. Fortunately, for the use cases in a very low rate experiment
such as CAST, long shutter times are possible, mitigating the effect
on the fractional dead time to an extent.

Fig. [[cluster_centers_likelihood]] shows a heatmap of all cluster centers
during roughly \SI{2000}{\hour} of background data after passing these
clusters through a likelihood based cut method aiming to filter out
non X-ray like clusters (details of this follow later in chapter
*CHAPTER FOR LIKELIHOOD METHOD*). It is clearly visible that the further a
cluster center is towards the chip edges, and especially the corners,
the more likely it is to be considered an X-ray like cluster. This has
an easy geometric explanation. Consider a perfect track traversing
over the whole chip. In this case it is clearly eccentric. Move the
same track such that its center is in one of the corners and rotate it
by \SI{45}{\degree} and suddenly the majority of the track won't be
detected on the chip anymore. Instead something roughly circular
remains visible, 'fooling' the likelihood method. For a schematic
illustrating this, see fig *SHOW CUT OFF FROM ONE OF MY TALKS*.

The septemboard therefore is expected to significantly reduce the
background over the whole center chip, with the biggest effect in the
regions with the most amount of background. 

\input{~/phd/Figs/backgroundClusters/background_cluster_centers.tex}
- [ ] *TODO: NEED CAPTION AND LABEL FOR BACKGROUND CLUSTERS*

- [ ] *SIDE BY SIDE INCLUDING A SEPTEM EVENT SHOWING TRACK CUT LEADS
  TO CIRCLE*

- [ ] *MENTION SEPTEMBOARDS ARE NAMED BY LETTERS, WHICH ONE USED IN
  DETECTOR*

- [ ] *SHOW SCHEMATIC OF LAYOUT*

- [ ] *FIND OUT WHERE 25 NS READOUT FOR SINGLE TIMEPIX COMES FROM*

- [ ] *READOUT TIME:*
    #+begin_quote
  The main driver for the readout speed is the time to readout the
  complete matrix (one frame) from the chip and this value is fixed for
  a given FCLOCK frequency. A frame consists of 917504 bits, which have
  to be packed to the data stream. As the data is sampled with FCLOCK,
  the same amount of clock cycles is needed, what defines the readout
  time
    #+end_quote
   page 83 of Lupberger thesis. 917504 * 25ns (one clock at 40MHz) = 22.9442 ms per frame under
  ideal conditions

[fn:detector_readout_time] We will later see that the practical
readout time of the final detector is closer to almost \SI{500}{ms}
under high rate conditions.  

*** Compute the cluster backgrounds                              :noexport:

To compute these cluster backgrounds, we need the following
ingredients:
- the fully reconstructed data files =DataRuns201*_Reco.h5= 
- the prepared CDL data from the 2019 dataset
  =calibration-cdl_2019.h5= and the X-ray reference datasets that
  define the X-ray like properties.
- apply the likelihood method to all background events in one of the
  files (gives enough statistics) to get a resulting file containing
  only passed clusters *over the whole chip*.

With the resulting file we can then use
[[file:~/CastData/ExternCode/TimepixAnalysis/Plotting/plotBackgroundClusters/plotBackgroundClusters.nim]]
to plot these cluster centers.

Assuming the reconstructed data files are found in *...* and the CDL
data files in *...*, let's generate the data after likelihood method:
#+begin_src sh
~/CastData/ExternCode/TimepixAnalysis/Analysis/ingrid/likelihood ~/CastData/data/DataRuns2017_Reco.h5 --h5out /tmp/lhood_2017_full_chip.h5 \
  --altCdlFile ~/CastData/data/CDL_2019/calibration-cdl-2018.h5 \
  --altRefFile ~/CastData/data/CDL_2019/XrayReferenceFile2018.h5 \
  --cdlYear=2018 --region=crAll 
#+end_src

Now we can create the plot:
#+begin_src sh
cd ~/CastData/ExternCode/TimepixAnalysis/Plotting/plotBackgroundClusters
nim c -d:danger --threads:on plotBackgroundClusters.nim
./plotBackgroundClusters -f /tmp/lhood_2017_full_chip.h5 --useTikZ
#+end_src

*** GENERAL

*REFERENCE* that schematic of how everything is connected is explained
in the detector @ CAST? Or explain it here, then refer back?

** Water cooling and temperature readout for the septemboard [0/1]

During development of the septemboard one particular set of problems
manifested. While testing a prototype board with 5 active GridPix in a
gaseous detector, the readout was plagued by excessive noise
problems. The detector exhibited a large number of frames with more
than \num{4096} active pixels (the limit for a zero suppressed
readout) and common pixel values of \num{11810} indicating overrun ToT
counters. On an occupancy (sum of all active pixels) of the individual
chips, it is quite visible the data is clearly not due to cosmic
background. Fig. [[fig:detector:occupancy_sparking_run_241]] shows such an
occupancy with the color scale topping out at the $80^{\text{th}}$
percentile of the counts for each chip individually. The chip in the
bottom left shows a large number of sparks (overlapping half ellipses
pointing downwards) at the top end. Especially the center chip in the
top row shows highly structured activity, which is in contrast to the
expectation of a homogeneous occupancy for a normal background
run. In addition on all chips some level of general noise on certain
pixels is visible (some being clearly more active than others
resulting in a scatter of 'points').

#+CAPTION: Occupancy of a testing background run with $\mathcal{O}(\SI{1}{s})$ long frames
#+CAPTION: using septemboard F during development without any kind of cooling.
#+NAME: fig:detector:occupancy_sparking_run_241
[[~/phd/Figs/detector/sparking/sparking_occupancy_80_quantile_run_241.pdf]]

The intermediate board and carrier board used during these tests were
the first boards equipped with two PT1000 temperature sensors. One on
the bottom side of the carrier board and another on the intermediate
board. Each is read out using a =MAX31685= micro controllers. Both of
which are communicated with via a =MCP2210= USB-to-SPI micro
controllers over a single USB port on the intermediate board. The
single =MCP2210= communicates with both temperature sensors via the
Serial Peripheral Interface (SPI) (see
sec. [[#sec:daq:temperature_readout]] for more information about the
temperature logging and readout). In the run shown in
fig. [[fig:detector:occupancy_sparking_run_241]] the temperature sensors
were not functional yet, as the readout software was not written
yet. The required logic was added to the Timepix Operating System
(TOS), the readout software of the detector, motivated by this noise
activity to monitor the temperature before and during a data taking
period. The temperature on the carrier board indicated temperatures on
the order of \SI{75}{\degree\celsius} in background runs similar to
the one of fig. [[fig:detector:occupancy_sparking_run_241]]. One way to
get a measure for the noise like activity seen on the detector is to
look at the rate of active pixels over time. With values well above
numbers expected due to background, excess temperature seemed a
possible cause for the issues. As no proper cooling mechanism was
available, a regular desk fan was placed pointing at the detector when
it was run without any kind of shielding. This saw the temperature
under the carrier board drop from \SI{76}{\degree\celsius} down to
\SI{68}{\degree\celsius}. As a result the majority of noise
disappeared as can be seen in
fig. \ref{fig:detector:sparking_run_with_fan_mean_hits} with the
temperature curve during the full run in
fig. \ref{fig:detector:sparking_run_with_fan_temps}. [fn:detector_sparking_run_268] [fn:detector_troubleshooting]

The features visible in the occupancy plots are thus likely multiple
different artifacts due to too high temperatures. A mixture of real
sparks (bottom left chip in
fig. [[fig:detector:occupancy_sparking_run_241]]), instabilities that
possibly affect either voltages for the pixels (and thus change the
thresholds of each pixel). As the temperature is measured on the
bottom side of the carrier board, temperatures in the amplification
region are likely significantly higher. As the gas gain is
proportional to the temperature, it is possible slight height
differences of the InGrid cause local amplification events, similar to
a photomultiplier tube. 

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/detector/sparking/temperature_sparking_run_268.pdf}
    \caption{Temperature}
    \label{fig:detector:sparking_run_with_fan_temps}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{./Figs/detector/sparking/mean_hit_rate_sparking_run_268.pdf}
    \label{fig:detector:sparking_run_with_fan_mean_hits}
    \caption{Mean hit rate}
  \end{subfigure}
  \label{fig:detector:sparking_run_with_fan}
  \caption{\subref{fig:detector:sparking_run_with_fan_temps} shows the temperature on the bottom side of the
    carrier board ('septem') and intermediate board ('IMB') during the background run. The point at which
    the desk fan is placed next to the detector is clearly visible by the \SI{8}{\degree\celsius} drop in
    temperature from about \SI{76}{\degree\celsius} to \SI{68}{\degree\celsius}. 
    \subref{fig:detector:sparking_run_with_fan_mean_hits} shows the mean hit rate of each of the 5 chips
    installed on the carrier board at the time during the same run. The placement of the desk fan is easily
    visible as a reduction in mean rate on all chips.
  }
\end{figure}

Following this a bespoke water cooling was designed made from
oxygen-free copper with *X MM* holes for water to circulate through
the copper body. The body has the same diameter as the intermediate
board and is installed right below. The water circulation is handled
by an off-the-shelf pump and radiator from
Alphacool [fn:detector_alphacool] intended for water cooling setups
for desktop computers. The pump manages a water flow rate of about
\SI{0.3}{\liter\per\minute} through the small holes in the copper. In
common operation the temperatures on the carrier board are between
\SIrange{45}{50}{\degree\celsius} and noise free operation is
possible. 

- [ ] *REF TOBI THESIS & UPCOMING PAPER*






- [ ] *REFERENCE CODE TO TEMP READOUT?*

[fn:detector_troubleshooting] The realization that the issues are
purely due to temperature effects was only after several months of
eliminating many other options, both on the software as well as the
hardware side. In particular power supply instabilities were long
considered to be a source of problems. While they possibly also had an
impact, better power supplies were built with larger capacitors to
better deal with large variations in required power. 

[fn:detector_alphacool] https://www.alphacool.com/

[fn:detector_sparking_run_268] See the full thesis version for the
occupancy of the run with temperature readout in the subsection
after this if interested.

*** Sparking behavior :noexport:

See the mails containing "Septem F" (among other things) for the
information about sparking behavior. From that we can also deduce the
run numbers of the noisy runs (run 241 is one of them); just keep in
mind that the run numbers are overlapping with some CAST run numbers,
as for CAST we started again at 0.

Specific run path of noisy run used in occupancy plot above:
=Run_241_170216-13-49=
So run from February 2017.


Let's plot the temperature during the sparking run in which we
installed the fan.

This is essentially a reproducible version of the following plot:
[[file:~/org/Figs/temps_plot_septemF_76_68deg_1s.pdf]]
#+begin_src nim :tangle /home/basti/phd/code/sparking_temperature.nim
import ggplotnim, times

const path = "/mnt/1TB/CAST/2017/development/Run_268_170418-05-43/temp_log.txt"

proc p(x: string): DateTime =
  result = x.parse("YYYY-MM-dd'.'HH:mm:ss", local())
let df = readCsv(path, sep = '\t', skipLines = 2, colNames = @["IMB", "Septem", "DateTime"])
  .filter(f{string -> bool: p(`DateTime`) < initDateTime(19, mApr, 2017, 0, 0, 0, 0, local())})
  .gather(@["IMB", "Septem"], "Type", "Temperature")
  .mutate(f{"Timestamp" ~ p(`DateTime`).toTime().toUnix()})

## XXX: fix plotting of string columns as date scales, due to discrete / continuous mismatch and lacking
## `dataScale` field
ggplot(df, aes("Timestamp", "Temperature", color = "Type")) +
  geom_line() +
  # scale_x_continuous() +
  ggtitle("Temperature during run on 2017/04/18 in which fan was placed next to detector") + 
  xlab("Time of day") + ylab("Temperature [°C]") +
  margin(top = 2.0) + 
  scale_x_date(isTimestamp = true,
               formatString = "HH:mm:ss",
               dateSpacing = initDuration(hours = 2),
               dateAlgo = dtaAddDuration,
               timeZone = local()) +                
  ggsave("/home/basti/phd/Figs/detector/sparking/temperature_sparking_run_268.pdf")
df.writeCsv("/home/basti/phd/resources/temperature_sparking_run_268.csv")  
#+end_src

#+RESULTS:
| INFO: The integer column `Timestamp` has been automatically determined to be continuous. To overwrite this behavior add a `+ scale_x/y_discrete()` call to the plotting chain. Choose `x` or `y` depending on which axis this column refers to. Or apply a `factor` to the column name in the `aes` call | i.e. `aes(... | Timestamp | ...)`. |

Next up we need to compute the mean hit rate of the four most active
chips and plot it against time.

How will we go about doing that? Read and reconstruct the run, then
manually extract hits per time, bin by time and that's it?

#+begin_src sh
cd /mnt/1TB/CAST/2017/development/
raw_data_manipulation -p Run_268_170418-05-43 --runType background --out raw_268_sparking.h5
reconstruction raw_268_sparking.h5 --out reco_268_sparking.h5
#+end_src

With the resulting file, we can now generate the plot of the hits over
time.

This is a reproducible version of the following plot:
[[file:~/org/Figs/hitrate_per_time_septemF_76_68deg_1s.pdf]]
#+begin_src nim :tangle /home/basti/phd/code/sparking_hit_rate_over_time.nim
import std / [options, sequtils, times]
import ggplotnim, nimhdf5, unchained
defUnit(Second⁻¹)
import ingrid / tos_helpers
const path = "/mnt/1TB/CAST/2017/development/reco_268_sparking.h5"
let h5f = H5open(path, "r")

var df = newDataFrame()
var dfR = newDataFrame()
for chip in 0 ..< 5:
  let dsets = @["hits"]
  let dfC = h5f.readRunDsets(
    268,
    chipDsets = some((chip: chip, dsets: dsets)),
    commonDsets = @["timestamp"]
  )
    .mutate(f{"chip" <- chip})
    .arrange("timestamp")
  df.add dfC

  # and directly compute the hit frequency
  let hits = dfC["hits", int]
  let time = dfC["timestamp", int]
  let ts = time.map_inline((x - time[0]).s)
  const Interval = 30.min
  var i = 0
  var rate = newSeq[Second⁻¹]()
  var rateTime = newSeq[float]()
  while i < time.len:
    var h = 0
    var Δt = 0.s
    let t0 = time[i]
    echo "Starting at t0 = ", t0
    while Δt < Interval and i < time.len:
      h += hits[i]
      if i > 0:
        Δt += ts[i] - ts[i-1]
      inc i
    rate.add (h.float / Δt)
    echo "To ", time[i-1]
    rateTime.add((time[i-1] + t0) / 2.0)
    h = 0
  dfR.add toDf({"rate" : rate.mapIt(it.float), rateTime, "chip" : chip})
echo df
echo dfR

dfR = dfR.filter(f{int -> bool: fromUnix(`rateTime`).inZone(local()) < initDateTime(19, mApr, 2017, 0, 0, 0, 0, local())})
ggplot(dfR, aes("rateTime", "rate", color = factor("chip"))) +
  geom_point() +
  scale_y_log10() + 
  scale_x_date(isTimestamp = true,
               formatString = "HH:mm:ss",
               dateSpacing = initDuration(hours = 2),
               dateAlgo = dtaAddDuration,
               timeZone = local()) +                
  ggsave("/home/basti/phd/Figs/detector/sparking/mean_hit_rate_sparking_run_268.pdf")

dfR.writeCsv("/home/basti/phd/resources/mean_hit_rate_sparking_run_268.csv", precision = 10)
#+end_src

Finally, combine both and plot together:
#+begin_src nim :tangle /home/basti/phd/code/temperature_and_sparking.nim
import std / times
import ggplotnim
const path = "/home/basti/phd/resources/"
let df = readCsv(path & "temperature_sparking_run_268.csv")
let dfR = readCsv(path & "mean_hit_rate_sparking_run_268.csv")
  .group_by("chip")
  .mutate(f{"rateNorm" ~ `rate` / max(`rate`) * 80.0})
  .rename(f{"Timestamp" <- "rateTime"})

let sa = secAxis(name = "Hit rate [a.u.]",
                 trans = f{1.0 / 80.0})
                 #invTransFn = f{`rateNorm` * 80.0})

ggplot(df, aes("Timestamp", "Temperature", color = "Type")) +
  geom_line() +
  geom_point(data = dfR, aes = aes("Timestamp", "rateNorm", color = factor("chip"))) + 
  # ggtitle("Temperature during run on 2017/04/18 in which fan was placed next to detector") + 
  xlab("Time of day") + ylab("Temperature [°C]") +
  margin(top = 2.0) +
  scale_y_continuous(secAxis = sa) + 
  scale_x_date(isTimestamp = true,
               formatString = "HH:mm:ss",
               dateSpacing = initDuration(hours = 2),
               dateAlgo = dtaAddDuration,
               timeZone = local()) + 
  legendPosition(0.835, 0.1) +
  yMargin(0.05) + 
  ggsave("/home/basti/phd/Figs/detector/sparking/temperature_and_sparking_run_268.pdf")

#+end_src

#+RESULTS:


And finally, let's also recreate the occupancy plot
[[file:~/phd/Figs/detector/sparking/occupancy_sparking_septem5chips_300V.pdf]] of run 241 during
development to showcase the sparking behavior.

In order to do that, we first need to reconstruct the run containing
the data:
#+begin_src sh
cd /mnt/1TB/CAST/2017/development/
raw_data_manipulation -p Run_241_170216-13-49 --runType background --out raw_241_sparking.h5
reconstruction raw_241_sparking.h5 --out reco_241_sparking.h5
#+end_src

With the reconstructed data file at hand, we can first of all generate
a large number of plots for each chip:
#+begin_src sh
plotData --h5file reco_241_sparking.h5 \
         --runType rtBackground \
         --config ~/CastData/ExternCode/TimepixAnalysis/Plotting/karaPlot/config.toml \
         --ingrid --occupancy
#+end_src
which can be adjusted according to the user's preference of course.

(For this plot in particular it's really important not use the =ToT=
cutting feature in =raw_data_manipulation= via the =rmToTLow= and
=rmToTHigh= in the =config.toml= file)

With the file in place, let's now create the plot of the occupancies
for each chip, embedded in the layout of the septemboard (at least for
the 5 chips that were on this septemboard F).

#+begin_src nim :tangle /home/basti/phd/code/occupancy_sparking_septem_layout.nim
import std / os except FileInfo
import std / strutils
import ingrid / [tos_helpers, ingrid_types]
import nimhdf5, ggplotnim, ginger

## The Septemboard layout code is a port of the code used in the python based event 
## display for TOS.

const
  Width = 14.1
  Height = 14.1
  BondHeight = 2.0
  FullHeight = Height + BondHeight
  NumChips = 7

  # If this is set to `true` the final plot will only contain the actual raster image. No legend or axes
  OnlyRaster = true

  Run = 241

type
  SeptemRow = object
    left: float
    right: float
    wspace: float
    top: float
    bottom: float

## XXX: replace the logic by one where we compute the relative positions on a
## 1x1 ratio grid for each chip separately instead of rows!

proc initSeptemRow(nChips: int, x_size, y_size, x_dist, x_offset, y_t_offset, y_b_offset, dist_to_row_below: float): SeptemRow =
  # this class implements a single row of chips of the septem board
  # nChips: number of chips in row
  # x_dist: distance in x direction between each chip
  # x_offset: offset of left edge of first chip in row from
  #           left side of center row
  # calculate width and height of row, based on chips and dist
  let width = nChips.float * Width + (nChips - 1).float * x_dist
  let height_active = Height
  let height_full = FullHeight + dist_to_row_below
  # using calc gridspec one calculates the coordinates of the row on
  # the figure in relative canvas coordinates
  # include padding by adding or subtracting from left, right, top, bottom
  result.left      = x_offset / x_size
  result.right     = result.left + width / x_size
  result.wspace    = x_dist / x_size
  result.top       = 1.0 - y_t_offset / y_size
  result.bottom    = result.top - height_active / y_size

proc initSeptemBoard(padding, fig_x_size, fig_y_size, scaling_factor: float): seq[SeptemRow] =
  # implements the septem board, being built from 3 septem rows

  proc initRows(y_size, scaled_x_size, scaled_y_size, y_row1_row2, y_row2_row3, row2_x_dist: float): seq[SeptemRow] =
    # this function creates the row objects for the septem class
    # calculation of row 1 top and bottom (in abs. coords.):
    let
      # (top need to add padding to top of row 1)
      row1_y_top    = y_size - BondHeight - Height
      # bottom in abs. coords.
      row1_y_bottom = 2 * FullHeight + y_row1_row2 + y_row2_row3 - Height
      # offset of left side from septem in abs. coords.
      row1_x_offset = 6.95
    # now create the first row with all absolute coordinates
    result.add initSeptemRow(2, scaled_x_size, scaled_y_size, 0.85, row1_x_offset, row1_y_top, row1_y_bottom, y_row1_row2)
    # calculation of row 2 top and bottom (top & bottom of row2 not affected by padding):
    let
      row2_y_top    = y_size - FullHeight - y_row1_row2 - Height
      row2_y_bottom = FullHeight + y_row2_row3 + BondHeight - Height
      # no offset for row2, defines our left most position in abs. coords.
      row2_x_offset = 0.0 #padding * x_size
    result.add initSeptemRow(3, scaled_x_size, scaled_y_size, row2_x_dist, row2_x_offset, row2_y_top, row2_y_bottom, y_row2_row3)
    # calculation of row 3 top and bottom (add padding to bottom):
    let
      row3_y_top    = y_size - 2 * FullHeight - y_row1_row2 - y_row2_row3 - Height
      row3_y_bottom = BondHeight - Height
      row3_x_offset = 7.22
    result.add initSeptemRow(2, scaled_x_size, scaled_y_size, 0.35, row3_x_offset, row3_y_top, row3_y_bottom, 0)

  # include a padding all around the septem event display of 'padding'
  # use size of figure to scale septem accordingly to have it always properly
  # scaled for the given figure
  # take the inverse of the scaling factor (want 1/2 as input to scale to half size)
  let scaling_factor = 1.0 / scaling_factor
  # first calculate the ratio of the figure
  let fig_ratio = float(fig_x_size) / float(fig_y_size)
  # distances between different rows in absolute coordinates
  let
    y_row1_row2 = 0.38
    y_row2_row3 = 3.1
    # size in y direction of whole septem board in absolute coordinates
    y_size      = 3 * FullHeight + y_row1_row2 + y_row2_row3
    # already define row2_x_dist here (in absolute coordinates) to calculate x_size
    row2_x_dist = 0.35
    # 3 chips * width + 2 * distance between chips (in absolute coordinates)
    x_size      = 3 * Width + (3 - 1) * row2_x_dist
  # calculate the ratio of the septem board
  var ratio = float(x_size) / float(y_size)
  # now calculate the needed ratio to get the correct scaling of the septem on any
  # figure scale. fig_ratio / own ratio
  ratio = fig_ratio / ratio
  let
    # scaled x and y sizes
    scaled_x_size = x_size * ratio * scaling_factor
    scaled_y_size = y_size * scaling_factor
  # and now create the row objects
  result = initRows(y_size, scaled_x_size, scaled_y_size, y_row1_row2, y_row2_row3, row2_x_dist)

proc readVlen(h5f: H5File,
              fileInfo: FileInfo,
              runNumber: int,
              dsetName: string,
              chipNumber = 0,
              dtype: typedesc = float): seq[seq[dtype]] =
  ## reads variable length data `dsetName` and returns it
  ## In contrast to `read` this proc does *not* convert the data.
  let vlenDtype = special_type(dtype)
  let dset = h5f[(fileInfo.dataPath(runNumber, chipNumber).string / dsetName).dset_str]
  result = dset[vlenDType, dtype]

proc calcOccupancy[T](x, y: seq[seq[T]], z: seq[seq[uint16]] = @[]): Tensor[float] =
  ## calculates the occupancy of the given x and y datasets
  ## Either for a `seq[seq[T: SomeInteger]]` in which case we're calculating
  ## the occupancy of a raw clusters or `seq[T: SomeFloat]` in which case
  ## we're dealing with center positions of clusters
  result = newTensor[float]([NPix, NPix])
  # iterate over events
  for i in 0 .. x.high:
    let
      xEv = x[i]
      yEv = y[i]
    var zEv: seq[uint16]
    if z.len > 0:
      zEv = z[i]
    ## continue if full event.
    ## TODO: replace by solution that also works for clusters!!
    #if xEv.len >= 4095: continue
    for j in 0 .. xEv.high:
      if zEv.len > 0:
        result[xEv[j].int, yEv[j].int] += zEv[j].float
      else:
        result[xEv[j].int, yEv[j].int] += 1.0

proc occForChip(h5f: H5File, chip: int, fileInfo: FileInfo): (Tensor[int], Tensor[int], Tensor[float]) =        
  const NPix = 256
  let
    xD = h5f.readVlen(fileInfo, Run, "x", chip, dtype = uint8)
    yD = h5f.readVlen(fileInfo, Run, "y", chip, dtype = uint8)
    zD = h5f.readVlen(fileInfo, Run, "ToT", chip, dtype = uint16)
  let occ = calcOccupancy(xD, yD) # , zD)
  var
    x = newTensorUninit[int](NPix * NPix)
    y = newTensorUninit[int](NPix * NPix)
    z = newTensorUninit[float](NPix * NPix)
  var i = 0
  for idx, val in occ:
    x[i] = idx[0]
    y[i] = idx[1]
    z[i] = val
    inc i
  result = (x, y, z)
      
proc handleOccupancy(h5f: H5File,
                     chip: int,
                     fileInfo: FileInfo,
                     quant: float = 0.0): PlotView =
  # get x and y datasets, stack and get occupancies
  let (x, y, z) = h5f.occForChip(chip, fileInfo)
  let df = toDf(x, y, z)
  var quant = quant
  if quant == 0.0:
    quant = percentile(z, 80)
  result = ggcreate(
    block:
      var plt = 
        ggplot(df, aes("x", "y", fill = "z"), backend = bkCairo) +
          geom_raster() +
          scale_fill_continuous(scale = (low: 0.0, high: quant)) + #high: 1600.0)) +
          xlim(0, NPix) + ylim(0, NPix)
      if OnlyRaster:
        plt = plt + theme_void() + hideLegend()
      plt
  )
  #ggplot(df, aes("x", "y", fill = "z"), backend = bkCairo) +
  #    geom_raster() +
  #    scale_fill_continuous(scale = (low: 0.0, high: 1600.0)) +
  #    xlim(0, NPix) + ylim(0, NPix) +
  #    ggsave("/t/test_occ_0_.pdf")

proc drawBounds(v: Viewport) =
  v.drawBoundary(writeName = true)
  for ch in mitems(v.children):
    ch.drawBounds()

proc calcQuantileChip3(h5f: H5File, fileInfo: FileInfo): float =
  let (x, y, z) = h5f.occForChip(3, fileInfo)
  result = percentile(z, 80)  

proc addRow(view: Viewport, h5f: H5File, septem: seq[SeptemRow], fileInfo: FileInfo, i, num, chipStart: int, showEmpty = false) =
  let width = septem[i].right - septem[i].left
  let height = septem[i].top - septem[i].bottom

  var row = view.addViewport(left = septem[i].left, bottom = septem[i].bottom,
                             width = width, height = height)
  row.layout(num, 1) #, margin = quant(septem[i].wspace, ukRelative))

  #let quant = calcQuantileChip3()
  
  for j in 0 ..< num:
    if not showEmpty:
      let plt = handleOccupancy(h5f, chipStart + j, fileInfo) #, quant)
      let v = if OnlyRaster: plt.view[4] else: plt.view
      var pltView = v.relativeTo(row[j]) 
      row.embedAt(j, pltView)
    row[j].drawBoundary()

  view.children.add row

## Read the data from the reconstructed H5 file of run 241
const path = "/mnt/1TB/CAST/2017/development/reco_$#_sparking.h5" % $Run
let h5f = H5open(path, "r")
let fileInfo = getFileInfo(h5f)

let
  fig_x_size = 10.0
  fig_y_size = 12.04186
  ratio = fig_x_size / fig_y_size

let septem = initSeptemBoard(0.0, fig_x_size, fig_y_size, 1.0)
let ImageSize = fig_x_size * DPI
let view = initViewport(c(0.0, 0.0),
                        quant(fig_x_size, ukInch), quant(fig_y_size, ukInch), backend = bkCairo,
                        wImg = ImageSize, hImg = ImageSize / ratio)

view.addRow(h5f, septem, fileInfo, 0, 2, 5, showEmpty = true)
view.addRow(h5f, septem, fileInfo, 1, 3, 2)
view.addRow(h5f, septem, fileInfo, 2, 2, 0)

view.draw("/home/basti/phd/Figs/sparking_occupancy_80_quantile_run_$#.pdf" % $Run)
#+end_src

Running the above code for run 268 (the run we installed the fan and
had temperature readout) yields fig. [[fig:detector:occupancy_sparking_run_268]].

#+CAPTION: Occupancy of a testing background run with $\mathcal{O}(\SI{1}{s})$ long frames
#+CAPTION: using septemboard F during development without any kind of cooling and temperature
#+CAPTION: logging. Temperatures on the underside of the carrier board reached \SI{76}{\degree\celsius}
#+CAPTION: before the fan was placed next to it.
#+NAME: fig:detector:occupancy_sparking_run_268
[[~/phd/Figs/detector/sparking/sparking_occupancy_80_quantile_run_268.pdf]]


** Full detector overview [0/4]
:PROPERTIES:
:CUSTOM_ID: sec:detector:detector_overview
:END:

- [ ] *TALK ABOUT SIZES OF FULL DETECTOR*

Generally the main detector follows the same design as the old
detector shown in sec. [[#sec:detector:detector_2014_15]], mainly so that
mounting it inside of the lead shielding and to the vacuum pipes is
possible without significant changes.

An exploded view of the full detector can be seen in
fig. [[fig:detector:full_septemboard_exploded]]. The FADC and large veto
scintillator paddle are not visible in the schematic of course. At the
center of the detector is the 'septemboard', 7 GridPix on a carrier
board. The housing with an inner diameter of \SI{78}{mm} is again made
of acrylic glass, same as in the old detector. The top shows the
\SI{300}{nm} \ce{Si_3 N_4} window, which also acts as part of the
detector cathode. The copper anode slots in right above the
septemboard. The carrier board sits on the intermediate board and
itself it is above the water cooling made of oxygen-free copper. At
the bottom, the SiPM veto scintillator can be seen.

The septemboard used in the final detector is septemboard H. The chips
of these are listed in tab. [[tab:detector:septem_h_chips]].

#+CAPTION: Overview of the different chips on septemboard H. The first part of the name corresponds
#+CAPTION: to the position on the wafer and =W69= is Timepix wafer number \num{69}.
#+NAME: tab:detector:septem_h_chips
#+ATTR_LATEX: :booktabs t
|---------+--------|
| Chip    | Number |
|---------+--------|
| E6 W69  |      0 |
| K6 W69  |      1 |
| H9 W69  |      2 |
| H10 W69 |      3 |
| G10 W69 |      4 |
| D9 W69  |      5 |
| L8 W69  |      6 |
|---------+--------|


- [ ] *SEPTEMBOARD CAN BE NAMED HERE INSTEAD OF ABOVE POSSIBLY*
- [ ] *REARRANGE THE TABLE TO ALIGN LEFT COLUMN*  

#+CAPTION: Exploded view of the main GridPix septemboard detector. The FADC and
#+CAPTION: large veto scintillator paddle are not shown for obvious reasons. At the
#+CAPTION: center of the detector is the 'septemboard', 7 GridPix on a carrier board.
#+CAPTION: The housing is made of acrylic glass, same as in the old detector. The
#+CAPTION: top shows the \SI{300}{nm} \ce{Si_3 N_4} window. Below the intermediate board
#+CAPTION: is the water cooling made of pure copper. At the bottom, the SiPM veto
#+CAPTION: scintillator can be seen.
#+NAME: fig:detector:full_septemboard_exploded
#+ATTR_LATEX: :height 0.5\textheight
[[~/phd/Figs/detector/detector-mk4c-assembly-exploded-whitebg-no-cables-cropped.jpg]]

*AS LAST SECTION?*

- [ ] *REPLACE IMAGE BY A PROPER RAYTRACED RENDER*
  
** Detector readout system (Virtex, ...) [0/1]

The detector is operated by a Xilinx Virtex-6 \textbf{F}ield
\textbf{P}rogrammable \textbf{G}ate \textbf{A}rray (FPGA) in the form
of a Virtex-6 ML605 evaluation board. [fn:ml605_weblink] It is
connected to the intermediate board via two
\textbf{H}igh-\textbf{D}efinition \textbf{M}ultimedia
\textbf{I}nterface (HDMI) cables. The Virtex-6 contains the firmware
controlling the Timepix ASICs and correlating the scintillator and
FADC signals (see sec. [[#sec:daq:tof]]). The high voltage (HV) supply both for the
septemboard as well as for the scintillators sit inside a VME crate,
which also houses the FADC. A USB connection is used to read out and
control the FADC and HV supply via the computer running the data
acquisition and control software (see sec. [[sec:daq:tos]]). A schematic
of this setup is shown in fig. [[fig:detector:flowchart_setup]].

#+CAPTION: Flowchart of the whole detector and readout system
#+NAME: fig:detector:flowchart_setup
[[file:~/org/Doc/Detector/figs/2016_detector_setup_schematic.pdf]]

Note however, that in this plot the SiPM is not illustrated, as it is
connected to the bottom of the intermediate board and only provides an
offline flag to be used in the analysis.

- [ ] *CLARIFY SIPM. PROBABLY ADD TO PLOT*
  
[fn:ml605_weblink]
https://www.xilinx.com/products/boards-and-kits/ek-v6-ml605-g.html
(visited 2022/10/17)

** Detector efficiency [0/1]

For the applications at CAST, the detector is filled with $\ce{Ar}$ / $\ce{iC_4 H_{10}}$ :
\SI{97.7}{\%} / \SI{2.3}{\%} gas. Combined with its \SI{300}{nm}
\ce{Si_3 N_4} window, the combined detection efficiency can be
computed, if the \SI{20}{nm} \ce{Al} coating for the detector cathode
is included by computing the product of the different
efficiencies. The efficiency of the window and coating are the
transmissions of X-rays at different energies for each material $t_i$. For
the gas, the absorption probability of the gas $a_i$ is needed. As such

\[
ε_{\text{tot}} = t_{\ce{Si_3 N_4}} · t_{\ce{Al}} · a_{\ce{Ar} / \ce{iC_4H_{10}}}
\]

describes the full detector efficiency assuming the parts of the
detector, which are not obstructed by the window strongbacks. For a
statistical measure of detection efficiency the occlusion of the
window needs to be taken into account. Because it is position
(and thus area) dependent, the need to include it is decided on a case
by case basis. For the absorption of a gas mixture, we can use
Dalton's law and compute the absorption of the individual gases according
to their mole fractions (their percentage as indicated by the gas
mixture) and then compute it for each partial pressure

\[
a_i = \text{Absorption}(P_{\text{total}} · f_i)
\]

where $P_{\text{total}}$ is the total pressure of the gas mixture (in
this case \SI{1050}{mbar} and $f_i$ is the fraction of the gas
$i$. 'Absorption' simply refers to the generic function computing the
absorption for a gas at a given pressure (see sec. [[#sec:theory:daltons_law]]).

The full combined efficiency as presented here is shown in
fig. [[fig:detector:combined_efficiency]]. Different aspects dominate the
combined efficiency (purple line) in different energy ranges. At
energies above \SI{5}{keV} the probability of X-rays to not generate a
photoelectron within the \SI{3}{cm} of drift distance becomes the
major factor for a loss in efficiency. This means the combined
efficiency at \SI{10}{keV} is slightly below \SI{30}{\percent}. The
best combined efficiency of about \SI{95}{\percent} is reached at
about \SI{3.75}{keV} where both the absorption is likely and the
energy is high enough to transmit well through the window. The argon
$K 1s$ absorption edge is clearly visible at around \SI{3.2}{keV}. At
energies below the mean free path of X-rays is significantly longer as
the $K 1s$ absorption is a significant factor in the possible
generation of a photoelectron. The window leads to a similar, but inverse, effect
namely due to the $K 1s$ line of \ce{Si} at around
$\SI{1.84}{keV}$. Because transmission is desired through the window
material, the efficiency /increases/ once we go below that
energy. Finally, the nitrogen $K 1s$ line also contributes to an
increase in efficiency once we cross below about \SI{400}{eV}. The
average efficiencies in the energy ranges between \SIrange{0}{5}{keV} and
\SIrange{0}{10}{keV} are *X* and *Y*, respectively.

The improvement in efficiency at energies below \SI{3}{keV} in
comparison to the mylar window used in the 2014/15 detector (see
sec. [[#sec:detector:sin_window]]) leads to a significant
improvement in possible signal detection at those energies, which is
especially important for searches with peak fluxes around
\SIrange{1}{2}{keV} as is the case for the axion-electron coupling or
a possible chameleon coupling.

#+CAPTION: Combined detection efficiency for the full detector, taking into account
#+CAPTION: the gas filling of \SI{1050}{mbar} $\ce{Ar}$ / $\ce{iC_4 H_{10}}$, the \SI{300}{nm}
#+CAPTION: \ce{Si_3 N_4} window and its \SI{20}{nm} \ce{Al} coating. 
#+NAME: fig:detector:combined_efficiency
[[~/phd/Figs/detector/detector_efficiency.pdf]]

Outside of that, the general background rate expected from the
detector should match and exceed the previous detector, due to the
additional detector features. 

- [ ] *ADD NUMBERS FOR AVERAGE EFFICIENCY IN RANGES, WHERE X AND Y*
- [ ] *REPLACE BY NATIVE TIKZ PLOT + VEGA*  

*** Calculation of full detection efficiency   :noexport:


#+begin_src nim :tangle /home/basti/phd/code/detector_efficiency.nim
import std / strutils
import xrayAttenuation, ggplotnim
# generate a compound of silicon and nitrogen with correct number of atoms
let Si₃N₄ = compound((Si, 3), (N, 4))
let al = Aluminium.init()

# define energies in which to compute the transmission
# (we don't start at 0, as at 0 energy the parameters are not well defined)
let energies = linspace(0.03, 10.0, 1000)

# instantiate an Argon instance
let ar = Argon.init()
# and isobutane
let iso = compound((C, 4), (H, 10))

proc compTrans[T: AnyCompound](el: T, ρ: g•cm⁻³, length: Meter): Column =
  let df = toDf({ "Energy [keV]" : energies })
    .mutate(f{float: "μ" ~ el.attenuationCoefficient(idx("Energy [keV]").keV).float},
            f{float: "Trans" ~ transmission(`μ`.cm²•g⁻¹, ρ, length).float},
            f{"Compound" <- el.name()})
  result = df["Trans"]
    
var df = toDf({ "Energy [keV]" : energies })
# compute transmission for Si₃N₄ (known density and desired length)
df[Si₃N₄.name()] = Si₃N₄.compTrans(3.44.g•cm⁻³, 300.nm.to(Meter))
# and aluminum coating
df[al.name()] = al.compTrans(2.7.g•cm⁻³, 20.nm.to(Meter))

# and now for the gas mixture.
# first compute partial pressures
const fracAr = 0.977
const fracIso = 0.023
# using it we can compute the density of each by partial pressure theorem (Dalton's law)
let ρ_Ar = density(1050.mbar.to(Pascal) * fracAr, 293.K, ar.molarMass)
let ρ_Iso = density(1050.mbar.to(Pascal) * fracIso, 293.K, iso.molarWeight)

# now add transmission of argon and iso
df[ar.name()] = ar.compTrans(ρ_Ar, 3.cm.to(Meter))
df[iso.name()] = iso.compTrans(ρ_Iso, 3.cm.to(Meter))

let nSiN = r"\SI{300}{nm} \ce{Si_3 N_4}"
let nAl = r"\SI{20}{nm} \ce{Al}"
let nAr = r"\SI{3}{cm} \ce{Ar} Absorption"
let nIso = r"\SI{3}{cm} \ce{iC_4 H_{10}} Absorption"
let nArIso = r"\SI{3}{cm} \SI{97.7}{\percent} \ce{Ar} / \SI{2.3}{\percent} \ce{iC_4 H_{10}}"

# finally just need to combine all of them in useful ways
# - argon + iso
df = df.mutate(f{"Trans_ArIso" ~ `Argon` * `C4H10`},
               f{"Abs ArIso" ~ 1.0 - `Trans_ArIso`},
               f{"Abs Ar" ~ 1.0 - `Argon`},
               f{"Abs Iso" ~ 1.0 - `C4H10`},
               f{"Efficiency" ~ idx("Abs ArIso") * `Si3N4` * `Aluminium`})
  .rename(f{nSiN <- "Si3N4"},
          f{nAl <- "Aluminium"},
          f{nAr <- "Abs Ar"},
          f{nIso <- "Abs Iso"},
          f{nArIso <- "Abs ArIso"}) # ,                    
  .gather([nSiN, nAl, nAr, nIso, nArIso, "Efficiency"], "Material", "Efficiency")

ggplot(df, aes("Energy [keV]", "Efficiency", color = "Material")) +
  geom_line() +
  xlab("Energy [keV]") + ylab("Efficiency") +
  xlim(0.0, 10.0) + 
  ggtitle(r"Transmission (absorption for gases) of relevant detector materials and combined \\" &
    "detection efficiency of the Septemboard detector",
    titleFont = font(10.0)) +
  margin(top = 1.25, right = 2.0) +
  legendPosition(0.42, 0.15) + 
  ggsave("/home/basti/phd/Figs/detector/detector_efficiency.pdf",
         #width = 800, height = 600,
         useTex = true, standalone = true) 
#+end_src

* Data acquisition, detector monitoring and preparation            :Detector:
#+LATEX: \minitoc
Having introduced the detector used for the data taking in this
thesis, we will now introduce the data acquisition (DAQ) software for the
detector (sec. [[#sec:daq:tof]] and [[#sec:daq:tos]]), discuss the data
formats used for readout as well as the logging facilities. Further,
we will introduce the calibrations performed for the Timepix to
achieve a correct operation with a GridPix detector as well as the
calibrations for the scintillators and FADC. Finally, we will present
the monitoring tools to monitor the detector operation (different
event displays) which are used for different data taking purposes.

- introduce TOS
- introduce data format
- logging data (temperature)
- different timepix calibrations (here?) maybe just introduce
  different calibrations and then in data taking part talk about what
  they actually look like?

- [ ] *INTRODUCE DAQ ACRONYM*  

** Timepix Operating Firmware - TOF [0/2]
:PROPERTIES:
:CUSTOM_ID: sec:daq:tof
:END:

Starting with the firmware of the detector, the \textbf{T}imepix
\textbf{O}perating \textbf{F}irmware (TOF), which runs on the Virtex-6
FPGA. TOF controls the Timepix ASICs of the Septemboard (both the slow
control aspects as well as the data taking) as well as coordinating
the scintillator signals and FADC trigger. It is a VHDL *OR NOT???*
project, intended to run at a clock frequency of
\SI{40}{MHz}. Communication with the GridPixes is done via two
\textbf{H}igh-\textbf{D}efinition \textbf{M}ultimedia
\textbf{I}nterface (HDMI) cables, while communication with the readout
software on the DAQ computer is handled via Ethernet.

For a detailed introduction to TOF, see \cite{lupberger2016pixel} as
well as \cite{*TOBI UPCOMING THESIS*}.


The firmware versions used for each data taking periods will be listed
with the other relevant parameters for each period in section *SECTION
NEEDS TO BE WRITTEN*.

- [ ] *CHECK IF VHDL*
- [ ] *LUPBERGER THESIS*

** Timepix Operating Software - TOS [0/2]
:PROPERTIES:
:CUSTOM_ID: sec:daq:tos
:END:

The \textbf{T}imepix \textbf{O}perating \textbf{S}ystem (TOS) is the
computer-side data acquisition software to read out Timepix based
detectors. It is an object oriented C++ project, available at *PUSH TO
GITHUB*. [fn:TOS_versions] *ACCORDING TO WIENER VME MANUAL ALL FILES
ARE OPEN SOURCE*
https://wikihost.nscl.msu.edu/S800Doc/lib/exe/fetch.php?media=wiki:manual_vm-usb_9_01_1.pdf
The project needs to be used in conjunction with the \textbf{T}imepix
\textbf{O}perating \textbf{F}irmware (TOF), which communicates with
TOS via Ethernet. The TOS project started as far back as 2009 by
people at the University of Mainz. Next is a short overview over the
basic blocks that make up the main logic of the software.

[fn:TOS_versions] There are unfortunately 2 different versions of TOS,
as development diverged for different readout systems. One version is
for the Xilinx Virtex-6 (V6) ML605 evaluation board and the other for
the \textbf{S}calable \textbf{R}eadout \textbf{S}ystem (SRS). The V6
version can read out only a single detector (with up to 8 Timepix
ASICs), but supports readout of an Ortec FADC and controlling a Wiener
HV module via VME. The SRS version instead supports neither of these
additional features, but supports multiple detectors at the same
time. The detector used in this thesis is read out using the Virtex-6
board.



- [ ] *PUSH TOS TO GITHUB OR SIMILAR AND REFERENCE*
- [ ] *CHECK AGAIN WIENER VME SOURCES OPEN SOURCE*  
*ADD FULL NAME OF V6 BOARD*

The fully object oriented nature of the project means that there are
different classes for the different software pieces:
- =Console=: A class representing the user facing REPL
  (Read-Evaluate-Print Loop, an 'interpreter') to control the
  software
- =PC=: A class representing the network layer and communication side
  of the software, sitting between the console and lower layers.
- =FPGA=: A class representing the functionality required to control
  the FPGA on the Virtex-6 evaluation board.
- =Chip=: A class representing each Timepix ASIC and its
  functionality.
- =HFManager=: A class unifying the FADC & Wiener HV control unit as
  they are both controlled via USB, installed in a VME crate. This
  class contains individual attributes that contain explicit classes
  for these two devices. The name is shortened for 'High Voltage and
  FADC Manager'.
  - =V1729=: A class representing the Ortec Flash ADC.
  - =HV*=: Multiple classes representing HV channels, groups and more.
- =MCP2210=: A class representing the PT1000 temperature sensors
  installed on the detector via a =MCP2210= micro controller,
  optionally connected via USB. The actual micro-controllers with
  attached PT1000s are =MAX31685= models.
- there are a few further classes of minor interest to the general
  functionality of TOS (tab command completion and history, classes
  to set masks on the chips, etc.)

In general TOS is a fully command line driven software package, with
its own REPL (Read-Evaluate-Print Loop; the name for an
interactive terminal process, which takes commands that are evaluated
and returns to the terminal). It brings all the expected features one
might wish from a REPL, including auto completion, history lookup,
emacs style keybindings and more.

The aforementioned =HFManager= and the temperature sensors are
optional pieces that are not required for basic Timepix
operation. Their functionality has to be activated via a manual
command, =ActivateHFM=. This triggers the USB connection to the VME
crate and tries to find the Wiener HV module as well as the Ortec FADC
in the crate. Additionally, the temperature sensors are attempted to
be found (via a secondary, optional USB connection). If the latter are
found a continuous temperature logging begins (see sec. [[#sec:daq:temperature_logging]]). 

The HV controls are specific to Wiener HV power supplies. In principle
the implemented functionality is a fully featured HV controller that
supports all Wiener functionality like grouping different channels to
ramp up together, kill channels on a trip and much more.

An example of a typical startup procedure is shown in listing
[[TOS_startup_commands]], in this case to start a background run. Note
that most essential commands in TOS also have shortened names via
numbers, due to historic reasons (TOS originally did not have
autocompletion or allowed moving the cursor in text input, making
typing complex names cumbersome and error prone), which is why many of
the inputs are simple numbers.

#+CAPTION: An example of the typical startup routine of TOS for a background data taking measurement at CAST
#+CAPTION: for the Septemboard based GridPix detector. The indented lines refer to commands given to the 
#+CAPTION: previous command at top level.
#+LABEL: TOS_startup_commands
#+begin_src sh
user@ingrid-DAQ~/ ./TOS
  > 7 # number of chips
  > 4 # preload
> SetChipIDOffset
  > 190
> lf # load FSR values for the chips
  > # return 7 times enter to load default paths
> uma # create a uniform matrix for all chips
  > 1 # Matrix settings
  > 0
  > 1
  > 1
  > 0
> LoadThreshold # load threshold equalisation files
  > 4 # write matrix
  > 3 # read out
  > 3 # 2nd readout to make sure pixels are 'empty'
> ActivateHFM # startup HV & FADC controls
> SetFadcSettings # load the FADC settings
> Run # start a data taking run
  > 1 # run time via # frames
  > 0
  > 0
  > 0
  > 2 # shutter range select
  > 30 # shutter time select (2 + 30 yields ~2.4 s frames)
  > 0 # zero suppression
  > 1 # FADC usage
  > 0 # accept FADC settings
#+end_src


Link to repositories (maybe we can make the Virtex TOS public?) 

- [ ] *Link to TOF firmware.*

- [X] *Septem event display example.* Section further down

- [ ] *INSERT TOS CONFIG FILES SOMEWHERE*


*** TOS output data format
:PROPERTIES:
:CUSTOM_ID: sec:daq:tos_output_format
:END:

TOS needs to talk about data format that was used in V6 TOS. Stupid
ASCII files. Mention that in hindsight the time should have been
invested to either use a really simple binary format (like NIO) or HDF5
(even if painful from C++).




Data taken with TOS is stored - for historic reasons - in raw ASCII
text files. Two different readout modes (with different output
formats) are supported. For the following explanation it is assumed
the Timepix is used in the ToT (Time-over-Threshold) mode.
1. full matrix readout: reads out the whole Timepix ASIC(s) and writes
   a single 256x256 pixel matrix as an ASCII file (for each chip). 256
   lines, each containing space separated ToT values for each pixel.
2. zero suppressed readout: reads out only those pixels that have ToT
   values larger than 0, up to \num{4096} pixels. Stores the data in
   TSV files (tab separated values) =X Y ToT= with an additional
   header. The header contains a global "run" and "event" header,
   which contains information about the run the event is taken from
   and a "chip" header, which contains information about the specific
   Timepix ASIC(s) being read out (up to 8 can be read out at the same
   time using TOS).

The Timepix is only capable of shutter based readouts. Typically, a
fixed shutter is used. The readout is complicated for the case of
using an FADC, in which case an FADC signal can be used as an external
trigger to close the shutter early. This will be further explained in
the FADC section, [[FADC]]
*REWRITE THIS PART, REFER TO SCHEMATIC ABOUT TIMEPIX*

As for our purposes most events are extremely sparse (< 500 pixels
active) the zero suppressed readout is the only relevant readout
mode. An example of the file type produced in this mode is in listing
[[zero_suppressed_readout]]. *REPHRASE*

The data files can be split into 3 distinct parts. A global run
header, see listing [[code:daq:zero_suppressed_readout_run_header]], which
contains information about the run the event is part of including important
settings used as well as the timestamp of the event. Next is an event
specific header, which contains specific information about the event
in relation to the FADC and the scintillators, see listing
[[code:daq:zero_suppressed_readout_event_header]]. The final part of the
data files is the chip header and tab separated value part of the ~X Y
ToT~ pairs of the active pixels for each chip of the detector in that
event, see listing [[code:daq:zero_suppressed_readout_chips]]. 

- [ ] *EXPLAIN RUN DATA LOCATION. DATA STORED IN =data/runs= AND
  DIRECTORY NAME SCHEMA*
- [ ] *HV AND WIENER VME EXPLANATION*  
- [X] *POSSIBLY SPLIT ZERO SUPPRESSED OUTPUT INTO CHUNKS? !! GENERAL
  HEADER, EVENT HEADER, CHIP HEADER, DATA*
- [ ] *ADD SECTION (EVEN IF POSSIBLY NOEXPORT) EXPLAINING THE FIELIDS
  OF THE DATA FILE*
- [ ] *ADD EXPLANATION OF HOW TO CALCULATE SHUTTER LENGTH. POSSIBLY
  SOMEWHERE HERE? OR IN TIMEPIX INTRO? NEED IT LATER TO EXPLAIN LENGTH
  OF EVENTS*  

#+CAPTION: TOS generated data files start by a general header, which mainly contains 
#+CAPTION: information about the run the data file is part of. The only exception is the
#+CAPTION: =dateTime= field, which represents the timestamp of the event. [fn:daq_datetime_header]
#+NAME: code:daq:zero_suppressed_readout_run_header
#+begin_src toml
## [General]
## runNumber:        339
## runTime:          7200
## runTimeFrames:    0
## pathName:         data/runs/Run_339_190218-10-36
## dateTime:         2019-02-18.10:36:34
## numChips:         7
## shutterTime:      2
## shutterMode:      verylong
## runMode:          0
## fastClock:        0
## externalTrigger:  0
#+end_src

#+CAPTION: After the general header follows the event header in similar fashion. It records
#+CAPTION: the event number and information about the FADC and scintillators. If the FADC triggered
#+CAPTION: ~fadcReadout~ is 1. Scintillator triggers may then be values in $[0, 4096)$. The ~fadcTriggerClock~
#+CAPTION: is the clock cycle of the Timepix frame in which the FADC trigger was received.
#+NAME: code:daq:zero_suppressed_readout_event_header
#+begin_src sh
## [Event]
## eventNumber:      2
## useHvFadc:        1
## fadcReadout:      1
## szint1ClockInt:   0
## szint2ClockInt:   0
## fadcTriggerClock: 647246
#+end_src

#+CAPTION: The event header is followed by the beginning of the actual GridPix data. Each chip
#+CAPTION: appears with a 3 line chip header containing number and name as well as the number
#+CAPTION: of hits seen by that chip in the event. ~numHits~ lines follow with ~X Y TOT~ values
#+CAPTION: in tab seperated fashion. This snippet would be followed by the remaining chips, 
#+CAPTION: as many as written in the run header [[code:daq:zero_suppressed_readout_run_header]]
#+CAPTION: as ~numChips~.
#+NAME: code:daq:zero_suppressed_readout_chips
#+begin_src sh
# chipNumber: 0
# chipName:   E 6 W69
# numHits:    0
# chipNumber: 1
# chipName:   K 6 W69
# numHits:    0
# chipNumber: 2
# chipName:   H 9 W69
# numHits:    2
106     160     75
211     142     2
#+end_src


[fn:daq_datetime_header] It is an oversight that the =dateTime= field
is part of the =[General]= header instead of the =[Event]= header.


**** FADC data files [/]
:PROPERTIES:
:CUSTOM_ID: sec:daq:fadc_data_files
:END:

If the FADC triggered during an event, as indicated by the
~fadcReadout~ field in the event header as seen in listing
[[code:daq:zero_suppressed_readout_event_header]], an additional data file
is written with the same name as the event file, but a ~.txt-fadc~
extension. It contains a memory dump of the channels of the circular
memory of the FADC plus a basic header about the FADC settings and the
information about when the trigger happened.

The different fields in the header, see listing
[[#code:daq:fadc_data_header]], are as follows:
- ~nb of channels~: decimal value of a 4-bit field that decides the
  number of active channels. ~0~ corresponds to using all channels as
  separate. We only use a single channel. [fn:fadc_chosen_settings]
- ~channel mask~: decimal value of a 4-bit field to (de-)activate
  channels. ~15~ corresponds to all 4 channels active.
- ~posttrig~: how many clock cycles in the \SI{50}{MHz} [fn:base_clock] base clock of
  the FADC after the threshold is crossed a trigger is sent.
- ~pretrig~: the minimum acquisition time before a trigger is allowed
  to happen, in units of the \SI{50}{MHz} [fn:base_clock] base clock.
- ~triggerrecord~: together with ~posttrig~ allows to reconstruct the
  time of the trigger in the acquisition window
- ~frequency~: decimal representation of a 6-bit field to select the
  operating frequency. ~2 = 0b000010~ corresponds to \SI{1}{GHz}
  operation.
- ~sampling mode~: decimal representation of a 3-bit field changing
  the operation mode (manual or automatic trigger) and register
  working mode (12 or 14-bit sensitivity of each register). We run in
  manual trigger and 12-bit mode. [fn:fadc_chosen_settings]
- ~pedestal run~: a 1-bit flag indicating whether this file is a
  pedestal run.

- [X] *Introduce FADC data files.*
- [ ] *VERIFY THE EXPLANATION OF THE HEADER FIELDS*
- [ ] *ISN'T THE POSTTRIG VALUE SOMETHING ONE SHOULD TAKE INTO ACCOUNT
  WHEN COMPUTING THE TIME OF THE ACTUAL TRIGGER IN RELATION TO OTHER
  DETECTOR FEATURES?*

#+CAPTION: The file starts with a header indicated by ~#~. Some of the values are
#+CAPTION: decimal representation of bit fields, hence the weird values like
#+CAPTION: "0 channels". It mixes both the configuration used as well as the
#+CAPTION: time the trigger occured (~triggerrecord~). 
#+NAME: code:daq:fadc_data_header
#+begin_src sh
# nb of channels: 0  
# channel mask: 15
# posttrig: 80
# pretrig: 15000
# triggerrecord: 56
# frequency: 2
# sampling mode: 0
# pedestal run: 0
#+end_src

The data portion starts with another semi-header of 12 data points,
see listing [[#code:daq:fadc_data_header_2]]. It contains fields that are
not explained in the FADC manual, but instead refer to "reserved for
expert usage" \cite{fadc_manual}. One exception is data point 2, which
is the so called Vernier, which could be used to determine the trigger
time within two registers to get up to $\sim\SI{50}{ps}$ RMS accurate
time information. For our purposes though \SI{1}{ns} time resolution
is more than enough, given the signal undergoes integration and
differentiation of a multiple of that anyway in the shaping amplifier.

#+CAPTION: After the header starts the data portion with some auxilaury information.
#+CAPTION: The lines are neither of significant interest to us, nor are they properly
#+CAPTION: explained in the manual. The second number corresponds to the Vernier, which
#+CAPTION: can be used to determine the trigger more precisely than between individual
#+CAPTION: register values, which is also not important for our purposes, as \SI{1}{ns}
#+CAPTION: resolution is plenty.
#+NAME: code:daq:fadc_data_header_2
#+begin_src sh
# Data:
# 3928
# 8022
# 3957
# 8076
# 3928
# 8023
# 3957
# 8077
# 2048
# 6138
# 2031
# 6151
#+end_src

The final portion of the file contains the actual data (\num{10240}
lines) and 3 fields at the very end to reconstruct the trigger within
the acquisition window [fn:fadc_data_last_3_lines]. The data
represents a pure memory dump of the cyclic register. See listing
[[code:daq:fadc_data_raw]] for a shortened example.

#+CAPTION: Actual data portion of the FADC data. The first \num{10240} lines represent
#+CAPTIOn: a memory dump of the cyclic registers at trigger time (that is in their natural
#+CAPTION: order instead of starting from the register in which the trigger was recorded).
#+CAPTION: It starts at register 0 for channel 0, followed by register 0 of channel 1, and so on.
#+CAPTION: As such each $4^{\text{th}}$ line corresponds to one channel. This is why the
#+CAPTION: values jump so much from line to line.
#+CAPTION: The last 3 lines are information to recover the trigger point in the acquisition
#+CAPTION: window [fn:fadc_data_last_3_lines].
#+NAME: code:daq:fadc_data_raw
#+begin_src sh
2028 # register 0, channel 0
6119 # register 0, channel 1
1999 # register 0, channel 2
6100 # register 0, channel 3
2021 # register 1, channel 0
6108 # ...
... # 10240 lines of data in total
# 56
# 4096
# 0
#+end_src

[fn:base_clock] If running in \SI{1}{GHz} mode. Else it corresponds to
\SI{100}{MHz} clocks.

[fn:fadc_chosen_settings] As of writing this thesis, I don't remember
why the choice was made to only use a single channel instead of using
all 4 channels to extend the time interval (development of these
things happened between 2015-2017). It's possible there were issues
trying to combine all 4 channels. But it's also just as likely it was
an oversight due to lack of time combined with the fact that a
\SI{2.5}{μs} window is long enough for all intents and
purposes. However, combining all 4 channels would even yield a long
enough acquisition window when running in the \SI{2}{GHz} sampling
mode. Similarly, the choice of the 12-bit readout mode may represent
plenty resolution in ADC values, but it seems prudent to not use the
14-bit mode given availability. All in all it leaves me head
scratching (and thinking the likely reason will have been lack of time
and being happy things working in the first place at the time).

[fn:fadc_data_last_3_lines] The last 3 lines of the data portion
contain the trigger record, which is already printed by us in the
header part and the ~Valp_cp~ and ~Vali_cp~ registers, which are only
important if the FADC is used at a sampling frequency of $<
\SI{1}{GHz}$, which is why we ignore it here.

***** Explanation of beginning of data portion                 :noexport:

Explanation of the data header [[#code:daq:fadc_data_header_2]] here:
- =hvFadcManager.cpp= =writeFadcData=
- FADC manual page 27 lists the data sent by the FADC.
  
However, neither explains what the "first sample" and the "rest
baseline" is. The manual calls these "expert features" and doesn't
explain them... That's how you keep it as an expert feature! The
second line is the Vernier, that I honestly don't really understand
either. I think it allows to more precisely find the time of trigger
between two register entries? Ah yes, see page 14 of the manual about
the Vernier. Allows for 50 ps RMS time information between two bins.

***** Explanation of FADC settings  :noexport:

As mentioned in the footnote in the previous section, I really don't
understand the choice of FADC settings we used for the actual data
taking. It's quite possible I'm nowadays just not aware of something
important, but well. Either way, unfortunately I only started being
serious about note taking about my work around the beginning of the
data taking period in October 2017. So retracing my thoughts during my
master thesis (2015-2016) and beginning of my PhD is unfortunately pretty much
impossible.

However, as mentioned the settings are good enough for what we are
doing with the data. The much bigger issues are related to the noise
we observed at times etc., which will be mentioned later.

*** TOS configuration file
:PROPERTIES:
:CUSTOM_ID: sec:daq:tos_config_file
:END:

Everything related to the =HFManager= in TOS is controlled by a
configuration file, normally located in
=TOS/config/HFM_settings.ini=. We will go through the sections of it
one by one and explain them.

Starting with the =[General]= section, listing
[[code:daq:general_config]]. This section defines the VME related
settings. The VME address of the HV module installed in the crate is
used as the base address. The FADC address in the same VME crate is
calculated from an offset in units of the VME address spacing of
=0x0400=. [fn:base_address_hv]

#+CAPTION: General section of the TOS configuration file. It sets the base address
#+CAPTION: of the HV module installed in the VME crate. The FADC address is given
#+CAPTION: as an offset from the base address.
#+NAME: code:daq:general_config
#+begin_src toml
[General]
sAddress_fadc = 1
baseAddress_hv = 0x4000
#+end_src 

The next section =[HvModule]=, listing [[code:daq:hv_module_config]], are
general settings about the used HV module. The settings are related to
the =KillEnable= feature of Wiener HV power supplies, the ramping
speed of the HV channels and the time in seconds between sanity checks
of the HV during data taking. [fn:check_hv_interval_setting]

#+CAPTION: The =[HvModule]= section contains settings related to the HV module as a whole.
#+CAPTION: Whether a single channel tripping causes all channels to ramp down (=KillEnable=)
#+CAPTION: the ramp speed and interval in which the HV module sanity status is checked.
#+NAME: code:daq:hv_module_config
#+begin_src toml
[HvModule]
setKillEnable                   = true
# Voltage and Current RampSped currently set to arbitrary value
# in percent / second
moduleVoltageRampSpeed          = 0.1
moduleCurrentRampSpeed          = 50
# checkModuleTimeInterval       = 60, checks the status of the
# module every 60 seconds during a Run, between two events
checkModuleTimeInterval         = 60
#+end_src

Next up, the =[HvGroups]= section in listing [[code:daq:hv_groups_config]]
defines the different groups that combine multiple channels. There are
multiple different kinds of groups in Wiener HV power supplies. The
important groups are ramping groups and trip groups. Essentially, if
one channel in a group starts ramping / trips all others also start
ramping / shut off the HV, respectively. The section in the config
file mainly exposes the already predefined sets of groups that are
relevant for the Septemboard detector in TOS. 

#+CAPTION: =[HvGroups]= defines multiple groups of different HV channels together. The
#+CAPTION: config file does not expose arbitrary groupings, but only sets flags whether
#+CAPTION: groups are active and what their numbers are.
#+NAME: code:daq:hv_groups_config
#+begin_src toml
# if this flag is set to true, anode and grid
# will be coupled to one group
[HvGroups]
anodeGridGroupFlag              = true
# grid is master channel of set on group
anodeGridGroupMasterChannel     = 4
anodeGridGroupNumber            = 0
monitorTripGroupFlag            = true
monitorTripGroupNumber          = 1
rampingGroupFlag                = true
rampingGroupNumber              = 2			     
gridChannelNumber               = 4
anodeChannelNumber              = 5
cathodeChannelNumber            = 8
#+end_src

After the =[HvGroups]= section is the definition of the individual HV
channels in listing [[code:daq:hv_channels_config]]. Here the physical
channels on the device are mapped to the desired voltages and current
bounds as well as to a human readable name. The fields repeat with
increasing prefix numbers.

#+CAPTION: This is an excerpt of the full =[HvChannels]= section for a single HV channel.
#+CAPTION: It maps the physical HV connectors to their voltages, current bounds and
#+CAPTION: a human readable name. In this case the grid of the GridPixes of the Septemboard
#+CAPTION: all receive a voltage of \SI{300}{V}. The naming scheme of the fields is 
#+CAPTION: hardcoded for practical reasons and simply repeats with increasing numbers.
#+NAME: code:daq:hv_channels_config
#+begin_src toml
[HvChannels]
# all currents given in A (vmecontrol shows mA)
0_Name                          = grid
0_Number                        = 5
0_VoltageSet                    = 300
0_VoltageNominal                = 500
0_VoltageBound                  = 2.5
0_CurrentSet                    = 0.000050
0_CurrentNominal                = 0.000500 
0_CurrentBound                  = 0
#+end_src

Second to last is the =[FADC]= section in listing
[[code:daq:fadc_config]]. As the name implies it configures all parameters
of the FADC. The main parameter to change is the
=fadcTriggerThresholdRegisterAll= parameter, which defines the trigger
threshold in effectively \si{mV}. Depending on the amount of noise in
the system, adjustments to the threshold may be necessary. 

#+CAPTION: The =[FADC]= section configures the FADC. The most important setting is the trigger
#+CAPTION: threshold as it defines the voltage required to trigger the FADC. 
#+NAME: code:daq:fadc_config
#+begin_src toml
[Fadc] # FADC Settings
fadcTriggerType                 = 3 
fadcFrequency                   = 2
fadcPosttrig                    = 80
fadcPretrig                     = 15000
# was 2033 before, 1966 corresponds to -40 mV
fadcTriggerThresholdRegisterAll = 1966 
# run time of a single pedestal run for the FADC in ms
fadcPedestalRunTime             = 100
# number of acquisition runs done for each pedestal calibration
fadcPedestalNumRuns             = 10
# using channel 0 on FADC as trigger source, thus bit 0 = 1!
fadcChannelSource               = 1
# set FADC mode register (mainly to enable 14-bit readout)
fadcModeRegister                = 0b000
#+end_src

The last section of the configuration file is the =[Temperature]=
section, which deals with the safety ranges of the temperature of the
detector. If the temperature leaves the safe range, the detector is to
be shut down. [fn:temperature_safety_config_settings]

#+CAPTION: =[Temperature]= defines the safe operating ranges of the detector. If the
#+CAPTION: range is left, the detector is to be shut down. 
#+NAME: code:daq:temperature_config
#+begin_src toml
[Temperature] # temperature related parameters, all temps in °C
safeUpperTempIMB                = 61
safeUpperTempSeptem             = 61
safeLowerTempIMB                = 0
safeLowerTempSeptem             = 0
#+end_src

[fn:base_address_hv] If in doubt about what the base address of the HV
supply in the VME crate is, start one of the Wiener HV programs (for
example =isegControl=), as it auto detects the module and prints the
address.

[fn:check_hv_interval_setting] The =checkModuleTimeInterval= setting
to check the HV status during the data taking was disabled at CAST, as
it caused issues due to false alarms of the HV status. Given that the
=KillEnable= flag was used, it was deemed unimportant. Attempting to
fix it would have caused possible data loss as it would have been
tested on the live detector.

[fn:temperature_safety_config_settings] The temperature safety range
is coupled to the =checkModuleTimeInterval= setting in the previous
footnote. It was disabled together with the above during actual data taking.

*** HV control via TOS

As is being alluded to in the previous section 
[[#sec:daq:tos_config_file]], the HV control built into TOS can also
handle ramping the channels of the detector. This is particularly
convenient as it offers a very smooth ramping mode, which keeps the
voltage potentials between all channels under a constant
ratio. This allows for automatic ramping even for highly sensitive
channels (like the GridPix grid).

In order to use the HV control and ramp the channels via TOS,
=ActivateHFM= must be followed by =InitHV=, which attempts to connect
to the HV power supply using the configuration of the config file. If
the channels are not ramped up, a call to =RampChannels= will start
the smooth ramping process (see listing [[code:daq:ramp_hv_channels]]).

#+CAPTION: The required commands to ramp the HV channels using the configuration
#+CAPTION: from the config file using a smooth ramping mode.
#+NAME: code:daq:ramp_hv_channels
#+begin_src sh
> ActivateHFM
> InitHV
> RampChannels
#+end_src

If the HV is to be ramped down, a call to =ShutdownHFM= will ask
whether the channels should be ramped down.

There are a multitude of further commands available to communicate
with the module, check the voltages, print status information etc.

Note that TOS can be started without ramping the HV channels and
stopped without ramping the channels down. It is capable of connecting
to a running HV power supply or leave it running after shut down. 

*** Temperature monitoring

- [ ] *SHOULD EXPLANATION OF THE READOUT _HARDWARE_ NOT BE IN THE
  DETECTOR CHAPTER?*

The two =MAX31685= micro controllers read out =PT1000= sensors, a
group of \textbf{R}esistance \textbf{T}emperature \textbf{S}ensors
(RTDs), which measure temperatures by its effect on the electrical
resistance. They are platinum based and have a resistance of
\SI{1000}{Ω} at \SI{0}{\degree\celsius}. As the expected change in
resistance is well understood, the temperature can be precisely
measured.

The micro controller communicates with another micro controller, an
=MC2210= via the \textbf{S}erial \textbf{P}eripheral
\textbf{I}nterface (SPI). SPI allows to address both =MAX31685= from
the single =MCP2210=. The =MCP2210= is a USB-to-SPI micro
controller. The USB connection from the intermediate board with the
computer is separate from the rest of the detector
communication. =TOS= communicates with it via the standard
\textbf{H}uman \textbf{I}nteface \textbf{D}evice (HID) driver and
utilizes an existing open source library for the =MCP2210=
\cite{wong_mcp2210}, which is slightly adapted.

The =ActivateHFM= command mentioned in the previous section also
attempts to find the USB device of the =MCP2210= (the two are
intertwined mainly, as the Septemboard detector is the only detector
with either of the two features). If it is found, temperature logging
starts immediately and the log files are placed in the default =log=
directory of the =TOS= repository. Once a data taking run starts,
the logging location is moved over to the data storage directory of
the run. In either case the log file is named =temp_log.txt= and
contains one temperature value for the intermediate board sensor
(=Temp_IMB=) and one for the carrier board sensor (=Temp_Septem=)
computed - based on an average over \SI{5}{s} - and a timestamp
(=DateTime=). A short snippet of the temperature log is shown in listing
[[code:daq:temperature_readout]]. [fn:temp_logs_lost]

- [X] *INSERT TEMPERATURE LOGGING EXAMPLE SNIPPET*
- [ ] *THINK ABOUT PUTTING FOOT NOTE INTO ACTUAL TEXT*
- [ ] *ADD CITATION* https://github.com/kerrydwong/MCP2210-Library  

#+CAPTION: Snippet of a temperature log file as recorded for a run during the
#+CAPTION: CAST detector lab measurements. Tabs were replaced by spaces for
#+CAPTION: better visual alignment here.
#+NAME: code:daq:temperature_readout
#+begin_src sh
# Temperature log file
# Temp_IMB  Temp_Septem   DateTime
26.5186     42.1472       2019-02-16.16:11:45
26.5217     42.2798       2019-02-16.16:11:51
26.5202     42.4371       2019-02-16.16:11:57
26.5309     42.5944       2019-02-16.16:12:03
26.5324     42.7347       2019-02-16.16:12:09
26.5355     42.8627       2019-02-16.16:12:15
26.5416     42.9707       2019-02-16.16:12:21
26.5432     43.0771       2019-02-16.16:12:27
26.5616     43.1804       2019-02-16.16:12:33
26.5692     43.2684       2019-02-16.16:12:39
26.5708     43.3454       2019-02-16.16:12:45
26.5908     43.4164       2019-02-16.16:12:51
26.5969     43.4904       2019-02-16.16:12:57
26.6015     43.5598       2019-02-16.16:13:03
26.6184     43.6154       2019-02-16.16:13:09
26.6215     43.6709       2019-02-16.16:13:15
26.6368     43.7264       2019-02-16.16:13:21
...
#+end_src

[fn:temp_logs_lost] This default temperature logging location was also
used as an unintended fallback mechanism during data taking, if the HV
of the detector was considered out of certain bounds. Unfortunately,
the bounds checking was entangled with the HV module sanity checks. As
both features were very only implemented shortly before data taking,
they triggered data taking aborts. For that reason the feature was
disabled manually in code for the data taking at CAST. This however
triggered a secondary code path for the temperature logging, storing
it in the default location outside the specific run directories. As an
effect the majority of CAST temperature logging data has been lost, as
most of it was overwritten several times. About daily manual
temperature measurements are still left and show the detector
operating in a good temperature range. Precise correlations with
certain detector behaviors are unfortunately impossible. The two
different code paths for the temperature logging are essentially a bug
in the code that was never intended, stemming from the fact that
temperature logging must be done to a 'global' location outside of
data taking (as no data taking specific directory exists). Due to how
the temperature logging and HV & FADC controls were added to TOS,
these things were more entangled than necessary. A more thorough
testing period of the detector and software package should have been
performed, but was not in scope.



*** TOS development                                              :noexport:

As mentioned in one of the footnotes in the previous section, there
are nowadays 2 independent versions of TOS.

The detector used for CAST in 2014/15 (and thus its successor used in
this thesis) was based on a readout using the Virtex 6 FPGA. This
system was, at the point I started on my master thesis in 2015,
already quite diverged from the SRS based system, which was mainly
developed for multi chip detectors that were initially planned for a
large GridPix based TPC to be used for the ILD (the detector planned
for the ILC, the International Linear Collider to be built in Japan).

In addition there was recent a master thesis (by Alexander Deisting, ref
*CITE DEISTING*), which included work on using an FADC to read out the
induced charges on the grid of the InGrid by decoupling the signal
using a capacitor.
The software library to interact with the used FADC had partially been
implemented into the Virtex 6 TOS. 

As the FADC was an integral part in the new detector design, it was
natural to start with the Virtex 6 version.

At the same time the SRS TOS version at the time was even more
ugly than the same code paths in the Virtex 6 TOS.

... 

A large amount of time spent

*what else*


** schematic of whole readout chain [0/1]

*ELSEWHERE AS WELL?*

Create a full flow chart of how everything is connected.

We have our notes about where each cable goes etc.

We have a schematic in the master thesis. That can be modified a bit
for the PhD thesis.

- [X] *THIS IS IN DETECTOR OVERVIEW NOW*

** Septemboard event display [/]

In order to monitor the data taking process while the detector is
running, an online event display tool was developed during the first
CAST data taking period in March 2017. It is a Python [fn:daq_python]
based project making heavy use of =matplotlib= \cite{Hunter:2007} for
an interactive view of both the Septemboard events as they are
recorded, the FADC readout as well as a general information header
about the current data taking run.

The backend consists of a multiprocessing architecture with multiple
worker processes. One process watches the current run directory for
changes and reads the raw data files, another performs basic event
reconstruction and another one updates the current event to be
displayed. The main process renders the =matplotlib= based graphical
user interface (GUI) [fn:daq_backend]. 

Fig. [[fig:daq:septemboard_event_display_example]] shows the graphical
user interface of the septemboard event display during a background
run. General information about the current run and event is shown in
the box at the top center. The top left box shows hit specific
information for the current event.  The current septemboard event is
always shown in the left pane in a realistic layout of the
septemboard. By default the Viridis *CITE VIRIDIS* color scale is used
in the display of the septemboard events, each shown as an image of
$(256, 256)$ pixels. If a chip did not record any activity during an
event, its plot remains white for easier identification of few hits
compared to no hits. The color scale can be adjusted when starting the
program and the images can be downsampled by any factor of 2 for
better visibility, as is done in
fig. [[fig:daq:septemboard_event_display_example]]. The right pane of the
event display shows the last recorded event of the FADC. It does not
automatically update the plot every time a new septemboard event is
recorded, as there can be multiple events without FADC activity and it
is useful to be able to glance at the last large event on the
FADC. The filename is printed as the title of the plot to show which
septemboard event it corresponds to.

- [ ] *CITE SOMETHING FOR VIRIDIS COLORSCALE*

#+CAPTION: Screenshot of the Septemboard event display showing a background
#+CAPTION: event from a CAST data taking run in 2017. The pixel density in the
#+CAPTION: septemboard on the left has been downsampled by a factor of 2 from
#+CAPTION: $(256, 256)$ for each chip to $(128, 128)$ for better visibilty of
#+CAPTION: the activity. The event display shows general information like run and
#+CAPTION: event number in the box at the top, hit specific information for the 
#+CAPTION: current event in the left top box and the current septemboard event
#+CAPTION: in the left pane. The right pane shows the last FADC event (if no
#+CAPTION: new FADC event is recorded, it stays).
#+NAME: fig:daq:septemboard_event_display_example
[[~/phd/Figs/daq/example_event_display.pdf]]

The event display provides multiple forms of interactivity, such as an
"auto follow" mode (the default in which new events are shown as they
are recorded), a "playback" mode (walks through all events with a
certain delay and general back and forth optionality. Further, a
shortcut to save images directly exists, as well as simple computation
of aggregate statistics of the current data taking period (different
occupancy maps and simple histograms showing the number of hits per
each event and chip).

All in all it provides a simple, but powerful way to monitor the
detector activity online as it takes data. [fn:daq_downsides]

[fn:daq_python] https://python.org

[fn:daq_backend] =matplotlib= provides a multitude of different GUI
backends. The explicit choice depends on the specific machine
(available backends may differ) and preference. Common choices are GTK
and TkAg. *CHECK BACKENDS*

[fn:daq_downsides] The main drawbacks are related to it being a
Python based project that utilizes =matplotlib= possibly too
heavily. The combination means the tool is not useful for fast data
taking, as it is too slow to show events in real time if data taking
exceeds one frame per second significantly.

** Timepix calibrations etc.

*ELSEWHERE AS WELL*

What kind of calibrations exist. How do they work, what do they do
etc.

From a purely detector standpoint.

Polya distribution goes here somewhere. Related to gaseous detector
physics & our detector in particular.

Before a Timepix based detector can be used for data taking, different
calibrations have to be performed.

We will discuss the main calibrations that are performed, starting
with a =THS= optimization and threshold equalization
(sec. [[#sec:daq:ths_opt_equalization]]). Next, the S-Curve scan
(sec. [[S-Curve scan]]) and finally the ToT calibration, section [[ToT
calibration]]. In these the first 3 are calibrations that are used to
set different DACs on the Timepix to 'good' values. The last
calibration on the other hand is one to *interpret* the ToT values in
amounts of charge.

- [ ] *REPHRASE, SCURVE NOT TO SET A DAC. SCURVE USED TO ESTIMATE THE THRESHOLD IN ELECTRONS*

In principle there are many other calibrations one could perform, as
the Timepix has *CHECK NUMBER* 10 different DACs. Most are used with
default values that are seen in *TABLE OF CALIBRATION*.

These calibrations are mainly explained to give context for the used
detector calibrations at CAST. All calibrations can be found in
appendix *APPEND CALIBRATIONS*.

Important references for the Timepix in general and for the
calibration procedures explained below are
\cite{LLOPART2007485_timepix, LlopartCudie_1056683, timepix_manual, lupberger2016pixel}.

*** =THS= optimization and threshold equalization
:PROPERTIES:
:CUSTOM_ID: sec:daq:ths_opt_equalization
:END:

For an optimal operation of a Timepix based detector, each pixel
should ideally have the same threshold. While all pixels are
theoretically identical, imperfections in the production process will
always lead to slight differences, either locally (transistor
threshold voltage or current mismatches
\cite{LLOPART2007485_timepix,pelgrom1989matching} ) or global effects
like small supply voltage instabilities. Therefore, each pixel has 4
independently selectable current sources to minimize the spread of
threshold values
\cite{timepix_manual,LLOPART2007485_timepix}. Together all 4 sources
act as an effective 4-bit DAC to slightly adjust the threshold. The
absolute current for the 4 sources is dependent on the global =THS=
DAC, allowing currents in the range of \SIrange{0}{40}{nA}.

To achieve a good calibration for a homogeneous threshold, first the
=THS= DAC has to be set correctly. This is referred to as the =THS=
optimization. Once the correct value is found, the 4-bit DAC on each
pixel can be adjusted to minimize the spread of threshold values of
all pixels together.

If the =THS= DAC is set too high, the 4-bit DAC on each pixel will be
too coarse for a fine adjustment (as the 'current steps' will be too
large). If it is too low, not enough range will be available to adjust
each pixel to an equal noise / sensitivity level (not enough current
available via the 4 current sources). The goal of the =THS=
optimization is therefore to find just the right value, as to provide
a range of values such that all values can be shifted to the same
threshold of the threshold DAC =THL=.

The algorithm scans a range of =THL= values through a subset of 4096
pixels using pixel 4-bit DAC values first of 0 for all pixels and then
the maximum value of 15. At each =THL= value and 4-bit value the
number of hits due to pure noise is recorded for each pixel. The
weighted mean of the =THL= values using the number of hits as weight
is the value of interest for each pixel and each 4-bit DAC 0 and 15
value, the effective =THL= noise value for that pixel. For each of the
two cases we can then compute a histogram of the number of pixels at
each =THL= value. The resulting histogram will be a normal
distribution around a specific =THL= value. The stopping criterion,
which defines the final =THS= value, is such that these two
distributions overlap at the 3 RMS level. This is performed by
comparing the means of the 0 and 15 value distribution at a starting
=THS= value and again at half of that =THS= value. Using linear
regression of the two differences, the optimal =THS= value is
computed.

- [ ] *I THINK THS OPT DOES NOT!! USE TEST PULSES* Yes, pretty sure
  now. The THS optimization (and obviously threshold equalization)
  does not use test pulses

- [ ] *INTRODUCE THE NAME 'PIXEL DAC' INSTEAD 4-BIT DAC?*  

- [ ] *MAYBE REPHRASE THE FOLLOWING. BUT THIS IS WHAT'S HAPPENING. THE TOS CODE IS PRETTY SIMPLE, JUST BLOATED AND UGLY*

With a suitable =THS= value set, the actual threshold equalization can
start. The algorithm used is fundamentally very similar to the logic
of the =THS= optimization. Each pixel of the chip is scanned for a
range of =THL= values and the weighted =THL= noise mean is computed
both at a 4-bit DAC value of 0 and at 15. The normalized deviation of
each pixel's =THL= value to the mean =THL= value of all pixels is
computed. Using a linear regression the optimal required shift (in
units of the 4-bit DAC) yields the final 4-bit DAC value for each
pixel.

An example of the 0 and 15 value distributions as well as the
distribution using the final 4-bit DAC values for each pixel is shown
in fig. [[fig:daq:optimal_ths_distributions]]. [fn:daq_histo_source] Each
of the distributions represent different 4-bit DAC settings of all
pixels of the chip. Orange ("min") represents all pixels using a 4-bit
DAC value of 0, purple ("max") of 15. In green is the same
distribution for the case where every pixel uses its optimal 4-bit DAC
value. The threshold equalization thus yields a very strong reduction
in the =THL= spread of all pixels. Fig. [[fig:daq:4bit_dac_distribution]]
shows how all pixels are spread in the values of the 4-bit DAC. The
narrow equalized line of fig. [[fig:daq:optimal_ths_distributions]] is
achieved by a normal distribution around \num{8} of the 4-bit DAC
values, with only very few at the edges of the DAC (\num{0} and \num{15}).

#+CAPTION: Distributions of different 4-bit DAC settings of all
#+CAPTION: pixels of the chip. Orange ("min"): all pixels using a 4-bit
#+CAPTION: DAC value of 0, purple ("max"): 15. Green: every pixel uses the
#+CAPTION: optimal 4-bit DAC value after equalization. The result is a significant
#+CAPTION: in =THL= value spread of all pixels.
#+NAME: fig:daq:optimal_ths_distribution
[[~/phd/Figs/detector/calibration/ths_optimization_distributions_example.pdf]]

#+CAPTION: Distribution of all 4-bit DAC values for the pixels after the
#+CAPTION: threshold equalization. A normal distribution around a middle
#+CAPTION: value is expected to largest likelihood of achieving a flat
#+CAPTION: threshold around the whole chip. Very few pixels are either in 
#+CAPTION: value \num{0} or \num{15}, implying few pixels likely outside their
#+CAPTION: range to adjust to the required threshold. In this example
#+CAPTION: represented is the center chip of the Septemboard with its calibration
#+CAPTION: from July 2018.
#+NAME: fig:daq:4bit_dac_distribution
[[~/phd/Figs/detector/calibration/optimized_equalization_bits_example.pdf]]

#+CAPTION: Heatmap of the distribution of the 4-bit DAC values of all chips
#+CAPTION: as they are spread over the full Timepix. In this example
#+CAPTION: represented is the center chip of the Septemboard with its calibration
#+CAPTION: from July 2018.
#+NAME: fig:daq:4bit_dac_heatmap
[[~/phd/Figs/detector/calibration/heatmap_threshold_equalization_example.pdf]]


- [ ] *FIRST EXPLAIN THS OPT, THEN EQ, BOTH USING THE PLOT*  

- [X] *REWRITE BELOW FOLLOWING THE ABOVE NOW*
- [X] *MENTION THIS IS TO MAKE EQUALIZATION OF EACH PIXEL DAC NICE*

- [ ] *PSEUDO CODE ALGORITHM? I THINK IT WOULD CLARIFY THE EXPLANATION QUITE A BIT. ESPECIALLY BECAUSE IT'S NOT DIFFICULT. JUST TOS IS
  UGLY*

*PLOT OF THESE TWO HISTOGRAMS. SHOW MAYBE IDEALIZED EXAMPLE OF BAD THS
AND GOOD THS VALUE*

- [X] *LOOK AT TOS CODE AGAIN*
  
- [X] *LOOK AT TOS CODE FOR EQUALIZATION AGAIN*

*CROSS CHECK THE NAMES ETC*

[fn:daq_histo_source] The plot is generated from the
=thresholdMeans.txt= file created as part of the equalization
procedure in TOS.


[fn:daq_tos_code_quality] Having to check out the TOS code to verify
the logic of the THS optimization and equalization procedures reminded
me of the abhorrent code quality of that code base. Holy moly...

**** Generate the plot for the THS optimization result :noexport:

#+begin_src nim :tangle code/ths_optimization.nim
import ggplotnim

proc main(fname: string) =
  var df = readCsv(fname, sep = '\t', colNames = @["x", "y", "min", "max", "bit", "opt"])
  let breaks = linspace(-0.5, 15.5, 17).toSeq1D
  echo breaks
  ggplot(df, aes("bit")) +
    geom_histogram(breaks = breaks, hdKind = hdOutline) +
    scale_x_continuous() +
    xlim(-0.5, 16.5) +
    xlab("4-bit DAC") + 
    ggtitle("Distribution of all equalization bits after optimization") + 
    ggsave("/home/basti/phd/Figs/detector/calibration/optimized_equalization_bits_example.pdf",
           useTeX = true, standalone = true)
  df = df.gather(["min", "max", "opt"], "type", "THL")
  ggplot(df, aes("THL", fill = "type")) +
    geom_histogram(binWidth = 1.0, position = "identity", hdKind = hdOutline, alpha = 0.7) +
    ggtitle("THL distributions for all equalization bits at 0, 15 and optimized") +
    ggsave("/home/basti/phd/Figs/detector/calibration/ths_optimization_distributions_example.pdf",
           useTeX = true, standalone = true)
when isMainModule:
  import cligen
  dispatch main
#+end_src

#+begin_src sh
./code/ths_optimization -f ~/septemH_calibration/SeptemH_FullCalib_2018_2/chip3/thresholdMeans3.txt
#+end_src

#+begin_src nim :tangle code/threshold_equalization_heatmap.nim
import ggplotnim
import std / [sequtils, strutils]

proc main(fname: string) =
  let aranged = toSeq(0 .. 255).mapIt($it)
  var df = readCsv(fname, sep = '\t', colNames = aranged)
  df["y"] = toSeq(0 .. 255)
  df = df.gather(aranged, "x", "4-bit DAC")
    .mutate(f{"x" ~ `x`.parseInt})
  echo df
  
  ggplot(df, aes("x", "y", fill = "4-bit DAC")) +
    geom_raster() + 
    #scale_x_continuous() +
    #xlim(-0.5, 16.5) +
    xlim(0, 255) + ylim(0, 255) + 
    ggtitle("Heatmap of all equalization bits after optimization") + 
    ggsave("/home/basti/phd/Figs/detector/calibration/heatmap_threshold_equalization_example.pdf",
           useTeX = true, standalone = true)

when isMainModule:
  import cligen
  dispatch main
#+end_src

#+begin_src sh
./code/threshold_equalization_heatmap -f ~/septemH_calibration/SeptemH_FullCalib_2018_2/chip3/threshold3.txt
#+end_src

**** Relevant code for calculation of mean values from TOS :noexport:

Filling of =sum= in =THscan=. =array_pos= is effectively the =THL=
value currently being scanned. =pix_tempdata= is the response matrix
of each pixel (contains hit counter for each pixel). Also fills
=hit_counter=, which is simply the counts.
#+begin_src c++
    fpga->DataFPGAPC(pix_tempdata2,chp); //!!!only one chip!!!
    for(short y=step;y<256;y+=(256/pix_per_row)){
	for(short x=0;x<256;x++){
	    if(pix_tempdata2[y][x]>=20 and pix_tempdata2[y][x]!=11810){
		//if (pix_tempdata2[y][x]>=200) {std::cout << "hits for thl " << thl <<" :" << pix_tempdata2[y][x] << std::endl;}
		p3DArray[y][x][array_pos] = pix_tempdata2[y][x];
		//if(LFSR_LookUpTable[(*VecData)[chp][y][x]]>=20 and LFSR_LookUpTable[(*VecData)[chp][y][x]]!=11810){
		//p3DArray[y][x][array_pos] = LFSR_LookUpTable[(*VecData)[chp][y][x]];
		sum[y][x]+=p3DArray[y][x][array_pos]*(array_pos);
		hit_counter[y][x]+=p3DArray[y][x][array_pos];
	    }
	    else{
		p3DArray[y][x][array_pos] = 0;
		sum[y][x]+=0;
		hit_counter[y][x]+=0;
	    }
	}
    }
#+end_src
And in the =THSopt= the code to compute the mean:

#+begin_src c++
	for(y=0;y<256;y++){
	    for(x=0;x<256;x++){
		if (hit_counter0[y][x]!=0){
		    mean0[y][x] = sum0[y][x]/hit_counter0[y][x];
		    mean0entries += 1;
		    summean0 += mean0[y][x];
		}
		if (hit_counter15[y][x]!=0){
		    mean15[y][x] = sum15[y][x]/hit_counter15[y][x];
		    mean15entries += 1;
		    summean15 += mean15[y][x];
		}
	    }
	}
#+end_src

Length of shutter used is
#+begin_src c++
    // calling CountingTime with second argument == 1
    // corresponds to n = 1, power of 256
    fpga->CountingTime(10, 1);
#+end_src
(could compute the length, but not important right now)

Given that the =THscan= is run for each THL value (and thus summing up
all contributions of all THL values for =sum0=), the algorithm
effectively computes:
#+begin_src
mean = Σ_i #hits_i * THL_i / Σ_i #hits_i
#+end_src
which is simply *the weighted mean of the =THL= value, weighted by the
number of hits.* Essentially we compute the THL value with the most
dominant noise? In a sense it makes sense as changing the 4-bit DAC
will move around the position of that noise effectively. The 

The point of interest then here is the fact that the number of hits
depends on the THL value strongly. We only see the number of injected
test pulses, if we're above the noise. Ideally we don't want to see
any noise due to too low =THL= range. Therefore let's check what is
used in TOS.

We will verify this by computing the same value for an S-curve
calibration file:
#+begin_src nim
import ggplotnim

const path = "/home/basti/septemH_calibration/SCurve/chip_3/voltage_100.txt"
let df = readCsv(path, sep = '\t', header = "#", colNames = @["THL", "counts"])
  .filter(f{`THL` > 424})
echo df
let thls = df["THL", float]
let counts = df["counts", float]
var sum = 0.0
var hits = 0.0
for (thl, count) in zip(thls, counts):
  sum += count * thl
  hits += count
echo "Mean value = ", sum / hits
#+end_src

#+RESULTS:
| DataFrame |  with |      2 |           columns | and | 175 | rows: |
|       Idx |   THL | counts |                   |     |     |       |
|    dtype: |   int |    int |                   |     |     |       |
|         0 |   425 |   1000 |                   |     |     |       |
|         1 |   426 |   1000 |                   |     |     |       |
|         2 |   427 |   1000 |                   |     |     |       |
|         3 |   428 |   1000 |                   |     |     |       |
|         4 |   429 |   1000 |                   |     |     |       |
|         5 |   430 |   1000 |                   |     |     |       |
|         6 |   431 |   1000 |                   |     |     |       |
|         7 |   432 |   1000 |                   |     |     |       |
|         8 |   433 |   1000 |                   |     |     |       |
|         9 |   434 |   1000 |                   |     |     |       |
|        10 |   435 |   1000 |                   |     |     |       |
|        11 |   436 |   1000 |                   |     |     |       |
|        12 |   437 |   1000 |                   |     |     |       |
|        13 |   438 |   1000 |                   |     |     |       |
|        14 |   439 |   1000 |                   |     |     |       |
|        15 |   440 |   1000 |                   |     |     |       |
|        16 |   441 |   1000 |                   |     |     |       |
|        17 |   442 |   1000 |                   |     |     |       |
|        18 |   443 |   1000 |                   |     |     |       |
|        19 |   444 |   1000 |                   |     |     |       |
|           |       |        |                   |     |     |       |
|      Mean | value |      = | 463.8075954222876 |     |     |       |

which results in a mean value of 463.8. Given the range of data
that's, surprise, what we would expect from a weighted mean with the
hit counter used.

Of course, in the =THS= optimization the input is purely noise and not
a fixed set of test pulses.

*** Final =THL= (threshold) DAC value selection [0/1]

... THL scan at desired shutter length! Semi automatically. Scan a
take no noise + 2

Once the detector is =THS= optimized and threshold equalized, the
final threshold value of the =THL= DAC can be determined for the data
taking. While measurements like an S-Curve scan (see
sec. [[#sec:daq:scurve_scan]]) can be used to understand where the noise
level of the chip is in terms of =THL= values, it is typically not a
reliable measure as the real noise depends strongly on the shutter
length. If an experiment - like a low rate experiment as CAST -
requires long shutter lengths, the best way to determine the lowest
possible noise-free =THL= value is to perform a simple scan through
all =THL= values using the shutter length in use for the experiment.

For a correctly equalized chip a sharp drop off of noisy pixels should
be visible at a certain threshold. In principle the =THL= value at
which no more pixels are noisy is the ideal =THL= value.

- [ ] *REPHRASE AND NOT TALK ABOUT ENC HERE?*
Each Timepix pixel has an electronic noise charge (ENC) of *CHECK
THIS* electrons. Of course the behavior of the charges on the pixels
are statistically distributed. For the different calibrations
typically very short shutter opening times are used to get fast
calibrations. For practical data takings at experiments like CAST,
very long shutter times on the order of $\mathcal{O}(> \SI{1}{\s})$
are used however. Due to the statistical nature of noise, a =THL=
value that is noise less may not be fully noise free for long
shutters. Therefore, one often uses =THL= values that are slightly
larger (i.e. ~3 values larger of the 10 bit DAC).

In this sense the S-Curve scan is a good cross check for whether the
=THL= value seems sensible, but in practice a =THL= scan with a longer
shutter time is more useful. 

- [ ] *CHECK ENC VALUE OF TIMEPIX AND CITE TIMEPIX PAPER*
  -> ENC is ~100 (timepix paper), but the ENC isn't the relevant
  property here. I think I misunderstood what the ENC really is.
- [ ] *FOR THE SECTION ABOVE I THINK ONLY THE MINIMALLY DETECTABLE
  CHARGE IS RELEVANT?*
- [ ] *REWRITE FULL SECTION WITH A CLEAR HEAD*  

*** ToT calibration
:PROPERTIES:
:CUSTOM_ID: sec:daq:tot_calibration
:END:

The purpose of the ToT (\textbf{T}ime \textbf{o}ver
\textbf{T}hreshold) calibration is not to perform a calibration for
stable operation of a Timepix based detector, but rather to interpret
the data received. It is needed to interpret the =ToT= values recorded
by each pixel as a charge, i.e. a number of recorded electrons.

This is done by injecting charges onto the individual pixels - 'test
pulses'. Capacitors are present to inject very precise voltage bursts
onto the pixels. In case of the Timepix 1, each pixel uses a
capacitance of \SI{8}{fF} \cite{timepix_manual}. Knowing the
capacitance and the voltage induced on them, the number of injected
electrons can be easily calculated from

\[
Q = C U.
\]

By varying the injected charge and recording the resulting ToT values
of the pixels a relation between electrons and ToT values is
determined:

#+begin_comment
  ## calculates the charge in electrons from the TOT value, based on the TOT calibration
  ## from MarlinTPC:
  ## measured and fitted is ToT[clock cycles] in dependency of TestPuseHeight [mV]
  ## fit function is:
  ##   ToT[clock cycles] = a*TestPuseHeight [mV]  + b - ( c / (TestPuseHeight [mV] -t) )
  ## isolating TestPuseHeight gives:
  ##   TestPuseHeight [mV] = 1/(2*a) * (ToT[clock cycles] - (b - a*t) +
  ##                         SQRT( (ToT[clock cycles] - (b - a*t))^2 +
  ##                               4*(a*b*t + a*c - a*t*ToT[clock cycles]) ) )
  ## conversion from charge to electrons:
  ##   electrons = 50 * testpulse[mV]
  ## so we have:
  ## Charge[electrons] = 50 / (2*a) * (ToT[clock cycles] - (b - a*t) +
  ##                     SQRT( (ToT[clock cycles] - (b - a*t))^2 +
  ##                           4*(a*b*t + a*c - a*t*ToT[clock cycles]) ) )
#+end_comment

\[
f(p) = a p + b - \frac{c}{p - t}
\]
where $a, b, c$ and $t$ are parameters to be determined via a
numerical fit and $p$ is the test pulse height in \si{mV}.

As such, inverting the relation this can be used to compute a charge
for a given =ToT= value: 

\[
f(\mathrm{ToT}) = \frac{α}{2 a} \left( \mathrm{ToT} - (b - a t) +
\sqrt{ \left( \mathrm{ToT} - (b - a t) \right)^2 + 4 (a b t + a c - a
t \mathrm{ToT} ) } \right)
\]
where $\mathrm{ToT}$ is the time over threshold value recorded for a
pixel, the constants $a, b, c, t$ the fit parameters determined above
and $α$ the conversion factor relating the number of electrons from a
pulse height of $\SI{1}{mV}$. 

An example of a ToT calibration of one chip is shown in
fig. [[fig:septem:tot_calibration_example]].

*TODO*:
- [ ] add =--outpath= argument to =plotCalibration= and use it to
  place it where we read it from
#+begin_src sh :exports none
# To generate fig:septem:tot_calibration_example
plotCalibration --tot --chip=3 --runPeriod=Run2 --useTeX
#+end_src

#+ATTR_LATEX: :width 0.8\textwidth
#+NAME: fig:septem:tot_calibration_example
#+CAPTION: Example of a ToT calibration measurement for the chip *INSERT CHIP*
#+CAPTION: as it was done for the CAST data taking period 2. *TODO: REPLACE BY TikZ!*
[[~/phd/Figs/tot_calib_3.pdf]]

Required understanding for our charge calibration.

Show function that is being fitted to it.

- [ ] *NOTE: AS FAR AS I CAN TELL, THE TOT CALIBRATION ALREADY REQUIRES A CORRECT =THL= DAC VALUE!*

*** S-Curve scan [3/15]
:PROPERTIES:
:CUSTOM_ID: sec:daq:scurve_scan
:END:

The S-Curve scan is one of 2 different ways to determine the optimal
=THL= value.

- [ ] *MAIN PURPOSE IS NOT!! THL VALUE DETERMINATION*


The purpose of the S-curve scan is to understand the relationship
between injected charges in electron and the =THL= DAC values by
providing a ${\text{\# } e^-}/\mathtt{THL}\text{ step}$ number (or
without a =ToT= calibration $\mathtt{ToT}/\mathtt{THL}$). 

It works by injecting charges onto each pixel and checking the pixel
response of each pixel at different =THL= values. Below a certain
=THL= value all pixels will respond to the injected charge. At some
point certain pixels will be insensitive to the induced charge and a
90° rotated "S" will form. By fitting an error function to this S an
ideal =THL= value can be deduced.

By calculating =THL= value at which half of all test pulses are
recorded, we can compute the number of electrons corresponding to that
=THL= DAC value, as we know the amplitude of the test pulse and thus
number of injected electrons.

Fig. [[fig:daq:s_curve_examples]] shows an S-Curve scan of chip 0 of the
Septemboard using the calibration from July 2018. The center peak in
the middle is the noise peak of the detector at the shutter length
used for the S-Curve scan. The symmetrical shape is due to specific
implementation details of how the pixels function, the upper side is
the one of interest. The falling edge of each curve can be fit by the
cumulative distribution function of a normal distribution. The center
point (half way between both plateaus) corresponds to the effective
threshold of the detector at that injected charge.

- [ ] *TURN INTO IF ELSE FUNCTION FOR z* (defined in seqmath)
  #+begin_src nim
  let z = (x - x0) / (sigma * sqrt(2.0))
  if z > 1.0:
    result = 0.5 * erfc(z)
  else:
    result = 0.5 * (1.0 - erf(z))

  #+end_src

#+NAME: eq:daq:s_curve_fit_function  
\[
f(μ, σ, N) = \frac{N}{2} · \text{erfc}((x - μ) / (σ · \sqrt{2}))
\]

where the parameter $N$ is simply a scaling factor and $μ$ represents
the x value of the half-amplitude point. $σ$ is the spread of the drop
and $\text{erfc}$ is the complementary error function $\text{erfc}(x)
= 1 - \text{erf}(x)$. The error function is of course just the
integral over a normal distribution up to the evaluation point $x$:

\[
\text{erf}(x) = \frac{2}{\sqrt{π}} ∫_0^{x} e^{-t²} dt
\]

Given that the number of injected electrons is known for each test
pulse amplitude (see sec. [[#sec:daq:tot_calibration]]), we can compute
the relationship of the number of electrons per =THL= value step. This
is called the =THL= calibration and an example corresponding to
fig. [[fig:daq:s_curves_examples]] is shown in
fig. [[fig:daq:thl_calibration_example]], where the =THL= values used
correspond to the $μ$ parameters of
eq. [[eq:daq:s_curve_fit_function]]. The resulting fit is useful, as it
allows to easily convert a given =THL= DAC value into an effective
number of electrons, which then corresponds to the effective threshold
in electrons required to activate a pixel on average. When looking at
the distribution of charges in a dataset, that cutoff in electrons is
of interest (see sec. [[#sec:daq:polya_distribution_threshold]]).

- [ ] *ADD FIT FUNCTION FOR SCURVE*

- [ ] *REFER TO THE CODE THAT DOES THE FIT*
  https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/calibration/calib_fitting.nim#L111

#+CAPTION: S-Curve scan of chip 0 of the Septemboard using the calibration from
#+CAPTION: July 2018. The scan works by injecting \num{1000} test pulses at different
#+CAPTION: amplitudes onto the pixels. Each line represents one such measurement
#+CAPTION: and each point is the mean number of counted hits for all pixels with injected
#+CAPTION: test pulses.
#+CAPTION: The center peak in the middle is the noise peak of the
#+CAPTION: detector. The symmetrical shape is due to specific implementation
#+CAPTION: details of how the pixels function. The upper side is the one of
#+CAPTION: interest. The falling edge of each curve can be fit by the complement of the
#+CAPTION: cumulative distribution function of a normal distribution. The center point
#+CAPTION: (half way between both plateaus) corresponds to the effective threshold 
#+CAPTION: of the detector at that injected charge. The fit parameters for all calibrations
#+CAPTION: are shown in tab. *INSERT*.
#+NAME: fig:daq:s_curves_example
[[~/phd/Figs/detector/calibration/s_curves_0.pdf]]

#+CAPTION: The =THL= calibration can be used to gauge the 'threshold gain' the
#+CAPTION: =THL= DAC has on the number of electrons required to cross the threshold.
#+CAPTION: The =THL= DAC in the Timepix normally adjusts the threshold by about
#+CAPTION: \num{25} electrons per DAC value \cite{timepix_manual}, which is reproduced
#+CAPTION: well here (parameter $1/m$). The root of the linear fit (written as
#+CAPTION: $f⁻¹(y=0)$ in the annotation) corresponds to the position of the noise peak
#+CAPTION: in fig. [[fig:daq:s_curves_example]].
#+NAME: fig:daq:thl_calibration_example
[[~/phd/Figs/detector/calibration/thl_calibration_chip_0.pdf]]



- [ ] *FIX UP TYPESETTING OF FIT PARAMETERS IN THL PLOT*

- [ ] *INSERT AND REFERENCE TABLE OF ALL FIT PARAMETERS FOR THE SCURVES*

- [ ] *UNDERSTAND HOW WE CAN USE SCURVE TO DEDUCE THRESHOLD AND EXPLAIN IT*

- [ ] *FIX PARAMETERS OF THL CALIBRATION. THEY ARE NONSENSICAL AND NOT ALIGNED*

- [ ] *CHECK WHAT 25e/THL IS CALLED IN TABLE OF TIMEPIX MANUAL*

- [X] *ADD THAT AT EVEN LOWER VALUE WE JUST SEE NOISE AND THEN DUE TO
  IMPLEMENTATION DETAILS THE WHOLE THING INVERTS*

- [X] *ADD ITS OWN SHORT SECTION ABOUT THRESHOLD SCANNING WITH BELOW
  REWRITTEN TEXT*

- [ ] *ADD NUMBER OF EXPECTED ELECTRONS A THRESHOLD AS MENTIONED IN TIMEPIX ORIGINAL PAPER*

- [X] *PLOT OF SCURVE SCANS*

- [ ] *APPENDIX ALL SCURVE SCANS FOR CAST DATA TAKING*

- [ ] *S-CURVE CAN BE USED TO DETERMINE #electron / THL DAC VALUE*
  (first gets THL value against pulse height of course)
- [ ] *MAKE THAT FIT AND SHOW EXAMPLE*

- [ ] *ADD EQUATION FOR MINIMUM DETECTABLE CHARGE AND GIVE A NUMBER*  

**** Compute electrons per THL DAC value [0/2]                  :noexport:

- [ ] *FIGURE OUT WHY 2017 CALIBRATION HAS ABOUT 50e/THL COMPARED TO
  25e/THL!*

- [ ] *REPLACE BELOW BY =plotCalibration= CALL?* That already handles
  it, even though currently via plotly.


For the S-Curve plot 
#+begin_src sh
./plotCalibration --scurve --chip 0 --runPeriod Run3 --useTeX --legendX 200.0 --legendY 3800
#+end_src
and for the THL calibration:
#+begin_src sh
./plotCalibration --scurve --chip 0 --runPeriod Run3 --useTeX --legendX 422.0 --legendY 3550
#+end_src
the only difference being the legend placement (as the coordinates are
applied to both plots).

The following is essentially the main code required to plot the
SCurves, determine the middle point and fit THL calib (not the SCurve
fit though):
#+begin_src nim :tangle /home/basti/phd/code/s_curve_electrons_per_thl.nim
import std / [strutils, strscans, os, strformat]
import ggplotnim
import unchained

proc charge(voltage: mV): UnitLess =
  ## Returns the number of electrons given a voltage pulse of amplitude `voltage`
  ## at the 8.fF capacitor of the Timepix1
  result = 8.fF * voltage / e

#const path = "/home/basti/septemH_calibration/SCurve/chip_3/voltage_*.txt"
#const path = "/home/basti/septemH_calibration/CalibJul2018/SCurves/chip_1/voltage_*.txt"
const path = "/home/basti/septemH_calibration/SeptemH_FullCalib_InGridDatabase/chip3/SCurve/voltage_*.txt"
#const path = "/home/basti/septemH_calibration/SeptemH_FullCalib_2018_2/chip0/SCurve/voltage_*.txt"
var charges = newSeq[float]()
var thls = newSeq[int]()
for file in walkFiles(path):
  let (success, _, voltage) = scanTuple(file.extractFilename, "$*_$i.txt$.")
  if voltage == 0: continue # skip 0
  charges.add charge(voltage.mV)
  ## we'll do the simplest approach to get the correct THL value:
  ## - strip everything before noise peak (to have single THL value)
  ## - compute
  var df = readCsv(file, sep = '\t', header = "#", colNames = @["THL", "counts"])
  let thlAtMax = df.filter(f{int: `counts` == `counts`.max})["THL", int][0] # must be single element
  const TestPulses = 1000
  df = df.filter(f{`THL` > thlAtMax})
    .mutate(f{int: "DiffHalf" ~ abs(`counts` - TestPulses div 2)})
    .filter(f{int: `DiffHalf` == min(col("DiffHalf"))}) # f{int: `DiffHalf` < 200})
  thls.add df["THL", int][0] # must be single element

import polynumeric
let fit = polyFit(thls.toTensor.asType(float),
                  charges.toTensor,
                  polyOrder = 1)
echo fit
proc linear(x, m, b: float): float = m * x + b

let thlFit = linspace(thls.min, thls.max, 10)
let chargesFit = linspace(charges.min, charges.max, 10)
var dfFit = toDf({ "thls" : thlFit,
                   "charges" : thlFit.map_inline(linear(x, fit[1], fit[0])) })
echo dfFit
let df = toDf(thls, charges)

ggplot(df, aes("thls", "charges")) + 
  geom_point() +
  geom_line(data = dfFit, aes = aes("thls", "charges"), color = parseHex("FF00FF")) +
  xlab("THL DAC") + ylab("Injected charge [e⁻]") + 
  ggtitle(&"Fit parameters: m = {fit[1]:.2f} e⁻/THL, b = {fit[0]:.2f} e⁻") +
  ggsave("/home/basti/phd/Figs/charge_per_thl.pdf")
#+end_src

#+RESULTS:

**** Compute minimally detectable charge                        :noexport:

Ref:
- \cite{LLOPART2007485_timepix} Timepix paper
- \cite{LlopartCudie_1056683} Llopert PhD thesis

The following quotes explain how to compute the effective threshold:

page 5/10:
#+begin_quote
The electronic noise and effective threshold can be measured using the
s-curve method [8] when the pixel is set in counting mode.
#+end_quote

page 5/10:
#+begin_quote
The effective threshold is at 50% of this s-curve. The charge
difference between the 97.75% and 2.25% of the s- curve is four times
the RMS noise of the front end assuming a gaussian distributed noise.
#+end_quote

#+begin_quote
The measured electronic noise is 99:4 ± 3:8 e⁻ rms for hole
collection and 104:8 ± 6 e⁻ rms for electron collection.  The
measured DAC step gain is 24:7 ± 0:7 e⁻ =step for hole collection
and 25:4 ± 1:2 e⁻ =step for electron collection.
#+end_quote

page 7/10:
#+begin_quote
The threshold variation before equalization is
~240 e⁻ rms and after equalization the achieved noise free
threshold variation is ~35 e⁻ rms for both polarities.
#+end_quote

page 7/10:
#+begin_quote
The minimum detectable charge can be calculated by quadratically
adding the measured electronic noise and the threshold variation
because both measurements are uncorrelated.
#+end_quote

#+begin_quote
Before equalization the minimum detectable charge for the full matrix
is ~1600 e⁻ and after equalization is ~650 e⁻ for both polarities.
#+end_quote

This means:
- [ ] compute the 97.75 ⇔ 2.25% range of the S-curve. Yields 4 times
  RMS noise. Width in THL of that can be converted to #e⁻ using THL
  calibration.
  -> electronic noise $N_e$
- [ ] compute width of optimized threshold variation based on
  histogram. Fit gaussian (?) to optimized threshold variation. σ of
  that gaussian is width in THL. Convert THL to electrons.
  -> threshold variation $N_t$

- [ ] *CHECK IF THIS IS CORRECT*:
  If I'm not mistaken, the noise peak we see in the S-curve scan is
  essentially the same as the optimized distribution from the
  threshold equalization.

Then with those two parameters we compute the effective detectable
charge as:

\[
N_d = √(N_e² + N_t²)
\]

which for the numbers listed above yields

\[
N_d = √(105² + 35²) = 110
\]

which is not close to the expected 650 e⁻!

Checking in the PhD thesis of Llopert, page 115, equation 4.5 is:

\[
\text{MinDetect}Q = 6·\sqrt{ ENC² + σ_{\text{dist}}²}
\]
which then works out nicely (110·6 = 660 is close enough)!

So in theory we can compute this for all our chips and all
calibrations.

- [ ] *CALCULATE FOR ALL CHIPS AND PUT INTO APPENDIX*


*** Pólya distribution & gas gain
:PROPERTIES:
:CUSTOM_ID: sec:daq:polya_distribution_threshold
:END:

In a gaseous detector the gas amplification (see
sec. [[#sec:theory:gas_gain_polya]]) allows to easily exceed the minimum
detectable charge of $\mathcal{O}(\SIrange{500}{1000}{e^-})$. The
typically used =THL= threshold will be quite a bit higher than the
'theoretical limit' however for multiple reasons. One can either
compute the effective threshold in use based on the =THL= calibration
as explained in sec. [[#sec:daq:scurve_scan]], or use an experimental
approach by utilizing the Pólya distribution as introduced in
sec. [[#sec:theory:gas_gain_polya]]. By taking data over a certain period
of time and computing a histogram of the charge values recorded by
each pixel, a Pólya distribution naturally arises.

This Pólya distribution has two different use cases. First of all it
is the source of the empirical gas gain the detector actually operated
under. On the one hand one of the parameters of the Pólya
parametrization as introduced in section [[#sec:theory:gas_gain_polya]] is
a measure for the gas gain. On the other hand, the mean of the
histogram can also be used as a measure for the gas gain (which is the
main number used in later chapters).

Secondly, the Pólya can also be used to determine the actual
activation threshold of the detector, by simply checking what the
lowest charge is that sees significant statistics.

- [X] *TALK ABOUT GAS GAIN*
- [ ] *MAYBE MOVE EXPLANATION ABOUT HOW TO EXTRACT GAS GAIN FROM POLYA
  TO EXPLANATION IN THEORY?*
- [ ] *IF IT STAYS HERE, INTRODUCE WHAT "MEAN OF HISTOGRAM" EVEN MEANS*  
  
An example of such a Pólya distribution is seen in
fig. [[fig:daq:polya_example_chip0]], where we see the same chip 0 using
the same calibration from July 2018 as in the figures in the previous
section [[#sec:daq:scurve_scan]]. The data is a \SI{30}{min} interval of
background data at CAST. The reasoning behind looking at a fixed time
interval for the Pólya will be explained in section [[#sec:?:gas_gain_time_binning]].
The pink line represents the fit of the Pólya
distribution to the data. The dashed part of the line was not used for
the fit and is only an extension using the final fit parameters. The
cutoff at the lower end due to the chip's threshold is clearly
visible. The fit determines a gas gain of about \num{2700}, compared
to the mean of the data yielding about \num{2430}. 

Based on the data a threshold value of - very roughly - \num{1000} can
be estimated. Using the =THL= calibration of the chip as shown in
fig. [[fig:daq:thl_calibration_example]] yields a value of

\[
Q(\text{THL} = 419) = 26.8 · 419 - 10300 = 929.2
\]

where we used the fit parameters as printed on the plot ($1/m$ and
$f⁻¹(y=0)$) and the =THL= DAC value of \num{419} as used during the
data taking for this chip. Indeed, the real threshold is in the same
range, but clearly a bit higher than the theoretical limit for this
chip. This matches our expectation.

#+CAPTION: An example of a Pólya distribution of chip 0 using the calibration
#+CAPTION: of July 2018 based on \SI{30}{min} of background data.
#+CAPTION: The lower cutoff is easily visible. The pink line represents the
#+CAPTION: fit of the Pólya distribution to the data. In the dashed region the
#+CAPTION: line was extended using the final fit parameters.
#+NAME: fig:daq:polya_example_chip0
[[~/phd/Figs/gas_gain_run_306_chip_0_placeholder_example.pdf]]

- [ ] *USE IT TO DETERMINE THRESHOLD*
- [X] *COMPUTE THRESHOLD IN EXAMPLE FROM THL CALIB AND COMPARE*
- [X] *INTRODUCE IT IS USED AS THE PRACTICAL WAY TO COMPUTE GAS GAIN*
- [ ] *MENTION THAT WE BIN BY TIME OF 90min AND THAT WE WILL EXPLAIN
  IN LATER CHAPTER HOW TIME INTERVAL WAS CHOSEN*
- [ ] *GENERATE A NEW PLOT OF POLYA FOR THESIS*  

Explain how all charge values combined as a histogram generate a
~Pólya distribution from which we can deduce the gas gain.

**** Generate Polya plot for chip 0, run period 3 [0/1]         :noexport:

The current placeholder polya distribution (although it's the right
chip and calibration) is:
#+begin_src sh
basti at void in /mnt/1TB/CAST/2018_2/out/DataRuns2018_Raw_2020-04-28_16-13-28 λ
  cp gas_gain_run_306_chip_0_5_30_min_1545294386.pdf \
     ~/phd/Figs/gas_gain_run_306_chip_0_placeholder_example.pdf
#+end_src

- [ ] *REPLACE BY BETTER PLOT. USING 90MIN AMONG OTHER THINGS*

*** Final Septemboard calibrations [0/4]

The detector was calibrated according to the descriptions of the
previous sections prior to both major data taking campaigns at CAST
(see sec. [[#sec:cast:data_taking_campaigns]] for a detailed overview of
both campaigns), once in October 2017 and then again in July 2018.

For an overview of all calibration parameters of interest, see the
appendix [[#sec:appendix:septemboard_calibrations]].

Tables [[tab:daq:thl_ths_calibration_run2]] and
[[tab:daq:thl_ths_calibration_run3]] show the =THL= and =THS= DAC values
used for the Septemboard detector at CAST during the data taking
campaign from October 2017 to March 2018 (run 2) and October 2018 to December
2018 (run 3), respectively. The other DACs were all set to the same values for
all chips in both data taking campaigns with the detector, shown in
tab. [[tab:daq:common_dac_values]].

- [ ] *WHAT ELSE*?
- [ ] *DISTRIBUTIONS OF 4-BIT DAC?* Only appendix
- [ ] *THEORETICAL THRESHOLDS COMPUTED AS IN SECTION ABOVE. RESULT
  ADDED TO TABLE?*

#+CAPTION: The =THL= and =THS= DAC values for each of the chips of the
#+CAPTION: Septemboard (board H) detector used at CAST for the data taking
#+CAPTION: campaign from October 2017 to March 2018 (run 2).
#+NAME: tab:daq:thl_ths_calibration_run2
#+ATTR_LATEX: :booktabs t
|-----+--------+--------+--------+---------+---------+--------+--------|
| DAC | E6 W69 | K6 W69 | H9 W69 | H10 W69 | G10 W69 | D9 W69 | L8 W69 |
|-----+--------+--------+--------+---------+---------+--------+--------|
| THL |    435 |    435 |    405 |     450 |     450 |    400 |    470 |
| THS |     66 |     69 |     66 |      64 |      66 |     65 |     66 |
|-----+--------+--------+--------+---------+---------+--------+--------|


#+CAPTION: The =THL= and =THS= DAC values for each of the chips of the
#+CAPTION: Septemboard (board H) detector used at CAST for the data taking
#+CAPTION: campaign from October 2018 to December 2018 (run 3).
#+NAME: tab:daq:thl_ths_calibration_run3
#+ATTR_LATEX: :booktabs t
|-----+--------+--------+--------+---------+---------+--------+--------|
| DAC | E6 W69 | K6 W69 | H9 W69 | H10 W69 | G10 W69 | D9 W69 | L8 W69 |
|-----+--------+--------+--------+---------+---------+--------+--------|
| THL |    419 |    386 |    369 |     434 |     439 |    402 |    462 |
| THS |     68 |     66 |     66 |      65 |      69 |     65 |     64 |
|-----+--------+--------+--------+---------+---------+--------+--------|
  
#+CAPTION: DAC values that are common between data taking periods and 
#+CAPTION: all chips of the Septemboard for CAST.
#+NAME: tab:daq:common_dac_values
#+ATTR_LATEX: :booktabs t
|-------------+------------|
| DAC         |      Value |
|-------------+------------|
| IKrum       |         20 |
| Hist        |          0 |
| GND         |         80 |
| Coarse      |          7 |
| CTPR        | 4294967295 |
| BiasLVDS    |        128 |
| SenseDAC    |          1 |
| DACCode     |          6 |
| RefLVDS     |        128 |
| Vcas        |        130 |
| ExtDAC      |          0 |
| Disc        |        127 |
| Preamp      |        255 |
| FBK         |        128 |
| BuffAnalogA |        127 |
| BuffAnalogB |        127 |
|-------------+------------|

Further, figure [[fig:daq:thl_optimized_distributinons]] shows the
optimized =THL= distributions of all chips after threshold
equalization for run 2 (left) and 3 (right).

#+CAPTION: Distributions of the =THL= values of all Septemboard (board H) chips
#+CAPTION: at the noise peak with the calibration for for run 2 on the left and
#+CAPTION: run 3 on the right.
#+ATTR_LATEX: :width 1\textwidth
#+NAME: fig:daq:thl_optimized_distributinons
[[~/phd/Figs/detector/calibration/sepemboard_all_thl_optimized.pdf]]

- [ ] *TURN PLOT INTO TIKZ*

**** Generate the FSR tables for all chips and each run period  :noexport:

Let's generate the tables containing the table for the FSR DAC values
for all chips for each of the different run periods.

We will use the =ChipCalibrations= directory that is part of the
=TimepixAnalysis= repository in the =resources= directory.

Further, we will create a plot of all pixels showing the noise peak in
THL values based on the optimized equalization.

#+begin_src nim :tangle code/generate_fsr_table.nim :results raw
import std / [sequtils, strutils, os, tables, algorithm]

const path = "/home/basti/CastData/ExternCode/TimepixAnalysis/resources/ChipCalibrations/"
const periods = ["Run2", "Run3"]
const chipInfo = "chipInfo.txt"
const thrMean = "thresholdMeans$#.txt"
const chips = toSeq(0 .. 6)

import ggplotnim
proc readThresholdMeans(path: string, chip: int): DataFrame =
  echo path / thrMean
  result = readCsv(path / (thrMean % $chip), sep = '\t', colNames = @["x", "y", "min", "max", "bit", "opt"])
    .select("opt")
    .rename(f{"THL" <- "opt"})
    .mutate(f{"chip" <- chip})

# parse the names of the chips from the run info file
var df = newDataFrame()    
for period in periods:
  var header = @["DAC"]
  var tab = initTable[int, seq[(string, int)]]()
  var dfPeriod = newDataFrame()
  for chip in chips:
    proc toTuple(s: seq[seq[string]]): seq[(string, int)] =
      for x in s:
        doAssert x.len == 2
        result.add (x[0], x[1].parseInt)
    let chipPath = path / period / "chip" & $chip
    let data = readFile(chipPath / "fsr" & $chip & ".txt")
      .splitLines
      .filterIt(it.len > 0)
      .mapIt(it.split)
      .toTuple()

    tab[chip] = data

    # read chip name and add to header
    proc readChipName(chip: int): string =
      result = readFile(chipPath / chipInfo)
        .splitLines()[0] 
      result.removePrefix("chipName: ")
    header.add readChipName(chip)

    dfPeriod.add readThresholdMeans(chipPath, chip)
  dfPeriod["Run"] = period
  df.add dfPeriod
  
  proc invertTable(tab: Table[int, seq[(string, int)]]): Table[string, seq[(int, int)]] =
    result = initTable[string, seq[(int, int)]]()
    for chip, data in pairs(tab):
      for (dac, value) in data:
        if dac notin result:
          result[dac] = newSeq[(int, int)]()
        result[dac].add (chip, value)

  proc wrap(s: string): string = "|" & s & "|\n"
  proc toOrgTable(s: seq[seq[string]], header: seq[string]): string =
    let tabLine = wrap toSeq(0 ..< header.len).mapIt("------").join("|")
    result = tabLine
    result.add wrap(header.join("|"))
    result.add tabLine
    for x in s:
      doAssert x.len == header.len
      result.add wrap(x.join("|"))
    result.add tabLine

  proc toOrgTable(tab: Table[string, seq[(int, int)]],
                  header: seq[string]): string =
    var commonDacs = newSeq[seq[string]]()
    var diffDacs = newSeq[seq[string]]()
    for (dac, row) in pairs(tab):
      var fullRow = @[dac]
      let toAdd = row.sortedByIt(it[0]).mapIt($it[1])
      if toAdd.deduplicate.len > 1:
        fullRow.add toAdd
        diffDacs.add fullRow 
      else:
        commonDacs.add @[dac, toAdd.deduplicate[0]]
    result.add toOrgTable(diffDacs, header)
    result.add "\n\n"
    result.add toOrgTable(commonDacs, @["DAC", "Value"])
    # now add common dacs table
  echo "Run: ", period
  echo tab.invertTable.toOrgTable(header)

ggplot(df.filter(f{`THL` > 100}), aes("THL", fill = factor("chip"))) +
  facet_wrap("Run") + 
  geom_histogram(binWidth = 1.0, position = "identity", alpha = 0.7, hdKind = hdOutline) +
  ggtitle("Optimized THL distribution of the noise peak for each chip") +
  ylab("# pixels") +
  ggsave("/home/basti/phd/Figs/detector/calibration/sepemboard_all_thl_optimized.pdf",
         width = 1200, height = 640)

#+end_src

#+RESULTS:
Run: Run2
|-----+--------+--------+--------+---------+---------+--------+--------|
| DAC | E6 W69 | K6 W69 | H9 W69 | H10 W69 | G10 W69 | D9 W69 | L8 W69 |
|-----+--------+--------+--------+---------+---------+--------+--------|
| THL |    435 |    435 |    405 |     450 |     450 |    400 |    470 |
| THS |     66 |     69 |     66 |      64 |      66 |     65 |     66 |
|-----+--------+--------+--------+---------+---------+--------+--------|


|-------------+------------|
| DAC         |      Value |
|-------------+------------|
| IKrum       |         20 |
| Hist        |          0 |
| GND         |         80 |
| Coarse      |          7 |
| CTPR        | 4294967295 |
| BiasLVDS    |        128 |
| SenseDAC    |          1 |
| DACCode     |          6 |
| RefLVDS     |        128 |
| Vcas        |        130 |
| ExtDAC      |          0 |
| Disc        |        127 |
| Preamp      |        255 |
| FBK         |        128 |
| BuffAnalogA |        127 |
| BuffAnalogB |        127 |
|-------------+------------|

Run: Run3
|-----+--------+--------+--------+---------+---------+--------+--------|
| DAC | E6 W69 | K6 W69 | H9 W69 | H10 W69 | G10 W69 | D9 W69 | L8 W69 |
|-----+--------+--------+--------+---------+---------+--------+--------|
| THL |    419 |    386 |    369 |     434 |     439 |    402 |    462 |
| THS |     68 |     66 |     66 |      65 |      69 |     65 |     64 |
|-----+--------+--------+--------+---------+---------+--------+--------|


|-------------+------------|
| DAC         |      Value |
|-------------+------------|
| IKrum       |         20 |
| Hist        |          0 |
| GND         |         80 |
| Coarse      |          7 |
| CTPR        | 4294967295 |
| BiasLVDS    |        128 |
| SenseDAC    |          1 |
| DACCode     |          6 |
| RefLVDS     |        128 |
| Vcas        |        130 |
| ExtDAC      |          0 |
| Disc        |        127 |
| Preamp      |        255 |
| FBK         |        128 |
| BuffAnalogA |        127 |
| BuffAnalogB |        127 |
|-------------+------------|

*** High voltage [/]

The high voltage settings used for the Septemboard detector are shown
in tab. [[tab:daq:hv_settings]]. The aim is a drift field on the order
of \SI{500}{V.cm⁻¹} and an amplification field of about
\SI{60}{kV.cm⁻¹}. The main voltages to choose are the grid voltage (to
determine the latter) and the cathode voltage (to determine the
former). The other voltages are computed based on a constant field gradient.


- [ ] *MENTION HV SETTINGS USED* Table plus short description.

** FADC [/]

The FADC requires care about multiple aspects. First the settings need
to be chosen that configure both the operating characteristics, data
readout and trigger threshold. Next, the Ortec 474 shaping amplifier
has multiple different settings. Finally, in order to interpret the
signals received from the FADC, a so-called "pedestal run" must be
recorded.

- FADC settings :: The chosen settings, as seen in the config file
  explanation in section [[#sec:daq:tos_config_file]], configure the FADC
  to run at a frequency of \SI{1}{GHz} as to cover a running time interval of
  \SI{10.24}{μs}. While it could run at up to \SI{2}{GHz}, \SI{1}{ns}
  per time bin is accurate enough given the time scales associated
  with the amplifier (see below) and a longer interval is more
  useful. Further, an external trigger is sent out to TOS if the
  threshold is exceeded. The threshold itself is set to
  \SI{-44}{mV}. The value was chosen based on trial and error to
  avoid no triggers based on baseline noise. Given the range of up to
  $\SI{-1}{V}, the relative threshold is pretty low. Finally, the
  operation mode and data readout is set, the input channel is chosen
  and the pedestal run parameters are configured (see below).
- Amplifier settings :: The 474 Ortec shaping amplifier has 3 settings
  of note. The absolute gain as a multiplier and a signal integration as
  well as differentiation time. The initial settings were set to an
  amplification of =6x=, an integration time of \SI{50}{ns} and a
  differentiation time of \SI{50}{ns}. However, these were changed
  during the data taking campaign, see more on this in section
  [[#sec:data_taking:fadc_noise]].
- Pedestals :: The $4 · \num{2560}$ registers of the FADC are part of
  4 separate cyclic registers. Due to implementation details, the
  absolute recorded values of each register is arbitrary. In a
  pedestal run multiple measurements ($\mathcal{O}(10)$ of a certain
  length (\SI{100}{ms} in our case) are performed and the pedestal
  values averaged. The resulting values represent a mean value for the
  typical value in each register, hence the name 'pedestal'. To
  interpret a real measured signal, these pedestals are subtracted
  from the recorded signal. Each of the 4 FADC channels may have very
  different pedestal values, but within a single channel they are
  usually within $\lesssim\num{50}$ ADC
  values. Fig. [[fig:daq:fadc_pedestal_run]] shows the pedestals of all 4
  FADC channels. The pedestals drift over time, but the associated
  time scales are long. [fn:fadc_pedestals_manual]

More details to each of these will be given later where it is of importance.  

- [X] *THRESHOLD. 44 mV. TO AVOID NOISE TRIGGERS*
- [X] *AMPLIFIER SETTINGS* (CAST data taking notes)
- [X] *PEDESTAL*

#+CAPTION: The FADC pedestal run used for CAST data split by each of the 4 FADC channels. Each
#+CAPTION: channel's pedestals vary by about $\mathcal{O}(30)$ ADC values. The first few registers
#+CAPTION: in each channel are not shown, as they are outlying by $\sim\num{100}$.
#+NAME: fig:daq:fadc_pedestal_run
#+Attr_LATEX: :width 1\textwidth
[[~/phd/Figs/detector/calibration/fadc_pedestal_split_by_channel.pdf]]

[fn:fadc_manual] https://archive.org/details/manualzilla-id-5646050/

[fn:fadc_pedestals_manual] The FADC pedestals can also be computed
from real data by computing a truncated mean of all FADC files in a
data taking run. This yields a usable pedestal to use for that
run. See the extended version of this document for a section about this.
  
*** Generate plot of pedestals                                   :noexport:

#+begin_src nim :tangle code/fadc_pedestals_plot.nim
import std / [strutils, os, sequtils, algorithm]
import ggplotnim

const path = "/home/basti/CastData/ExternCode/TimepixAnalysis/resources/pedestalRuns/"
const file = "pedestalRun000042_1_182143774.txt-fadc"
# read the FADC files using our CSV parser. Everything `#` is header
# aside from the last 3 lines. Skip those using `maxLines`
var df = readCsv(path / file, header = "#", maxLines = 10240)
  .rename(f{"val" <- "nb of channels: 0"})
# generate indices 0, 0, 0, 0, 1, 1, 1, 1, ..., 2559, 2559, 2559, 2559 
df["Register"] = toSeq(0 ..< 2560).repeat(4).concat.sorted
df["Channel"] = @[1, 2, 3, 4].repeat(2560).concat
when false:
  df["Channel"] = @[1, 2, 3, 4].repeat(2560)
  df = df.mutate(f{int -> bool: "even?" ~ `Channel` mod 2 == 0})
  echo df
  echo df.tail(20)
  ggplot(df, aes("Channel", "val", color = "even?")) +
    geom_point(size = 1.0) +
    ggtitle("FADC channel values of pedestal run") +  
    ggsave("/home/basti/phd/Figs/detector/calibration/fadc_pedestal_run.pdf")
  #         useTeX = true, standalone = true)
  ggplot(df.group_by("even?").filter(f{float -> bool: `val` < percentile(col("val"), 95)}),
         aes("Channel", "val", color = "even?")) +
    facet_wrap("even?", scales = "free") +
    facetMargin(0.5) +
    margin(bottom = 1.0, right = 3.0) +
    geom_point(size = 1.0) +
    legendPosition(0.91, 0.0) +
    ggtitle("FADC channel values of pedestal run, split by even and odd channel numbers") +
    ggsave("/home/basti/phd/Figs/detector/calibration/fadc_pedestal_split_even_odd.pdf", width = 1200, height = 600)#
  #         useTeX = true, standalone = true)
else:
  ggplot(df.group_by("Channel").filter(f{float -> bool: `val` < percentile(col("val"), 99)}),
         aes("Register", "val", color = "Channel")) +
    facet_wrap("Channel", scales = "free") +
    geom_point(size = 2.0) +
    facetMargin(0.5) +
    margin(bottom = 1.0, right = 3.0) +
    ggtitle("FADC register pedestal values, split by channels") +    
    xlab("Channel", margin = 0.0) + 
    ggsave("/home/basti/phd/Figs/detector/calibration/fadc_pedestal_split_by_channel.pdf")
#+end_src

*** Understanding FADC settings                                  :noexport:

Given the time since last working with this, I need to look up the
values of the TOS config file in the FADC manual.

For reference our settings:
#+begin_src toml
[Fadc] # FADC Settings
fadcTriggerType                 = 3 
fadcFrequency                   = 2
fadcPosttrig                    = 80
fadcPretrig                     = 15000
# was 2033 before, 1966 corresponds to -40 mV
fadcTriggerThresholdRegisterAll = 1966 
# run time of a single pedestal run for the FADC in ms
fadcPedestalRunTime             = 100
# number of acquisition runs done for each pedestal calibration
fadcPedestalNumRuns             = 10
# using channel 0 on FADC as trigger source, thus bit 0  1!
fadcChannelSource               = 1
# set FADC mode register (mainly to enable 14-bit readout)
fadcModeRegister                = 0b000
#+end_src

=FP_FREQUENCY= is the name for the address =0x01= for the. It needs 6
bits of data:
#+begin_src 
Bits 0-5 Function
Val = 1 => Fsample = 2GHz.
Val = 2 => Fsample = 1GHz.
Val = 4 => Fsample = 500MHz.
Val = 5 => Fsample = 400MHz.
Val = 10 => Fsample = 200MHz.
Val = 20 => Fsample = 100MHz.
Val = 40 => Fsample = 50MHz.
#+end_src
As such our used value of ~fadcFrequency = 2~ corresponds to
\SI{1}{GHz} as I remembered.

=MODE_REGISTER= is for value =0x03= and its 3 bits of data.
[[/home/basti/phd/Figs/fadc_settings_mode_register.png]]
Our value of =0b000= for the data means no interruption tagging, 12
bits data output and normal acquisition mode.

*** Calculate pedestals from real FADC data                      :noexport:

We will now see what happens if we compute the FADC pedestals from the
raw data by computing a truncated mean of all FADC files in a single
run and comparing to the real pedestal run we normally use as a reference.

#+begin_src nim :tangle code/attempt_fadc_pedestals_from_data.nim
import std / [strutils, os, sequtils, sugar, algorithm]
import ggplotnim

proc readFadc(f: string): DataFrame =
  # read the FADC files using our CSV parser. Everything `#` is header
  # aside from the last 3 lines. Skip those using `maxLines`
  result = readCsv(f, header = "#", maxLines = 10240)
    .rename(f{"val" <- "nb of channels: 0"})
  #result["Channel"] = toSeq(0 ..< result.len)
  result["Register"] = toSeq(0 ..< 2560).repeat(4).concat.sorted
  result["Channel"] = @[1, 2, 3, 4].repeat(2560).concat

## Main function to avoid bug of closure capturing old variable  
proc readFadcData(path: string): DataFrame =
  var dfs = newSeq[DataFrame]()
  var i = 0
  for f in walkFiles(path / "*.txt-fadc"):
    echo "Parsing ", f
    dfs.add readFadc(f)
    inc i
    #if i > 100: break
  let df = assignStack(dfs)
  var reg = newSeq[int]()
  var val = newSeq[float]()
  var chs = newSeq[int]()
  for (tup, subDf) in groups(df.group_by(["Channel", "Register"])):
    let p20 = percentile(subDf["val", float], 20)
    let p80 = percentile(subDf["val", float], 80)
    reg.add tup[1][1].toInt
    chs.add tup[0][1].toInt
    let dfF = if p80 - p20 > 0: subDf.filter(f{float: `val` >= p20 and `val` <= p80})
             else: subDf
    val.add dfF["val", float].mean
  let dfP = toDf({"Channel" : chs, val, "Register" : reg})
  dfP.writeCsv("/t/pedestal.csv")
  echo dfP.pretty(-1)
  result = dfP

proc main(path: string, outfile: string = "/t/empirical_fadc_pedestal_diff.pdf",
          plotVoltage = false) =
  let pData = readFadcData(path)
  
  const path = "/home/basti/CastData/ExternCode/TimepixAnalysis/resources/pedestalRuns/"
  const file = "pedestalRun000042_1_182143774.txt-fadc"
  let pReal = readFadc(path / file)
  echo pData
  echo pReal
  var df = bind_rows([("Data", pData), ("Real", pReal)], "ID")
    .spread("ID", "val")
    .mutate(f{"Diff" ~ abs(`Data` - `Real`)})
    # alternatively compute the voltage corresponding to the FADC register values,
    # assuming 12 bit working mode (sampling_mode == 0)
    .mutate(f{"DiffVolt" ~ `Diff` / 2048.0})
  var plt: GgPlot
  if plotVoltage:
    plt = ggplot(df, aes("Register", "DiffVolt", color = "Channel")) +
      ylim(0, 100.0 / 2048.0)    
  else:
    plt = ggplot(df, aes("Register", "Diff", color = "Channel")) +
      ylim(0, 100)
  plt +
    geom_point(size = 1.5, alpha = 0.75) +
    ylab("Difference between mean and actual pedestal [ADC]") + 
    ggtitle("Attempt at computing pedestal values based on truncated mean of data") +
    margin(top = 2) +
    xlim(0, 2560) + 
    ggsave(outfile)
  
when isMainModule:
  import cligen
  dispatch main
#+end_src

We can call it on different runs with FADC data:
#+begin_src sh
code/attempt_fadc_pedestals_from_data \
    -p /mnt/1TB/CAST/2017/DataRuns/Run_77_171102-05-24 \
    --outfile ~/phd/Figs/detector/calibration/pedestal_from_data_compare_real_run77.pdf
#+end_src
for an early 2017 run
#+begin_src sh
code/attempt_fadc_pedestals_from_data \
    -p /mnt/1TB/CAST/2018_2/DataRuns/Run_303_181217-16-52 \
    --outfile ~/phd/Figs/detector/calibration/pedestal_from_data_compare_real_run303.pdf
#+End_src

#+RESULTS:

for a late 2018 run.

These yield fig. \subref{fig:daq:fadc_pedestals_from_data_compare_real}

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/phd/Figs/detector/calibration/pedestal_from_data_compare_real_run77.pdf}
    \caption{Run 77}
    \label{fig:daq:fadc_pedestals_from_data_compare_real_run77}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/phd/Figs/detector/calibration/pedestal_from_data_compare_real_run303.pdf}
    \label{fig:reco:fadc_pedestals_from_data_compare_real_run303}
    \caption{Run 303}
  \end{subfigure}
  \label{fig:daq:fadc_pedestals_from_data_compare_real}
  \caption{Calculation of the FADC pedestals from data by averaging all channels
    over all FADC data files of a single run using a truncated mean from the 20-th
    to 80-th percentile of the distribution. Both data runs show a comparatively small
    variance. Arguably it may make sense to \textit{always} compute it based on each
    run instead of relying on a pedestal run though.
  }
\end{figure}

Surprisingly, the deviation for the end 2018 run is lower than for the
2017 run, despite the 2017 run being closer in time to the real
pedestal run.

Keep in mind that in our data taking we used the 12 bit readout
mode. This means the register values divided by \num{2048} correspond
to the voltages recorded by the register. As such the absolute values
of the deviations are quite a bit smaller than $\lesssim \SI{48}{mV}$
(which is small given the absolute range of $±\SI{1}{V}$ of the FADC. 

** Scintillator calibration
:PROPERTIES:
:CUSTOM_ID: sec:daq:scintillator_calibration
:END:

The final piece of the detector requiring calibration, are the two
scintillators. As both of them are only used as digital triggers and
no analogue signal information is recorded, a suitable discriminator
threshold voltage has to be set.

- [ ] *MENTION THAT WE PREFER TOO HIGH THRESHOLD OVER TOO LOW? BETTER
  FEWER SIGNALS THAN LOTS OF NOISE?*

*** Large scintillator paddle
- [ ] Part that now lives in appendix.

The large veto scintillator paddle was calibrated at the RD51
laboratory at CERN prior to the data taking campaign in
March 2017. Using two smaller, calibrated scintillators to create a
coincidence setup of the three scintillators, measurements were taken
at different thresholds. Each measurement was $\SI{10}{\minute}$ long.

An amplifier was installed after the PMT to increase the signal. The
PMT was supplied with a voltage of \SI{1200}{V}. Table
[[tab-daq-scintillator_coincidence_measurements]] shows the recorded
measurements. Based on these a threshold of \SI{-110}{mV} was chosen
for the CAST data taking. Fig. [[fig:daq:veto_scintillator_coincidence]]
also shows the data from table. While the coincidence counts at
\SI{-110}{mV} are below the visible plateau above \SI{-100}{mV}, the
threshold was chosen as the raw counts were still considered too high
compared to expectation based on cosmic muon rate and the size of the
scintillator. [fn:threshold_choice]

#+CAPTION: Measurements for the calibration of the large veto scintillator taken
#+CAPTION: at RD51 at CERN with two smaller, calibrated scintillators in a coincidence.
#+CAPTION: Each measurement was \SI{10}{min}. The thresholds set on the discriminator for
#+CAPTION: the veto scintillator were originally measured
#+CAPTION: with a 10x scaling and have been rescaled here to their correct values.
#+NAME: tab-daq-scintillator_coincidence_measurements
#+ATTR_LATEX: :booktabs t
|----------------+---------------+--------------------|
| Threshold / mV | Counts Szinti | Counts Coincidence |
|----------------+---------------+--------------------|
|          -59.8 |         31221 |                634 |
|          -70.0 |         30132 |                674 |
|          -80.4 |         28893 |                635 |
|          -90.3 |         28076 |                644 |
|         -100.5 |         27012 |                684 |
|         -110.3 |         25259 |                566 |
|         -120.0 |         22483 |                495 |
|         -130.3 |         19314 |                437 |
|         -140.3 |         16392 |                356 |
|         -150.5 |         13677 |                312 |
|         -160.0 |         11866 |                267 |
|         -170.1 |         10008 |                243 |
|----------------+---------------+--------------------|

#+begin_src nim :var tbl=tab-daq-scintillator_coincidence_measurements :results none :exports none
import ggplotnim, sequtils
let df = toDf({ "Thr" : tbl["Threshold / mV"],
                "Szinti" : tbl["Counts Szinti"],
                "Coinc" : tbl["Counts Coincidence"] })
  .mutate(f{"SzintiErr" ~ sqrt(`Szinti`)},
          f{"CoincErr" ~ sqrt(`Coinc`)})
## XXX: `ebLinesT` is broken?!  
ggplot(df, aes("Thr", "Szinti")) +
  geom_point() + geom_line() +
  geom_errorbar(aes = aes(yMin = f{`Szinti` - `SzintiErr`},
                          yMax = f{`Szinti` + `SzintiErr`}),
                errorBarKind = ebLines,
                color = parseHex("FF00FF")) + 
  xlab(r"Threshold [\si{mV}]") + ylab(r"Counts [\#]") +
  ggtitle(r"Calibration measurements of \SI{10}{min} each") + 
  ggsave("/home/basti/phd/Figs/detector/calibration/veto_scintillator_calibration_rd51.pdf",
         useTeX = true, standalone = true)

ggplot(df, aes("Thr", "Coinc")) +
  geom_point() + geom_line() +
  geom_errorbar(aes = aes(yMin = f{`Coinc` - `CoincErr`},
                          yMax = f{`Coinc` + `CoincErr`}),
                errorBarKind = ebLines) +   
  xlab(r"Threshold [\si{mV}]") + ylab(r"Counts [\#]") +
  ggtitle(r"Calibration measurements of \SI{10}{min} each in 3-way coincidence") + 
  ggsave("/home/basti/phd/Figs/detector/calibration/veto_scintillator_calibration_coinc_rd51.pdf",
         useTeX = true, standalone = true)
#+end_src

#+CAPTION: Calibration measurements for the veto scintillator printed in table
#+CAPTION: [[tab-daq-scintillator_coincidence_measurements]]. The line is simply an
#+CAPTION: interconnection of all data points. The errors simply represent Poisson-like
#+CAPTION: $\sqrt{N}$ uncertainties.
#+NAME: fig:daq:veto_scintillator_coincidence
[[~/phd/Figs/detector/calibration/veto_scintillator_calibration_coinc_rd51.pdf]]

See the appendix [[#sec:appendix:scintillator_calibration_notes]] for a
reproduction of the notes taken during the calibration of the veto
paddle scintillator.

[fn:threshold_choice] While it is unclear to me now given it's been 5
years, I believe at the time of the calibration we wrongly assumed a
muon rate of \SI{100}{Hz.m⁻².sr⁻¹} instead of about
\SI{1}{Hz.min⁻¹}. The former number only works out if one integrates
it over the $\cos^2(θ)$ dependence, _but only along $θ$_ and not $φ$!
Either way, the number seems problematic. However, it did misguide us
in likely choosing a too low threshold, as using the former number
yields an expected number of counts of $\sim\num{32000}$ compared to
only $\sim\num{20000}$ in our naive approach.

**** Raw scintillator data  :noexport:

#+CAPTION: Calibration measurements for the veto scintillator printed in table
#+CAPTION: [[tab-daq-scintillator_coincidence_measurements]]. In this case the
#+CAPTION: raw data is shown instead of the coincidence. The line is simply an
#+CAPTION: interconnection of all data points. The errors are colored to be seen at all.
#+NAME: fig:daq:veto_scintillator_raw_counts
[[~/phd/Figs/detector/calibration/veto_scintillator_calibration_rd51.pdf]]

In particular looking at the raw counts, in hindsight I would now
probably choose a threshold closer to \SI{-90}{mV} or
\SI{-95}{mV}. But well.

**** Calculate expected rate  :noexport:

Let's compute the expected rate based on a mean cosmic muon rate at
the surface and the area of the scintillator.

The scintillator has a size of 31.49x15.74 inches and we roughly have
a mean cosmic muon rate of 1 per cm⁻² min⁻¹. Measurement time was 600 s.
#+begin_src nim
import unchained
let rate = 1.cm⁻²•min⁻¹
let area = 31.49.inch * 15.74.inch
let time = 600.s
echo "Expected rate: ", time * rate * area
#+end_src

#+RESULTS:
: Expected rate: 31977.5 UnitLess

So about 32,000 counts in the 10 min time frame. It's a bit
frustrating that for some reason during that calibration we assumed a
muon rate of 100 Hz m⁻² sr⁻¹, so that we only got an expected number
of counts of about 20,000.

If we assume the 100 Hz m⁻² sr⁻¹ number and integrate only over $θ$
(not $φ$ as we should also!) using the $\cos² θ$ dependence we get a
more comparable number:

#+begin_src nim
import unchained
let integral = 1.5708.sr # ∫_{-π/2}^{π/2} cos²(θ) dθ = 1.5708
let rate = 100.Hz•m⁻²•sr⁻¹
let angleInt = 2*π
let time = 600.s
let area = 31.49.inch * 15.74.inch
echo rate * time * area * integral
#+end_src

#+RESULTS:
: 30138.2 UnitLess

In any case, it seems like our assumption of 20000 as seen in appendix
[[#sec:appendix:scintillator_calibration_notes]] is clearly flawed and
lead to a possibly too large threshold for the discriminator.

In addition: why the hell did I not take note of the size of the
scintillators that Theodoros gave us? That would be a much better
cross check for the expected rate. It is certainly possible that our
choice of $\SI{-110}{mV}$ was actually due to an expected coincidence
rate matching at that threshold given the sizes of the calibrated
scintillators, but I can't verify that anymore.

*** SiPM [/]

The SiPM was calibrated during the bachelor thesis of Jannes Schmitz
in 2016 \cite{JannesBSc} based on a coincidence measurement with
calibrated scintillators. The exact threshold used *FIND A VALUE OR
REPHRASE*.

- [ ] *FIND VALUE*

* Data reconstruction [0/1]                                  :reconstruction:
:PROPERTIES:
:CUSTOM_ID: sec:reconstruction
:END:

#+LATEX: \minitoc

As discussed in the previous chapter, in particular section
[[#sec:daq:tos_output_format]], the output data format of the Septemboard data
acquisition software is ASCII based. We will now go through the
general data reconstruction based on recorded data for each of the
detector components. Motivations for the type of reconstructions
performed, will be given where necessary.

Starting with the GridPix data in section [[#sec:reco:gridpix_data]] as
it's the main component and its properties and shortcomings define the
need for the other detector components. The FADC data reconstruction
follows in section [[#sec:reco:fadc_data]]. Finally the scintillators are
mentioned in section [[#sec:reco:scintillators_data]].

There is an additional long section in the appendix
[[#sec:appendix:software_data_reconstruction]] that goes through the
software used for the data reconstruction intended for people using
these tools in the future. 

- [X] *WRITE CHAPTER SUMMARY*

- explain the whole data reconstruction pipeline? What we do with
  ingrid data, clustering, reconstruction
- everything up to energy calibration
- [ ] wherever we finally show the real calibrations of the detector
  for each run, show:
  - the full FSR (for one chip, then differences for each,
    particularly THS & THL)
  - show plot of THL calibration from SCurves, with the THL value as a
    "rectangle" line (from y axis to fit, down to x axis)
  - in Polya plot show the theoretical threshold in electrons as a
    vertical line (computed from the used THL DAC value and THL
    calibration)

- [ ] *SHORT INTRO TO TIMEPIX ANALYSIS AND NIM HERE. LIKE 2
  PARAGRAPHS.* Then link to

** ~TimepixAnalysis~ and Nim

The data reconstruction software handling the processes mentioned in
the remainder of this chapter is the ~TimepixAnalysis~ \cite{TPA} [fn:tpa_github]
framework. It is only a "framework" in a loose sense, as it is a set
of programs to parse data from different Timepix (usually GridPix) DAQ
software packages and process and analyze it. In addition it contains
a large number of tools to visualize that data as well as analyze
auxiliary data like lists of data taking runs, CAST log files and
more.

The entire code base is written in the Nim programming language
\cite{nim} [fn:nim_lang]. Nim is a statically typed, compiled language
with a Python-like whitespace sensitive syntax, taking inspirations
from Pascal, Modula and in particular ideas regarding type safety from
Ada. Further, it has a strong metaprogramming focus with full access
3to the abstract syntax tree (AST) at compile time, offering Lisp-like
macro functionality, which allows to construct powerful and concise
domain specific languages (DSLs). Nim compiles its code by default
first to C code, which can then utilize the decades of compiler
optimization techniques available via GCC \cite{gcc} or Clang
\cite{LLVM:CGO04}, while allowing to target every single platform
supported by C (which effectively means almost all). As such it also
achieves performance on-par with C, while providing high-level
features normally associated with languages like Python.

Nim was chosen as the language of choice for ~TimepixAnalysis~, due to
its combination of concise and clean syntax, high-level features for
productivity, high performance due to native code generation, easy
interfacing with existing C and C++ code bases and its strong
metaprogramming features, which allow to reduce boilerplate code to a
minimum.

Appendix [[#sec:appendix:software]] contains a detailed overview of the
important tools part of ~TimepixAnalysis~ and how they are used for
the context of the data analysis presented in this thesis. Read it if
you wish to understand how to recreate the results presented in this thesis.

[fn:tpa_github] https://github.com/Vindaar/TimepixAnalysis

[fn:nim_lang] [[https://nim-lang.org]]

** GridPix data reconstruction [/]

- [X] introduce what signal and background events actually look like
  -> motivates the kind of steps we then perform. So an "intro"
  section, then description of the processes.
- [X] data parsing?
- [X] clustering (our custom and DBSCAN \cite{ester1996density})
- [ ] in particular the geometric reconstruction. Split up our explanation
  schematic made in inkscape and somehow present that?

- [ ] *THIS WAS: * ~***~ Expectation of event shapes [/]

Based on the theoretical aspects of a gaseous detector as explained in
chapter [[#sec:theory_detector]] and the expected kinds of signal sources
at an experiment like CAST (c.f. [[#sec:cast]]), we can have a good
expectation of the kinds of signals that a GridPix detector records
for different types of events.

The signal source we are interested in for an axion helioscope are
soft energy X-rays, typically below \SI{10}{keV}. The main goal in
later determining a background rate and computing a physics result
from data is to filter out these X-rays from the rest of the data the
detector records. The dominant source of background in any gaseous
detector at surface level is due to cosmic muons.

Fortunately, muons and X-rays behave very different in the
detector. X-rays generally produce a single photoelectron, which
creates further primary electrons in a local region. These drift under
transverse diffusion to the readout plane, which effectively gives
them a roughly circular shape. Muons on the other hand produce
electrons (which each produce further local primaries) on a track
along their entire path through the gas volume. Under most angles this
implies their shape is very eccentric, i.e. 'track-like'.

Two example events, one of a $\sim\SI{5.9}{keV}$ $\ce{^{55}Fe}$ X-ray
and the other of a typical muon is shown in
fig. [[fig:reco:example_signal_background_event]].

#+CAPTION: Two example events one might see in the detector, left a common background event
#+CAPTION: of a (likely) muon track, which enters the readout plane (hence the slightly
#+CAPTION: triangular shape) and right a classical \SI{5.9}{keV} X-ray from a $\ce{^{55}Fe}$
#+CAPTION: calibration source.
#+NAME: fig:reco:example_signal_background_event
[[~/phd/Figs/reco/gridpix_example_events.pdf]]

Given the distinct geometric properties of these different types of
events and the fact that a GridPix provides extremely high spatial
resolution and single electron efficiency, the data reconstruction
fully embraces this. Most of the computed properties, which we will
introduce in the next sections, are directly related to geometric
properties of the events.

- [ ] *SHOULD WE MENTION ALPHAS, NEUTRONS ETC HERE?*
- [ ] *MOTIVATED BY PHYSICAL STUFF SHOWN IN THEORY, DESCRIBE
  EXPECTATION OF WHAT EVENTS SHOULD LOOK LIKE*

**** Generate example events for known events                   :noexport:  

While we have two pretty nice events to plot as examples, in
principle, they are generated by =karaPlot= (an extensive plotting
tool part of TPA) and thus not quite suited to a thesis.

As we know the run number and event number, we can just generate them
quickly here. The two events (and plots) are:
- [[~/org/Figs/statusAndProgress/exampleEvents/background_event_run267_chip3_event1456_region_crAll_hits_200.0_250.0_centerX_4.5_9.5_centerY_4.5_9.5_applyAll_true_numIdxs_100.pdf]]
- [[~/org/Figs/statusAndProgress/exampleEvents/calibration_event_run266_chip3_event5791_region_crAll_hits_200.0_250.0_centerX_4.5_9.5_centerY_4.5_9.5_applyAll_true_numIdxs_100.pdf]]
so run 267 and 266, events 1456 and 5791.

Ah, I had forgotten that these are not the event numbers, but their
indices of the clusters. Therefore, we'll just search for pretty
events in the same runs.
  
#+begin_src nim :tangle code/generate_example_gridpix_event.nim
const calib = "/mnt/1TB/CAST/2018_2/CalibrationRuns/Run_266_181107-22-14"
const back  = "/mnt/1TB/CAST/2018_2/DataRuns/Run_267_181108-02-05"
const cEv = 5898
const bEv = 1829 # this event is nice
import ingrid / tos_helpers
import std / [strformat, os, strutils, sequtils]
import ggplotnim

proc toFile(i: int, path: string): string =
  let z = align($i, 6, '0')
  path / &"data{z}.txt"

proc drawPlot() =   
  let protoFiles = readMemFilesIntoBuffer(@[toFile(cEv, calib), toFile(bEv, back)])
  var df = newDataFrame()
  var names = @["X-ray", "Background"]
  for (pf, name) in zip(protoFiles, names):
    let ev = processEventWithScanf(pf)
    let pix = ev.chips[3].pixels
    if pix.len == 0: return
    let dfL = toDf({ "x" : pix.mapIt(it.x.int), "y" : pix.mapIt(it.y.int),
                     "ToT" : pix.mapIt(it.ch.int), "type" : name })
    df.add dfL
  ggplot(df, aes("x", "y", color = "ToT")) +
    facet_wrap("type") +
    geom_point() +
    xlim(0, 256) + ylim(0, 256) +
    ggsave("/home/basti/phd/Figs/reco/gridpix_example_events.pdf", width = 1200, height = 600)

drawPlot()
#+end_src

*** TOS data parsing [/]

The first part of the GridPix data reconstruction is the parsing of
the raw ASCII data files, presented in
[[#sec:daq:tos_output_format]]. This is implemented in the
~raw_data_manipulation~ program [fn:reco_raw_data_manip], part of
~TimepixAnalysis~ \cite{TPA}. Its main purpose is the
conversion of the inefficient ASCII data format to the more
appropriate and easier to work with HDF5 [fn:hdf5] \cite{hdf5} format,
a binary file format intended for scientific datasets. While this data
conversion is the main purpose, pixels with ~ToT~ or ~ToA~ values
outside a user defined range can be filtered out at this
stage [fn:toa_tot_filter_in_raw]. Each data taking run is processed
separately and will be represented by one group (similar to a
directory on a real file system) in the output HDF5 file.

As the data is being processed anyway, at this time we already compute
an occupancy map for each chip in the run. This allows for a quick
glance at the (otherwise unprocessed) data.

[fn:reco_raw_data_manip]
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/raw_data_manipulation.nim

[fn:hdf5] HDF5 \cite{hdf5} is the Hierarchical Data Format of
version 5. It is a binary data format intended for scientific
datasets, which uses an in-file layout similar to a virtual file
system. Datasets (equivalent to files) are stored in groups
(equivalent to directories). Metadata can be attached to either and
linking between datasets, even across files is supported. It supports
a large number of compression filters to reduce the file size of the
stored data.

[fn:toa_tot_filter_in_raw] These type of cuts are applied at this
stage of the processing, because for certain use cases or certain
detectors specific ~ToT~ or ~ToA~ ranges are of no interest / contain
junk data (because of a faulty chip for example). In this case it is
useful to remove such data in this preprocessing stage to lighten the
workload for anything after.

**** HDF5 data layout generated by ~raw_data_manipulation~      :optional:

The listing [[code:reco:abstract_hdf5_layout]] shows the layout of the
data stored in the HDF5 files after the ~raw_data_manipulation~
program has processed the TOS run folders. The data is structured
in groups based on each run, chip and the FADC (if
available). Generally each "property" is stored in its own dataset
for performance reasons to allow faster access to individual subsets
of the data (read only the hits, only $x/y$ data, etc.). While HDF5
supports even heterogeneous compound datasets (that is different data
types in different "columns" of a 2D like dataset), these are only
used sparingly and not at all in the ~raw_data_manipulation~ output,
as reading individual columns from these is inefficient. 

#+CAPTION: An abstract overview of the general layout of the generated HDF5 files.
#+CAPTION: Each entry shown that does not have any children is an HDF5 group. Every
#+CAPTION: leaf node is an HDF5 dataset. The data is ordered by availability. Each
#+CAPTION: run is a separate group. Within all chips have their own groups with data
#+CAPTION: associated to that chip. The common datasets are those that contain data
#+CAPTION: from the TOS event header. FADC data is that, which is contained in the
#+CAPTION: FADC files (for which fewer than regular TOS data files exist).
#+NAME: code:reco:abstract_hdf5_layout
#+begin_src toml
- runs
  - run_<number>
    - chip_0 # one for each chip in the event
      - Hits # number of hits in each event
      - Occupancy # a 2D occupancy map of this run
      - ToT # all ToT values of this run
      - raw_ch # the ToT/ToA values recorded for each event (ragged data)
      - raw_x # the x coordinates recorded for each event (ragged data)
      - raw_y # the y coordinates recorded for each event (ragged data)
    - chip_i # all other chips
      - ...
    - fadc # if available
      - eventNumber # event number of each entry
                    # (not all events have FADC data)
      - raw_fadc # raw FADC data (uncorrected, all 10240 registers)
      - trigger_record # temporal correction factor for each event
    - fadcReadout # flag if FADC was readout in each event
    - fadcTriggerClock # clock cycle FADC triggered
    - szintillator trigger clocks # datasets for each scintillator
    - timestamp # timestamp of each event
  - run_i # all other runs
    - ...
#+end_src

*** Data reconstruction

With the data stored in an HDF5 file after processing the raw data
with ~raw_data_manipulation~, the actual data and event reconstruction
can begin. This is handled by the
~reconstruction~ [fn:reco_reconstruction] program. It continues from
the HDF5 file created before and proceeds to reconstruct all runs in
the given input file.

- [ ] *REFER TO ~reconstructSingleChip~ HERE*
For each run, each GridPix chip is processed sequentially, while all
events for that chip are then processed in parallel using
multithreading.

For each event, the data processing is essentially a two step process:
1. perform cluster finding, see section [[#sec:reco:cluster_finding]].
2. compute geometric properties for each found cluster, see section
   [[#sec:reco:cluster_geometry]].


Basic reconstruction:
- [ ] per run, per chip
- [ ] clustering (2 cluster methods)
- [ ] geometric properties
  - [ ] find rotated coordinate system
  - [ ] compute parameters for long & short axis
  - [ ] resulting parameters
- [ ] table of parameters (we have that somewhere already)
- [ ] use a description to describe all parameters like
  - X :: description    

[fn:reco_reconstruction]
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/reconstruction.nim

**** Cluster finding 
:PROPERTIES:
:CUSTOM_ID: sec:reco:cluster_finding
:END:

The cluster finding algorithm splits a single event into possibly
multiple clusters. Clusters are defined based on a certain notion of
distance (the details depend on the clustering algorithm used). The
multiple clusters from a single event are then treated fully equally
for the rest of the analysis. The fact that they originate from the
same event has no further relevance (with a slight exception for one
veto technique, which utilizes clustering over multiple chips, more on
that in section [[sec:septem_veto]]).

There are two different cluster finding algorithms implemented for use
in ~TimepixAnalysis~. By default one is strictly used for the general
cluster finding as part of the reconstruction, the other is intended
to be used for one of the vetoes (again, sec. [[sec:septem_veto]]). The
choice is user configurable however. [fn:clustering]

- Default :: The default one is the same clustering algorithm
  introduced for the data reconstruction of the 2014/15 GridPix
  detector in \cite{krieger2018search}. It defines a cluster by all
  pixels within the squares of side length $N$ centered around each
  pixel. It is best thought of as a recursive square neighbor search
  around each pixel. For each neighbor in the search square, start
  another search square. Once no neighbor finds any neighbors not
  already part of the cluster, it is finished.
- DBSCAN :: The secondary clustering algorithm is the
  \textbf{D}ensity-\textbf{b}ased \textbf{s}patial \textbf{c}lustering
  of \textbf{a}pplications with \textbf{n}oise (DBSCAN)
  \cite{ester1996density} algorithm. In contrast to the default
  algorithm it is - as the name implies - a density based
  algorithm. This means it distinguishes points which have more
  neighbors (high density) from those with few neighbors (low
  density). The algorithm has a parameter ~minSamples~, which defines
  the density threshold. If a point has at least ~minSamples~ neighbors within a
  (euclidean) distance of $ε$ (the second parameter) it is considered
  a "core point". All core points build a cluster with all other
  points in their reach. Those points in reach of a core point,
  but do itself not have ~minSamples~ neighbors are still part of the
  cluster. Any point _not_ in reach of a core point is a "noise
  point". The main advantage of this algorithm over many other more
  classical algorithms is the ability to separate clusters close to one
  another, which are not separateable by a linear cut. This results in
  a more humanly "intuitive" clustering.
  DBSCAN is one of the most widely used clustering algorithm in many
  scientific fields and even in 2017 was still considered highly
  relevant \cite{10.1145/3068335}.

- [ ] *THINK ABOUT EXAMPLE OF CLUSTERING THAT DBSCAN FINDS AND DEFAULT
  WOULDN'T* NON LINEAR CLUSTERABLE

[fn:clustering] The clustering logic of TPA is found here: https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/clustering.nim

[fn:default_algo_core] The heart of the algorithm is the following
pixel search: https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/clustering.nim#L120-L148

***** CLASSIX clustering algorithm [/]                         :noexport:

- [ ] *OR SHOULD THIS GO INTO MAIN SECTION BEFORE?* OR AS :optional:?

There is one further clustering algorithm, which is extremely exciting
and seems like a great candidate for a clustering algorithm for
~TimepixAnalysis~. That is the CLASSIX algorithm, introduced as "a
fast and explainable clustering method" \cite{CLASSIX}.

See the GitHub page with many examples here:
https://github.com/nla-group/classix

It is an algorithm, which first sorts the data based on the first
principal component in the data. 

***** Clustering bug in MarlinTPC for 2014/15 data             :noexport:

One of the initial goals of ~TimepixAnalysis~ was the reproduction of
the background rate computed for the 2014/15 data with the MarlinTPC
framework. While that whole ordeal wasted a lot of time trying to
achieve the exact same results from both frameworks to satisfy other
people, among other things it lead to the discovery of a clustering
bug in MarlinTPC (which was finally the point that let me drop this
pursuit).



- [ ] *INSERT DISCUSSION FROM STATUSANDPROGRESS ABOUT MARLIN CLUSTER
  BUG* See section ~sec:marlin_vs_tpa_output~ in TPA for the Marlin
  clustering bug.

**** Calculation of geometric properties
:PROPERTIES:
:CUSTOM_ID: sec:reco:cluster_geometry
:END:


- [ ] *REWRITE ME*
For each individual cluster the geometric event reconstruction
is up next. As the basic differentiator between X-rays and common
background events is their circularity, most properties are in some
sense related to eccentric clusters are. Therefore, the first thing to
be computed for each cluster, is the rotation
angle [fn:rotation_angle].

The rotation angle is found via a non linear optimization

\begin{align}
  x'_i &= \cos(θ) \left( x_i - \bar{x} \right) · P - \sin(θ) \left( y_i - \bar{y} \right) · P \\
  y'_i &= \sin(θ) \left( x_i - \bar{x} \right) · P + \cos(θ) \left( y_i - \bar{y} \right) · P 
\end{align}

where $θ$ is the rotation angle (in the context of the optimization
the parameter to be fitted), $x_i, y_i$ the coordinates of the $i$-th
pixel in the cluster, and $\bar{x}, \bar{y}$ the center coordinates of
the cluster. $P = \SI{55}{μm}$ is the pixel pitch of a Timepix. The
resulting variables $x'_i, y'_i$ define a new rotated coordinate
system. From these coordinates, the RMS of each of these new axes is
computed via

\begin{align}
  x_{\text{RMS}} &= \sqrt{ \frac{1}{N} \left( \sum_i x^{\prime2}_i \right) - \frac{1}{N²} \left( \sum_i x'_i \right)² }\\
  y_{\text{RMS}} &= \sqrt{ \frac{1}{N} \left( \sum_i y^{\prime2}_i \right) - \frac{1}{N²} \left( \sum_i y'_i \right)² }.
\end{align}

These then can define the eccentricity $ε$ to (see also fig. [[fig:reco:prop_expl_ecc]])

\[
ε = \frac{x_{\text{RMS}}}{y_{\text{RMS}}}
\]

During the non linear optimization, the algorithm attempts to maximize
the eccentricity. In a track like cluster, the maximum eccentricity is
found under the rotation angle $θ$, which points along the longest
axis of the cluster. The resulting rotated coordinate system after the
fit has converged, is illustrated in
fig. \subref{fig:reco:prop_expl_axes}.

Once the rotation angle and therefore the rotated coordinate system of
a cluster is defined, most other properties follow in a straight
forward fashion. In the rotated coordinate system the axis along the
long axis of the cluster is called "longitudinal" and the short axis
"transverse" in the following. The higher moments skewness and
kurtosis for each axis are computed as well as the length and width of
the cluster based on the biggest spread of pixels along each axis.  In
addition to the geometric properties a few other properties like the
number of pixels are also computed. 

- [ ] *EXPLANATION OF THE 3 MAIN PROPERTIES USED FOR LIKELIHOOD*
- [ ] *LOOK INTO \subref RENDERING. SHOULDN'T JUST SHOW a) HERE*  

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/org/Figs/InGridPropExplanation/long_short_axis.pdf}
    \caption{Rotated axes}
    \label{fig:reco:prop_expl_axes}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/org/Figs/InGridPropExplanation/eccentricity.pdf}
    \label{fig:reco:prop_expl_ecc}
    \caption{Eccentricity}
  \end{subfigure}
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/org/Figs/InGridPropExplanation/frac_in_trans_rms.pdf}
    \caption{Fraction in transverse RMS}
    \label{fig:reco:prop_expl_fracRms}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/org/Figs/InGridPropExplanation/length_div_rms_trans.pdf}
    \label{fig:reco:prop_expl_ldiv}
    \caption{Length divided by transverse RMS}
  \end{subfigure}
  \label{fig:reco:property_explanations}
  \caption{Funky things.
  }
\end{figure}

#+begin_comment
Probably won't end up using this table, instead use the descriptions
below.

#+CAPTION: Table of all the (mostly) geometric properties of a single cluster computed during the
#+CAPTION: =reconstruction= tool. All but the likelihood, charge and energy properties are computed
#+CAPTION: during the first pass of the tool.
#+NAME: tab:geometric_properties
#+ATTR_LATEX: :booktabs t
| Property                  | Meaning                                                          |
|---------------------------+------------------------------------------------------------------|
| igCenterX                 | =x= position of cluster center                                   |
| igCenterY                 | =y= position of cluster center                                   |
| igHits                    | number of pixels in cluster                                      |
| igEventNumber             | event number cluster is from                                     |
| igEccentricity            | eccentricity of the cluster                                      |
| igSkewnessLongitudinal    | skewness along long axis                                         |
| igSkewnessTransverse      | skewness along short axis                                        |
| igKurtosisLongitudinal    | kurtosis along long axis                                         |
| igKurtosisTransverse      | kurtosis along short axis                                        |
| igLength                  | size along long axis                                             |
| igWidth                   | size along short axis                                            |
| igRmsLongitudinal         | RMS along long axis                                              |
| igRmsTransverse           | RMS along short axis                                             |
| igLengthDivRmsTrans       | length divided by transverse RMS                                 |
| igRotationAngle           | rotation angle of long axis over chip coordinate system          |
| igEnergyFromCharge        | energy of cluster computed from its charge                       |
| igLikelihood              | likelihood value for cluster                                     |
| igFractionInTransverseRms | fraction of pixels within radius of transverse RMS around center |
| igTotalCharge             | integrated charge of total cluster in electrons                  |
| igNumClusters             |                                                                  |
| igFractionInHalfRadius    | fraction of pixels in half radius around center                  |
| igRadiusDivRmsTrans       | radius divided by transverse RMS                                 |
| igRadius                  | radius of cluster                                                |
| igLengthDivRadius         | length divided by radius                                         |
#+end_comment

The following is a list of all properties of a single cluster computed
by the ~reconstruction~ tool. All but the likelihood, charge and energy properties are computed
during the first pass of the tool, namely in the context discussed
above. [fn:geometry_calc]

- igCenterX / igCenterY :: The center position of the cluster along
  the ~x~ / ~y~ axis of the detector.
- igHits :: The number of pixels in the cluster.
- igEventNumber :: The event number the cluster is part of (multiple
  clusters may share the same event number).
- igRotationAngle :: The rotation angle of the long axis of the
  cluster over the chip coordinate system.
- igLength :: The length of the cluster along the long axis in the 
  rotated coordinate system, defined by the furthest pixel at each
  end in that direction.
- igWidth :: The equivalent of *igLength* for the short axis.
- igRadius :: The radius of the cluster, defined by *IM NOT DEFINED
  YET, DEFINE ME*
- igRmsLongitudinal :: The root mean square (RMS) along the long axis.
- igRmsTransverse :: The RMS along the short axis.
- igSkewnessLongitudinal / igKurtosisLongitudinal :: The skewness / kurtosis along the long axis.
- igSkewnessTransverse / igKurtosisTransverse :: The skewness / kurtosis along the short axis.
- igEccentricity :: The eccentricity of the cluster, defined by the
  ratio of the longitudinal RMS over the transverse RMS.
- igLengthDivRmsTrans :: The length of the cluster divided by the
  transverse RMS (see fig. [[fig:reco:prop_expl_ldiv]]).
- igFractionInTransverseRms :: The fraction of all pixels within a
  radius of the transverse RMS around the center (see fig. [[fig:reco:prop_expl_fracRms]]).
- igRadiusDivRmsTrans :: The radius over the transverse RMS.
- igFractionInHalfRadius :: Equivalent to *igFractionInTransveresRms*
  but for a radius of half the cluster radius.
- igLengthDivRadius :: The length divided by the cluster radius.
- igTotalCharge :: The sum of the charge of the ~ToT~ calibrated
  charges of all pixels in the cluster.
- igEnergyFromCharge :: The calibrated energy of the cluster in \si{keV}.
- igLikelihood :: The likelihood value of the cluster for the
  likelihood cut method, explained in detail in section
  [[#sec:logL:likelihood_of_cluster]].

After the calculation of all geometric properties for all events and
chips, the data is written to an output HDF5 file (similar in format to
the output of ~raw_data_manipulation~) for each run. This concludes
the first pass of ~reconstruction~ over the data.

The properties are computed here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L308-L366
and here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L517-L569

- [ ] *PLACE THE LINKS AFTER FIX UP SOMEWHERE THEY BELONG*
- [ ] *CONSIDER MOVING LIST OF ALL PROPERTIES TO FURTHER DOWN ONCE WE
  HAVE DISCUSSED CHARGE CALIB?*  

[fn:rotation_angle] Note that the absolute value of the rotation angle
is of secondary importance. For X-rays the rotation angle is going to
be random, as the definition of a long and short axis in a
(theoretically perfect) circle depends on the statistical distribution
of the pixels. However, for pure muons it allows to map the rotation
angle to the incidence angle.

[fn:calc_eccentricity]
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L296-L329

[fn:geometry_calc] In particular all these properties are computed
here: https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L331-L391
  
**** HDF5 data layout generated by ~reconstruction~             :optional:

The HDF5 file generated by ~reconstruction~ follows closely the one
from ~raw_data_manipulation~. The main difference is that within each
chip group now each chip has a different number of entries in the
datasets, as each entry now corresponds to a single cluster, not an
event from the detector. On some events multiple clusters on a single
chip may be reconstructed, while other events may be fully empty. This
means an additional ~eventNumber~ dataset is required for each chip,
which maps back each cluster to a corresponding event.

Aside from that the other major difference is simply that each chip
has a larger number of datasets, as each computed cluster property is
a single variable. Also additional new datasets will be created during
the data calibration (charge calibration, computation of the gas gain,
etc.).

Listing [[code:reco:abstract_reco_hdf5_layout]] shows the layout in a
similar fashion to the equivalent for ~raw_data_manipulation~ before.

#+CAPTION: Abstract overview of the data layout of the ~reconstruction~ HDF5
#+CAPTION: output. It is essentially the same layout as the ~raw_data_manipulation~
#+CAPTION: HDF5 files, but contains more datasets, due to larger number of
#+CAPTION: properties.
#+NAME: code:reco:abstract_reco_hdf5_layout
#+begin_src toml
- reconstruction
  - run_<number>
    - chip_0 # one for each chip in the event
      - datasets for each property
      - optional datasets for calibrations
    - chip_i # all other chips
      - ...
    - fadc # if available
      - datasets for each FADC property
    - common datasets # copied from `raw_data_manipulation` input 
  - run_i # all other runs
    - ...
#+end_src

*** Data calibration

The next step of the reconstruction is the data calibration. This is a
separate pass over the data as it is optional on the one hand and
requires further inputs about each used GridPix than just the raw data
(different calibration files).

There are different calibrations to be performed:

1. the charge calibration via the application of the ~ToT~ calibration
   as introduced in section [[#sec:daq:tot_calibration]].
2. the calculation of the gas gain, introduced in section
   [[#sec:daq:polya_distribution_threshold]].
3. the energy calibration (see
   sec. [[#sec:calibration:energy_calibration]] in the next chapter).

Here we will only discuss the ~ToT~ calibration, as the other two are
more involved and require deeper explanations.

The ~ToT~ calibration is in principle performed simply by converting
each ~ToT~ value to an equivalent charge in electrons using the
calibration as presented in section [[#sec:daq:tot_calibration]]. For each
GridPix used in a detector, a ~ToT~ calibration must be available.

- [ ] *SHOW AGAIN?*


~TimepixAnalysis~ comes with a library and helper program, which
manages a simple database about different GridPixes, their
calibrations and their validity (in time & runs they apply to). The
user needs to add the chips for which they wish to perform a ~ToT~
calibration to the database before it can be performed. See appendix
[[#sec:appendix:software:ingrid_database]] for a detailed overview.

For any chip part of the database, the ~ToT~ calibration is a single
pass over the ~ToT~ values of all runs. This generates a calibrated
charge for every pixel of every cluster and a combined property, the
~totalCharge~ of the full charge of each cluster.



And this is where the ugly mess of needing X or Y starts :(
at least for energy calibration, we will refer to section later

While the energy calibration is also handled by ~reconstruction~, we
will cover it in section [[#sec:calibration:energy]], due to its more
complex nature.

- [ ] *MENTION INGRID DATABASE STORING TOT CALIB DATA*

**** ~InGridDatabase~ [0/1]                                     :optional:
(or :noexport: ?)
- [ ] introduce database including the data structure needed to add a
  detector to the database?

- [ ] *OR SHOULD THIS BE PART OF THE APPENDIX ABOUT SOFTWARE AND IN
  SECTION ABOVE WE MENTOIN AND REFER TO THAT?*  

*** Event duration [0/1]

During the reconstruction of the data, another important parameter is
computed, namely the event duration of each individual event. In
principle each event has a fixed length, because the Timepix uses a
shutter based readout, with the shutter length predefined. However, as
the FADC is used as an external trigger to close the shutter early, if
it recorded a signal, all events with an FADC trigger have a shorter
duration.

For the fixed length duration events their length is computed by the
shutter length as indicated in TOS. In section
[[#sec:daq:tos_output_format]], listing
[[code:daq:zero_suppressed_readout_run_header]] the ~shutterTime~ and
~shutterMode~ fields were listed. These define the absolute length of
the shutter opening in (effectively) number of clock cycles. The
~shutterMode~ acts as a modifier to the number of clock cycles:

\[
t_{\text{clocks}}(\mathtt{mode}, t) = 256^{\mathtt{mode}} · t
\]

where $t$ is the ~shutterTime~ and $\mathtt{mode}$ corresponds to the
~shutterMode~. The available modes are:
- ~short~: \num{0}
- ~long~: \num{1}
- ~verylong~: \num{2}

In case of the FADC triggering, the clock cycles after shutter opening
that were recorded up to the trigger is also reported in the data
files, see sec. [[#sec:daq:tos_output_format]], listing
[[code:daq:zero_suppressed_readout_event_header]].

With the number of clock cycles the shutter was open, the total event
duration can then be computed in either case via:

\[
d(t_{\text{clocks}}) = \frac{t_{\text{clocks}} · 46}{40 · \num{1000000}}.
\]


- [X] How to compute length of events, given
  - shutter mode & length
  - FADC trigger

[fn:event_duration_calc] https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/pure.nim#L266-L297

*** InGrid database                                              :optional:

Section about InGrid database (or maybe :noexport: instead
of :optional: ?), which explains the idea of storing the chip
calibration data in a single HDF5 file, which can then be easily
accessed from the reconstruction / calibration 

** FADC [/]
:PROPERTIES:
:CUSTOM_ID: sec:reco:fadc_data
:END:

The data files created from the FADC data sent upon a trigger are
essentially memory snapshots of the circular register of the FADC. We
will go through the necessary steps to convert that raw data into
usable signals, given the FADC settings we use and the data TOS
generates from it. For a detailed overview of the process see the FADC
manual \cite{fadc_manual} [fn:reco_fadc_manual].

- [ ] *ADD SOME KIND OF MOTIVATON FOR WHAT WE MIGHT WANT TO DO WITH THE SIGNALS?*

- [ ] *ADD EXPLANATION HOW IT FITS INTO ~raw_data_manipulation~ AND
  ~reconstruction~*

- [ ] *ADD MENTION OF SAVITZKY GOLAY!*  
  
*** FADC spectrum reconstruction [/]

The first step to reconstruct the FADC data is to perform the pedestal
correction. This is simply done by subtracting the pedestals register
by register from the data file

\[
N_{i, \text{corr}} = N_{i, \text{raw}} - N_{i, \text{pedestal}}
\]

with the raw data $N_{i, \text{raw}}$ and the pedestals
$N_{i, \text{pedestal}}$ in register $i$.

With the pedestals removed, the temporal correction is next to unfold
the data into the correct order. This needs to be performed on each of
the \num{2560} registers for each channel separately. The temporal
rotation is performed by shifting all registers by

\[
n_\text{rot} = (\mathtt{TRIG\_REC} - \mathtt{POSTTRIG}) · 20
\]

places to the left. The constants $\mathtt{TRIG\_REC}$ and
$\mathtt{POSTTRIG}$ are those from section [[#sec:daq:fadc_data_files]],
written in each data file in the header.

The final step is to convert the ADC values of each register into
voltages in \si{V}. Given that the ADC covers the range of
\SIrange{-1}{1}{V} as the ADC values 0 to 4096 (16384) with 12 (14)
bit, this means the conversion from ADC to ticks is simply

\[
U_i = \frac{N_{i, \text{corr}} - 2048}{2048}
\]

when using the 12 bit operating mode for each register.

With these corrections applied, the recorded FADC spectrum is
recovered, centered around the trigger position.


[fn:reco_fadc_manual] A PDF of the FADC manual is available here:
https://archive.org/details/manualzilla-id-5646050/

[fn:fadc_code] Data parsing and the mentioned reconstruction code is
found at *CITE*

- [ ] *ADD CITATION FOR* https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/fadc_helpers.nim

*** Signal baseline, rise time and fall time [/]                 :analysis:

Assuming a singular event is recorded with the FADC, the main
properties of interest of the resulting signal pulse are the signal
baseline and based on that the rise and fall time.

Computing the position of the baseline is generally a non trivial
problem, as a priori the position, width and number of signals in the
spectrum is unknown. A reasonable expectation though is that the
majority of points in a signal should lie close to the baseline. As
such a somewhat empirical way to compute the baseline $B$ was chosen to

\[
B = \text{median}(S) + 0.1 · \max(S)
\]

that is, adding \SI{10}{\percent} of the maximum value of the spectrum
$S$ to the median of it. Note that the signals are _negative_ and so
the maximum represents some noise outlier to positive values. The
median by itself is generally slightly too low. An optimal solution
would perform a rigorous peak finding for a signal pulse, remove those
points and compute the mean of the remainder of the points. 

Once the baseline is defined it can be used to determine both the rise
and the fall time. These are simply computed as the number of
registers between the register of the minimum of the spectrum
$\text{argmin}(S)$ and the baseline on the left (rise time) and right
(fall time). [fn:naming_rise_fall] From the difference in number of
registers, the time can be computed.

- [ ] *CHANGE FADC CODE TO NOT USE MIN, BUT MEAN OF N POINTS AROUND
  MIN?*

Together, a reconstructed FADC spectrum including indications for
baseline, rise and fall time as well as the minimum is shown in
fig. [[fig:reco:fadc_reco_example]].


#+CAPTION: Example of a fully reconstructed FADC spectrum from a \SI{5.9}{keV} X-ray
#+CAPTION: recorded with the Septemboard detector during a calibration run. *REPLACE PLOT*
#+NAME: fig:reco:fadc_reco_example
[[~/phd/Figs/reco/fadc_spectrum_baseline1645898374.pdf]]

- [ ] *REPLACE THE PLOT!*
- [ ] *ADD CITATION FOR* https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/fadc_analysis.nim  

[fn:naming_rise_fall] The naming of the rise and fall time in the
context of a negative pulse is slightly confusing. Rise time refers to
the _negative rise_ towards the minimum of the pulse and the fall time
to the time to return-to-baseline.  

*** Noise sensitive [/]

Because of the small amplitude of the associated signals induced on
the grid, electromagnetic interference is a serious issue with this
FADC setup. Ideally, the detector should be installed in a Faraday
cage and a short, shielded LEMO cable should be used to connect it to
the

- [ ] *WHAT TO DO WITH THIS? WHERE SHOULD THIS GO? MAYBE MENTION IN
  FADC INTRODUCTION ALREADY? OR HERE BECAUSE AFTER ALL? IT SHOWS UP IN
  ANALYSIS AND WE HAVE SIMPLE NOISE DETECTION IN CODE*

*** FADC amplifier settings / calibration of amplifier settings

FADC does not require a proper calibration. However, better
measurements of the effect of the different integration /
differentiation settings of the amplifier would have been very
valuable. [fn:detector_fadc_amp_measurements]

Outside of that 

[fn:detector_fadc_amp_measurements] 
** Scintillator data
:PROPERTIES:
:CUSTOM_ID: sec:reco:scintillator_data
:END:

For the scintillator signals we only record a trigger flag and the
number of clock cycles since the last scintillator trigger from the
moment the FADC triggered. These two pieces of information are part of
the Septemboard data files included in the
header. [fn:reco_scinti_data_bug_1] [fn:reco_scinti_data_bug_2]

[fn:reco_scinti_data_bug_1] Important note for people potentially
investigating the raw data from 2017: There was a small bug in the
readout software during the beginning of the 2017 data taking period,
which wrote the scintillator trigger values clock cycle values into
subsequent output files even if no FADC trigger was received (and thus
no scintillator trigger was actually read out). However, there is a
flag for an FADC trigger. To correctly read the first data runs it is
therefore required to not only look at the scintillator trigger clock
cycles, but also at whether the FADC actually triggered. This is
handled in the analysis framework.

[fn:reco_scinti_data_bug_2] *REWRITE AND MOVE* In addition to the
above bug, there was unfortunately a more serious bug, which rendered
the scintillator counts useless in the end of 2017 / beginning of 2018
data taking period. The polarity of the signals was inverted in the
detector firmware, resulting in useless "trigger" information. 


- [ ] *WAS POLARITY REALLY THE ISSUE? I THINK SO, BUT NOT SURE*

- [ ] *SHOULD SCINTI BUG NO TRIGGERS IN RUN 2 BUG BE MENTIONED HERE OR
  IN CAST DATA TAKING CHAPTER? IT THINK LATTER* Investigate the scinti
  bug again that caused data loss in the first place. What was wrong?


* Detector installation at CAST & data taking                         :Part3:
:PROPERTIES:
:CUSTOM_ID: sec:cast
:END:

#+LATEX: \minitoc

- [ ] *HAVE A SORT OF TIMELINE APPROACH?*
  Or instead first start with a factual representation of what the
  setup actually looked like and then a "retrospective" of the
  different times? Including the problems that were encountered?

In this chapter we will cover the data taking with the Septemboard
detector at the CAST experiment. We will begin with a timeline of the
important events and the different data taking periods to give some
reference and put certain things into perspective,
sec. [[#sec:cast:timeline]]. After that we will provide an overview of the
technical aspects (vacuum system, operations, etc.) in section
[[#sec:cast:operation]]. This is followed by further details on different
aspects mentioned in the timeline, which require further details,
sections [[#sec:cast:X]] *WHAT SECTIONS*. In the second to last section
[[#sec:cast:data_overview]] we will provide an overview of the total data
taken with the Septemboard detector. The final section
[[#sec:cast:problems_lessons]] finishes by discussing different issues
encountered and lessons learned.  


bla bla bla, the setup includes a $\ce{^{55}Fe}$ source mounted to a
pneumatic manipulator, see sec. [[#sec:cast:55fe_manipulator]], ...

The appendix contains an additional chapter
[[#sec:appendix:cast_operations]], which contains details about the
operating procedures with respect to the gas supply and vacuum
system. As the details of that are not particularly relevant after
shutdown of the experiment, it is not discussed here.

** Introduction about data taking? [/]

- [ ] *MENTION 2016 COSMIC ALIGNMENT MEASUREMENT? Maybe as a footnote
  "for completeness sake"*

- [ ] *INTRODUCE NAMING OF RUN-2 AND RUN-3! RELATED TO DETECTOR
  CALIBRATIONS AND WORKING FEATURES*

- [ ] *INTRODUCE NAMING FOR AIRPORT, JURA, SUNSET, SUNRISE*  


** TODO [0/4]

- [X] alignment photo of laser alignment
- [X] geometer measurements
- [X] X-ray finger for alignment
- [X] section about the 55Fe source and manipulator, with noexport
  section about the software used to control it.  

- [ ] compute real dead time as done in `run_statistics.txt` files
  available for 2016 data taking campaign in December (grepping
  through tpc19, I finally found the code: [[file:~/CastData/Code/scripts/PyS_timeOfRunFolder.py]]
  

*** X-ray finger [/]

- [ ] include funky reconstruction info / expected rate of X-ray
  finger and what we actually got?

** Timeline

The Septemboard detector was prepared for data taking at the CAST
experiment in July 2017 for preliminary alignment and fit tests. The
detector was mounted behind the LLNL telescope and aligned with a
laser from the opposite side of the magnet on <2017-07-07> (see
fig. [[fig:cast:laser_alignment1]]). Vacuum leak tests were performed and
the detector installed on <2017-07-10> (see
fig. [[fig:cast:detector_installed]]). In addition geometer measurements
were done for final alignment and as a reference measurement the day
after. An Amptek COOL-X X-ray generator [fn:amptek] ('X-ray finger')
was installed on the opposite side of the magnet. A calibration
measurement with the X-ray finger ran from <2017-07-13> over
night. The aim of an X-ray finger run is to roughly verify the focal
spot of the X-ray telescope. After this initial test the detector was
dismounted to make space for the KWISP experiment.

Two months later the detector was remounted between <2017-09-11 Mon>
to <2017-09-14 Thu> with another geometer measurement on the last
day. During an attempt to clean the detector water cooling system on
<2017-09-19>, the window of the detector was destroyed (see section
[[#sec:cast:window_accident]]). This required a detector dismount and
transport to Bonn for repairs as the detector was electronically dead
after the incident.

Near the end of October <2017-10-23> the remount of the detector
started and was finished by <2017-10-26> in time for another geometer
measurement and alignment. The next day the veto paddle scintillator
was calibrated using a 3-way coincidence in the RD51 laboratory (see
sec. [[#sec:daq:scintillator_calibration]]), followed by the installation
of the lead shielding and scintillator installation another day
later. With everything ready, data taking of the first data taking
period with the Septemboard detector started on <2017-10-30>. During
the period until <2017-12-22> few minor issues were encountered, see
sec. [[#sec:cast:data_taking_woes_2017]]. As CERN is typically closed over
Christmas and well into January, data taking was paused until
<2017-02-17> (further time is necessary to prepare the magnet for data
taking again).

The second part of the first data taking then continued on until
<2017-04-17>, with a few more small problems encountered, see
[[#sec:cast:data_taking_woes_2018]]. After data taking commenced,
dismounting of the detector began the next day by removing the veto
scintillator and the lead shielding. On <2018-04-20> another X-ray
finger run was performed to get a sense of the placement of the
detector during its actual mount as it was during the first data
taking period. Afterwards, the detector was fully removed by
<2018-04-26> to bring it back to Bonn to fix a few problems.

Data taking was initially intended to continue by summer of 2018. The
fully repaired detector was installed between <2018-07-16> and
<2018-07-19> with a few minor delays due to a change in mounting of
the lead shielding support to accommodate a parallel data taking with
KWISP. Unfortunately, external delays pushed the begin of the data
taking campaign back into late October. On <2018-10-20> the data
taking finally begins after a power supply issue was fixed the day
before. For alignment another Geometer measurement was performed on
<2018-07-23>. The issues encountered during this data taking period,
which lasted until <2018-12-20> are mentioned in sec. [[#sec:cast:data_taking_woes_2018_2]].

With the end of 2018 the data taking campaign of the Septemboard was
at an end. The detector was moved over from CAST to the CAST Detector
Lab (CDL) on <2019-02-14> for a measurement campaign behind an X-ray
tube for calibration purposes. Data was taken until <2019-02-21> with
a variety of targets and filters (see sec. [[#sec:calibration:cdl]] in the
next chapter for a deeper overview). Afterwards the detector was
dismounted and taken back to Bonn.

- [ ] *MENTION 55Fe for outer chips here?*

For the results of the different alignments, further see section [[#sec:cast:alignment]].

#+CAPTION: Alignment of the telescope side pipes using an acryllic glass
#+CAPTION: flange with a centered grid and a laser aligned to the magnet
#+CAPTION: bore. The central laser spot is the point on the vertical line
#+CAPTION: extending out from the center. The other points towards the lower right
#+CAPTION: are further refractions. This was better visible by eye.
#+NAME: fig:cast:laser_alignment1
[[~/phd/Figs/CAST_Alignment/laser_alignment_IMG_20170707_121738.jpg]]

#+CAPTION: Detector installed on the beamline behind the LLNL telescope on <2017-07-10>.
#+NAME: fig:cast:detector_installed
[[~/org/Figs/CAST_Alignment/detector_installed_after_laser_alignment_IMG_20170710_185009.jpg]]

- [ ] *MERGE TWO FIGURES TO SUBFIG*

[fn:amptek]
https://www.amptek.com/internal-products/obsolete-products/cool-x-pyroelectric-x-ray-generator

*** Detailed technical timeline [/]                              :noexport:

- [ ] *COPY BACK TO STATUS AND PROGRESS WITH UPDATES!*

- Initial installation 2017 ::
  - ref:
    https://espace.cern.ch/cast-share/elog/Lists/Posts/Post.aspx?ID=3420
    and [[file:~/org/Documents/InGrid_calibration_installation_2017_elog.pdf]]
  - June/July detector brought to CERN
  - before <2017-07-07 Fri> alignment of LLNL telescope by Jaime
  - <2017-07-07 Fri> laser alignment (see [[file:~/org/Figs/CAST_Alignment/laser_alignment_IMG_20170707_121738.jpg]])
  - <2017-07-10 Mon> vacuum leak tests & installation of detector
    (see:
    [[file:~/org/Figs/CAST_Alignment/detector_installed_after_laser_alignment_IMG_20170710_185009.jpg]])
  - after <2017-07-10 Mon> installation of lead shielding
  - <2017-07-11 Tue> Geometer measurement of InGrid alignment for
    X-ray finger run
  - <2017-07-13 Thu> - <2017-07-14 Fri>: first X-ray finger run (not
    useful to determine position of detector, due to dismount after)
  - after: dismounted to make space for KWISP

- Installation for data taking start ::    
  - Remount in September 2017 <2017-09-11 Mon> - <2017-09-14 Thu>
  - installation from <2017-09-11 Mon> to <2017-09-15 Fri> 
  - <2017-09-14> Alignment with geometers for data taking, magnet warm and under vacuum.

- Window explosion cleaning accident ::
  - weekend: (ref: [[file:~/org/Talks/CCM_2017_Sep/CCM_2017_Sep.org]])
    - calibration (but all wrong)
    - water cooling stopped working
  - next week: try fix water cooling
  - quick couplings: rubber disintegrating causing cooling flow to go to
    zero
  - attempt to clean via compressed air
  - final cleaning <2017-09-19 Tue>: wrong tube, compressed detector...
  - detector window exploded...
    - show image of window and inside detector
  - detector investigation in CAST CDL <2017-09-19 Tue>
    see
    [[file:~/org/Figs/CAST_detector_exploded/broken_window_close_IMG_20170919_152130.jpg]]
    images & timestamps of images
  - study of contamination & end of Sep CCM
  - detector back to Bonn, fixed

- Reinstallation for data taking start (Run 2) ::
  - detector installation before first data taking
  - reinstall in October for start of data taking in 30th Oct 2017
  - remount start <2017-10-23 Mon>
  - <2017-10-26 Thu> Alignment with Geometers (after removal &
    remounting due to window accident) for data taking. Magnet *cold*
    and under vacuum.
  - <2017-10-27 Fri> calibration of scintillator veto paddle in RD51 lab
  - remount installation finished incl. lead shielding <2017-10-28 Sat>
    (mail "InGrid status update" to Satan Forum on <2017-11-09 Thu>)  
  - <data taking period from <2017-10-30 Mon> to <2017-12-22 Fri> in
    2017>
    - between runs 85 & 86: fix of ~src/waitconditions.cpp~ TOS bug,
      which caused scinti triggers to be written in all files up to next
      FADC trigger
    - run 101 <2017-11-29 Wed 6:40> was the first with FADC noise
      significant enough to make me change settings:
      - Diff: 50 ns -> 20 ns (one to left)
      - Coarse gain: 6x -> 10x (one to right)
    - run 109: <2017-12-04 Mon> crazy amounts of noise on FADC
    - run 111: stopped early. tried to debug noise and blew a fuse in
      gas interlock box by connecting NIM crate to wrong power cable
    - run 112: change FADC settings again due to noise:
      - integration: 50 ns -> 100 ns
        This was done at around <2017-12-07 Thu 8:00>
      - integration: 100 ns -> 50 ns again at around
        <2017-12-08 Fri 17:50>.
    - run 121: Jochen set the FADC main amplifier
      integration time from 50 -> 100 ns again, around
      <2017-12-15 Fri 10:20>
  - <data taking period from <2018-02-17 Sat> to <2018-04-17 Tue>
    beginning 2018>
    - start of 2018 period: temperature sensor broken!
    - <2018-02-15 Thu> to <2018-02-17 Sat> issues with moving THL
      values & weird detector behavior. Changed THL values temporarily
      as an attempted fix, but in the end didn't help, problem got worse.
      <2018-02-17 Sat> (ref: gmail "Update 17/02" and
      [[file:~/org/Mails/cast_power_supply_problem_thlshift/power_supply_problem.org]])
      issue with power supply causing severe drop in gain / increase
      in THL (unclear, #hits in 55Fe dropped massively ; background
      eventually only saw random active pixels).
      Fixed by replugging all power cables and improving the grounding
      situation.
      iirc: this was later identified to be an issue with the
      grounding between the water cooling system and the
      detector.
    - by <2018-02-17 Sat 20:41> everything was fixed and detector was
      running correctly again.
    - 2 runs:
      1. <2018-02-15 Thu 7:01>    <2018-02-15 Thu 8:33>
      2. <2018-02-16 Fri 7:00>    <2018-02-16 Fri 8:31>
      were missed because of this.
  - <2018-04-18 Wed> removal of veto scintillator and lead shielding
  - X-ray finger run 2 on <2018-04-20 Fri>. This run is actually
    useful to determine the position of the detector.
  - <2018-04-24 Tue> Geometer measurement after warming up magnet and
    not under vacuum. Serves as reference for difference between
    vacuum & cold on <2017-10-26 Thu>!
  - <2018-04-26 Thu> detector fully removed and taken back to Bonn

- Reinstallation for data taking in Oct 2018 (Run 3) ::
  - installation started <2018-07-16>. Mounting due to lead shielding
    support was more complicated than intended (see mails "ingrid
    installation" including Damien Bedat)
  - shielding fixed by <2018-07-19> and detector installed the next
    couple of days
  - <2018-07-23 Mon> Alignment with Geometers for data taking. Magnet
    warm and not under vacuum.
  - data taking was supposed to start end of September, but delayed.
  - detector had issue w/ power supply, finally fixed on
    <2018-10-19 Fri>. Issue was a bad soldering joint on the Phoenix
    connector on the intermediate board.
    *Note*: See chain of mails titled "Unser Detektor..." starting on
    <2018-10-03 Wed> for more information. Detector behavior was weird
    from beginning Oct. Weird behavior seen on the voltages of the
    detector. Initial worry: power supply dead or supercaps on
    it. Replaced power supply (Phips brought it a few days after), but no change.    
  - data taking starts <2018-10-20 Sat>
  - run 297, 298 showed lots of noise again, disabled FADC on
    <2018-12-13 Thu 18:40> (went to CERN next day)
  - data taking ends <2018-12-20 Thu>
  - runs that were missed:
    1. <2018-10-19 Fri 6:21>    <2018-10-19 Fri 7:51>
    2. <2018-10-28 Sun 5:32>    <2018-10-28 Sun 7:05>
    3. <2018-11-24 Sat 7:08>    <2018-11-24 Sat 7:30>
    The last one was not a full run.
    - [ ] *CHECK THE ELOG FOR WHAT THE LAST RUN WAS ABOUT*
       
- CAST Detector Lab measurements ::
  - detector mounted in CAST Detector Lab <2019-02-14 Thu>
  - data taking from <2019-02-15 Fri> to <2019-02-21 Thu>.
  - detector dismounted and taken back to Bonn

- Outer chip 55Fe calibrations ::
  - ref: [[file:~/org/outerRingNotes.org]]
  - calibration measurements of outer chips with a 55Fe source using a
    custom anode & window
  - between <2021-05-20 Thu> and <2021-05-31 Mon 09:54> calibrations
    of each outer chip using Run 2 and Run 3 detector calibrations
  - <2021-08-31 Tue> start of a new detector calibration
  - another set of measurements between <2021-10-12 Tue 18:00> to
    <2021-10-16 Sat 19:55> with a new set of calibrations


** Alignment

- [ ] MAYBE rename to Detector setup & alignment
- [ ] maybe explain X-ray finger measurements here fully instead of a
  separate section?
- [ ] X-ray finger not performed for 2018 data taking for logistical
  reasons and knowledge that geometer measurements give us precise
  information relative to "known good" alignment in 2017.  

Detector alignment with the X-ray telescope, the magnet and by
extension the solar core during solar tracking is obviously crucial
for a helioscope for a good physics result. The alignment procedure
used for the Septemboard detector is a three-fold approach:

1. alignment of the piping up to the detector using an acryllic glass
   target with a millimeter spaced cross. This target is mounted to
   the vacuum pipes in the same way the detector will be mounted. A
   laser is installed on the opposite side of the magnet. With the
   magnet bores fully open the laser is aligned such that it propagates
   the full bore and is reflected by the X-ray telescope into the
   focal spot. This alignment guarantees the focal spot location to be
   near the center of the detector. Uncertainty is introduced due to
   the need to remove the acrylic glass target and install the
   detector, as the mounting screws allow for small movements. In
   addition the vacuum pipes are also not perfectly fixed.
2. alignment of the fully installed detector using an X-ray
   finger. The X-ray finger is a small electric X-ray generator, which
   is installed in the magnet bore at the opposite end of the
   magnet. The generated X-rays must traverse the magnet and
   telescope, thereby being focused by the telescope into the focal
   spot. As the X-ray finger does not emit parallel light, the
   resulting distribution of the X-rays on the detector is not a
   perfect focal spot, even if the telescope was perfect and the
   detector placed right in the focus. The mean position of the taken
   data can anyhow be used to determine the likely focal spot
   position. See below for an example and the resulting position from
   one of the X-ray finger runs.
3. alignment by the geometer group at CERN. A theodolite is installed
   in the CAST hall and the location of many targets on the magnet,
   telescope, vacuum pipes and the detector itself are measured up to
   $\SI{0.5}{mm}$ precision at $1σ$ level. The initial geometer
   measurement from <2017-07-11> mainly serves as a baseline
   reference. As the first two alignment procedures provide a good
   alignment, a measurement of the existing position by the geometers
   can then later be used to re-align the detector after it was
   removed relative to the previous baseline position relative to the
   telescope. This assures the detector can be remounted and placed in
   the right location without the need for an additional laser
   alignment.

The X-ray finger run taken in April 2018 can be used as a reference
for the alignment as used during the first data taking. The center
positions of each cluster can be shown as a heatmap, where the number
of hits each pixel received is colored. Computing the mean position of
all those clusters yields the most likely center position of the focal
spot. See fig. [[fig:cast:xray_finger_centers]] for an example of
this. The position of the center based on the mean of all cluster
centers is about \SI{0.4}{mm} away from the center in both axes.

- [X] *REPHRASE ABOVE W.R.T. CORRECT RUN 189 AND WHAT IS WINDOW ETC*
  Might change significantly. Ideally we can cross reference the X-ray
  finger center position to the geometer measurement, i.e. use it for
  the next data taking campaign where we know the deltas to the
  geometer associated with /this/ X-ray finger run.
- [ ] *REPHRASE ABOVE TO NOT READ LIKE EXTENSION OF POINT NUMBER 2 ABOVE*  
- [ ] *ADD NOTE HOW IN PRINCIPLE ONE COULD ARGUE THE POSITION IS
  ARTIFICIALLY MOVED UP DUE TO CHIP CUT OFF AT BOTTOM!*
- [ ] *ROTATE THE PLOT*  

#+CAPTION: Cluster center positions of the X-ray finger run 189 from April
#+CAPTION: 2018. The red cross marks the center of all cluster centers,
#+CAPTION: which is the most likely position of the focal spot. It is
#+CAPTION: $\sim\SI{0.4}{mm}$ away from the chip center in both axes.
#+NAME: fig:cast:xray_finger_centers
[[~/phd/Figs/CAST_Alignment/xray_finger_centers_run_189.pdf]]
   

With this setup after each remounting a geometer measurement was
performed to align the detector back to the initial laser
alignment. As the second mounting of the detector in September 2017
was not used for any data taking, the associated geometer measurement
is irrelevant.

Tab. [[tab:cast:geometer_alignments]] summarizes the values of the
geometer alignment results for each of the measurements using the
CenterR and CenterF positions defined based on the initial geometer
measurement in July 2017. In each case the shifts in X, Y and Z
direction is usually significantly less than $\SI{1}{mm}$.


- [ ] split these things up into something that is not a list? We can
  still add subsections here.   

#+CAPTION: Image showing the targets on the detector. The acryllic glass
#+CAPTION: cylinders are the fiducial marks used to hold the actual survey
#+CAPTION: target. The survey target is a mirror to reflect the laser of the
#+CAPTION: theodolite. Image from \cite{geometer_1}.
#+NAME: fig:cast:alignment_targets
[[~/phd/Figs/CAST_Alignment/detector_targets_for_alignment_small.png]]

- [ ] have own section for alignment? Problem is that alignment takes
  place over the whole period, as the detector was removed multiple
  times etc.

- [ ] Alignment section which goes over the seen deviations based on
  geometers & X-ray finger run?

- [ ] Geometer measurement 1 not relevant directly. But relevant as it
  was used later to align against!
- [ ] Geometer measurement 2 irrelevant, as detector was mounted &
  dismounted without any data taking due to window rupture
- [ ] Geometer measurement 3 relevant for data taking Run 2
- [ ] Geometer measurement 4 relevant for data taking Run 3

- [ ] image showing the targets from 2017/07/11

- [ ] Note: from Oct 2017 report on there's also numbers relative to
  *magnet* fiducials. We care only about telescope fiducials as that's
  what we align to. Maybe ask Johanna again about this...

  
#+CAPTION: Overview of the results of the different geometer alignment measurements. The
#+CAPTION: first measuremnt servese as the baseline to define 2 points (CenterR and CenterF)
#+CAPTION: relative to which alignment later is done. The initial alignment is done both
#+CAPTION: by laser and X-ray finger. The second geometer measurement is not useful, as 
#+CAPTION: no data was taken with it, due to the window rupture accident.
#+NAME: tab:cast:geometer_alignments
#+ATTR_LATEX: :booktabs t
|-------------+---------+--------------+--------------+--------------+--------|
| Measurement | Target  | ΔX [\si{mm}] | ΔY [\si{mm}] | ΔZ [\si{mm}] | Useful |
|-------------+---------+--------------+--------------+--------------+--------|
|  11.07.2017 |         |              |              |              | yes    |
|-------------+---------+--------------+--------------+--------------+--------|
|  14.09.2017 | CenterR |         -0.1 |          0.3 |         -0.8 | no     |
|             | CenterF |         -0.1 |          0.3 |         -0.9 |        |
|-------------+---------+--------------+--------------+--------------+--------|
|  26.10.2017 | CenterR |          0.2 |          0.6 |          0.2 | yes    |
|             | CenterF |          0.1 |          0.6 |         -0.1 |        |
|-------------+---------+--------------+--------------+--------------+--------|
|  24.04.2018 | CenterR |          0.5 |          0.5 |          0.0 | yes    |
|             | CenterF |          0.4 |          0.5 |         -0.3 |        |
|-------------+---------+--------------+--------------+--------------+--------|
|  23.07.2018 | CenterR |          1.1 |          0.5 |          0.6 | yes    |
|             | CenterF |          1.0 |          0.5 |          0.3 |        |
|-------------+---------+--------------+--------------+--------------+--------|

- [ ] *CLARIFY WHAT THE SIGN MEANS. IS MINUS UP OR DOWN, LEFT OR
  RIGHT?*
- [ ] *LETS HOPE WHEN THINKING MORE DEEPLY ABOUT NUMBERS IT DOESN'T
  MAKE 1mm IN ΔX APPEAR TOO MUCH!*
  -> Not sure thinking about it more. On the one hand we need to keep
  in mind that the coordinates X & Y should be flipped. Ok, next the
  center Y position (so real X) in the X-ray finger cluster center
  plot for the 2017 July plot should in theory be further at the
  bottom as the chip cuts of data and therefore artifically moves the
  position slightly up. Now the issue is that this is movement *in
  addition to* the already existing ~1 mm that are offset based on
  the difference calculation of the X-ray finger plots, but the X
  difference is only 0.2mm while we are not insensitive to changes in
  X! It's very confusing. Maybe the real takeaway is just that this is
  not super reliable...
  If we can't figure this out later, the correct thing to do will be:
  - Explain the above in a paragraph, numbers don't fully
    match. Therefore both should be taken with a grain of salt &
    systematic uncertainty is simply forced to 0.5mm as a rough 1σ
    behavior.
  *Well*: One explanation could simply be that the movement is non
  linear. A shift in geometer X/Y might not be the same shift in our
  X-ray finger X/Y! 
- [ ] *SEE TIMELINE WHICH ONES ARE UNDER VACUUM AND MAGNET COLD / WARM
  MAYBE MENTION*  

For a detailed overview of the geometer measurements see the public
EDMS links under \cite{geometer_1,geometer_2,geometer_3,geometer_4,geometer_5}
containing the PDF reports for each measurement.

*** Some extra info about the geometer alignment                 :noexport:

The following is the snippet from the <2017-09-14> PDF report about
the definition of the CenterR and CenterF positions.
  #+begin_quote
Goal of the operation has been to align the InGRID detector with
respect to the LLNL telescope as on 11.07.2017 after the alignment of
the setup with respect to the LASER installed.  Coordinates of the
measurement on 11.07.2017 are given below.

In order to compare InGRID position on 11.07 and 14.09, two points
close to the detector axis CenterR and CenterF have been defined on
11.07. Afterwards their coordinates for the measurement on 14.09 have
been calculated.
  #+end_quote

*** Generate X-ray heatmap [/]                                   :noexport:

- [ ] *FIND XRAY FINGER RUN 2, RUN 189!*
- [ ] *RECREATE BELOW FOR THE OTHER XRAY FINGER RUN!*
- [ ] *RECREATE PLOTS AS TIKZ + VEGA*
- [ ] *VERIFY THAT WE (LIKELY) HAVE TO ROTATE THE DATA BY 90 DEGREES AS ONE OF THE VERTICAL LINES IS THE TELESCOPE AXIS WHICH SHOULD BE
  HORIZONTAL TO THE GROUND*

First let's reconstruct the X-ray finger run:
#+begin_src nim :tangle code/xray_finger_data_parsing.nim
import shell, strutils

proc main(path: string, run: int) =
  # parse data
  let outfile = "/t/xray_finger_$#.h5" % $run
  let recoOut = "/t/reco_xray_finger_$#.h5" % $run
  
  shell:
    raw_data_manipulation -p ($path) "--runType xray --out " ($outfile)
  shell:
    reconstruction ($outfile) "--out " ($recoOut)
  
when isMainModule:
  import cligen
  dispatch main
#+end_src

And now we simply create a heatmap of the cluster centers:
 
#+begin_src nim :tangle code/xray_finger_center_plot.nim
import nimhdf5, ggplotnim, options
import ingrid / tos_helpers
import std / [strutils, tables]

proc main(run: int) =
  let file = "/t/reco_xray_finger_$#.h5" % $run
  
  #proc readClusters(h5f: H5File): (seq[float], seq[float]) =
  var h5f = H5open(file, "r")
  
  # compute counts based on number of each pixel hit
  proc toIdx(x: float): int = (x / 14.0 * 256.0).round.int.clamp(0, 255)
  var ctab = initCountTable[(int, int)]() 
  
  var df = readRunDsets(h5f, run = run,
                        chipDsets = some((
                          chip: 3, dsets: @["centerX", "centerY"])))
    .mutate(f{"xidx" ~ toIdx(idx("centerX"))},
            f{"yidx" ~ toIdx(idx("centerY"))})
  let xidx = df["xidx", int]
  let yidx = df["yidx", int]
  forEach x in xidx, y in yidx:
    inc cTab, (x, y)
  df = df.mutate(f{int: "count" ~ cTab[(`xidx`, `yidx`)]})
  let centerX = df["centerX", float].mean
  let centerY = df["centerY", float].mean
  discard h5f.close()
 
  echo "Center position of the cluster is at: (x, y) = (", centerX, ", ", centerY, ")"
  ggplot(df, aes("centerX", "centerY", color = "count")) +
    geom_point(size = 0.75) +
    geom_point(data = newDataFrame(), aes = aes(x = centerX, y = centerY),
               color = "red", marker = mkRotCross) + 
    scale_color_continuous() +
    ggtitle("X-ray finger clusters of run $#" % $run) +
    xlim(0.0, 14.0) + ylim(0.0, 14.0) +
    ggsave("/home/basti/phd/Figs/CAST_Alignment/xray_finger_centers_run_$#.pdf" % $run)

when isMainModule:
  import cligen
  dispatch main
#+end_src

#+RESULTS:
# Center position of the cluster is at: (x, y) = (7.210714052855218, 5.669514297250704)

#+begin_src sh
./code/xray_finger_data_parsing -p ~/CastData/data/XrayFingerRuns/Run_21_170713-11-03 --run 21
./code/xray_finger_data_parsing -p ~/CastData/data/XrayFingerRuns/Run_189_180420-09-53 --run 189

./code/xray_finger_center_plot -p 21
./code/xray_finger_center_plot -p 189
#+end_src

For run 21:
Center position of the cluster is at: (x, y) = (7.210714052855218,5.669514297250704)
For run 189:
Center position of the cluster is at: (x, y) = (7.428075467697270,6.594113570730057)


First the plot for the (unused) X-ray finger run taken at the first
installation before any data taking (detector removed afterwards):
[[file:Figs/CAST_Alignment/xray_finger_centers_run_21.pdf]]

And second the plot of the 2018 X-ray finger run taken _before_ the
detector was removed in Apr 2018. This is the baseline for our idea
where the focal spot is going to be.
file:Figs/CAST_Alignment/xray_finger_centers_run_189.pdf

** Detector setup at CAST [/]

- [ ] *POSSIBLY CHANGE TO SOMETHING W/O RENDER AND SHOW IMAGES OF FULL
  SETUP WITH VETO SCINTI AS WELL*
- [ ] *MENTION ~VT3~ AS ITS IMPORTANT*  

The setup of the full beamline from the magnet end cap to the detector
is shown in a render in fig. [[fig:cast:render_beamline_setup]]. The
piping shows a clear kink introduced using a flexible bellow. This
setup is used to move the detector mount further away from the other
beamline to provide more space for two setups side-by-side. Not shown
in the image is the lead shielding installed around the detector as
well as the veto scintillator, which covers the majority of the
beamline area. The lead shielding is a $\SIrange{5}{15}{cm}$ thick
castle of lead around the detector (\SI{10}{cm} on top and behind,
\SI{15}{cm} in front and \SI{5}{cm} and \SI{10}{cm} on each side). An
annotated image of the real setup is seen in
fig. [[fig:cast:annotated_setup]], which shows lead shielding, veto
scintillator, $\ce{^{55}Fe}$ source manipulator and the LLNL X-ray
telescope. 



- [ ] *CHECK THICKNESS OF LEAD SHIELDING
- [ ] *SHOW REAL (ANNOTATED?) IMAGE OF SETUP*  

#+CAPTION: Render of the detector setup up to the magnet end cap as seen
#+CAPTION: from above. The beamline kinks away from the other beamline
#+CAPTION: ("below" in this image) to provide more space for two detectors
#+CAPTION: at the same time.
#+CAPTION: Image courtesy of Tobias Schiffer.
#+NAME: fig:cast:render_beamline_setup
[[~/phd/Figs/CAST_Alignment/llnl_cast_gridpix_render_small.png]]

#+CAPTION: Annotated setup as installed in October 2017 for the first data taking campaign.
#+CAPTION: The detector is seen in its lead shielding, with the veto scintillator covering
#+CAPTION: a large angular portion above the detector. The $\ce{^{55}Fe}$ source manipulator
#+CAPTION: is seen head-on here. On the right towards the magnet we see the housing of the
#+CAPTION: LLNL X-ray telescope.
#+NAME: fig:cast:annotated_setup
[[~/phd/Figs/CAST_Nov2017Aufbau_annotated_small.png]]

*** $^{55}\text{Fe}$ source and manipulator
:PROPERTIES:
:CUSTOM_ID: sec:cast:55fe_manipulator
:END:

As seen in the previous section the setup includes a $\ce{^{55}Fe}$
source. Its purpose is both monitoring of the detector behavior and it
serves as a way to calibrate the energy of events (as mentioned in
theory section [[#sec:theory:escape_peaks_55fe]]). More details on the
usage and importance for data analysis will be given in chapter
[[#sec:calibration:energy]]. It is installed on a pneumatic
manipulator. Using a compressed air line with about \SI{6}{bar}
pressure the manipulator can be moved up and down. Under vacuum
conditions of the setup the manipulator is inserted unless the
compressed air is used to keep it out.

A Raspberry Pi is installed close to the manipulator and connects to
the two Festo control sensors at the top and bottom end of the
manipulator using the general purpose input/output (GPIO) pins. Two
pins are used to read the sensor status from each. 5 more pins connect
to a $\SI{24}{V}$ relay, which is used to control the controllers for
the compressed air line. The relay is controlled via pulse width
modulation (PWM). The software controlling the GPIO pins of the
Raspberry Pi is written in Python. It does not need to run on the
Raspberry Pi itself, instead it connects to it via network. It starts
a server process, which can receive connections via a socket, which
allows for remote and programmatic control of the manipulator via a
set of simple string based messages. Further it provides a REPL
(read-evaluate-print loop) to control it interactively. 

- [ ] *REFERENCE / LINK TO FESTO*
- [ ] *MAYBE SHORTEN INFO ABOUT PWM?*
- [ ] *LINK TO SOFTWARE HERE*

**** Manipulator software and notes [0/1]                       :noexport:

- [ ] *MOVE MANIPULATOR CODE TO TPA TOOLS AND LINK TO IT?*

The source code of the python script running on the Raspberry Pi to
control the manipulator is the following:

#+begin_src python
#!/usr/bin/env python3.6

import sys
import pigpio
import readline
import logging
import argparse
import time
import socket
import threading
import json
import asyncio
import functools
import weakref

# the program needs to do the following
# 
# - on RPi 7 pins used (5 controlled via software):
#     - relay:
#         - GOOD  - input, Pin 14
#         - OUT   - input, Pin 15
#         - RC IN - output (via PWM), via Pin 14
#         - VRC   - const voltage, using 5V via PIN 2, not done in software
#         - GND   - ground, pin 6, not done in software
#     - sensors 2 pins:
#         - input, read sensor output
# 
# 
# program always listens to GOOD and OUT
# using PWM we activate the manipulator. done by waiting for 
#  - command line input?
#  - reading some file, s.t. this program runs as a daemon and we use
#    some external tool to write file via usb to Pi
#  - finally be able to execute from TOS. easiest via script to call
# reading sensor inputs done in connection with usage of PWM
# 
# finally compile this program to jar to run it


# in order to control the source via network, the basic usage is something like
# the following:
# s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# s.connect(('localhost', 42000))
# s.send("insert".encode())
# depening on whether the call is from the local machine or not.
# "insert" and "remove" are supported at the moment
# sends back a byte string containing the bool of the
# insertion / removal

#class client(asyncio.Protocol):



# connect to pi at IP address
p = pigpio.pi('10.42.0.91')

# define dict of pins
d = {"GOOD"    : 14,
     "OUT"     : 15,
     "RC_IN"   : 18,
     "S_OPEN"  : 20,
     "S_CLOSE" : 21}

    

class server(threading.Thread):
    # this is a simple server class, which receives the necessary
    # parameters to control the raspberry pi and a socket, from
    # which it listens to commands
    # inherits from threading.Thread to run in a separate thread

    def __init__(self, socket, p, d, pwm):
        # init the object
        self.socket = socket
        self.p      = p 
        self.d      = d
        self.pwm    = pwm
        self._stop  = False
        # now call the Thread init
        threading.Thread.__init__(self)
        # and set it as a daemon, so that it cannot
        # stop the main program from quitting
        self.setDaemon(True)

    async def process_client(self, reader, writer):
        client = writer.get_extra_info('peername')
        print("New client connected: {}".format(client))
        while self._stop == False:
            #data = socket.recv(1024).decode()
            data = (await reader.readline()).decode()
            if data:
                success = self.parse_message(data, client)
                message = self.create_message(client[0], success)
                writer.write(message)
                await writer.drain()
            else:
                writer.close()
                break

    # hacky get loop...
    def get_loop_and_server(self):
        return (self.loop, self.socketserver)

    def run(self):
        # using run we start the thread

        # need a new event loop, in which asyncio works
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        # start server on specific port open on all interfaces
        self.server_future = asyncio.start_server(self.process_client, host = "0.0.0.0", port = 42000)
        # the returned future is handed to the event loop
        self.socketserver = self.loop.run_until_complete(
            asyncio.ensure_future(
                self.server_future,
                loop = self.loop))
        
        print(self.socketserver.sockets)
        # run 
        self.loop.run_forever()
                
    def stop_server(self):
        # in case stop_server is called, the stop flag is
        # set, such that the while loop, which waits for
        # data from the socket stops
        self._stop = True

        while self.loop.is_running() == True:
            print("current sockets still connected {}".format(self.socketserver.sockets))
            print("loop is still running: {}".format(self.loop.is_running()))

            #self.socketserver.wait_closed()
            self.loop.stop()
            self.server_future.close()
            self.socketserver.close()
            # next line raises an exception, loop still running....
            # TODO: fix problem that we cannot stop the running event loop :(
            self.loop.close(self.loop.run_until_complete(self.socketserver.wait_closed()))
            time.sleep(0.2)
        
        self.loop.close()


    def parse_message(self, data, address):
        # this function parses the data. If there is a function
        # call in the data, we call the appropriate function
        ip, port = address
        result = False
        if 'insert' in data:
            result = insert_source(self.p, self.d, self.pwm)
            #logging.info("source inserted via network socket {}:{}".format(ip, port))
        elif 'remove' in data:
            result = remove_source(self.p, self.d, self.pwm)
            #logging.info("source removed via network socket {}:{}".format(ip, port))
        elif 'out?' in data:
            result = read_out(self.p, self.d)
            #logging.info("out? status requestet via network socket {}:{}".format(ip, port))
        elif 'good?' in data:
            # read GOOD and print
            result = read_good(self.p, self.d)
            #logging.info("good? status requestet via network socket {}:{}".format(ip, port))
        elif 's_open?' in data:
            # read sensor 1 and print
            result = read_sensor_open(self.p, self.d)
            #logging.info("s_open? status requestet via network socket {}:{}".format(ip, port))
        elif 's_close?' in data:
            # read sensor 1 and print
            result = read_sensor_close(self.p, self.d)
            #logging.info("s_close? status requestet via network socket {}:{}".format(ip, port))
        else:
            result = "Unknown command"

        return result

    def create_message(self, client, data):
        # this function creates a JSON message containing the returned value
        # of the RPi call and a clientname
        # using dictionary, we create a json dump and return the encoded
        # string
        message = {"username" : client, "message" : data}
        # add trailing \r\l to indicate end of data stream
        json_data = json.dumps(message) + '\n'
        return json_data.encode()


# set relay_sleep time (time to wait for activation of relay): 50ms
relay_sleep = 50e-3
# set manipulator_sleep time: 1s
manip_sleep = 1

def print_help():

    help_string = """
    The following commands are available:\n
        insert : insert source into bore
        remove : remove source from bore
        out?   : print current value of relay OUT
        good?  : print current value of relay GOOD
        d?     : parameters used for relay (pin layout etc.)
        pwm?   : parameters used for PWM (frequency, duty cycle, ...)
        help   : prints this help
    """

    print(help_string)
    return

    

def read_good(p, d):
    # simple function which returns the value of the
    # GPIO pin for the GOOD output of the relay
    good = bool(p.read(d["GOOD"]))
    return good

def read_out(p, d):
    # simple function which returns the value of the
    # GPIO pin for the OUT output of the relay
    out = bool(p.read(d["OUT"]))
    return out

def read_sensor_open(p, d):
    # simple function which returns bool corresponding to
    # GPIO pin of sensor for OPEN
    val = bool(p.read(d["S_OPEN"]))
    return val

def read_sensor_close(p, d):
    # simple function which returns bool corresponding to
    # GPIO pin of sensor for CLOSED
    val = bool(p.read(d["S_CLOSE"]))
    return val

def configure_pins(p, d):
    # function to export all pins and set to correct modes
    # relay control / reading
    p.set_mode(d["GOOD"], pigpio.INPUT)
    p.set_mode(d["OUT"], pigpio.INPUT)
    p.set_mode(d["RC_IN"], pigpio.OUTPUT)
    # sensor reading
    p.set_mode(d["S_OPEN"], pigpio.INPUT)
    p.set_mode(d["S_CLOSE"], pigpio.INPUT)
    return

def pwm_control(p, d, freq, duty_cycle):
    # function to control the pwm of the RC IN pin
    p.hardware_PWM(d["RC_IN"], freq, duty_cycle)
    return

def insert_source(p, d, pwm):
    # inserts the source into the bore by activating the relay
    # wrapper for source_control
    success = source_control(p, d, pwm, "on")
    return success

def remove_source(p, d, pwm):
    # removes source from bore by disabling the relay
    # wrapping source control
    success = source_control(p, d, pwm, "off")
    return success

def source_control(p, d, pwm, direction):
    # this function provides a generalized interface to control the source
    # inputs:
    #     p: the Pi object
    #     d: the dict. containing the parameters
    #     pwm: the dict. containing pwm parameters
    #     direction: a string describing the direction to move the source
    #         "on"  : insert source
    #         "off" : remove source

    
    pwm_control(p, d, pwm["f"], pwm[direction])
    # relay was triggered: means relay should now read
    # insert:
    # GOOD == True &
    # OUT  == True
    # remove:
    # GOOD == True &
    # OUT  == False
    time.sleep(relay_sleep)
    good = read_good(p, d)
    out  = read_out(p, d)
    success = False

    # set expected values based on insertion / removal
    if direction == "on":
        good_exp = True
        out_exp  = True
    elif direction == "off":
        good_exp = True
        out_exp  = False
    else:
        raise NotImplementedError("only 'on' and 'off' implemented to control source.")

    s1 = None
    s2 = None
    if good == good_exp and out == out_exp:
        # if good is True and out False, everything fine
        #logging.debug("pwm set to {}, relay reports: (good : {}), (out : {})".format(direction, good ,out))
        # after setting of relay, wait again and check sensors
        print('pwm switched, waiting for manipulator to be moved')
        time.sleep(manip_sleep)
        # check sensors
        s1 = read_sensor_open(p, d)
        s2 = read_sensor_close(p, d)

        #logging.debug('sensors report: s1 = {}, s2 = {}'.format(s1, s2))
        # TODO: implement logic, which deals with sensors of manipulators

        if direction is "on":
            # after insertion the sensors should read:
            # s1 (sensor open) == True
            # s2 (sensor close) == False
            if s1 == True and s2 == False:
                success = True
            else:
                success = False
        else:
            if s1 == False and s2 == True:
                # after removal the sensors should read:
                # s1 (sensor open) == False
                # s2 (sensor close) == True
                success = True
            else:
                success = False
        
        if success == False:
            #logging.warning("""WARNING: direction was {}, but sensors read (open): {} (close): {}. 
            #Relay switched correctly.""".format(direction, s1, s2))
            pass

    elif good == good_exp and out != out_exp:
        # something is wrong, seems like relay did not change, both still repot True
        #logging.warning("pwm set to {}, relay good, but OUT still reports True: {}, {}".format(direction, good, out))
        pass
    elif good == False:
        #logging.warning("relay reports bad signal: {}".format(good))
        pass
    else:
        #logging.warning("should not happen. Contact developer.")
        pass

    if direction == "on":
        print("Insertion returned {}".format(success))
        if success == False:
            print("WARNING: insertion may have failed, but sensors read (open): {} (close): {}".format(direction, s1, s2))
            print("However, relay was activated correctly.")    
    elif direction == "off":
        print("Removal returned {}".format(success))
        if success == False:
            print("WARNING: removal may have failed, but sensors read (open): {} (close): {}".format(direction, s1, s2))
            print("However, relay was activated correctly.")    


    # the following lines are here to make sure there is a new prompt
    # even in case a network call was made before
    sys.stdout.write('> ')
    sys.stdout.flush()

    return success
    
def control_loop(p, d, pwm):
    # this function defines the main control loop of the manipulator
    # control
    print('Starting command prompt')
    print('\t insert : inserts source into bore')
    print('\t remove : removes source out of bore')
    print('\t quit   : stop the program')

    # TODO: still need to implement the checks for
    #       - sensor positions
    #         output warning to console and log file in case sensors
    #         don't report what was commanded
    #       - output warning in case signal not good
    
    while True:
        # the sys calls are used to make sure the line is empty before we
        # write to it via input. Don't want two > > to appear (depening
        # on network calls this might happen)
        sys.stdout.write('\r')
        sys.stdout.flush()
        line = input('> ')
        if 'insert' in line:
            insert_source(p, d, pwm)
            #logging.info("source inserted")
        elif 'remove' in line:
            remove_source(p, d, pwm)
            #logging.info("source removed")
        elif 'out?' in line:
            # read OUT and print
            print(read_out(p, d))
        elif 'good?' in line:
            # read GOOD and print
            print(read_good(p, d))
        elif 's_open?' in line:
            # read sensor 1 and print
            print(read_sensor_open(p, d))
        elif 's_close?' in line:
            # read sensor 1 and print
            print(read_sensor_close(p, d))
        elif 'd?' in line:
            # print dictionary
            print(d)
        elif 'pwm?' in line:
            # print dictionary
            print(pwm)
        elif line in ['help', 'h', 'help?']:
            print_help()
        elif line in ['quit', 'q', 'stop']:
            break
        elif line is not "":
            print('not a valid command.')
        else:
            continue

        # perform some logging of input, exit
        #logging.debug("command: {}".format(line))


    # after loop perform final logging?
    #logging.info('stopping program.')

    return

def create_message(client, data):
    # this function creates a JSON message containing the returned value
    # of the RPi call and a clientname
    # using dictionary, we create a json dump and return the encoded
    # string
    message = {"username" : client, "message" : data}
    # add trailing \r\l to indicate end of data stream
    json_data = json.dumps(message) + '\n'
    return json_data.encode()

def main(args):

    # setup arg parser
    parser = argparse.ArgumentParser(description = 'parse log level')
    parser.add_argument('--log', default="DEBUG", type=str)

    parsed_args = parser.parse_args()
    loglevel = parsed_args.log

    # setup logger
    numeric_level = getattr(logging, loglevel.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError('Invalid log level: {}'.format(loglevel))


    # add an additional handler for the asyncio logger so that it also
    # writes the errors and exceptions to console
    console = logging.StreamHandler()
    logging.getLogger("asyncio").addHandler(console)

    LOG_FILENAME = 'log/manipulator.log'
    logging.basicConfig(filename = LOG_FILENAME,
                        #stream = sys.stdout, 
                        format = '%(levelname)s %(asctime)s: %(message)s',
                        datefmt='%d/%m/%Y %H:%M:%S',
                        level = numeric_level)


    # now configure all pins
    configure_pins(p, d)

    # define PWM settings
    pwm = {"f"   : 200,
           "off" : 200000,
           "on"  : 400000}

    # set pwm for RC IN pin
    pwm_control(p, d, pwm["f"], pwm["off"])

    # configure readline
    readline.parse_and_bind('tab: complete')
    readline.set_auto_history(True)

    # create the socket for the server
    # instantiate the server object
    # thr = server(serversocket, p, d, pwm)
    thr = server(None, p, d, pwm)
    # and start
    thr.start()

    # now that everything is configured, start the control loop
    control_loop(p, d, pwm)

    #try:
    #thr.stop_server()
    #except:
        

    # after control loop has finished, shut down the server thread
    loop, socketserver = thr.get_loop_and_server()
    # the following is an ugly hack to close the program without getting any
    # exceptions, thrown because the event loop in the server class is
    # not being shut down. Trying, but doesn't work, so this will have
    # to do for now
    try:
        thr.stop_server()
    except:
        socketserver.close()
    
    #loop.close()
    
    
if __name__=="__main__":
    import sys
    main(sys.argv[1:])
#+end_src

The following are my notes taken during development of the hardware &
software that describe the specific hardware in use.

***** DONE Manipulator [3/3]
****** DONE test for leaks
****** DONE test using compressed air, reading sensors
Regarding sensors, setup and hardware: 
Hardware:
    - sensors: Festo 150 857
      accept between 12 and 30 V DC
      max. output amperage: 500 mA
      switch on time: 0.5 ms
      switch off time: 0.03 ms
    - cable  : Festo NEBU-M8G3-K5-LE3 (541 334)
    - cable (power): Festo NEBV-Z4WA2L-R-E-5-N-LE2-S1
Thus, supply sensors with 24 V DC as well. Build setup such that 
valve and sensors receive same 24 V. 
Sensor outputs need to go on RPi GPIO pins. These max value of 
3.3 V (!). 
Using voltage divider something like the following seems
reasonable
#+BEGIN_LaTeX
$\frac{U_{\text{Pi, in}}}{U_{\text{sensor, out}}} = \frac{R_2}{R_1 + R_2}$
#+END_LaTeX
with 
#+BEGIN_LaTeX
$U_{\text{Pi, in}} < 3.3\,\text{V}$
$U_{\text{sensor, out}} = 24\,\text{V}$
#+END_LaTeX
Thus, we'd get:
#+BEGIN_SRC python
R2 = 1e3
R1 = 8.2e3
U_sensor_out = 24
U_pi_in = U_sensor_out * R2 / (R1 + R2)
return U_pi_in
#+END_SRC

#+RESULTS:
: 2.60869565217

Build simple board using these resistors (first check output
 current of sensor does not exceed 0.5 mA! max of RPi) to feed
the sensor values into the RPi. Should be simple?

Tested basic setup today (<2017-08-29 Di 18:47>). 
- 24V power supply prepared
- RPi connected to relay
- tpc20 used to run PyS_manipController.py
- relay connected as:
  - power supply 24V+: relay COM
  - power supply GND: valve GND
  - valve +: relay NO
is all there is to do. :)
      
****** DONE finalize software
The software to readout and control the manipulator needs to be
finished. The [[file:~/CastData/ManipulatorController/PyS_manipController.py][Python script to control manipulator]] currently
creates a server, which listens for connections from a client
connecting to it. Commands are not final yet (use only "insert"
and "remove" so far). 
Still need to:
1. DONE separate server and client into two actually separate threads
2. DONE try using nim client of chat app as the client. allows me to
   use nim, yay.

Note <2017-09-07 Do>: took me the last two days to figure out, why the server
application was buggy. See mails to Lucian and Fabian for an
explanation titled 'Python asyncio'. 
Having a logger enabled, causes asyncio to redirect all error
output from the asyncio code parts to land in the log file.

CLOSED: <2017-09-09 Sa 01:51>
Python server is finished, allows multiple incoming connections at the
same time, thanks to asyncio (what a PITA...).
Final version is [[file:~/CastData/ManipulatorController/PyS_manipController.py][PyS_manipController.py]].
Nim client works well as a client to control the server. See
[[file:~/CastData/ManipulatorController/nim/client.nim][client.nim]] for the code currently in use.

*** Lead shielding layout [/]                                    :noexport:  

The full lead shielding layout can be found here (created by Christoph Krieger):

[[file:resources/lead_shielding_assembly_ingrid_2017.pdf]]



** Window accident
:PROPERTIES:
:CUSTOM_ID: sec:cast:window_accident
:END:

During the preparations of the detector for data taking, it became
clear that the rubber seals of the quick connectors used for the water
cooling system started to disintegrate. The connectors were replaced
by Swagelok connectors, but the water cooling system still contained
rubber pieces blocking the flow. Due to the small diameter and twisted
layout of the cooling ducts in the copper body, the only way at hand
to clean them was a compressed air line, normally used for operation
of the $\ce{^{55}Fe}$ manipulator (see
sec. [[#sec:cast:55fe_manipulator]]). This cleaning process worked very
well. Multiple cleaning & water pumping cycles were needed, as after
cleaning the system with compressed air, pumping water the next time
moved some remaining pieces, which blocked again. After multiple
cycles at which no more clogging happened upon water pumping a final
cycle was intended. As the gas supply and the water cooling system
after replacement of the quick connectors now used not only the same
tubing, but also the same connectors, the compressed air line was
mistakenly connected to the gas supply instead of water cooling line
by me. The windows - tested up to $\SI{1.5}{bar}$ pressure - could not
withstand the sudden pressure of the compressed air line of about
$\SI{6}{bar}$. A sudden and catastrophic window failure broke the
vacuum and shot window pieces as well as possible contamination into
the vacuum pipes towards the X-ray optics.

Because the LLNL telescope is an experimental optics there was worry
about potential oil contamination coming from dirty air of the
compressed air line. An conservative estimate of this given an upper
bound on contamination of the air, volume of the vacuum pipes and the
telescope area was computed. Assuming a flow of compressed air of
\SI{5}{s}, a ISO 8573-1:2010 class 4 compressed air contamination of
$\text{ppmv}_{\text{oil}} = \SI{10}{\milli\gram\per\meter\cubed}$ and
all oil in the air sticking to the telescope shells would lead to a
contamination of $c_{\text{oil}} =
\SI{41.7}{\nano\gram\per\cm\squared}$. More realistic is about
$\SI{1}{\percent}$ of that due to the telescope only being less than
$\frac{1}{10}$ of the full system area and the primary membrane pump
likely removing the majority ($>\SI{90}{\percent}$) of the oil in the
first place. This puts an upper limit of $c_{\text{oil}} =
\SI{0.417}{\nano\gram\per\cm\squared}$, which is well below anything
considered problematic for further data taking.

Further, the $\ce{^{55}Fe}$ source manipulator likely caught most of the
debris, as it was fully inserted due to the necessary removal of the
compressed air line from it, which is normally needed to keep the
manipulator extruded when the system is under vacuum. For this reason
it is unlikely and window debris could have caused significant
scratches in the telescope layers.

After the incident the detector was dismounted and taken to the CAST
detector lab. Fig. \subref{fig:cast:window_accident:broken_window} shows the
detector from above with the small remaining pieces of the
window. Fig. \subref{fig:cast:window_accident:broken_window_inside} shows the
detector inside after opening it. A bulge is visible where the gas
inlet is and the compressed air entered. As the detector was
electronically dead after the incident, the decision was made to move
it back to Bonn for repairs. It turned out that the Septemboard had
become loose from the connector.

- [ ] LIKELY NOT LIST EXACT NUMBERS HERE, BUT IF SO REFERENCE ISO CLASS
- [X] contamination calculation
- [X] pictures of broken window & detector
- [ ] *REWRITE CODE TO USE UNCHAINED*

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/phd/Figs/CAST_detector_exploded/broken_window_close_IMG_20170919_152130.jpg}
    \caption{Broken window from the inside}
    \label{fig:cast:window_accident:broken_window}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \includegraphics[width=0.95\textwidth]{/home/basti/phd/Figs/CAST_detector_exploded/detector_broken_window_open_top_IMG_20170919_152130.jpg}
    \label{fig:cast:window_accident:broken_window_inside}
    \caption{View into the detector after accident}
  \end{subfigure}
  \label{fig:cast:window_accident:broken_window_subfig}
  \caption{\subref{fig:cast:window_accident:broken_window} shows the cathode of the detector from the inside
    with the broken window. Essentially the full window directly exposed to vacuum is gone.
    \subref{fig:cast:window_accident:broken_window_inside} is the view into the detector without the cathode.
    A bulge of the field cage is visible where the compressed air entered.
  }
\end{figure}  

*** Calculations of contamination [0/1]                          :noexport:

- [ ] *REWRITE TO USE UNCHAINED!!*

Check the appendix [[#sec:appendix:vacuum_contamination]] for the document
written that contains my thoughts about the calculations below.

Here are the calculations done to estimate the contamination. First a
file containing the tubing sizes of the vacuum system:
#+begin_src nim :tangle code/vacuum_contamination/tubing.nim
import tables

type
  # defines the TubesMap datatype, which is a combined object to
  # store the different parts of the tubing each sequences of tuples
  TubesMap* = object
    static_tubes* : seq[tuple[diameter: float, length: float]]
    flexible_tubes* : seq[tuple[diameter: float, length: float]]
    t_pieces* : seq[tuple[diameter: float, length_long: float, length_short: float]]
    crosses* : seq[tuple[diameter: float, length: float]]

proc getVacuumTubing*(): TubesMap =
  # this function returns the data (originally written in calc_vacuum_volume.org
  # as a set of hash maps as a "TubesMap" datatype
  let st_tubing = @[(63.0, 10.0),
                    (63.0, 51.0),
                    (63.0, 21.5),
                    (25.0, 33.7),
                    (63.0, 20.0),
                    (63.0, 50.0),
                    (40.0, 15.5),
                    (16.0, 13.0),
                    (40.0, 10.0)]

  let fl_tubing = @[(16.0,  25.0),
                    (16.0,  25.0 ),
                    (16.0,  25.0 ),
                    (16.0,  25.0 ),
                    (16.0,  40.0 ),
                    (25.0,  90.0 ),
                    (25.0,  80.0 ),
                    (40.0,  50.0 ),
                    (16.0, 150.0 ),
                    (40.0,  80.0 ),
                    (40.0,  80.0)]

  let t_pieces = @[(40.0, 18.0, 21.0),
                   (16.0, 7.0, 4.5),
                   (40.0, 10.0, 10.0)]

  let crosses = @[(16.0, 10.0),
                  (40.0, 14.0),
                  (40.0, 14.0),
                  (40.0, 14.0)]
                    
  let t = TubesMap(static_tubes: st_tubing, flexible_tubes: fl_tubing, t_pieces: t_pieces, crosses: crosses)
  echo "Vacuum tubing is as follows:"
  echo t
  return t
#+end_src

And the actual code using the tubing to calculate possible
contamination:

#+begin_src nim :tangle code/vacuum_contamination/vacuum_contamination.nim
import math
import tubing
import sequtils, future
import typeinfo

# This script contains a calculation for the total volume of the
# currently in use vacuum system at CAST (behind and including LLNL
# telescope)

proc cylinder_volume(diameter, length: float): float =
  # this proc calculates the volume of a cylinder, given a
  # diameter and a length both in cm
  result = PI * pow(diameter / 2.0, 2) * length
  
proc t_piece_volume(diameter, length_long, length_short: float): float =
  # this proc calculates the volume of a T shaped vacuum piece, using
  # the cylinder volume proc
  # inputs:
  # diameter: diameter of the tubing in cm
  # length_long: length of the long axis of the tubing
  # length_short: length of the short axis of the tubing
  result = cylinder_volume(diameter, length_long) + cylinder_volume(diameter, length_short - diameter)

proc cross_piece_volume(diameter, length: float): float =
  # this proc calculates the volume of a cross shaped vacuum piece, using
  # the cylinder volume proc
  # inputs:
  # diameter: diameter of the tubing in cm
  # length: length of one axis of the tubing
  result = 2 * cylinder_volume(diameter, length) - pow(diameter, 3)

proc calcTotalVacuumVolume(t: TubesMap): float =
  # function which calculates the total vacuum volume, using
  # the rough measurements of the length and diameters of all the
  # piping
  # the TubesMap consists of:
  # static_tubes : seq[tuple[diameter: float, length: float]]
  # flexible_tubes : seq[tuple[diameter: float, length: float]]
  # t_pieces : seq[tuple[diameter: float, length_long: float, length_short: float]]
  # crosses : seq[tuple[diameter: float, length: float]]
  # define variables to store static volume etc

  # calc volume of static tubing
  let static_vol = sum(map(
    t.static_tubes, (b: tuple[diameter, length: float]) ->
    float =>
    cylinder_volume(b.diameter / 10, b.length)))
  let flexible_vol = sum(map(
    t.flexible_tubes, (b: tuple[diameter, length: float]) -> 
    float =>
    cylinder_volume(b.diameter / 10, b.length)))
  let t_vol = sum(map(
    t.t_pieces, (b: tuple[diameter, length_long, length_short: float]) ->
    float =>
    t_piece_volume(b.diameter / 10, b.length_long, b.length_short)))
  let crosses_vol = sum(map(
    t.crosses, (b: tuple[diameter, length: float]) ->
    float =>
    cross_piece_volume(b.diameter / 10, b.length)))

  result = static_vol + flexible_vol + t_vol + crosses_vol

proc calcFlowRate(d, p, mu, x: float): float =
  # this function calculates the flow rate following the Poiseuille Equation
  # for a non-ideal gas under laminar flow.
  # inputs:
  # d: diameter of the tube in m
  # p: pressure difference between both ends of the tube in Pa
  # mu: dynamic viscosity of the medium
  # x: length of the tube
  # note: get viscosity e.g. from https://www.lmnoeng.com/Flow/GasViscosity.php
  # returns the flow rate in m^3 / s
  result = PI * pow(d, 4) * p / (128 * mu * x)

proc calcGasAmount(p, V, T: float): float =
  # this function calculates the amount of gas in moles follinwg
  # the ideal gas equation p V = n R T for a given pressure, volume
  # and temperature
  let R = 8.31446
  result = p * V / (R * T)

proc calcVolumeFromMol(p, n, T: float): float =
  # this function calculates the volume in m^3 follinwg
  # the ideal gas equation p V = n R T for a given pressure, amount in mol
  # and temperature
  let R = 8.31446
  result = n * R * T / p
    
proc main() =

  # TODO: checke whether diameter of 63mm for telescope is a reasonable
  # number!
  let t = getVacuumTubing()
  # first of all we need to calculate the total volume of the vacuum
  let volume = calcTotalVacuumVolume(t)
  echo volume

  # now calcualte flow rate through pipe
  let
    # 3 mm diameter
    d = 3e-3
    # 6 bar pressure diff
    p = 6.0e5
    # viscosity of air
    mu = 1.8369247e-4
    # ~2m of tubing
    x = 2.0
    flow = calcFlowRate(d, p, mu, x)

  echo(flow * 1e3, " l / s")

  # given the flow in liter, calc total gas inserted into the system
  let flow_l = flow * 1e3

  # detector volume in m^3
  let det_vol = cylinder_volume(12.0, 3.0) * 1e-6
  echo("Detector volume is : ", det_vol)
  # initial gas volume inside detector (1 bar is argon!), thus
  # only .5 bar
  let n_initial = calcGasAmount(0.5e5, det_vol, 293.15)
  # gas which came in after window ruptured
  let valve_open = 5.0
  # total volume in m^3
  let flow_vol = flow_l * 1e-3 * valve_open
  
  # since the flown volume is given for normal pressure and temp, calc
  # amount of gas
  let n_flow = calcGasAmount(1.0e5, flow_vol, 293.15)
  echo("Initial gas is : ", n_initial, " mol")
  echo("Gas from flow is : ", n_flow, " mol")
  let n_total = n_initial + n_flow
  echo("Total compressed air, which entered system : ", n_total)

  # calc volume corresponding to normal pressure
  let tot_vol_atm = calcVolumeFromMol(1e5, n_total, 293.15)
  echo("Total volume of air at normal pressure : ", tot_vol_atm * 1e3, " l")
  
when isMainModule:
  main()
#+end_src

** Data taking woes [/]
:PROPERTIES:
:CUSTOM_ID: sec:cast:data_taking_woes
:END:

In this section we will cover the smaller issues encountered during
the data taking that are worth naming due to having an impact on the
quality of the data or specific features in the data someone who
analyzes the data should be aware of. We will cover each of the
effectively three data taking periods one after another.

- [ ] *LATER HAVE SECTION ON FADC NOISE, NOISE DETECTION AND WHAT
  EVENTS LOOK LIKE IN EACH CASE?*
- [ ] *THIS DOES NOT TALK ABOUT DRIFT OF PEAK IN DATA NOR GAIN
  VARIATION! TOPIC FOR ANOTHER SECTION*  

*** 2017 Oct - Dec
:PROPERTIES:
:CUSTOM_ID: sec:cast:data_taking_woes_2017
:END:

The first data taking period from <2017-10-30 Mon> to <2017-12-22 Fri>
initially had a bug in the data acquisition software, which failed to
reset the veto scintillator values from one event to the next, if the
next one did not have an FADC trigger. In that case in principle the
veto scintillators should not have any values other than ~0~. However,
as there is a flag in the data readout for whether the FADC triggered
at all, this is nowadays handled neatly in the software by only
checking the triggers if there was an FADC trigger in the first
place. Unfortunately, it was later found that the scintillator
triggers were nonsensical in this data taking period due to firmware
bug anyway.

Starting from the solar tracking run on <2017-11-29 Wed> the analogue
FADC signals showed significant signs of noise activity. This lead to
an effectively extremely high dead time of the detector, because the
FADC triggered pretty much immediately after the Timepix shutter was
opened. As I was on shift during this tracking, I changed the FADC
settings to a value, which got rid of the noise enough to continue
normal data taking. The following changes were made:

- differentiation time reduced from $\SI{50}{ns}$ to $\SI{20}{ns}
- coarse gain of the main amplifier increased from ~6x~ to ~10x~

Evidently this has a direct effect on the shape of the FADC signals.

On <2017-12-05 Tue> while trying to investigate the noise problem
which resurfaced the day before despite the different settings, a fuse
blew in the gas interlock box. This caused a loss of a solar tracking
the next day. The still present FADC noise lead me to change the
amplification settings more drastically on <2017-12-07 Thu 8:00>
during the shift:

- integration time from \SI{50}{ns} to \SI{100}{ns}

The same day in the evening the magnet quenched causing the shift to
be missed the next day. In the evening of <2017-12-08 Fri> the
integration time was turned down to \SI{50}{ns} again, as the noise
issue was gone again.

A week later the integration time was finally changed again to
\SI{100}{ns}. By this time it was clear that there would be no easy
fix to the problem and that it is strongly correlated to the magnet
activity during a shift. For that reason the setting was kept for the
remaining data taking periods.

*** 2018 Feb - Apr
:PROPERTIES:
:CUSTOM_ID: sec:cast:data_taking_woes_2018
:END:

2 days before the data taking period was supposed to start again in
2018 there were issues with the detector behavior with respect to the
thresholds and the gain of the GridPixes. During one calibration run
with the $\ce{^{55}Fe}$ source the effective gain dropped further and
further such that instead of $\sim\num{220}$ electrons less than
$\sim\num{100}$ were recorded. This turned out to be a grounding issue
of the detector relative to the water cooling system.

Further, the temperature readout of the detector did not work
anymore. It is unclear what happened exactly, but the female micro
USB connector on the detector had a bad soldering joint as was found
out after the data taking campaign. It is possible that replugging
cables to fix the above mentioned issue caused an already weak
connector to fully break.

The second data taking period finally started on <2018-02-17 Sat> and
ran until <2018-04-17 Tue>.

This data taking campaign still ran without functioning scintillators,
due to lack of time and alternative hardware in Bonn to debug the
underlying issue and develop a solution.

*** 2018 Oct - Dec [/]
:PROPERTIES:
:CUSTOM_ID: sec:cast:data_taking_woes_2018_2
:END:

Between the spring and final data taking campaign the temperature
readout as well as the firmware was fixed to get the scintillator
triggers working correctly, with the installation being done end of
July 2018. By the time of the start of the actual solar tracking data
taking campaign at the end of October however, a powering issue had
appeared. This time the Phoenix connector on the intermediate board
had a bad soldering joint, which was finally fixed
<2018-10-19 Fri>. Data taking started the day after.

Two runs in mid December showed strong noise on the FADC again. This
time no amount of changing amplifier settings had any effect, which is
why 2 runs were done without the FADC. For the last runs it was
activated again and no more noise issues appeared.

The FADC noise issue was in many ways the most disrupting active issue
the detector was plagued by. In hindsight the standard LEMO cable used
should have been a properly shielded cable and someone with more
knowledge about RF interference should have assisted in the
installation. In a later section *WHICH!!* the typical signals
recorded by the FADC under noise will be shown as well as mitigation
strategies software side and how the signals and the FADC activation
threshold changed due to the changed settings will be presented.

- [ ] *FIX REFERENCE TO FADC NOISE LATER*

** High voltage supply [/]

- [ ] *MOVE SOME OF THIS TO THE DAQ SECTION WHERE WE HAVE A HV SECTION*

The high voltage supply is an iseg HV module, which is located in the
VME crate on the airport side of the magnet. The HV is controlled via
a USB connection to the VME crate, which it shares with the FADC. The
veto scintillator however has its own HV supply, since it needs a
positive HV, instead of a negative one.

The detector uses $\num{7}$ different high voltages. $\num{5}$ of
these are for the detector itself, $\num{1}$ for the SiPM and the last
for the veto scintillator on top. Their voltages are shown in
tab. [[tab:cast:high_voltage]]. 

#+CAPTION: Table of high voltages in use for the InGrid Mk. IV. 
#+CAPTION: Note that the veto scintillator is not controlled via
#+CAPTION: the iseg module, but by a CAEN N470.
#+NAME: tab:cast:high_voltage
#+ATTR_LATEX: :booktabs t
|-------------+---------+-------------+------------------|
| Description | Channel | Voltage / V | TripCurrent / mA |
|-------------+---------+-------------+------------------|
| grid        |       0 |        -300 |            0.050 |
| anode       |       1 |        -375 |            0.050 |
| cathode     |       2 |       -1875 |            0.050 |
| ring 1      |       3 |        -415 |            0.100 |
| ring 29     |       4 |       -1830 |            0.100 |
| veto scinti |       5 |       +1200 |                2 |
| SiPM        |       6 |       -65.6 |             0.05 |
|-------------+---------+-------------+------------------|

The voltages in use should remain unchanged, however in case they were
to change, the actual values in use are defined in
[[file:~/TOS/config/HFM_settings.ini][~/TOS/config/HFM_settings.ini]].

The HV cables in use are red cables with LEMO HV connectors. They run
from the detector to an iseg HV module sitting in a VME crate on the
airport side of the magnet. The cables are marked with zip ties and
the same names as in tab. [[tab:cast:high_voltage]]. 

The interlock system for the high voltage supply is detailed in
section [[#sec:cast:hv_interlock]], together with the other interlock
systems in place.

** Vacuum system [/]
:PROPERTIES:
:CUSTOM_ID: sec:cast:vacuum_system
:END:

This section covers the vacuum system of the detector. It is pumped
via a single primary membrane pump and two turbo pumps. One turbo pump
is used to pump the main vacuum vessel of the beam pipe, while the
second small turbo pump is used to pump the interstage part of our
X-ray source manipulator to reduce leakage during movement of the
source.

Fig. [[fig:cast:vacuum-schematic]] shows a schematic of the whole vacuum
system including all interlock systems and the pressure sensors. The
pressures of the sensors P3 and P-MM are used as an interlock for VT3
and the gas supply, respectively.

- [ ] *EXPLAIN INTERLOCKS HERE OR IN APPENDIX?*

#+CAPTION: Schematic of the vacuum system behind the LLNL telescope including
#+CAPTION: interlocks and pressure sensors.
#+NAME: fig:cast:vacuum-schematic
#+ATTR_LATEX: :width 1\textwidth :options angle=90
[[file:~/phd/Figs/detector/vacuum_system2017.png]]

** Watercooling system & gas supply

In this section the watercooling system as well as the gas supply is
discussed. In section [[#sec:cast:water_gas_schematic]] a combined schematic of both systems is
shown. 

*** Watercooling 

In order to keep the detector cool enough to avoid noise and damage to
the septemboard, a watercooling system is used. This section describes
the relevant information for the system.

To readout the temperature two PT1000 temperature sensors are
installed on the detector. One is located on the bottomside of the
intermediate board (outside of the detector volume), while the other
is located on the bottom side of the Septemboard. This temperature
$T_{\text{Septem}}$ is also included in the schematic
[[fig:detector-schematic]], because it is part of the HV interlock, as
described in [[#sec:cast:hv_interlock]].

Fig. [[fig:watercooling]] shows the main part of the system including the
pump, reservoir and radiator. The tubing is specifically chosen in
*blue* to clear up potential confusion with other tubes used in the
detector system. These tubes use special Festo quick couplings, which
cannot be connected to the connectors of the gas supply, to avoid
potential accidents. The tubes have zipties installed on them, which
label the tubes as well, with the naming convention as it is used in
fig. [[fig:detector-schematic]]. 
*NOTE: NAMES NOT CORRECT YET!*

#+CAPTION: Picture of the water cooling system of the InGrid Mk. IV detector
#+NAME: fig:watercooling
<file to be inserted>

**** Maintenance

At the end of every shift it should be checked, whether the water
level in the reservoir is still within the black lines seen in
Fig. [[fig:watercooling]]. If not, water should be added by the shift
coordinator (or trusted shifters; you know if you're one of these). 


*** Gas supply

The gas supply uses red tubing (in parts where flexible tubing is
used) to differentiate itself from the watercooling
system. Additionally, the tubes have zipties showing which tube is
which. These are located on both ends of the tubes. The naming
convention is the same as in [[fig:detector-schematic]].

The connectors of the gas line are standard Swagelok connectors.

As can be seen in the schematic, the gas supply has 4 valves on the
inlet side and 2 on the outlet side. In addition a buffer gas volume
is installed before the detector for better flow control. 

It follows a short explanation of the different valves:

- $V_{\text{in, 1}}$ is the main electrovalve installed right after the gas
  bottle outside the CAST hall. 
- $V_{\text{interlock}}$ is installed is the electrovalve installed
  below the platform where the beamline is located. This valve is part
  of the gas supply interlock, as described in section [[#sec:cast:gas_supply_interlock]].
- $V_{\text{in, 2}}$ is the manual valve located on the second gas
  supply mounting below the beamline. 
- $V_{\text{in, N1}}$ is the first needle valve, which is located on
  the sceond gas supply mounting below the beamline. It is the one
  part of the flow meter placed there.
- $V_{\text{P}}$ is the valve inside the pressure controller, which is
  placed roughly below the telescope (on the platform), while
  $P_{\text{Detector}}$ is the pressure gauge inside this controller.

*** Combined schematic (water & gas)
:PROPERTIES:
:CUSTOM_ID: sec:cast:water_gas_schematic
:END:


Fig. [[fig:detector-schematic]] shows a combined schematic of both the
watercooling system and the gas supply. Additionally, the relevant
interlock systems and their corresponding members are shown.

#+CAPTION: Combined schematic of the detector system, consisting of the
#+CAPTION: water cooling system and the gas supply. The interlock systems
#+CAPTION: are shown with dashed lines. See section [[Interlock systems]]
#+CAPTION: regarding explanations of when the interlock is activated.
#+NAME: fig:detector-schematic
#+ATTR_LATEX: :width 1\textwidth :options angle=90
[[file:~/org/Doc/Detector/figs/detector_system2017.png]]


** Interlock systems

This section describes the interlock systems, which are related to the
detector. There are 3 interlock systems to speak of. 
- The CAST magnet interlock, which prohibits the gate valve VT3 to be
  opened, if the pressure in the vacuum system is not good enough.
- A gas supply interlock, which makes sure the detector is only
  flushed with gas, if all other parameters are considered nominal
  (mainly a good vacuum in the system).
- A HV interlock, which makes sure the detector is only under HV, if
  the temperature of the detector is still good (otherwise a lot of
  sparks are produced) and the currents on the HV lines are nominal.

*** HV interlock
:PROPERTIES:
:CUSTOM_ID: sec:cast:hv_interlock
:END:

The HV system is part of an interlock, which tracks the following
properties:
- detector temperature
- currents on HV lines
- TO BE IMPLEMENTED: gas pressure inside the detector

The detector temperature is measured at two points by PT1000
sensors. One of these is located on the bottom side of the
intermediate board (and thus is more a measure the the temperature
surrounding the detector), while the second is located on the bottom
side of the septemboard. The second is the best possible measure for
the temperature of the InGrids. However, there is still a PCB
separating the sensor from the actual InGrids. This means there is
probably a temperature difference of a minimum of $\SI{10}{\celsius}$
between the measured value and the actual temperature of the InGrids. 

Whenever the TOS is configured to use the FADC readout and control the
HV (note: the two are intertwined, since both sit in the same VME
crate, which is controlled via a single USB connection), a background
process which monitors the temperature is started. If the temperature
exceeds the following boundaries
#+BEGIN_EXPORT latex
$\SI{0}{\celsius} \leq T \leq \SI{60}{\celsius}$,
#+END_EXPORT
on the lower side of the septemboard, the HV is shut down
immediately. The lower bound is of less practical value in a physical
sense, but in case of sensor problems negative temperature
values may be reported. As the upper bound a value is taken at which
sparks seen on the pixels become unacceptable. This bound is
potentially going to be lowered to $\SI{50}{\celsius}$ in the future,
at which no noticeable noise is detectable. 

The interlock currents at which the HV trips are already shown in
tab. [[tab:hv]]. During ramp up of the HV, these trip currents are set
higher to avoid trips, while capacitors are being charged.

In the future the gas pressure within the detector is included into
the interlock system to shut down the HV if the pressure inside the
detector leaves a certain safe boundary, since this might indicate a
leak in the detector or an empty gas bottle.

*** Gas supply interlock
:PROPERTIES:
:CUSTOM_ID: sec:cast:gas_supply_interlock
:END:

The gas supply is also part of an interlock system. In case of a
window rupture the potential amount of gas that might enter the vacuum
system should be limited by electrovalves. In the future the pressure
inside the detector will be included into the gas supply
interlock. This is to make sure the gas inlet and outlet are closed in
case the pressure inside the detector drops (which might indicate a
leak somewhere or an empty gas bottle) or in case of rising
pressure. 

The latter is not as important thought, because a pressure controller is
already installed behind the detector, which controls the flow such
that the pressure stays at $\SI{1050}{\milli \bar}$. While a failure
of the controller is thinkable, potentially leading to a pressure
increase inside the detector, it is questionable whether this could be
dealt with using this interlock system. That is because the pressure
sensor used is part of the pressure controller.

Thus, three electrovalves are placed on the gas line of the
detector. One, $V_{\text{in}}$, is outside of the building next to the
gas bottles (see fig. [[fig:electrovalve-outside]]). The second valve
$V_{\text{interlock}}$ is located right before the buffer volume, next
to the watercooling system, below the shielding platform. The final
electrovalve $V_{\text{out}}$ is located after the pressure
controller on a blue beam, which supports the optical table below the
telescope (see fig. [[fig:electrovalve-V-out]]). These valves are normally
closed, i.e. in case of power loss they automatically close. They are
open if a voltage is applied to them. 

The valves are connected to the pressure sensor $P_{\text{MM}}$ (see
fig. [[fig:cast:vacuum-schematic]]). The pressures to activate the interlock
system is defined by upper and lower thresholds asymmetrically. They
are as follows:
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{MM, Gas enable}} \leq \SI{9.9e-3}{\milli \bar}
\end{align}
#+END_EXPORT
and 
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{MM, Gas disable}} \leq \SI{2e-2}{\milli \bar}
\end{align}
#+END_EXPORT
#+BEGIN_COMMENT
*CHECK THESE VALUES, they are still wrong I believe*.
#+END_COMMENT


- [ ] *MERGE IMAGES INTO ONE SUBFIG*

#+CAPTION: Location of the electrovalve $V_{\text{in}}$ located outside the building.
#+NAME: fig:electrovalve-outside
[[file:~/org/Doc/Detector/figs/electrovalve_outside.jpg]]

#+CAPTION: Location of the electrovalve $V_{\text{interlock}}$ next to the 
#+CAPTION: watercooling system below the shielding table.
#+NAME: fig:electrovalve-V-interlock
[[file:~/org/Doc/Detector/figs/electrovalve_V_interlock.jpg]]

#+CAPTION: Location of the electrovalve $V_{\text{out}}$ connected to the beam
#+CAPTION: supporting the optical table, on which the telescope is mounted.
#+NAME: fig:electrovalve-V-out
[[file:~/org/Doc/Detector/figs/electrovalve_V_out.jpg]]


*** CAST magnet interlock
:PROPERTIES:
:CUSTOM_ID: sec:cast:cast_magnet_interlock
:END:

The main CAST magnet interlock, as it is relevant to our detector, is
as follows. The gate valve VT3 separating the magnet volume from the
telescope volume is interlocked. Only if the vacuum in the telescope
volume is good enough, VT3 can be opened while the interlock is
activated. 

For this the pressure of $P_{\text{3}}$ is considered relevant
(cp. fig. [[fig:cast:vacuum-schematic]]). The upper and lower thresholds which
activate and deactivate the interlock are asymmetric and as follows:
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{3, VT3 enable}} &\leq \SI{1e-5}{\milli\bar}
\end{align}
#+END_EXPORT
while
#+BEGIN_EXPORT latex
\begin{align}
P_{\text{3, VT3 disable}} &\leq \SI{8e-5}{\milli\bar}.
\end{align}
#+END_EXPORT
This is to make sure there can be no rapid toggling between the two
states during pumping or flushing the system. 

** X-ray finger runs [/]

- [ ] should this go to the alignment part? I suppose we could mention
  this as part of the alignment with a heatmap and the center location
  _before_ (?) geometer alignment and movement? For context
  We can then later refer to this again in the context of determining
  the systematic uncertainty on the position.

2 X-ray finger runs were made. One near beginning, one near end.

Plot of X-ray finger centers.

Mention how this plays into the analysis side, that it means we need
to adjust the ray tracing.

- [X] *ONE RUN NOW PART OF ALIGNMENT, OTHER IS MISSING ON MY LAPTOP*
** CAST log files [/]

- [ ] in the above we simply state the number of trackings etc. Of
  course realistically that is simply not enough. We need the slow
  control and tracking files to compute when a tracking starts and
  stops.
  I think this implies it needs to go before the summary!
- [ ] INSERT FOOTNOTE LINK TO LABVIEW  

The CAST experiment is controlled by a central computer running the
LabVIEW based slow control system. It receives data from all sensors
installed at CAST (vacuum pressure, temperature, magnet current,
magnet position etc.). A separate LabVIEW program is responsible for
controlling the magnet position, either by moving the magnet to a
specific coordinate or by following the Sun, if it's in reach of the
magnet.

The slow control software records all sensor data and on the one hand
presents it in a multitude of graphs and on the other generates log
files of all information. There are two different kinds of log files
of interest in the context of the Septemboard detector at CAST.

1. The general slow control log file is a versioned space separated
   values file (similar to a comma separated value (CSV) or tab
   separated value (TSV) file, except using spaces as delimiters). The
   filename contains the version number, which decides the columns
   contained in the file and their order. A ~Version.idx~ file maps
   version numbers to file columns for easy access. These slow control
   log files normally contain one entry every minute. For the
   Septemboard detector of interest in this file are mainly the magnet
   current, relevant vacuum pressure sensors and the state of the gate
   valve ~VT3~.
2. The second kind of log files are the tracking log files. These are
   also space separated value files with fields describing the
   pointing location of the magnet as well as whether the magnet is
   currently tracking the Sun.

Both of these log files need to be read by the analysis software to
decide whether one or multiple trackings took place in a given
background run and if so extract the exact start and end time for a
precise data splitting and calculation of background / solar tracking
time.

Generally the latter log files are all that is needed to determine the
existence of a solar tracking. However, the slow control log file can
be used as a further sanity check to make sure the gate valve was
actually open and the magnet under current during the solar tracking.

This is implemented in *LINK TO LOGREADER*. The code first parses the
log files and determines valid solar trackings. Then, given a HDF5
data file containing the background data each solar tracking is mapped
to a background run. One background run may have zero or more solar
trackings attached to it. In the final step the solar tracking start
and stop information is added to each run as additional meta
data. During the later stages of processing this meta data is then
used to only consider background (non tracking) or solar tracking data
(starting from the computation of background rates).

- [ ] *LINK TO CODE!*

*** Add tracking log information to background files             :noexport:

The code dealing with the log files is [[file:~/CastData/ExternCode/TimepixAnalysis/LogReader/cast_log_reader.nim]]

In case previous log information is available we first have to remove
that information. This is done by just calling the program just with
the H5 file as an input:
#+begin_src sh
cast_log_reader h5file -f ~/CastData/data/DataRuns2017_Reco.h5
cast_log_reader h5file -f ~/CastData/data/DataRuns2018_Reco.h5
#+end_src

With an 'empty' (in terms of tracking information) HDF5 file we can
then go ahead and add all tracking information to them. This of course
requires the tracking log files:

#+begin_src sh
./cast_log_reader tracking -p ../resources/LogFiles/tracking-logs --h5out ~/CastData/data/DataRuns2017_Reco.h5
./cast_log_reader tracking -p ../resources/LogFiles/tracking-logs --h5out ~/CastData/data/DataRuns2018_Reco.h5
#+end_src

One can also run it without any output H5 file ~--h5out~ to simply get
information about the runs. In particular all runs

#+begin_src sh
./cast_log_reader tracking -p ../resources/LogFiles/tracking-logs --startTime 2017/09/01 --endTime 2018/12/30
#+end_src
:RESULTS:
FILTERING TO DATE: 2017-09-01T02:00:00+02:00 and 2018-12-30T01:00:00+01:00
<2017-10-31 Tue 6:37>    <2017-10-31 Tue 8:10>
<2017-11-02 Thu 6:39>    <2017-11-02 Thu 8:14>
<2017-11-03 Fri 6:41>    <2017-11-03 Fri 8:15>
<2017-11-04 Sat 6:42>    <2017-11-04 Sat 8:17>
<2017-11-05 Sun 6:43>    <2017-11-05 Sun 8:18>
<2017-11-07 Tue 6:47>    <2017-11-07 Tue 8:23>
<2017-11-06 Mon 6:45>    <2017-11-06 Mon 8:20>
<2017-11-08 Wed 6:48>    <2017-11-08 Wed 8:24>
<2017-11-09 Thu 6:49>    <2017-11-09 Thu 8:26>
<2017-11-10 Fri 6:51>    <2017-11-10 Fri 8:28>
<2017-11-11 Sat 6:52>    <2017-11-11 Sat 8:30>
<2017-11-12 Sun 6:54>    <2017-11-12 Sun 8:31>
<2017-11-14 Tue 6:56>    <2017-11-14 Tue 8:34>
<2017-11-13 Mon 6:55>    <2017-11-13 Mon 8:33>
<2017-11-15 Wed 6:57>    <2017-11-15 Wed 8:36>
<2017-11-17 Fri 7:00>    <2017-11-17 Fri 8:39>
<2017-11-18 Sat 7:01>    <2017-11-18 Sat 8:41>
<2017-11-19 Sun 7:02>    <2017-11-19 Sun 8:43>
<2017-11-25 Sat 7:10>    <2017-11-25 Sat 8:53>
<2017-11-26 Sun 7:11>    <2017-11-26 Sun 8:54>
<2017-11-27 Mon 7:12>    <2017-11-27 Mon 8:56>
<2017-11-28 Tue 7:14>    <2017-11-28 Tue 8:57>
<2017-11-29 Wed 7:15>    <2017-11-29 Wed 8:59>
<2017-11-30 Thu 7:16>    <2017-11-30 Thu 9:00>
<2017-12-01 Fri 7:17>    <2017-12-01 Fri 9:01>
<2017-12-02 Sat 7:18>    <2017-12-02 Sat 8:59>
<2017-12-03 Sun 7:19>    <2017-12-03 Sun 8:58>
<2017-12-04 Mon 7:20>    <2017-12-04 Mon 9:01>
<2017-12-05 Tue 7:21>    <2017-12-05 Tue 8:59>
<2017-12-07 Thu 7:22>    <2017-12-07 Thu 9:02>
<2017-12-09 Sat 7:25>    <2017-12-09 Sat 9:05>
<2017-12-10 Sun 7:26>    <2017-12-10 Sun 9:01>
<2017-12-11 Mon 7:27>    <2017-12-11 Mon 9:00>
<2017-12-12 Tue 7:28>    <2017-12-12 Tue 9:02>
<2017-12-13 Wed 7:28>    <2017-12-13 Wed 9:00>
<2017-12-14 Thu 7:29>    <2017-12-14 Thu 8:59>
<2017-12-15 Fri 7:29>    <2017-12-15 Fri 9:00>
<2017-12-16 Sat 7:30>    <2017-12-16 Sat 9:01>
<2017-12-17 Sun 7:31>    <2017-12-17 Sun 9:01>
<2017-12-18 Mon 7:31>    <2017-12-18 Mon 9:01>
<2017-12-19 Tue 7:32>    <2017-12-19 Tue 9:02>
<2017-12-20 Wed 7:33>    <2017-12-20 Wed 9:02>
<2018-02-15 Thu 7:01>    <2018-02-15 Thu 8:33>
<2018-02-16 Fri 7:00>    <2018-02-16 Fri 8:31>
<2018-02-18 Sun 6:57>    <2018-02-18 Sun 8:28>
<2018-02-19 Mon 6:56>    <2018-02-19 Mon 8:26>
<2018-02-20 Tue 6:53>    <2018-02-20 Tue 8:24>
<2018-02-21 Wed 6:52>    <2018-02-21 Wed 8:22>
<2018-02-22 Thu 6:50>    <2018-02-22 Thu 8:20>
<2018-02-23 Fri 6:48>    <2018-02-23 Fri 8:18>
<2018-02-24 Sat 6:47>    <2018-02-24 Sat 8:16>
<2018-02-28 Wed 6:40>    <2018-02-28 Wed 8:09>
<2018-03-02 Fri 6:36>    <2018-03-02 Fri 8:05>
<2018-03-03 Sat 6:35>    <2018-03-03 Sat 8:03>
<2018-03-04 Sun 6:33>    <2018-03-04 Sun 8:01>
<2018-03-05 Mon 6:31>    <2018-03-05 Mon 7:59>
<2018-03-06 Tue 6:29>    <2018-03-06 Tue 7:57>
<2018-03-07 Wed 6:27>    <2018-03-07 Wed 7:55>
<2018-03-14 Wed 6:14>    <2018-03-14 Wed 7:41>
<2018-03-15 Thu 6:12>    <2018-03-15 Thu 7:39>
<2018-03-16 Fri 6:10>    <2018-03-16 Fri 7:37>
<2018-03-17 Sat 6:08>    <2018-03-17 Sat 7:35>
<2018-03-18 Sun 6:07>    <2018-03-18 Sun 7:33>
<2018-03-19 Mon 6:05>    <2018-03-19 Mon 7:31>
<2018-03-20 Tue 6:03>    <2018-03-20 Tue 7:29>
<2018-03-21 Wed 6:01>    <2018-03-21 Wed 7:27>
<2018-03-22 Thu 5:59>    <2018-03-22 Thu 7:25>
<2018-03-24 Sat 5:55>    <2018-03-24 Sat 7:21>
<2018-03-25 Sun 6:53>    <2018-03-25 Sun 8:20>
<2018-03-26 Mon 5:51>    <2018-03-26 Mon 7:18>
<2018-10-19 Fri 6:21>    <2018-10-19 Fri 7:51>
<2018-10-22 Mon 6:24>    <2018-10-22 Mon 7:55>
<2018-10-23 Tue 6:26>    <2018-10-23 Tue 7:57>
<2018-10-24 Wed 6:27>    <2018-10-24 Wed 7:58>
<2018-10-25 Thu 6:28>    <2018-10-25 Thu 8:00>
<2018-10-26 Fri 6:30>    <2018-10-26 Fri 8:02>
<2018-10-27 Sat 6:31>    <2018-10-27 Sat 8:03>
<2018-10-28 Sun 5:32>    <2018-10-28 Sun 7:05>
<2018-10-29 Mon 6:34>    <2018-10-29 Mon 8:06>
<2018-10-30 Tue 6:35>    <2018-10-30 Tue 8:08>
<2018-11-01 Thu 6:38>    <2018-11-01 Thu 8:11>
<2018-11-02 Fri 6:39>    <2018-11-02 Fri 8:13>
<2018-11-03 Sat 6:40>    <2018-11-03 Sat 8:16>
<2018-11-04 Sun 6:43>    <2018-11-04 Sun 8:17>
<2018-11-05 Mon 6:44>    <2018-11-05 Mon 8:19>
<2018-11-06 Tue 6:45>    <2018-11-06 Tue 8:21>
<2018-11-09 Fri 6:49>    <2018-11-09 Fri 8:26>
<2018-11-10 Sat 6:51>    <2018-11-10 Sat 8:27>
<2018-11-11 Sun 6:52>    <2018-11-11 Sun 8:29>
<2018-11-12 Mon 6:53>    <2018-11-12 Mon 8:31>
<2018-11-13 Tue 6:54>    <2018-11-13 Tue 8:32>
<2018-11-14 Wed 6:56>    <2018-11-14 Wed 8:34>
<2018-11-15 Thu 6:57>    <2018-11-15 Thu 8:36>
<2018-11-16 Fri 6:58>    <2018-11-16 Fri 8:37>
<2018-11-17 Sat 7:00>    <2018-11-17 Sat 8:39>
<2018-11-18 Sun 7:01>    <2018-11-18 Sun 8:41>
<2018-11-19 Mon 7:02>    <2018-11-19 Mon 8:42>
<2018-11-24 Sat 7:08>    <2018-11-24 Sat 7:30>
<2018-11-25 Sun 7:09>    <2018-11-25 Sun 8:52>
<2018-11-26 Mon 7:10>    <2018-11-26 Mon 8:53>
<2018-11-27 Tue 7:11>    <2018-11-27 Tue 8:55>
<2018-11-29 Thu 7:14>    <2018-11-29 Thu 8:58>
<2018-11-30 Fri 7:15>    <2018-11-30 Fri 8:59>
<2018-12-01 Sat 7:16>    <2018-12-01 Sat 9:00>
<2018-12-02 Sun 7:17>    <2018-12-02 Sun 9:02>
<2018-12-03 Mon 7:18>    <2018-12-03 Mon 9:03>
<2018-12-05 Wed 8:55>    <2018-12-05 Wed 9:04>
<2018-12-06 Thu 7:22>    <2018-12-06 Thu 9:04>
<2018-12-07 Fri 7:23>    <2018-12-07 Fri 9:03>
<2018-12-08 Sat 7:24>    <2018-12-08 Sat 9:04>
<2018-12-10 Mon 7:25>    <2018-12-10 Mon 9:03>
<2018-12-11 Tue 7:26>    <2018-12-11 Tue 9:02>
<2018-12-12 Wed 7:27>    <2018-12-12 Wed 9:03>
<2018-12-13 Thu 7:28>    <2018-12-13 Thu 9:03>
<2018-12-14 Fri 7:29>    <2018-12-14 Fri 9:06>
<2018-12-16 Sun 7:30>    <2018-12-16 Sun 9:00>
<2018-12-15 Sat 7:30>    <2018-12-15 Sat 9:01>
<2018-12-17 Mon 7:31>    <2018-12-17 Mon 9:01>
<2018-12-18 Tue 7:32>    <2018-12-18 Tue 9:01>
<2018-12-20 Thu 7:33>    <2018-12-20 Thu 9:03>
There are 120 solar trackings found in the log file directory
The total time of all trackings: 186 h (exact: 1 week, 18 hours, 46 minutes, and 19 seconds)
Total time the magnet was on (> 1 T): 0 h h
:END:

This lists 5 runs that were *not* part of our data taking, meaning we
lost them.


And finally (and most useful for information purposes) we can run the
log reader over the files and do a fake insert (aka dry run) of
inserting the files, which only outputs the run information including
which runs were missed:
#+begin_src sh
./cast_log_reader tracking -p ../resources/LogFiles/tracking-logs \
                  --startTime 2017/09/01 --endTime 2018/05/01 \
                  --h5out ~/CastData/data/DataRuns2017_Reco.h5 --dryRun
#+end_src
:RESULTS:
There are 70 solar trackings found in the log file directory
The total time of all trackings: 109 h (exact: 4 days, 13 hours, 3 minutes, and 22 seconds)
Total time the magnet was on (> 1 T): 0 h h
Filtering tracking logs to date: 2017-09-01T02:00:00+02:00 and 2018-05-01T02:00:00+02:00
========== Logs mapped to trackings in the output file: ==========
<2017-10-31 Tue 6:37>    <2017-10-31 Tue 8:10>  for run: 76
<2017-11-02 Thu 6:39>    <2017-11-02 Thu 8:14>  for run: 77
<2017-11-03 Fri 6:41>    <2017-11-03 Fri 8:15>  for run: 78
<2017-11-04 Sat 6:42>    <2017-11-04 Sat 8:17>  for run: 79
<2017-11-05 Sun 6:43>    <2017-11-05 Sun 8:18>  for run: 80
<2017-11-06 Mon 6:45>    <2017-11-06 Mon 8:20>  for run: 81
<2017-11-07 Tue 6:47>    <2017-11-07 Tue 8:23>  for run: 82
<2017-11-08 Wed 6:48>    <2017-11-08 Wed 8:24>  for run: 82
<2017-11-09 Thu 6:49>    <2017-11-09 Thu 8:26>  for run: 84
<2017-11-10 Fri 6:51>    <2017-11-10 Fri 8:28>  for run: 86
<2017-11-11 Sat 6:52>    <2017-11-11 Sat 8:30>  for run: 87
<2017-11-12 Sun 6:54>    <2017-11-12 Sun 8:31>  for run: 87
<2017-11-13 Mon 6:55>    <2017-11-13 Mon 8:33>  for run: 89
<2017-11-14 Tue 6:56>    <2017-11-14 Tue 8:34>  for run: 90
<2017-11-15 Wed 6:57>    <2017-11-15 Wed 8:36>  for run: 91
<2017-11-17 Fri 7:00>    <2017-11-17 Fri 8:39>  for run: 92
<2017-11-18 Sat 7:01>    <2017-11-18 Sat 8:41>  for run: 94
<2017-11-19 Sun 7:02>    <2017-11-19 Sun 8:43>  for run: 95
<2017-11-25 Sat 7:10>    <2017-11-25 Sat 8:53>  for run: 97
<2017-11-26 Sun 7:11>    <2017-11-26 Sun 8:54>  for run: 98
<2017-11-27 Mon 7:12>    <2017-11-27 Mon 8:56>  for run: 99
<2017-11-28 Tue 7:14>    <2017-11-28 Tue 8:57>  for run: 100
<2017-11-29 Wed 7:15>    <2017-11-29 Wed 8:59>  for run: 101
<2017-11-30 Thu 7:16>    <2017-11-30 Thu 9:00>  for run: 103
<2017-12-01 Fri 7:17>    <2017-12-01 Fri 9:01>  for run: 104
<2017-12-03 Sun 7:19>    <2017-12-03 Sun 8:58>  for run: 106
<2017-12-02 Sat 7:18>    <2017-12-02 Sat 8:59>  for run: 105
<2017-12-04 Mon 7:20>    <2017-12-04 Mon 9:01>  for run: 107
<2017-12-05 Tue 7:21>    <2017-12-05 Tue 8:59>  for run: 109
<2017-12-07 Thu 7:22>    <2017-12-07 Thu 9:02>  for run: 112
<2017-12-09 Sat 7:25>    <2017-12-09 Sat 9:05>  for run: 112
<2017-12-11 Mon 7:27>    <2017-12-11 Mon 9:00>  for run: 114
<2017-12-10 Sun 7:26>    <2017-12-10 Sun 9:01>  for run: 113
<2017-12-12 Tue 7:28>    <2017-12-12 Tue 9:02>  for run: 115
<2017-12-13 Wed 7:28>    <2017-12-13 Wed 9:00>  for run: 117
<2017-12-14 Thu 7:29>    <2017-12-14 Thu 8:59>  for run: 119
<2017-12-15 Fri 7:29>    <2017-12-15 Fri 9:00>  for run: 121
<2017-12-16 Sat 7:30>    <2017-12-16 Sat 9:01>  for run: 123
<2017-12-17 Sun 7:31>    <2017-12-17 Sun 9:01>  for run: 124
<2017-12-18 Mon 7:31>    <2017-12-18 Mon 9:01>  for run: 124
<2017-12-19 Tue 7:32>    <2017-12-19 Tue 9:02>  for run: 125
<2017-12-20 Wed 7:33>    <2017-12-20 Wed 9:02>  for run: 127
<2018-02-18 Sun 6:57>    <2018-02-18 Sun 8:28>  for run: 146
<2018-02-20 Tue 6:53>    <2018-02-20 Tue 8:24>  for run: 150
<2018-02-19 Mon 6:56>    <2018-02-19 Mon 8:26>  for run: 148
<2018-02-21 Wed 6:52>    <2018-02-21 Wed 8:22>  for run: 152
<2018-02-22 Thu 6:50>    <2018-02-22 Thu 8:20>  for run: 154
<2018-02-23 Fri 6:48>    <2018-02-23 Fri 8:18>  for run: 156
<2018-02-24 Sat 6:47>    <2018-02-24 Sat 8:16>  for run: 158
<2018-02-28 Wed 6:40>    <2018-02-28 Wed 8:09>  for run: 160
<2018-03-02 Fri 6:36>    <2018-03-02 Fri 8:05>  for run: 162
<2018-03-03 Sat 6:35>    <2018-03-03 Sat 8:03>  for run: 162
<2018-03-04 Sun 6:33>    <2018-03-04 Sun 8:01>  for run: 162
<2018-03-05 Mon 6:31>    <2018-03-05 Mon 7:59>  for run: 164
<2018-03-06 Tue 6:29>    <2018-03-06 Tue 7:57>  for run: 164
<2018-03-07 Wed 6:27>    <2018-03-07 Wed 7:55>  for run: 166
<2018-03-14 Wed 6:14>    <2018-03-14 Wed 7:41>  for run: 170
<2018-03-15 Thu 6:12>    <2018-03-15 Thu 7:39>  for run: 172
<2018-03-16 Fri 6:10>    <2018-03-16 Fri 7:37>  for run: 174
<2018-03-17 Sat 6:08>    <2018-03-17 Sat 7:35>  for run: 176
<2018-03-18 Sun 6:07>    <2018-03-18 Sun 7:33>  for run: 178
<2018-03-19 Mon 6:05>    <2018-03-19 Mon 7:31>  for run: 178
<2018-03-20 Tue 6:03>    <2018-03-20 Tue 7:29>  for run: 178
<2018-03-21 Wed 6:01>    <2018-03-21 Wed 7:27>  for run: 178
<2018-03-22 Thu 5:59>    <2018-03-22 Thu 7:25>  for run: 178
<2018-03-24 Sat 5:55>    <2018-03-24 Sat 7:21>  for run: 180
<2018-03-25 Sun 6:53>    <2018-03-25 Sun 8:20>  for run: 182
<2018-03-26 Mon 5:51>    <2018-03-26 Mon 7:18>  for run: 182
==================================================================

========== Logs *not* mapped to a run ============================
<2018-02-15 Thu 7:01>    <2018-02-15 Thu 8:33>
<2018-02-16 Fri 7:00>    <2018-02-16 Fri 8:31>
==================================================================
:END:

And for 2018:
#+begin_src sh
./cast_log_reader tracking -p ../resources/LogFiles/tracking-logs \
                  --startTime 2018/05/01 --endTime 2018/12/31 \
                  --h5out ~/CastData/data/DataRuns2018_Reco.h5 --dryRun
#+end_src
:RESULTS:
There are 50 solar trackings found in the log file directory
The total time of all trackings: 77 h (exact: 3 days, 5 hours, 42 minutes, and 57 seconds)
Total time the magnet was on (> 1 T): 0 h h
Filtering tracking logs to date: 2018-05-01T02:00:00+02:00 and 2018-12-31T01:00:00+01:00
========== Logs mapped to trackings in the output file: ==========
<2018-10-22 Mon 6:24>    <2018-10-22 Mon 7:55>  for run: 240
<2018-10-23 Tue 6:26>    <2018-10-23 Tue 7:57>  for run: 242
<2018-10-24 Wed 6:27>    <2018-10-24 Wed 7:58>  for run: 244
<2018-10-25 Thu 6:28>    <2018-10-25 Thu 8:00>  for run: 246
<2018-10-26 Fri 6:30>    <2018-10-26 Fri 8:02>  for run: 248
<2018-10-27 Sat 6:31>    <2018-10-27 Sat 8:03>  for run: 250
<2018-10-29 Mon 6:34>    <2018-10-29 Mon 8:06>  for run: 254
<2018-10-30 Tue 6:35>    <2018-10-30 Tue 8:08>  for run: 256
<2018-11-01 Thu 6:38>    <2018-11-01 Thu 8:11>  for run: 258
<2018-11-02 Fri 6:39>    <2018-11-02 Fri 8:13>  for run: 261
<2018-11-03 Sat 6:40>    <2018-11-03 Sat 8:16>  for run: 261
<2018-11-04 Sun 6:43>    <2018-11-04 Sun 8:17>  for run: 261
<2018-11-05 Mon 6:44>    <2018-11-05 Mon 8:19>  for run: 263
<2018-11-06 Tue 6:45>    <2018-11-06 Tue 8:21>  for run: 265
<2018-11-09 Fri 6:49>    <2018-11-09 Fri 8:26>  for run: 268
<2018-11-10 Sat 6:51>    <2018-11-10 Sat 8:27>  for run: 270
<2018-11-11 Sun 6:52>    <2018-11-11 Sun 8:29>  for run: 270
<2018-11-12 Mon 6:53>    <2018-11-12 Mon 8:31>  for run: 272
<2018-11-13 Tue 6:54>    <2018-11-13 Tue 8:32>  for run: 272
<2018-11-14 Wed 6:56>    <2018-11-14 Wed 8:34>  for run: 272
<2018-11-15 Thu 6:57>    <2018-11-15 Thu 8:36>  for run: 274
<2018-11-16 Fri 6:58>    <2018-11-16 Fri 8:37>  for run: 274
<2018-11-17 Sat 7:00>    <2018-11-17 Sat 8:39>  for run: 274
<2018-11-18 Sun 7:01>    <2018-11-18 Sun 8:41>  for run: 276
<2018-11-19 Mon 7:02>    <2018-11-19 Mon 8:42>  for run: 276
<2018-11-25 Sun 7:09>    <2018-11-25 Sun 8:52>  for run: 279
<2018-11-26 Mon 7:10>    <2018-11-26 Mon 8:53>  for run: 279
<2018-11-27 Tue 7:11>    <2018-11-27 Tue 8:55>  for run: 281
<2018-11-29 Thu 7:14>    <2018-11-29 Thu 8:58>  for run: 283
<2018-11-30 Fri 7:15>    <2018-11-30 Fri 8:59>  for run: 283
<2018-12-01 Sat 7:16>    <2018-12-01 Sat 9:00>  for run: 283
<2018-12-02 Sun 7:17>    <2018-12-02 Sun 9:02>  for run: 285
<2018-12-03 Mon 7:18>    <2018-12-03 Mon 9:03>  for run: 285
<2018-12-05 Wed 8:55>    <2018-12-05 Wed 9:04>  for run: 287
<2018-12-06 Thu 7:22>    <2018-12-06 Thu 9:04>  for run: 289
<2018-12-07 Fri 7:23>    <2018-12-07 Fri 9:03>  for run: 291
<2018-12-08 Sat 7:24>    <2018-12-08 Sat 9:04>  for run: 291
<2018-12-10 Mon 7:25>    <2018-12-10 Mon 9:03>  for run: 293
<2018-12-11 Tue 7:26>    <2018-12-11 Tue 9:02>  for run: 295
<2018-12-12 Wed 7:27>    <2018-12-12 Wed 9:03>  for run: 297
<2018-12-13 Thu 7:28>    <2018-12-13 Thu 9:03>  for run: 297
<2018-12-14 Fri 7:29>    <2018-12-14 Fri 9:06>  for run: 298
<2018-12-15 Sat 7:30>    <2018-12-15 Sat 9:01>  for run: 299
<2018-12-16 Sun 7:30>    <2018-12-16 Sun 9:00>  for run: 301
<2018-12-17 Mon 7:31>    <2018-12-17 Mon 9:01>  for run: 301
<2018-12-18 Tue 7:32>    <2018-12-18 Tue 9:01>  for run: 303
<2018-12-20 Thu 7:33>    <2018-12-20 Thu 9:03>  for run: 306
==================================================================

========== Logs *not* mapped to a run ============================
<2018-10-19 Fri 6:21>    <2018-10-19 Fri 7:51>
<2018-10-28 Sun 5:32>    <2018-10-28 Sun 7:05>
<2018-11-24 Sat 7:08>    <2018-11-24 Sat 7:30>
==================================================================
:END:

** Summary of CAST data taking [3/8]
:PROPERTIES:
:CUSTOM_ID: sec:cast:data_taking_campaigns
:END:

- [ ] *UNIFORMLY DECIDE TO EITHER USE ~Run-2~ or ~Run 2~ STYLE*

In summary then the data taken at CAST with the Septemboard detector
can be split into two periods. The first from October 2017 to April
2018 and the second from October 2018 to December 2018. The former
will from here on be called "Run-2" and the latter "Run-3". Run-1
refers to the data taking campaign with the single GridPix detector in
2014 and 2015. The distinction of run periods is mainly based on the
fact that the detector was dismounted between Run-2 and Run-3 and
additionally a full detector recalibration was performed, meaning the
datasets require slightly different parameters for calibration related aspects.

During Run-2 the scintillator vetoes were not working correctly. The
FADC was partially noisy. In Run-3 all detector features were working
as intended. The feature list is summarized in
tab. [[tab:cast:features_by_run]].

In total 115 solar trackings were recorded between Run-2 and
Run-3. This amounts to about $\SI{180}{\hour}$ of tracking
data. Further, $\SI{3526}{\hour}$ of background data and
$\SI{194}{\hour}$ of $\ce{^{55}Fe}$ calibration data were
recorded. Two X-ray finger runs were done for alignment purposes.

The appendix [[#sec:appendix:cast_run_list]] lists the full run list with
additional information about each run.

Outside the issues mentioned in the previous section
[[#sec:cast:data_taking_woes]], the detector generally ran very
stable. Certain detector behaviors will be discussed later, which do
not affect data quality as they can be calibrated out. 


- [ ] table for number of shifts in each run, column for number of
  trackings
- [X] number of X-ray finger runs  
- [X] table of total time taking in each run
- [X] link to appendix containing total run list!  
- [X] table of working detector features in each run
- [ ] table of recorded temperatures (or as a plot? Table takes a lot
  of space! ~Tools/mapSeptemTempToFePeak.nim~)
- [ ] numbers of the total activity, number of events on the center &
  outside chips, # of FADC triggers, event durations etc.
- [ ] plot of event durations already created!

#+caption: Overview of the total data taken with the Septemboard detector at CAST
#+CAPTION: in the time between October 2017 and December 2018.
#+NAME: tab:cast:total_data_time
#+ATTR_LATEX: :align lrrr :booktabs t
|-------+----------------+------------+-------------|
|       | solar tracking | background | calibration |
|-------+----------------+------------+-------------|
| Run-2 | 106 h          | 2401 h     | 107 h       |
| Run-3 | 74 h           | 1125 h     | 87 h        |
| Total | 180 h          | 3526 h     | 194 h       |
|-------+----------------+------------+-------------|

#+CAPTION: Overview of working (\green{o}), mostly working (\orange{m}), not
#+CAPTION: working (\red{x}) features in each run. FADC was partially noisy
#+CAPTION: in Run-2.
#+NAME: tab:cast:features_by_run
#+ATTR_LATEX: :booktabs t
|-------------+------------+-----------|
| Feature     | Run 2      | Run 3     |
|-------------+------------+-----------|
| Septemboard | \green{o}  | \green{o} |
| FADC        | \orange{m} | \green{o} |
| Veto scinti | \red{x}    | \green{o} |
| SiPM        | \red{x}    | \green{o} |
|-------------+------------+-----------|
  

* Detector preparation / study / characterization etc.                :Part3:
:PROPERTIES:
:CUSTOM_ID: sec:calibration:energy
:END:
#+LATEX: \minitoc
There are two different kinds of calibrations used for the data taking
campaign at CAST. One is a data taking campaign behind an X-ray tube
at the CAST Detector Lab (CDL) to characterize the geometric
properties of X-rays at different energies (as the foundation for
discrimination methods), discussed in section
[[#sec:preparation:cdl]]. The second are measurements using a
$^{55}\text{Fe}$ source installed on a pneumatic manipulator at CAST
to perform regular calibration runs to monitor the detector behavior
and serve as a basis for the energy calibration of events, see
section [[#sec:preparation:55fe]].

*NOTE*: Should we therefore maybe split up the section rather by type
of calibration? Certainly clearer that way. Only question is how to
best present the other calibrations then (FADC, scintillators).

- [ ] *MAYBE THIS CHAPTER CAN NOT ONLY CONTAIN STRICT CALIBRATIONS, BUT ALSO THINGS LiKE GAS GAIN TIME BINNING?*

** Detector calibrations + characterization plots

*** FADC spectrum & threshold [0/4]

- [ ] show spectra
- [ ] show 55Fe spectrum of FADC data
- [ ] apply Savitzky Golay filter to FADC spectra & describe
- [ ] train NN on FADC data and see what we can gain <- this goes
  towards analysis chapter of course!
  Best use a CNN with 1D input data & kernel!


** Detector behavior over time [/]

- [ ] this should be in the detector energy calibration section. It
  only matters (and can be computed) once we discuss the energy calibration.

Plot of the (known) temperature at PCB from shift forms.
Unfortunately, most of the high resolution temperature logs were lost due to a
software bug.
Cooling power varied over time, probably due to slight clogging.

Plot of the peak position of the 55Fe calibration runs.

*** Gas gain binning
:PROPERTIES:
:CUSTOM_ID: sec:?:gas_gain_time_binning
:END:

Explain why we did it and how we ended up at 90 min time binning.
  
** 55Fe spectra
:PROPERTIES:
:CUSTOM_ID: sec:preparation:55fe
:END:

Example spectrum. What's the point of these spectra.

** Energy calibration, how done? [0/1]
:PROPERTIES:
:CUSTOM_ID: sec:calibration:energy
:END:

- [ ] Mention something about section [[#sec:large_events_few_pixels_tot]] in
=StatusAndProgress=, i.e. events that convert very close to grid and
thus have few pixels, but a lot of energy as determined by the
ToT. This is an argument in favor of using ToT over #pix.

** CAST Detector Lab [/]
:PROPERTIES:
:CUSTOM_ID: sec:preparation:cdl
:END:

Measurements for X-ray reference data

Detector lab measurements were only performed after the data taking
period at CAST was over. From a logical standpoint it makes more sense
to talk about it before though.

Everything required in StatusAndProgress. Will need to redo all plots
of course.

- [ ] *FINISH CDL FIRST*
- [ ] *FIND OUT WHAT CHIP CALIBRATION USED FOR CDL*
- [ ] *REFERENCE HENDRIK MSC FOR CDL*    

*** CDL measurements (from =StatusAndProgress=)

To derive the background rate plots a likelihood method is
used. Basically a likelihood distribution is built from 3
geometric properties of extracted pixel clusters:
- eccentricity
- length / transverse RMS
- fraction of pixels within transverse RMS
To define these distributions however a set of X-ray pure datasets is
needed. In addition the geometric properties above are highly
dependent on the X-ray's energy, see:
#+BEGIN_CENTER
#+ATTR_LATEX: :width 0.49\textwidth :center
[[~/org/Figs/CDL-reference/excentricity_comparison.pdf]]
#+ATTR_LATEX: :width 0.49\textwidth :center
[[~/org/Figs/DPG_Aachen_2019/eccentricity_merged.pdf]]
#+END_CENTER
where the left plot compares the $\ce{Mn}$ line ($^{55}\ce{Fe}$
equivalent) to the $\ce{Cu}$ line from $\SI{0.9}{\kilo\volt}$ electrons
and the right plot compres $^{55}\ce{Fe}$ with typical cosmic
background. Obvious that a single cut value will result in wildly
different signal efficiencies and background rejections.
Thus, take different distributions for different energies.

The distributions which the previous background rate plots were based
on were obtained in 2014 with the Run-1 detector at the CAST Detector
Lab (CDL).
Using a different detector for this extremely sensitive part of the
analysis chain will obviously introduce systematic errors.
Thus, new calibration data was taken with the current Run-2 and Run-3
detector from 15-19 Feb 2019.
A summary of the target filter combinations, applied HV and resulting
pixel peak position is shown in [[cdl-tab]] and the fluorescence lines these
target filter combinations correspond to are listed in tab. [[cdl_lines]].

#+CAPTION: Table of all data runs taken at CDL in Feb 2019
#+NAME: cdl-tab
|-------+-------+--------+--------+---------+-----------------------------------+-------------|
| Run # | FADC? | Target | Filter | HV / kV | $\langle\mu_{\text{peak}}\rangle$ | $\Delta\mu$ |
|-------+-------+--------+--------+---------+-----------------------------------+-------------|
|   315 | y     | Mn     | Cr     |    12.0 |                            223.89 |        8.79 |
|   319 | y     | Cu     | Ni     |    15.0 |                            347.77 |        8.49 |
|   320 | n     | Cu     | Ni     |    15.0 |                            323.23 |       21.81 |
|   323 | n     | Mn     | Cr     |    12.0 |                            224.78 |        8.92 |
|   325 | y     | Ti     | Ti     |     9.0 |                            176.51 |        1.22 |
|   326 | n     | Ti     | Ti     |     9.0 |                            173.20 |        2.20 |
|   328 | y     | Ag     | Ag     |     6.0 |                            117.23 |        2.02 |
|   329 | n     | Ag     | Ag     |     6.0 |                            118.66 |        1.21 |
|   332 | y     | Al     | Al     |     4.0 |                             55.36 |        1.26 |
|   333 | n     | Al     | Al     |     4.0 |                             54.79 |        2.33 |
|   335 | y     | Cu     | EPIC   |     2.0 |                             32.33 |        2.52 |
|   336 | n     | Cu     | EPIC   |     2.0 |                             33.95 |        0.67 |
|   337 | n     | Cu     | EPIC   |     2.0 |                             31.51 |        4.76 |
|   339 | y     | Cu     | EPIC   |     0.9 |                             25.00 |        0.79 |
|   340 | n     | Cu     | EPIC   |     0.9 |                             21.39 |        2.27 |
|   342 | y     | C      | EPIC   |     0.6 |                             18.04 |        1.46 |
|   343 | n     | C      | EPIC   |     0.6 |                             17.16 |        0.57 |
|   345 | y     | Cu     | Ni     |    15.0 |                            271.16 |        6.08 |
|   347 | y     | Mn     | Cr     |    12.0 |                            198.73 |        4.72 |
|   349 | y     | Ti     | Ti     |     9.0 |                            160.86 |        1.25 |
|   351 | y     | Ag     | Ag     |     6.0 |                            106.94 |        2.55 |
|-------+-------+--------+--------+---------+-----------------------------------+-------------|

#+CAPTION: Table of all target filter combinations and the corresponding fluorescence lines
#+NAME: cdl_lines
|--------+--------+-----+-------------------------------+----------------+--------------|
| Target | Filter |  HV | line                          | Name in Marlin | Energy / keV |
|--------+--------+-----+-------------------------------+----------------+--------------|
| Cu     | Ni     |  15 | $\ce{Cu}$ $\text{K}_{\alpha}$ | A              |         8.04 |
| Mn     | Cr     |  12 | $\ce{Mn}$ $\text{K}_{\alpha}$ | B              |         5.89 |
| Ti     | Ti     |   9 | $\ce{Ti}$ $\text{K}_{\alpha}$ | C              |         4.51 |
| Ag     | Ag     |   6 | $\ce{Ag}$ $\text{L}_{\alpha}$ | D              |         2.98 |
| Al     | Al     |   4 | $\ce{Al}$ $\text{K}_{\alpha}$ | E              |         1.49 |
| Cu     | EPIC   |   2 | $\ce{Cu}$ $\text{L}_{\alpha}$ | F              |        0.930 |
| Cu     | EPIC   | 0.9 | $\ce{O }$ $\text{K}_{\alpha}$ | G              |        0.525 |
| C      | EPIC   | 0.6 | $\ce{C }$ $\text{K}_{\alpha}$ | H              |        0.277 |
|--------+--------+-----+-------------------------------+----------------+--------------|

For a reference of the X-ray fluorescence lines (for more exact values
and $\alpha_1$, $\alpha_2$ values etc.) see: https://xdb.lbl.gov/Section1/Table_1-2.pdf.

The raw data is combined by target / filter combinations. To clean the
data somewhat a few simple cuts are applied, as shown in
tab. [[cdl_cleaning_cuts]].

#+CAPTION: Cuts applied to the CDL datasets in order to roughly clean of potential
#+CAPTION: background events and double hits (recognized as single cluster).
#+CAPTION: RMS refers to the transverse RMS of the clusters.
#+NAME: cdl_cleaning_cuts
#+ATTR_LATEX: :align lllrrrrr
|--------+--------+-------------------------------+-----+--------+-----------+-----------+--------------|
| Target | Filter | line                          |  HV | length | rms_T_min | rms_T_max | eccentricity |
|--------+--------+-------------------------------+-----+--------+-----------+-----------+--------------|
| Cu     | Ni     | $\ce{Cu}$ $\text{K}_{\alpha}$ |  15 |        |       0.1 |       1.0 |          1.3 |
| Mn     | Cr     | $\ce{Mn}$ $\text{K}_{\alpha}$ |  12 |        |       0.1 |       1.0 |          1.3 |
| Ti     | Ti     | $\ce{Ti}$ $\text{K}_{\alpha}$ |   9 |        |       0.1 |       1.0 |          1.3 |
| Ag     | Ag     | $\ce{Ag}$ $\text{L}_{\alpha}$ |   6 |    6.0 |       0.1 |       1.0 |          1.4 |
| Al     | Al     | $\ce{Al}$ $\text{K}_{\alpha}$ |   4 |        |       0.1 |       1.1 |          2.0 |
| Cu     | EPIC   | $\ce{Cu}$ $\text{L}_{\alpha}$ |   2 |        |       0.1 |       1.1 |          2.0 |
| Cu     | EPIC   | $\ce{O }$ $\text{K}_{\alpha}$ | 0.9 |        |       0.1 |       1.1 |          2.0 |
| C      | EPIC   | $\ce{C }$ $\text{K}_{\alpha}$ | 0.6 |    6.0 |       0.1 |       1.1 |              |
|--------+--------+-------------------------------+-----+--------+-----------+-----------+--------------|

With these in place both to the pixel as well as charge spectra a
mixture of gaussian / exponential gaussian functions is fitted.

Specifically the gaussian:
#+BEGIN_EXPORT latex
\begin{equation}
G(E; \mu, \sigma, N) = \frac{N}{\sqrt{2 \pi}} \exp\left(-\frac{(E - \mu)^2}{2\sigma^2}\right)
\end{equation}
#+END_EXPORT
and exponential gaussian:
#+BEGIN_EXPORT latex
\begin{equation}
EG(E; \mu, \sigma, N, a, b) =
\begin{cases}
N \exp\left(-\frac{(E-\mu)^2}{2\sigma^2}\right) & \mathrm{for}: E > c\\
   \exp(aE + b) & \mathrm{for}: E < c \\
\end{cases}
\end{equation}
#+END_EXPORT
where the constant $c$ is chosen such that the resulting function is
continuous.

The functions fitted to the different spectra then depend on which
fluorescence lines are visible. The full list of all combinations is shown
in tab. [[fit_funcs_pixel]] and [[fit_func_charge]].

#+CAPTION: All fit functions for the pixel spectra for the different combinations.
#+NAME: fit_funcs_pixel
|--------+--------+-------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Target | Filter | line                          |  HV | Fit function                                                                                                                                                                                                        |
|--------+--------+-------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Cu     | Ni     | $\ce{Cu}$ $\text{K}_{\alpha}$ |  15 | $EG^{\mathrm{Cu,esc}}_{\mathrm{K}_{\alpha}}(a,b,N,\mu,\sigma) + EG^{\mathrm{Cu}}_{\mathrm{K}_{\alpha}}(a,b,N,\mu,\sigma)$ 	                                                                                  |
| Mn     | Cr     | $\ce{Mn}$ $\text{K}_{\alpha}$ |  12 | $EG^{\mathrm{Mn,esc}}_{\mathrm{K}_{\alpha}}(a,b,N,\mu,\sigma) + EG^{\mathrm{Mn}}_{\mathrm{K}_{\alpha}}(a,b,N,\mu,\sigma)$ 	                                                                                  |
| Ti     | Ti     | $\ce{Ti}$ $\text{K}_{\alpha}$ |   9 | $G^{\mathrm{Ti,esc}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Ti}}_{\mathrm{K}_{\beta}}(N,\mu,\sigma) + EG^{Ti}_{K_{\alpha}}(a,b,N,\mu,\sigma) + G^{Ti}_{K_{\beta}}(N,\mu,\sigma)$                          |
| Ag     | Ag     | $\ce{Ag}$ $\text{L}_{\alpha}$ |   6 | $EG^{\mathrm{Ag}}_{\mathrm{L}_{\alpha}}(a,b,N,\mu,\sigma) + G^{\mathrm{Ag}}_{\mathrm{L}_{\beta}}(N,\mu,\sigma)$                                                                                                     |
| Al     | Al     | $\ce{Al}$ $\text{K}_{\alpha}$ |   4 | $EG^{\mathrm{Al}}_{\mathrm{K}_{\alpha}}(a,b,N,\mu,\sigma)$                                                                                                                                                          |
| Cu     | EPIC   | $\ce{Cu}$ $\text{L}_{\alpha}$ |   2 | $G^{\mathrm{Cu}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma)$	                                                                                                                                                       |
| Cu     | EPIC   | $\ce{O }$ $\text{K}_{\alpha}$ | 0.9 | $G^{\mathrm{O}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{C}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Fe,esc}}_{L_{\alpha,\beta}}(N,\mu,\sigma) + G^{\mathrm{Ni}}_{L_{\alpha,\beta}}(N,\mu,\sigma)$ |
| C      | EPIC   | $\ce{C }$ $\text{K}_{\alpha}$ | 0.6 | $G^{\mathrm{C}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{O}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma)$                                                                                                           |
|--------+--------+-------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|

#+CAPTION: All fit functions for the charge spectra for the different combinations.
#+NAME: fit_func_charge
|--------+--------+-------------------------------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Target | Filter | line                          |  HV | fit functions                                                                                                                                                                                                                |
|--------+--------+-------------------------------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Cu     | Ni     | $\ce{Cu}$ $\text{K}_{\alpha}$ |  15 | $G^{\mathrm{Cu,esc}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Cu}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma)$                                                                                                              |
| Mn     | Cr     | $\ce{Mn}$ $\text{K}_{\alpha}$ |  12 | $G^{\mathrm{Mn,esc}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Mn}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma)$                                                                                                              |
| Ti     | Ti     | $\ce{Ti}$ $\text{K}_{\alpha}$ |   9 | $G^{\mathrm{Ti,esc}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Ti}}_{\mathrm{K}_{\beta}}(N,\mu,\sigma) + G^{\mathrm{Ti}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Ti}}_{\mathrm{K}_{\beta}}(N,\mu,\sigma)$    |
| Ag     | Ag     | $\ce{Ag}$ $\text{L}_{\alpha}$ |   6 | $G^{\mathrm{Ag}}_{\mathrm{L}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Ag}}_{\mathrm{L}_{\beta}}(N,\mu,\sigma)$                                                                                                                   |
| Al     | Al     | $\ce{Al}$ $\text{K}_{\alpha}$ |   4 | $G^{\mathrm{Al}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma)$                                                                                                                                                                        |
| Cu     | EPIC   | $\ce{Cu}$ $\text{L}_{\alpha}$ |   2 | $G^{\mathrm{Cu}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma)$                                                                                                                                                                        |
| Cu     | EPIC   | $\ce{O }$ $\text{K}_{\alpha}$ | 0.9 | $G^{\mathrm{O}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{C}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{Fe,esc}}_{L_{\alpha,\beta}}(N,\mu,\sigma) + G^{\mathrm{Ni}}_{\mathrm{L}_{\alpha,\beta}}(N,\mu,\sigma)$ |
| C      | EPIC   | $\ce{C }$ $\text{K}_{\alpha}$ | 0.6 | $G^{\mathrm{C}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma) + G^{\mathrm{O}}_{\mathrm{K}_{\alpha}}(N,\mu,\sigma)$                                                                                                                    |
|--------+--------+-------------------------------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|

The exact implementation in use for both the gaussian and
exponential gaussian:
- Gauss:
  https://github.com/Vindaar/seqmath/blob/master/src/seqmath/smath.nim#L997-L1009
- exponential Gauss:
  https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/calibration.nim#L182-L194

The fitting was performed both with [[https://www.physics.wisc.edu/~craigm/idl/cmpfit.html][MPFit]] (Levenberg Marquardt C
implementation) as a comparison, but mainly using [[https://nlopt.readthedocs.io/en/latest/][NLopt]]. Specifically
the gradient based [[http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.146.5196]["Method of Moving Asymptotes"]] algorithm was used
(NLopt provides a large number of different minimization /
maximization algorithms to choose from) to perform maximum likelihood
estimation written in the form of a poisson distributed log likelihood
$\chi^2$:
#+BEGIN_EXPORT latex
\begin{equation}
\chi^2_{\lambda, P} = 2 \sum_i y_i - n_i + n_i \ln\left(\frac{n_i}{y_i}\right),
\end{equation}
#+END_EXPORT
where $n_i$ is the number of events in bin $i$ and $y_i$ the model
prediction of events in bin $i$.

The required gradient was calculated simply using the [[https://en.wikipedia.org/wiki/Symmetric_derivative][symmetric
derivative]]. Other algorithms and minimization functions were tried,
but this proved to be the most reliable.  See the implementation:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/calibration.nim#L131-L162

The fits to all spectra are shown below.




* Chapter about analysis principle                                 :Software:
#+LATEX: \minitoc
*IDEA*: Maybe this chapter should only be about everything from raw
data to clustering, charge & energy calibration, gas gain, computation
of geometric properties? Well, two of these are already mentioned in
the previous chapter.

*NOTE:* We need to better understand how to:
- explain the theoretical foundations of what we do, e.g. cluster
  finding algorithms. Certain things, e.g. cluster finding algos could
  also just go to the appendix. Interesting, but technically just a detail.
- introduce the software stack we use
- introduce the physics for the calibration (e.g. ToT calib, ...)
- explain the algorithms used in the software

Can we disentangle this from the purely detector focused things? I'm
not so sure.

After introducing detector specific calibrations etc. we can go on to
what the steps are that are required to turn a calibrated detector
(one that is sensitive to N electrons essentially) into something that
can do physics.

Need some chapter that talks about the detector specific details that
explain how a limit / physics result is obtained.

- [ ] turn the ingrid reconstruction schematic into a generalized flow chart?

** Take data. Output data is ASCII files

Parsing of data in format.

Present format.
#+begin_quote
Generic header.

Data.
#+end_quote

Store data in HDF5 files. Not much going on here aside from making it
fast.

** Reconstruct & calibrate data

Read data from HDF5 files. 

What does reconstruction mean?

Multiple things.

*** 1. perform cluster finding

Present our current two clustering algorithms. 

- dumb search in radius around each pixel (add foot note that the
  implementation in MarlinTPC had a bug), based on *rectangular*
  search, not circular
- optional: DBSCAN, short introduction give full reference to
  implementation.

**** Investigation of buggy clustering in MarlinTPC             :noexport:

*** 2. for each cluster, compute geometric properties

Table of the computed properties.

As they are geometric easy to explain.

Highlight the ones used for likelihood. Done here? 

Show our sketch explaining what each property means from one of the
talks. Maybe need to fix the radius variable?



*** 3. (optional / required for analysis) charge calibration

Use Timepix ToT calibration (ref theory section before where we
explain how it works).

Given ToT calibration apply function to get number of electrons (given
that we ran in ToT mode).

*** 4. (optional / required for analysis) compute gas gain

Computing gas gain. Polya fit. Explain not fit parameter used, but
mean of data.

Heavy gas gain variation over time. 

Explain that thus behavior chosen that minimizes effect by binning in
time.

90 minutes.

Show plot with old way (full runs) vs. new length.

Results in stable operation. This section probably belongs somewhere
else? 

**** Study for optimal gas gain time length                     :noexport:



*** 5. (optional / required for analysis) energy computation

Requires: charge calibration, gas gain

Very easy in theory. In practice complicated.

Theoretically, two ways:

1. pixel counting. Due to single electron detection efficiency (or a
   slight correction for under/overcounting) can just multiply hits by
   eV per hit
2. charge calibration plus reference spectrum of 55Fe runs. 

Both cases are very simple *iff* the detector is stable over
time. Then just take closest 55Fe run and compute correction factor
for hits / conversion factor from peak in charge values.

But: instability means we need to average over more data.

Compute for all runs.

Fit.

Apply fit.

*** 6. (optional) FADC reconstruction

Apply pedestals.

Determine lowest point. Determine rising / falling times in ns.

Compute other properties.

** Compute reference spectra 

Possibly explain in chapter about CDL? Or talk there only about the
*data* we took there, but not in detail about *what* this data is *for*?

If so explain here.

** Log file reader to get tracking (maybe no export)

Talk about log file reader (full section definitely :noexport:), used
to mark times in runs that correspond to tracking.

** Likelihood method

Explain likelihood method in theory (maybe do in section before).

Explain our methods for linear interpolation between the reference
spectra.

Apply reference data for limit at specific custom software efficiency.

Started at 80% reference and then tweaked for optimal ε = S/√B (or
something). 

Likelihood method gives us everything we need for background
rate. Whatever comes out gives us left over clusters.

*** Septem veto
:PROPERTIES:
:CUSTOM_ID: sec:septem_veto
:END:

Talk about the septem veto we finally use.

In the septem veto the main idea is to go back to the raw data for any
event, which contains a cluster on the central chip, which is
signal-like based on the likelihood method presented above. For these,
a so called 'septem event' is built based on the raw pixel data of all
chips. This is simply an 'event' in the same notion as understood by
the =reconstruction= tool (c/f [[sec:reconstruction]]), i.e. a two
dimensional array of the ToT values. Except in this case it is not a
$256 \times 256$ array, but rather a $3 \cdot 256 \times 3 \cdot 256$
array, where the full septemboard detector is merged into a single
event without any spacing between the chips (more on that below). 

These septem events are then pushed through the whole reconstruction
and calibration pipeline. Thanks to starting from an event that now
includes information that was previously not taken into account (pixel
activity outside the center chip), the cluster finding algorithm can
detect larger clusters than previously. This can change the shape of
the cluster that was previously considered signal like. In the case
that this cluster now looks more like background, it will be vetoed by
this technique.

The decision to merge the different chips into a single event
*without* any spacing between the chips is made to ensure good cluster
finding. The spacing between chips is of course a dead zone where no
activity can be measured. For a cluster finding algorithm this may
cause a cutoff that should not happen, as the information is simply
not *available*. Ideally, one could imagine an algorithm that
interpolates data between the chips based on the information on the
two neighboring chips. But this is too experimental. 

If there is data on the neighboring chip, it is extremely likely there
was ionization between the chips as well, meaning the merging of the
chips "only" makes the event less eccentric than the physical
event. If there is no data on the neighboring chip, the merging has no
effect, the cluster will simply look the same as in the original
single chip event. 

This excludes two possibilities:
1. a physical event may have no active pixels between the chips, despite
   having active pixels on both chip borders. This is extremely
   unlikely, if the events are significantly close to the border. The
   main case of this would be two real X-rays (extremely low
   probability) or either of the clusters is a track parallel to
   border of the chip. 
2. a more likely loss information for events without information on
   the neighboring chips, despite the physical event being more
   eccentric than the recorded one. This is a real limitation that
   cannot be worked around.

**** Explain why no spacing between chips

**** Hough transformation experiments                           :noexport:

*** Scintillator veto

Talk about scintillator veto. Main ideas of course.

*** FADC veto

Explain the veto we use based on FADC.



*** Comparison with other attempts                               :noexport:

Show the other attempts we did about the different ways to
interpolate.

** Compute limit

Limit computation done. Needs to be after ray tracing introduction I'd
say. Input for theory is required.

Perform signal / background rejection.

Get background rate + signals in tracking.

Get expected flux from theory.

Get detector efficiencies.

Combine efficiencies & theory flux in raytracing simulation.

Compute 'real' expected signal.

Use suitable limit calculation method to compute a limit.

We can split this into two pieces?:

** How to compute background rate

** How to compute a limit

For =mclimit= use the notes in StatusAndProgress about how limit
calculation works. Might be good in general, because a lot of it
applies elsewhere anyway.

Describe unbinned likelihood method from Nature paper adapted to our
work. We can plot some funny plots explaining how it works.


* Software                                                         :Software:
#+LATEX: \minitoc
Introduce used software for analysis.

Previous code used MarlinTPC (already extended a framework for use for
gaseous detectors, focus on strips). Additional extension to use our
new detector features would be beyond the scope of the framework. 

- [ ] *POSSIBLY MAKE THIS A LONG APPENDIX* Then we can just refer to
  that appendix and at the same time then don't have to worry about
  keeping it very focused on things that "should be" in a thesis.

- [ ] *IN APPENDIX ABOUT THIS, EXPLAIN CONFIG FILE OF TPA!*  

** Nim

Shortly introduce Nim & why it was chosen.

Efficient, productive, gets out of my way.

** TimepixAnalysis

Framework written for data analysis.

Rewrites Timepix / InGrid related code from MarlinTPC in Nim and
extends it (e.g. supports Timepix3).

[[https://github.com/Vindaar/TimepixAnalysis]]

After the thesis is published it is possible that this repository will
become the de facto repository for the thesis and the actual analysis
code will become its own repository. We'll see.

*THESE SECTIONS MUST BE MERGED WITH THE ANALYSIS BELOW*. Maybe let
this chapter simply be a high level overview: introduce Nim and the
why. Mention the TimepixAnalysis repo only as a "this is the code for
the analysis, the details of which will be explained in the next
section? In that case one might merge the whole chapter with the next
one and simply have these as the introductory part of the chapter.

*** =raw_data_manipulation=

*LINK TO HDF5 FORMAT IF FIRST TIME MENTIONING*

The first step of the analysis pipeline is essentially just a parsing
stage of the data generated by TOS (see section [[#sec:daq:tos_output_format]]
for an explanation of it) and storing it in a compressed HDF5 data
file.

The program is fed with a directory containing a TOS run, i.e. a
single data taking period ranging typically from minutes to days in
length, or a directory that itself contains multiple TOS run directories.

All data files contained in a run directory will then be parsed in a
multithreaded way. The files are memory mapped and parsed in parallel
into a =Run= data structure, which itself contains =Event= structures.

Depending on the designated run type of a file, some slight
processing steps are performed. *WHAT?*

If FADC files are present in a directory, these will also be parsed
into =FadcEvent= structures in a similar fashion.

Each run is then written into the output HDF5 file as a group. The
meta data about each run and event are stored as attributes and
additional datasets, respectively.

An example structure of a resulting HDF5 file is shown in:
*EXAMPLE LAYOUT WITH EXAMPLE ATTRIBUTES AND DATASETS?*

In addition the tool also supports input from HDF5 files containing
the raw data from a Timepix3 detector. That data is parsed and
reprocessed into the same kind of file structure.

#+CAPTION: Usage of the =raw_data_manipulation= tool. Input is in the form of a run directory / a directory
#+CAPTION: containing multiple run directories. The parsed output is stored in compressed HDF5 files.
#+NAME: list:raw_data_manipulation_help
#+begin_src shell-session
Version: 13809be built on: 2021-05-07 at 00:53:39
  InGrid raw data manipulation.

Usage:
  raw_data_manipulation <folder> [options]
  raw_data_manipulation <folder> --runType <type> [options]
  raw_data_manipulation <folder> --out=<name> [--nofadc] \
    [--runType=<type>] [--ignoreRunList] [options]
  raw_data_manipulation <folder> --nofadc [options]
  raw_data_manipulation --tpx3 <H5File> [options]
  raw_data_manipulation --tpx3 <H5File> --runType <type> [options]
  raw_data_manipulation --tpx3 <H5File> --runType <type> --out=<name> \
    [options]
  raw_data_manipulation -h | --help
  raw_data_manipulation --version

Options:
  --tpx3 <H5File>     Convert data from a Timepix3 H5 file to TPA format
  --runType=<type>    Select run type (Calib | Back | Xray)
                      The following are parsed case insensetive:
                      Calib = {"calib", "calibration", "c"}
                      Back = {"back", "background", "b"}
                      Xray = {"xray", "xrayfinger", "x"}
  --out=<name>        Filename of output file
  --nofadc            Do not read FADC files
  --ignoreRunList     If set ignores the run list 2014/15 to indicate
                      using any rfOldTos run
  --overwrite         If set will overwrite runs already existing in the
                      file. By default runs found in the file will be skipped.
                      HOWEVER: overwriting is assumed, if you only hand a
                      run folder!
  -h --help           Show this help
  --version           Show version.
#+end_src

*** =reconstruction=
:PROPERTIES:
:CUSTOM_ID: sec:reconstruction
:END:

After the raw data has been converted to storage in HDF5, the
=reconstruction= tool is used to start the actual analysis of the
data.

As the name implies, the first stage of data analysis is in the form
of reconstructing the basic properties of each event. In this stage
all events are processed in a multithreaded way. A cluster finding
algorithm is applied to each event on each chip separately, splitting
a single event into possibly multiple clusters. Clusters are defined
based on a certain notion of distance (the details depend on the
clustering algorithm used). The multiple clusters from a single event
are then treated fully equally for the rest of the analysis. The fact
that they originate from the same event has no further relevance (with
a slight exception for one veto technique, which utilizes clustering
over multiple chips, more on that in section [[sec:septem_veto]]).

For the individual clusters geometric properties will be
computed. These are the long and short axis, the eccentricity as well
as the statistical moments up to kurtosis along the long and short
axis. The full list is shown in tab. [[tab:geometric_properties]].

#+CAPTION: Table of all the (mostly) geometric properties of a single cluster computed during the
#+CAPTION: =reconstruction= tool. All but the likelihood, charge and energy properties are computed
#+CAPTION: during the first pass of the tool.
#+NAME: tab:geometric_properties
#+ATTR_LATEX: :booktabs t
|---------------------------+------------------------------------------------------------------|
| Property                  | Meaning                                                          |
|---------------------------+------------------------------------------------------------------|
| igCenterX                 | =x= position of cluster center                                   |
| igCenterY                 | =y= position of cluster center                                   |
| igHits                    | number of pixels in cluster                                      |
| igEventNumber             | event number cluster is from                                     |
| igEccentricity            | eccentricity of the cluster                                      |
| igSkewnessLongitudinal    | skewness along long axis                                         |
| igSkewnessTransverse      | skewness along short axis                                        |
| igKurtosisLongitudinal    | kurtosis along long axis                                         |
| igKurtosisTransverse      | kurtosis along short axis                                        |
| igLength                  | size along long axis                                             |
| igWidth                   | size along short axis                                            |
| igRmsLongitudinal         | RMS along long axis                                              |
| igRmsTransverse           | RMS along short axis                                             |
| igLengthDivRmsTrans       | length divided by transverse RMS                                 |
| igRotationAngle           | rotation angle of long axis over chip coordinate system          |
| igEnergyFromCharge        | energy of cluster computed from its charge                       |
| igLikelihood              | likelihood value for cluster                                     |
| igFractionInTransverseRms | fraction of pixels within radius of transverse RMS around center |
| igTotalCharge             | integrated charge of total cluster in electrons                  |
| igNumClusters             |                                                                  |
| igFractionInHalfRadius    | fraction of pixels in half radius around center                  |
| igRadiusDivRmsTrans       | radius divided by transverse RMS                                 |
| igRadius                  | radius of cluster                                                |
| igLengthDivRadius         | length divided by radius                                         |
|---------------------------+------------------------------------------------------------------|

The properties are computed here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L308-L366
and here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L517-L569

*NOTE:* How should we take care of linking to our code? Of course need
tagged version that corresponds to stuff in the thesis, but beyond
that?


After all geometrical properties have been computed, the next step is
to apply the ToT calibration (sec. [[sec:daq:tot_calibration]]) to the ToT
values of all clusters, resulting in the equivalent charge in
electrons. The charge values for all recorded pixels are then used to
compute a histogram, which roughly follows a Pólya distribution
(sec. [[sec:polya_distribution]]). From the mean value of that
distribution a value for the gas gain is obtained, which is a
necessary input to perform an energy calibration for each cluster.

Second step of analysis, performs most of the major steps.

- cluster finding
- calculation of geometric properties
- charge calibration
- gas gain computation
- energy calibration
- ...



*** =likelihood=

Apply likelihood method for background suppression.

*** =computeLimit=

Computes the limit *NOT THE ONE USED*

*** Other

**** =cdl_spectrum_creation=

Generates the data from the CDL data that is used as X-ray reference
data for the likelihood method.

**** ...

Many other tools are present. Mainly different plotting tools and
tools dealing with other data, e.g. log files of the CAST experiment.



* Raytracing - where does this belong? [0/1]                       :Software:
#+LATEX: \minitoc
Generally, this should become a *section* in the chapter that
introduces the inputs required for the limit calculation. Namely:

*Signal hypotheis - raytracing from Sun to detector*

(It can be a reasonably long section, I think that's fair)


Ray tracing through the detector. Put this before limit calculation stuff?

The whole theoretical side needs to be described in the theory chapter
in [[Axion-electron flux]]. Then here we can just describe how one
implements this (in particular in the noexport section).

Raytracing in a Weekend: \cite{Shirley2020RTW1}

For an in depth guide to raytracing, from theoretical principles to a
pretty sophisticated raytracer, see the amazing 'Physically based
rendering' \cite{pharr2016physically}. 


- [ ] *PLOT OF MIRROR SHELLS*

- [ ] *AXION ELECTRON IMAGE*

- [ ] *PRIMAKOFF IMAGE*

- [ ] *CHAMELEON IMAGE*

- [ ] *NUMBERS FOR FLUX FRACTION ENCOUNTERED WHERE*

- [ ] *INTRODUCE CONCEPT OF RAYTRACING*

- [ ] *CITE PBR*

- [ ] *MAYBE SHOW RAYTRACING IN A WEEKEND PICTURE AS EXAMPLE*


[fn:raytracing_interactive] An interactive raytracer for the
applications of solar axion fluxes, which allows to investigate the
scene (geometry of objects) in 'visible light' as well as serve as an
X-ray raytracer is in development. For time reasons that development
is somewhat on halt unfortunately. https://github.com/Vindaar/rayTracingInOneWeekend/tree/interactiveRayTracer


** Related to explicit axion image [/]

- [ ] *SHOW PLOTS CHARACTERIZING USED SOLAR MODEL*
- [ ] *REFERENCE SOLAR MODEL*

** TODO Can we finish our interactive ray tracer?

Need:
- light sources (4h of work at most)
- cylinders, hyperboloids, paraboloids as objects (once we figure out
  one, the rest should be relatively easy)
- placing different telescope layers etc. (2h)

In theory this *should* be possible as an extensive weekend project!
I'd say this is definitely worth it.


** Computation of atomic processes :noexport:

Computation of atomic processes done in *CODE*. 




* Background rate computation                                      :Analysis:
#+LATEX: \minitoc
Mitigation strategies for detector behavior, e.g. gain variation over time.

** Understanding background rate

3 keV is easy to understand.

8-9 keV is more difficult. 

** Muon calculations                                              :noexport:

Probably not going to make it into final thesis? We'll see, take from
StatusAndProgress. Maybe shortened version will make it.

** FROM IAXO TDR PART: Analysis software & background rate

*NOTE*: This needs to be split up into a part that explains the vetoes
& the parts that show the achieved background rates. Also needs more
explanation on most topics, e.g. how likelihood cut works.


To achieve the desired background rates both special hardware features
as well sophisticated software features are required.

The main hardware features beyond the general ability to achieve
single electron efficiency and thus reconstruct the geometric event
shapes and their energies, are:
- scintillators allowing to tag likely background induced X-rays
- either in case of pure ToT & shutter based readout: an FADC reading
  out the induced signal on the grid to act as a trigger and provide
  longitudinal shape information
  or in case of the GridPix3, which allows ToT and ToA readout at the
  same time, in a stream based manner: ToA information yields
  precise longitudinal shape information and allows to perform offline
  time based clustering
- multiple GridPix around the central 'main' GridPix to clarify event
  shapes of either sparse events or events near the edge of the chip

Each of these requires specific methods to achieve a background
reduction. In the following each aspect will be explained separately
and their possible effect is shown based on a GridPix1 based detector,
which was deployed at CAST in 2017 and 2018.

*TODO*: write summary of following sections

*** Analysis software

Data reconstruction and analysis of GridPix data is performed with the
[[https://github.com/Vindaar/TimepixAnalysis][TimepixAnalysis]] framework, written in the [[https://nim-lang.org][Nim programming language]].

The software is capable of reading GridPix1 data from multiple readout
systems as well as GridPix3 data.

In addition to providing a full analysis readout chain, from raw data
parsing, to clustering and characterisation of individual cluster
properties, it provides a large number of convenience tools and
plotting utilities.

*** Basic background rate
:PROPERTIES:
:CUSTOM_ID: sec:likelihood_method
:END:


As a reference first the background rate achievable using only a
single GridPix1 without any additional features will be discussed.

The detection principle of the GridPix detector implies physically
different kinds of events will have different geometrical shapes.

*TODO:* merge these into a subfig environment or something

#+begin_center
#+CAPTION: Example event of a $^{55}\text{Fe}$ X-ray photon taken with the
#+CAPTION: GridPix1 detector at CAST. The event shape is mostly spherical
#+CAPTION: as there is a single point of origin for the photo-electron.
#+CAPTION: Diffusion as a random process yields the shape.
[[~/org/Figs/statusAndProgress/exampleEvents/calibration_event_run266_chip3_event5791_region_crAll_hits_200.0_250.0_centerX_4.5_9.5_centerY_4.5_9.5_applyAll_true_numIdxs_100.pdf]]
#+end_center

#+begin_center
#+CAPTION: Example background event taken with the GridPix1 event at CAST.
#+CAPTION: A typical track like shape is visible, likely from a muon with
#+CAPTION: some additional interaction. The irregular shape is caused by
#+CAPTION: background events not having a single origin, but rather ionizing
#+CAPTION: the gas at many points on their path through the detector.
#+CAPTION: *TODO MAYBE CHANGE EVENT*
[[~/org/Figs/statusAndProgress/exampleEvents/background_event_run267_chip3_event1456_region_crAll_hits_200.0_250.0_centerX_4.5_9.5_centerY_4.5_9.5_applyAll_true_numIdxs_100.pdf]]
#+end_center

Combined caption (once merged):

Use the individual captions as is, with references to a) and b).  On
the left hand side of each plot, a list of all geometric properties
and their values that are calculated for the visible clusters is
shown. Some of these properties are used for the classification of
events into signal and background like events.

The method to distinguish the two types of events, is based on a
likelihood cut. X-ray data taken at multiple energies (possibly taken
with an X-ray tube) are used to define reference distributions for
(currently) 3 different geometrical variables:
1. the eccentricity $ε$ of the cluster, determined by
   computing the long and short axis of the two dimensional cluster and
   then computing the ratio of the RMS of the projected positions of
   all active pixels within the cluster along each axis.
2. the fraction of all pixels within a circle of the radius of one
   transverse RMS from the cluster center, $f$.
3. the length of the cluster (full extension along the long axis)
   divided by the transverse RMS, $l$. 

These variables are obviously highly correlated, but still provide a
very good separation between the typical shapes of X-rays and
background events. They mainly characterize the "spherical-ness" as
well as the density near the center of the cluster, which is precisely
the intuitive sense in which these type of events differ.

*TODO*: rewrite / remove parts of the ln L part. Don't use ln
The reference distributions are then treated as a probability density,
specifically the likelihood for a cluster to be "X-ray-like". For one
property $i$ we thus define a likelihood $\mathcal{L}_i(x_i)$, where $x_i$ is the
value of the property $i$. This gives us the total likelihood:

\[
\mathcal{L}(ε, f, l) = \mathcal{L}_{ε}(ε) \cdot \mathcal{L}_{f}(f)
\cdot \mathcal{L}_l(l)
\]

where the subscript is denoting the individual likelihood distribution
and the argument corresponds to the individual value of each property.

#+begin_comment
Due to numerical issues dealing with very small probabilities, instead
of using the raw likelihood $\mathcal{L}$, instead the negative log is
used:

\[
-\ln \mathcal{L}(ε, f, l) = - \ln \mathcal{L}_ε(ε) - \ln \mathcal{L}_f(f)- \ln \mathcal{L}_l(l)
\]

For the GridPix1 detector, data with 8 different X-ray energies (via
multiple targets and filters with an X-ray tube) was taken. Each of
these energies first define the X-ray property in a fixed energy
range. Consider fig. [[fig:eccentrility_mn]] for an example comparing the
distribution for the eccentricity of the X-ray data around
$\SI{6}{keV}$ for X-ray vs. background like data.

As only 8 energies is problematic for multiple reasons (e.g. discontinuities of the
properties at the interval boundaries), for each cluster with energy $E_i$ a linear
interpolation of the reference distributions between the nearest two
neighboring distributions is performed.
#+end_comment

To finally classify events as signal or background, one then sets a
desired "software efficiency" $ε_{\text{eff}}$, which is defined as:
\[
ε_{\text{eff}} = \frac{∫_0^{L} \mathcal{L}(ε, f, l) \, \mathrm{d} L'}{∫_0^{∞} \mathcal{L}(ε, f, l) \, \mathrm{d} L'}
\]
where $L'$ denotes a specific $\mathcal{L}$ value, which yields the
desired $ε_{\text{eff}}$.
#+begin_comment
In practical terms one computes the
normalized cumulative sum of the log likelihood and searches for the point at
which the desired $ε_{\text{eff}}$ is reached.
#+end_comment

The software efficiency commonly used and for all figures presented
below is $\SI{80}{\percent}$.

With the software efficiency defined, the $-\ln\mathcal{L}$ of each
cluster is simply computed using the linear interpolation of the log
likelihood distribution determined based on the cluster energy. A
cluster is considered a signal if its $L$ is smaller than the $L$
computed for the desired $ε_{\text{eff}}$ at the energy of the cluster.

Using this approach for the GridPix1 data taken at CAST, a background
rate shown in fig. [[fig:background_rate_eff80_only_center]] is achieved.

#+begin_center
#+CAPTION: Background rate achieved based on the $\ln\mathcal{L}$ method at
#+CAPTION: $ε_{\text{eff}} = \SI{80}{\percent}$ using the GridPix1 CAST 2017/18 data
#+CAPTION: without the application of any vetoes.
#+NAME: fig:background_rate_eff80_only_center
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2017_2018_no_vetoes.pdf]]
#+end_center

*** Scintillators as vetoes

*TODO*: rewrite this paragraph in context of full chapter
The usage of scintillators (ideally 4π around the whole detector
setup) can be very helpful to reduce the background rate further. The
likelihood method presented in the previous section is capable of
separating X-rays from background events. However, given the
required background levels, cosmic induced X-ray fluorescence plays a
significant role in the datasets. A muon that excites a piece of the
detector material, which as a result emits an X-ray cannot be
separated from a desired X-ray originating from an axion.

A scintillator setup can be used to tag events. For a fully
encapsulated detector, any (at least) muon induced X-ray would be
preceded by a signal in one (or multiple) scintillators. As such, if
the time $t_s$ between the scintillator trigger and the time of activity
recorded with the GridPix is small enough, the two are likely to be in
real coincidence.

In addition the scintillator triggers are only taken into account for
clusters, which are signal like. If one applies a strict cut on $t_s$,
for example $400\,\text{clock cycles}$ at \SI{40}{MHz} ($\SI{10}{μs}$,
the value used for the GridPix1 detector at CAST), the rate of random
coincidences should be extremely low (or in other words the added dead
time is minuscule). The cutoff of $\SI{10}{μs}$ for the GridPix1 is
chosen as that is the order of the time scale associated with the maximum drift
time in the gas volume, which is of course much longer than any
fluorescence related time scales.

The resulting improvement of the background rate is shown in
fig. [[fig:background_rate_scinti_veto]], albeit only for the end of 2018
data as the scintillator trigger was not working correctly before.

#+begin_center
#+CAPTION: Background rate achieved based on the addition of a scintillator cut veto
#+CAPTION: of $\SI{10}{μs}$ for any cluster that initially passes the log likelihood
#+CAPTION: cut. Improvements are relatively small, which is mainly due to the relatively
#+CAPTION: small coverage of the veto scintillator used & generally low expected rates of
#+CAPTION: indcued signal like events.
#+NAME: fig:background_rate_scinti_veto
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2018_scinti_veto.pdf]]
#+end_center

*** FADC / ToA as veto

Beyond the usage of a likelihood method for geometrically X-ray like
signals and scintillators to suppress X-ray fluorescence, another
background is expected at helioscope experiments, in particular during
solar tracking periods.

Even for an almost fully 4π coverage of scintillators around the
detector setup, there is exactly one part that is never covered: the
window of the detector towards the magnet bore.

The distribution of muons at surface level follow a roughly
$\cos²(θ)$ distribution ($θ$ the zenith angle). During background
taking times (i.e. magnet is horizontal), few muons are expected to
reach the detector via the magnet bore ($θ \approx
\SI{90}{\degree}$). During solar tracking the expected rate is
expected to increase as the magnet is pointed upwards.

Muons entering in such a way traverse the gas volume orthogonally to
the readout plane. The projection on the readout is thus also roughly
spherical (same as an X-ray). The speed of the muon compared to the
time scale of gas diffusion & clock speed of the readout electronic
means that a muon ionizes the gas along its path effectively
instantly.

*TODO*: likely remove part 1, then rewrite text accordingly
Two distinctions can be made between X-rays and such muons:
1. (hard to detect) Each ionized electron undergoes diffusion along
   its path to the readout plane. Those that are ionized far away from
   the readout yield large diffusion, whereas those close to the
   readout barely any. Assuming a constant ionization per distance,
   this implies the muon track is formed like a cone. The electrons
   arriving at the readout first are almost exactly on the muon path
   and the later ones have more and more diffusion.  In a setup with a
   GridPix3, which allows for ToA readout this effect may be visible
   (yet to be tested). With the CAST GridPix1 setup, which used an
   FADC for the induced grid signal, this is not visible, as there is
   no relation between pixel positions and time information.
2. The effective instant ionization implies that such an cluster has a
   'duration' that is equivalent to the drift velocity times the gas
   volume height. For a typical GridPix setup of height $\SI{3}{cm}$
   with an Argon/Isobutane gas mixture, this implies times of
   $\mathcal{O}(\SI{2}{μs})$. Compared to that the duration of an
   X-ray is roughly the equivalent of the geometrical size in the
   readout plane, which for the same conditions is
   $\mathcal{O}(\SI{3}{mm})$, expressed as a time under the drift
   velocity.
   Thus, if the duration of a cluster is reasonably well known, this
   can easily separate the two types of clusters.

For a Argon/Isobutane mixture at $\SI{1050}{mbar}$ the energy
deposition of most muons will be in the range of
$\SIrange{8}{10}{keV}$, which in any case is outside of the main
region of interest for axion searches.

Note: for a detector with an almost perfect 4π coverage, the
scintillators *behind* the detector would of course trigger for such
muons. Indeed, it is likely that using that information would already
be enough to remove such events. A discrimination based on time
information yields a more certain result than a large scintillator
might, which (even if to a small degree) does introduce random
coincidences.

In an test background run using a GridPix3, which was pointed towards
the zenith, 50 clusters remained after the likelihood cut. Using the
duration of the clusters, another 15 could be removed, showing the
usefulness of the approach.

*TODO: get correct numbers!*

*** Outer GridPix as veto - 'septem veto'

The final hardware feature that is used to improve the background
rate, is the outer ring of GridPix. The size of large clusters is a
significant fraction of a single GridPix. This means that depending on
the cluster center position, parts of the cluster may very well be
outside of the chip. While the most important area of the chip is the
center area (due to the X-ray optics focusing the axion induced
X-rays), misalignment and the extended nature of the 'axion image'
mean that a significant portion of the chip should be as low in
background as possible.

Fig. [[fig:background_clusters_no_septem_veto]] shows the cluster centers
based on the background data taken at CAST in 2017 and 2018 remaining
after the likelihood cut. Evidently, the cluster density is
significantly lower in the center area than towards the edges and in
particular the corners. The closer the cluster center is to the edges,
the higher the chance that parts of it are cut off. In particular,
cutting of from a track like cluster most likely *reduces* the length
and thus makes the cluster *more* spherical.

#+begin_center
#+CAPTION: Each point represents the cluster center of a single cluster that passes
#+CAPTION: the likelihood cut. The color scale in addition represents whether multiple
#+CAPTION: cluster centers were on the same pixel. The data is the full 2017/18 background
#+CAPTION: data. It is very evident that the gold region (marked as a square) has the
#+CAPTION: lowest background. From there towards the edges and in particular the corners
#+CAPTION: the background increases significantly. This is mostly a geometric effect,
#+CAPTION: for which an example can be seen in fig. [[fig:example_clusters_septem_veto]].
#+CAPTION: *TODO ADD THE GOLD REGION OUTLINE*
#+NAME: fig:background_clusters_no_septem_veto
#+end_center

Normally the individual chips are treated as separate in the analysis
chain. The 'septem veto' is the name for an additional veto step,
which can be optionally applied to the center chip. With it, each
cluster that is considered signal like based on the likelihood cut,
will be analysed in a second step. The full event is reconstructed
again from the beginning, but this time as an event covering *all* 7
chips. This allows the cluster finding algorithm to detect clusters
beyond the center chip boundaries. After finding all clusters, the
normal cluster reconstruction to compute all properties is done
again. Finally, for each cluster in the event again the likelihood
value is computed and compared with the likelihood cut. If now all
clusters whose center is on the central chip are considered
background-like, the event is vetoed (because the initial signal-like
cluster turned out to be part of a larger cluster).

An example that shows two clusters on the center chip, one of which
was initially interpreted as a signal like event before being vetoed
by the 'septem veto', is shown in
fig. [[fig:example_clusters_septem_veto]]. The colors indicate the
clusters each pixel belongs to according to the cluster finding
algorithm. As the chips are treated separately initially, there are
two clusters found on the center chip. The purple and cyan cluster
"portions" of the center chip. The purple part passes the likelihood
cut (X-rays at such low energies are much less spherical on average;
same diffusion, but less electrons) initially, which triggers the
'septem veto'. A full 7 GridPix event reconstruction shows the
additional parts of the two clusters. The purple cluster is finally
rejected.

It is a good example, as it shows a cluster that is still relatively
close to the center, and yet still 'connects' to another chip.

#+begin_center
#+CAPTION: An example event showing all 7 GridPix of the CAST GridPix1 detector.
#+CAPTION: The outlines are the boundaries of each chip (without the real spacing between
#+CAPTION: them) and the color of each point indicates the cluster which it is part of
#+CAPTION: according to the cluster finder.
#+CAPTION: Initially the purple cluster (center chip portion) passes the log likelihood cut
#+CAPTION: (i.e. is signal like), but is vetoed by the 'septem veto'
#+CAPTION: as there are more pixels outside the center chip that are part of this cluster.
#+CAPTION: The cyan cluster in the bottom left of the center chip is in addition a good example of
#+CAPTION: how in particular cutting a track in the corners leads to a much more spherical
#+CAPTION: cluster.
#+NAME: fig:example_clusters_septem_veto
[[~/org/Figs/statusAndProgress/exampleEvents/background_septem_vetoed.pdf]]
#+end_center

The background rate with the septem veto is shown in
fig. [[fig:background_rate_septem_veto]], where we see that most of the
improvement is in the lower energy range $< \SI{2}{keV}$. This is the
most important region for the solar axion flux for the axion-electron coupling.

#+begin_center
#+CAPTION: Background rate achieved based on the 'septem veto' (in addition to the
#+CAPTION: scintillator cut) for the full 2017/18 dataset within the center
#+CAPTION: $\SI[parse-numbers=false]{5 \times 5}{mm²}$. Significant improvement in the
#+CAPTION: $< \SI{2}{keV}$ range, which is most important for axion-electron coupling solar
#+CAPTION: flux.
#+NAME: fig:background_rate_septem_veto
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2017_2018_scinti_veto_septem_veto.pdf]]
#+end_center

*** 'Line veto' 

There is one more further optional step, dubbed the 'line veto', which
checks whether there are clusters whose long axis "points at" the
cluster that passed the log likelihood cut. The idea being that there
is a high chance that such clusters are correlated, especially because
ionization is an inherently statistical process. An example of an
event being vetoed by the 'line veto' is shown in
fig. [[fig:example_clusters_line_veto]].

#+begin_center
#+CAPTION: Example event, which highlights the use case of the 'line veto'. The
#+CAPTION: blue cluster in the upper chip is eccentric and its long axis 'points'
#+CAPTION: towards the red center cluster (which initially passes the $\ln\mathcal{L}$ cut).
#+CAPTION: The black circle is a measure for the radius of the center cluster. If the
#+CAPTION: line of the eccentric cluster cuts the circle, the cluster is vetoed.
#+NAME: fig:example_clusters_line_veto
[[~/org/Figs/statusAndProgress/exampleEvents/background_event_vetoed_by_lineveto.pdf]]
#+end_center

Applying this veto to the full center chip improves the amount of
background significantly over the background seen in
fig. [[fig:background_clusters_no_septem_veto]]. The equivalent plot using
the septem veto is seen in fig. [[fig:background_clusters_septem_veto]].

#+begin_center
#+CAPTION: The equivalent figure to fig. [[fig:background_clusters_no_septem_veto]] but including
#+CAPTION: the 'septem veto'. The main improvement happens towards the corners. In total the
#+CAPTION: number of background clusters drops by a factor of 4, from $\sim\num{43000}$ to
#+CAPTION: $\sim\num{9600}$.
#+CAPTION: *TODO THIS INCLUDES THE LINE VETO. COMPARISON SHOULD BE SHOWN LATER!*
#+NAME: fig:background_clusters_septem_veto
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_clusters_2017_2018_septemveto_lineveto.pdf]]
#+end_center

In total this is a reduction of a factor of 4 over the whole chip. But
even in the center most region (a square of the center \SI{25}{mm²})
sees an improvement, especially at low energies. 

*** Final background rate using all vetoes

All the vetoes discussed above yield a very good improvement of the
background rate, shown in fig. [[fig:background_rate_all_vetoes]], which
contains the comparisons of all vetoes discussed above. Each veto
builds on the previous ones.

The background rate between $\SIrange{0}{8}{keV}$ ends up at
$<\SI{1.1e-5}{keV⁻¹ cm⁻² s⁻¹}$. While the vetoes allow for a good
reduction over the initial background rate (in particular over the
whole chip, as seen in fig. [[fig:background_clusters_septem_veto]], the
limitations of the achieved background needs to be discussed in the
context of a GridPix3 based detector with 7 GridPix.

First of all the main features visible in the background rate are of
course the argon fluorescence line at around $\SI{3}{keV}$ and the
copper fluorescence lines at $\sim\SIrange{8}{9}{keV}$. There are two
main ways to excite these lines:
1. via cosmics
2. via radioactive impurities of the detector material
These also split into two groups:
1. the inducing particle induces these *within* the sensitive area of
   the readout (only possible for the excitation of the argon line or
   the copper of the anode)
2. the inducing particle induces these *outside* the sensitive area of
   the readout
   
In the first case the GridPix1 detector runs into a severe limitation
due to its readout. The readout of the Timepix1 is shutter based. The
combination of 7 such GridPix1 leads to a significantly long readout
time, which is why a shutter length of about $\SI{2.4}{s}$ was chosen
for the data taking at CAST. As we only had an FADC to trigger and
thus close the shutter prematurely for the center chip, the long time
scales mean the chance of random coincidences of events on the outer
chips is significant. For example a muon that traverses over the outer
chips, but neither fulfills the septem or line veto, there is no way
to be certain whether the cluster seen on the center chip is
correlated or not. While an aggressive "no activity on outer chips
allowed" veto is possible, it severely increases the dead time due to
the long shutter times. This particular case is perfectly resolved by
the usage of the GridPix3, as that version not only
allows for a data driven readout resolving the problem of long
shutter times, but also allows for *simultaneous* readout of ToT and
ToA. So with a GridPix3 detector such random coincidences are reduced
to 'real' random coincidences, which are of the time scale of the
physical processes we are interested in.

The second case will remain an issue even with a GridPix3 based
detector. *However*, passive mitigation of this is possible by
using a different gas mixture (e.g. xenon based) to avoid the
argon fluorescence line altogether.

*TODO*: once merged, replace/add radiopure talk with reference to
corresponding section
Further, the GridPix3 detector will be built using radiopure
materials. This should significantly reduce the amount of induced
fluorescence to those parts that are cosmic induced. And finally the
cosmic induced events will also be further reduced by usage of a fully
covering scintillator veto system.

All of these combinations should lead to a significant improvement of
the background rate. 

#+begin_center
#+CAPTION: Background rate in the center $\SI[parse-numbers=false]{5 \times 5}{mm²}$ region using
#+CAPTION: the full 2017/18 GridPix1 dataset from CAST. Each successive veto, applied in the order
#+CAPTION: in which they are explained above is shown cumulatively. The 'line veto' contains all
#+CAPTION: discussed vetoes. It yields a background rate in the region between $\SIrange{0}{8}{keV}$ of
#+CAPTION: $<\SI{1.1e-5}{keV⁻¹ cm⁻² s⁻¹}$.
#+NAME: fig:background_rate_all_vetoes
[[~/org/Figs/statusAndProgress/IAXO_TDR/background_rate_2017_2018_scinti_veto_septem_veto_line_veto.pdf]]
#+end_center

*** Neural network based classification

The likelihood cut based method presented in section
[[#sec:likelihood_method]] works well, but does not use the full potential
of the data. It mainly uses length / eccentricity related properties,
which are hand picked and ignores the possible separation power of all
other properties.

Multiple different ways to use all separation power exist. One
promising approach is the usage of artificial neural networks (ANN). A
multi-layer perceptron (MLP; (*reference something?*) ) is a simple ANN model, which consists of an
input and output layer plus N fully connected hidden layers. By
training such a network on the already computed geometric properties
of the clusters, computational requirements remain relatively
moderate.

As a reference an MLP was trained (implementation [[https://github.com/Vindaar/TimepixAnalysis/blob/master/Tools/NN_playground/train_ingrid.nim][here]]) on a mix of
X-ray reference data (as signal-like training data) and a subset of
the CAST background data. The implementation was done using [[https://github.com/scinim/flambeau][Flambeu]], a
wrapper for [[https://pytorch.org/][libtorch]], using the following parameters:

- Input neurons: 12
- Hidden layers: 1
- Neurons on hidden layer: 500
- Output neurons: 2
- Activation function: =ReLU= (Rectified linear unit) (*ref?*)
- Gradient algorithm: Stochastic Gradient Descent (SGD) (*ref?*)
- Learning rate: 0.005
- Momentum: 0.2
- Batch size: 100 

The 12 input neurons were fed with all geometric properties that do
not scale directly with the energy (no number of active pixels or
direct energy) or position on the chip (as the training data is skewed
towards the center).

This is considered a "reference" implementation, as it is essentially
the simplest ANN layout possible. As a comparison to the likelihood
method the receiver operating characteristic (ROC) curves (*REFERENCE
SOMETHING*) for the different
X-ray reference datasets is used. The signal and background data used
for each case (likelihood and MLP) is the test dataset used to test
the MLP performance after training. Fig. [[fig:roc_curves_logl_mlp]] shows
these ROC curves with the line style indicating the method and the
color corresponding to the different targets and thus different
fluorescence lines. The improvement in background rejection at a fixed signal efficiency
exceeds $\SI{10}{\percent}$ at multiple energies.

The usage of such neural networks is plainly a replacement for the
likelihood cut method used to detect the initial cluster candidates
and during classification of the septem/line veto. It does not replace
any of the vetoes, as these include information outside the center
chip, which is not available for the neural network (training and
validation becomes much more complicated if all chips were to be used,
due to the random coincidence problem mentioned in a previous section).

#+begin_center
#+CAPTION: ROC curves for the comparison of the likelihood cut method (solid lines) to the
#+CAPTION: MLP predictions (dashed lines), colored by the different targets used to generate the
#+CAPTION: reference datasets. The background data used for each target corresponds to background
#+CAPTION: clusters in an energy range around the fluorescence line.
#+CAPTION: The MLP visibly outperforms the likelihood cut method in all energies. At the same
#+CAPTION: signal efficiency (x axis) a significantly higher background rejection is achieved.
#+NAME: fig:roc_curves_logl_mlp
[[~/org/Figs/statusAndProgress/neuralNetworks/roc_curve_mlp_vs_likelihood_split_by_target_1000_epochs_no_energy_hits.pdf]]
#+end_center

**** Combination of NN w/ vetoes

[[file:~/CastData/ExternCode/TimepixAnalysis/Tools/NN_playground/predict_event.nim]]

#+begin_src sh
./predict_event ~/CastData/ExternCode/TimepixAnalysis/resources/LikelihoodFiles/lhood_2017_crGold_septemveto_lineveto_dbscan.h5 \
                ~/CastData/ExternCode/TimepixAnalysis/resources/LikelihoodFiles/lhood_2018_crGold_septemveto_lineveto_dbscan.h5 \
  --lhood --cutVal 3.2 --totalTime 3400
#+end_src

Within 0 - 8 keV:
6.413398692810459e-6 keV⁻¹•cm⁻²•s⁻¹
Within 0 - 2.8 & 4.0 - 8.0 keV:
4.133025759323338e-6 keV⁻¹•cm⁻²•s⁻¹

yields

[[~/org/Figs/statusAndProgress/neuralNetworks/background_rate_after_logl_septemveto_lineveto_and_mlp.pdf]]



*** Example using GridPix3 data

Maybe separate, maybe merged into the other sections.



* Limit calculation                                                :Analysis:
#+LATEX: \minitoc

In a physics experiment after performing all measurements there comes
the question of "did I measures something and do I want to compute
some confidence interval on an observable or did I measure nothing and
want to set a limit on the observable?"

These questions can be answered in a variety of different ways. 

In the end it is highly dependent on a Frequentist vs. Bayesian
approach to statistics.

#+begin_comment
If we decide to present different limits, we should have one section
(maybe in theory) where we present our methodology and then compute
the limits based on that method for each of the different cases:
- chameleon
- axion photon
- axion electron

Using background rate & methods to determine it.

*Need* to show the log L phase space according to Igor. Well, that
seems useful anyway.

*TODO* somewhere explain what an expected vs. a real limit is.
#+end_comment

** Generic limit calculation method
:PROPERTIES:
:CUSTOM_ID: sec:stats:limit_method
:END:


We will now present a limit calculation method that is based on the
limit presented in \cite{cast_nature}, but extended to provide a fully
generic limit calculation method that requires no restriction to
specific regions of interest.

The likelihood function used in \cite{cast_nature} is
#+NAME: eq:nature_likelihood_function
\begin{align}
\ln \mathcal{L} = -R_T + \sum_i^n \ln R(E_i, d_i, \vec{x}_i) 
\end{align}
where $R_T$ is the total expected signal and $R$ the sum of signal and
background contributions. The details will be explained further down.

First we will derive the Bayesian method and discuss the individual contributions.

#+begin_comment
Describe log L and χ² distribution and how to compute limit.

Unphysicality, fix by rescaling, χ² min + 4 thing
*UPDATE*: good that we now understand how this actually works,
i.e. integrate the posterior probability (likelihood * prior / normalization)
#+end_comment

The maths of the likelihood expression we use, is mostly straight
forward.

A likelihood function is purely defined as the product of the
individual probabilities for each 'channel' in our measurement. That
way the likelihood gives us the total probability to get this exact
measurement outcome out of all possible outcomes.

If we start from a likelihood ratio \footnote{Likelihood ratio simply
means taking a ratio of two different likelihood functions.} of the
signal + background hypothesis over the pure background hypothesis, in
the binned case we can derive formula [[#eq:nature_likelihood_function]]
from first principles. The number of measured counts in each bin is
simply a Poisson distribution:

#+begin_comment
Clarify what a "bin" refers to and what "channels" are. 
#+end_comment

\[
P_{\text{Pois}}(k; λ) = \frac{λ^k e^{-λ}}{k!}
\]
for each bin an expected number of counts $λ$ (the mean) then means a probability given $P$
for a "measured" number of counts $k$. Combining multiple "channels"
is then simply the product of these individual channels, giving us the
likelihood for one experiment:

\[
\mathcal{L} = \prod_i P_{i, \text{Pois}}(k; λ) = \prod_i \frac{λ_i^{k_i} e^{-λ_i}}{k_i!}
\]

Applying this to the previously mentioned likelihood ratio $Q$ gives
us:

\[
Q = \frac{\prod_i P_{i, \text{Pois}}(n_i; s_i + b_i)}{\prod_i P_{i, \text{Pois}}(n_i; b_i)} =
  \prod_i \frac{ \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)} }{ \frac{b_i^{n_i}}{n_i!} e^{-b_i}}
\]

where $n_i$ is simply the number of measured candidates within the
signal sensitive region in each bin $i$. Typically, each bin might be a
bin in energy, but it can be any kind of "bin" as long as each bin
corresponds to something that follows a Poisson distribution. We will
make use of this fact in a bit.

This can be interpreted as an extended likelihood function, as the
ratio of two Poisson distributions does not satisfy the normalization
condition:

\[
\int_{-∞}^{∞}P\, \mathrm{d}x = 1
\]

anymore. Instead we have:

\[
\int_{-∞}^{∞}Q\, \mathrm{d}x = N
\]

where $N$ can be interpreted as a hypothetical number of total number
of counts measured in the experiment; the starting point of the
definition of the extended maximum likelihood estimation.

From here we derive the logarithm of the expression to get the
numerically more stable $\ln \mathcal{L}$ expression:

#+NAME: eq:likelihood_1_plus_s_over_b_form
\begin{align*}
\ln \mathcal{Q} &= \ln \prod_i \frac{ \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)}  }{ \frac{b_i^{n_i}}{n_i!} e^{-b_i} } \\
  &= \sum_i \ln \frac{ \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)}  }{ \frac{b_i^{n_i}}{n_i!} e^{-b_i} } \\
  &= \sum_i \ln \frac{(s_i + b_i)^{n_i}}{n_i!} e^{-(s_i + b_i)}  - \ln \frac{b_i^{n_i}}{n_i!} e^{-b_i}  \\
  &= \sum_i n_i \ln (s_i + b_i) - \ln n_i! - (s_i + b_i) - (n_i \ln b_i - \ln n_i! -b_i)  \\
  &= \sum_i n_i \ln (s_i + b_i) - (s_i + b_i) - n_i \ln b_i + b_i  \\
  &= \sum_i n_i \ln (s_i + b_i) - (s_i + b_i - b_i) - n_i \ln b_i  \\
  &= \sum_i n_i \ln \left(\frac{s_i + b_i}{b_i}\right) - s_i  \\
  &= -s_{\text{tot}} + \sum_i n_i \ln \left(\frac{s_i + b_i}{b_i} \right) \\
  &\text{or alternatively} \\
  &= -s_{\text{tot}} + \sum_i n_i \ln \left(1 + \frac{s_i}{b_i} \right) \\
\end{align*}

here $s_{\text{tot}}$ represents the total number of "signal" like
counts expected (in our case total number of expected photons due to
axion conversion).

The last two lines show us that all that is really important is that
the normalization of $s_i$ and $b_i$ are the same. The absolute
normalization (e.g. if it's $\si{keV⁻¹}$ or absolute counts etc.) plays no
role as that will be a constant multiplier. That constant can always
be neglected in the total likelihood (a constant only moves the logL
curve up / down, but does not change its maximum!).

Coming back to the "channels" / the binning: if we choose our bins
such that they are bins in time, so small that each bin either
contains 0 or 1 count, we reduce this to our desired unbinned log
likelihood, if we start from the second to last line above and drop
the constant $-\ln b_i$ term:

\[
\ln \mathcal{L} = -R_{\text{tot}} + \sum_{\text{candidates}} \ln(s_i + b_i)
\]
where the sum now runs over each candidate instead of the abstract
"channels".

With an understanding of where the formula comes from, we can more
safely make statements about what the shape of the logL curve is going
to look like. For that it is important to realize that:
- $-R_{\text{tot}}$ depends on $g_{ae²}$, $-R_{\text{tot}}(g_{ae²})$
- $s_i$ depends on $g_{ae²}$, $\vec{x}$ and the cluster energy $E$,
  $s_i(g_{ae²}, \vec{x}, E)$
- $b_i$ only depends on the cluster energy $E$

This means $b_i$ for all intents and purposes is constant under a
change of the coupling constant for a fixed set of candidate
clusters. For a scan over $\ln\mathcal{L}$ this is precisely given.

Now let's consider what each part's contribution will look like as a
$\ln\mathcal{L}$ curve:

1. $-R_{\text{tot}}$: the total number of counts depends on the axion
   flux, the tracking time and the total detection efficiencies. The
   latter two are simply constants when integrating over the region of
   interest in energy, namely \SIrange{0}{10}{\keV}. The axion flux
   scales as:
   \[
   f(g') = f(g) \frac{g^{\prime 2}}{g²}
   \]
   i.e. a squared rescaling of the flux. Given that we scan the logL
   space in $g_{ae²}$, this means the total flux (the integral of $f$
   over all energies) just scales linearly with $g_{ae²}$.
   Due to the minus sign in front, the result is plainly a line with
   negative slope going through the origin at $g_{ae²} = 0$.
2. $b_i$: the background hypothesis is a function only depending on
   the energy of each cluster (and implicitly on the relevant area and
   tracking time). For a fixed set of candidates during a $g_{ae²}$
   scan, its contribution is plainly constant.
3. $s_i$: this is the complicated one. It not only depends on
   $g_{ae²}$, but also the energy $E$ and more importantly the
   position of the cluster center $\vec{x}$. The latter is used for
   the effective flux at each position on the chip that is expected
   from axion conversion after focusing of the X-ray telescope.
   In principle the cluster center positions are constant for a single
   scan of $g_{ae²}$. This means effectively the signal $s_i$ behaves
   exactly like $R_{\text{tot}}$ under $g_{ae²}$. The resulting
   behavior is thus also linear, except with a positive slope.
   The big difference between $s_i$ and $R_{\text{tot}}$ however is
   that $R_{\text{tot}}$ is integrated over all energies, whereas
   $s_i$ is only evaluated at specific energies (in keV⁻¹).

#+begin_comment
Rephrase this whole part & remove the confusion, as it's now fully
understood how to approach it.
#+end_comment

Combining these three facts we expect to find some maximum somewhere,
where the $R_{\text{tot}}$ term and the $s_i$ term cancel each
other. The $b_i$ term only contributes an offset (which however
depends on the candidates, which is why it cannot be ignored!).

This brings us to a particular problem:
What happens if the candidates are all located outside of the axion
sensitive region? In that case their contribution will be zero, due to
the position dependency of $\vec{x}$. This leads to a pure
$R_{\text{tot}}$ negative slope on top of a constant background $b_i$.
In this case the logL curve does *not* have a maximum! And in cases
where arbitrarily little contribution is had, there *will* be a
maximum somewhere, but it will be very far into the unphysical range,
at which point the 1σ width (based on logL_max - 0.5) yield a width
that leads to a physical limit at 0 (due to the gaussian CDF being
essentially 1 many σ away from the center).

Given our statistics of $O(30)$ candidates in our tracking time, this
presents a problem. For toy experiments there is a high chance of
getting precisely that problem. A large number of candidates (70 - 90%
maybe) will be outside the sensitive region, resulting in no good way
to determine the limit.

**** Further expl: Bayes integral *AFTER MAIL FROM IGOR ON <2021-10-03 Sun>*:

Essentially saying that we simply integrate over and demand:

0.95 = ∫_-∞^∞ L(g_ae²) Π(g_ae²) / L_0 d(g_ae²)

where L is the likelihood function (*not* the ln L!), Π is the prior
that is used to exclude the unphysical region of the likelihood phase
space, i.e. it is:

Π(g_ae²) = { 0 if g_ae² < 0, 1 if g_ae² >= 0 }

And L_0 is simply a normalization constant to make sure the integral
is normalized to 1.

Thus, the integral reduces to the physical range:

0.95 = ∫_0^∞ L(g_ae²) / L_0 d(g_ae²)

where the 0.95 is, due to normalization, simply the requirement of a
95% confidence limit.

With this out of the way I implemented this into the limit calculation
code as the =lkBayesScan= limit.

** Extending the method for systematic uncertainties
:PROPERTIES:
:CUSTOM_ID: sec:limit:limit_method
:END:

The limit calculation method is based on the approach presented in
\cite{cast_nature}, with modifications to better suit the GridPix
detector and make the method more generic (under exchange of the
model to be studied).

#+begin_comment
Extend this by the derivation for the marginal likelihood that shows
how one gets to the shown equation from what's shown in the previous section.
#+end_comment

We will now go through the ingredients for the limit method one by
one. The final likelihood including nuisance parameters we evaluate is
(see section [[#sec:stats:limit_method]] for the derivation):

\[
\mathcal{L}_{SBM} = ∫_{-∞}^∞∫_{-∞}^∞∫_{-∞}^∞∫_{-∞}^∞ \exp(-s'_{\text{tot}}) \cdot \prod_i \left(1 +
\frac{s_i''}{b_i'}\right) \cdot
\exp\left[-\frac{θ_b²}{2 σ_b²} - \frac{θ_s²}{2 σ_s²} -
\frac{θ_x²}{2 σ_x²} - \frac{θ_y²}{2 σ_y²} \right]
\, \mathrm{d}\,θ_b \mathrm{d}\,θ_s \mathrm{d}\,θ_x \mathrm{d}\,θ_y.
\]
where primed symbols refer to the base symbol with a modification due
to the value of the corresponding nuisance parameter, i.e.
$x' = x(1 + θ_x)$. The double primed $s_i''$ not only includes $θ_s$,
but also the position dependent nuisance parameters $θ_x$ and $θ_y$
(see again the previous section).

The inputs required to compute a likelihood value are (with the
relevant parameters):
- a set of candidate clusters (either from the real solar tracking or
  randomly sampled ones) with cluster centers at $(x_i, y_i)$ and
  associated energies $E_i$ (over which the product $i$ runs).
- the solar axion flux produced the model to be analyzed, as a
  function of energy (depending on $g_{ae}$ and $g_{aγ}$, but the
  $g_{aγ}$ contribution can be ignored for certain choices of $g_{ae}$
  and $g_{aγ}$.
- the conversion probability of axions in a magnetic field (depending
  on $g_{aγ}$.
- the efficiency of the X-ray optics as a function of energy $E$.
- the transmission probability of X-rays through the detector window
  as a function of $E$ and the entrance position $(x, y)$.
- the absorption probability of X-rays in the used Argon gas as a
  function of energy $E$.
- the average depth $\langle d \rangle$ at which the X-rays produce a photo-electron in
  the Argon gas for the expected flux of converted solar axions (after
  propagation through the X-ray optics and detector window).
- the resulting flux of axion induced X-rays as a function of the
  position $(x, y)$ on the detector, depending on $g_{ae}$.
- the expected background rate at any position $(x, y)$ in the
  detector and any energy $E$.

From here we will go through each of these contributions to explain
how each is obtained and what they look like.

- [ ] Should we here essentially just refer back to the "theory like"
  sections before where each of these ingredients is already
  introduced? At least for things like Argon absorption / detection
  efficiency etc. those will certainly be presented before. That means
  by showing them here again, we essentially show the same thing
  again.
  For things like the background interpolation that I would just
  introduce "somewhere here".

  One option would be: for all where it _makes sense_, have a big
  "inputs plot" (maybe a facet, or a =ggmulti= plot) of all inputs we
  have? (*UPDATE*: <2022-08-13 Sat 15:48> see sanity checks for
  likelihood code)
  Then again, here we mainly present the *technique* still. So for
  example the final candidates wouldn't show up here. But ok, it's
  *only* the candidates that actually changes.

*** Candidates

The candidates are the X-ray like clusters remaining after the background
rejection algorithm has been applied for the data taken during the solar
tracking. For the computation of the expected limit the set of
candidates is drawn from the background rate distribution via sampling
from a Poisson distribution with the mean of the background rate.

A set of toy candidates is shown in
fig. [[fig:limit:toy_candidates]]. Each point represents one toy candidate
at its cluster center position. The color scale represents the energy
of each cluster in \si{keV}.

#+ATTR_LATEX: :width 0.8\textwidth
#+CAPTION: A set of toy candidates drawn from the background rate using a Poisson distribution
#+CAPTION: with mean of the background rate at different positions and energies. Each point is
#+CAPTION: the center of a cluster with the color scale showing the energy of that cluster.
#+CAPTIOn: *TODO:* REPLACE THE PLOT!
#+NAME: fig:limit:toy_candidates
[[~/org/Figs/statusAndProgress/limitCalculation/problematic_candidates_syst_uncert_limit.pdf]]

*** Solar axion flux [0/3]

The solar axion flux for the model to be studied must be known both as
a function of energy $E$ and also as a differential flux as a function
of the solar radius to produce the expected axion image via raytracing
(see sec. [[#sec:raytracing]]).

This means in principle we require knowledge about the production as
shown in the heatmap of fig. [[fig:limit:axion_production_heatmap]]. (Move
this to theory?)

- [ ] generate heatmap of production as function of energy and solar
  radius
- [ ] or show here just the signal?
- [ ] the idea being here that we highlight what one needs to replace
  in order to compute a limit of something else possibly (which then
  allows us later to have a section "axion-photon" or "chameleon"
  where we just present the inputs "see sec. blub, here's the
  production heatmap" kind of deal

*** Conversion probability

The conversion probability of the arriving axions is simply a constant
factor, depending on $g_{aγ}$, see section
[[#sec:theory:axion_conversion]] for the derivation from the general
formula.

The simplified expression for coherent conversion in a constant
magnetic field \footnote{Note that in a perfect analysis one would
compute the conversion in a realistic magnetic field, as the field
strength is not perfectly homogeneous. That would require a very
precise field map of the magnet. In addition the calculations for
axion conversions in inhomogeneous magnetic fields is significantly
more complicated. As far as I understand it requires essentially a
"path integral like" approach of all possible paths through the
magnet, where each path sees different, varying field strengths. Due
to the small size of the LHC dipole prototype magnet and general
stringent requirements for homogeneity this is not done for this
analysis. However, likely for future (Baby)IAXO analyses this will be
necessary.} is

\[
P(g_{aγ}, B, L) = \left(\frac{g_{aγ} \cdot B \cdot L}{2}\right)^2
\]
where the relevant numbers for the CAST magnet are:
- $B = \SI{9}{T}$
- $L = \SI{9.26}{m}$
and in the basic axion-electron analysis a fixed axion-photon coupling
of $g_{aγ} = \SI{1e-12}{\per\giga\electronvolt}$.

Looking closely at the units of this expression, the equation as it is
written uses natural units. This requires either conversion of the
equation into SI units by adding the "missing" constants or converting
the SI units into natural units. As the result is a unit less number,
the latter approach is simpler.

The conversion factors from Tesla and meter to natural units are as follows:
#+begin_src nim :results raw
import unchained
echo "Conversion factor Tesla: ", 1.T.toNaturalUnit()
echo "Conversion factor Meter: ", 1.m.toNaturalUnit()
#+end_src

#+RESULTS:
Conversion factor Tesla: 195.353 ElectronVolt²
Conversion factor Meter: 5.06773e+06 ElectronVolt⁻¹

*TODO*: Move this out of the thesis and just show the numbers in text?
Keep the "derivation / computation" for the "full" version (:noexport:
?).

As such, the resulting conversion probability ends up as:

#+begin_src nim :results raw
import unchained, math
echo "9 T    = ", 9.T.toNaturalUnit()
echo "9.26 m = ", 9.26.m.toNaturalUnit()
echo "P      = ", pow( 1e-12.GeV⁻¹ * 9.T.toNaturalUnit() * 9.26.m.toNaturalUnit() / 2.0, 2.0)
#+end_src

#+RESULTS:
9 T    = 1758.18 ElectronVolt²
9.26 m = 4.69272e+07 ElectronVolt⁻¹
P      = 1.701818225891982e-21

\begin{align}
P(g_{aγ}, B, L) &= \left(\frac{g_{aγ} \cdot B \cdot L}{2}\right)^2 \\
               &= \left(\frac{\SI{1e-12}{\per GeV} \cdot \SI{1758.18}{eV^2} \cdot \SI{4.693e7}{eV}}{2}\right)^2 \\
               &= \num{1.702e-21}
\end{align}

Note that this is of the same (inverse) order of magnitude as the flux
of solar axions ($\sim10^{21}$ in some sensible unit of time), meaning
the experiment expects $\mathcal{O}(1)$ counts, which is sensible.

*** Telescope efficiency

- [ ] Refer back to section that describes the LLNL telescope!

The X-ray telescope further has a direct impact not only on the shape
of the axion signal on the readout, but also the total number of
X-rays transmitted. The effective transmission of an X-ray telescope
is significantly lower than in the optical range. This is typically
quoted using the term "effective area". In section
[[#sec:cast:llnl_telescope]] the effective area of the two X-ray optics
used at CAST in shown.

The term effective area refers to the equivalent area a perfect X-ray
telescope would cover. As such, the real efficiency $ε_{\text{tel}}$ can be computed by
the ratio of the effective area $A_{\text{eff}}$ and the total area of the optic $A_{\text{tel}}$.

\[
ε_{\text{tel}}(E) = \frac{A_{\text{eff}}(E)}{A_{\text{tel}}}
\]

where the effective area $A_{\text{eff}}$ depends on the energy
\footnote{Note that $ε_{\text{tel}}$ here is the average effective
efficiency of the full telescope and *not* the reflectivity of a
single shell. As a Wolter I optic requires two reflections
$ε_{\text{tel}}$ is equivalent to the reflectivity squared
$R²$. Individual reflectivities of shells are further complicated by
the fact that different shells receive parallel light under different
angles, which means the reflectivity varies between shells. Therefore
this is a measure for the average efficiency.}. In case of CAST
the relevant total area is not actually the cross-sectional area of
the optic itself, but rather the exposed area due to the diameter of
the magnet coldbore. With a coldbore diameter of $d_{\text{cb}} = \SI{43}{mm}$ the
effective area can be converted to $ε_{\text{tel}}$.

The resulting effective area is shown in
fig. [[fig:limitCalculation:combined_detection_eff]] in the next section together
with the window transmission and gas absorption.

*** Window transmission and Argon gas absorption

The detector entrance window is the next point affecting the possible
signal to be detected. The windows, as explained in section
[[#sec:detector:sin_window]] are made from $\SI{300}{nm}$ thick silicon
nitride



- [ ] plot of the effective area
- [ ] compute window transmission with =xrayAttenuation=
- [ ] compare with Henke

*** Combined detection efficiency

The previous two sections cover aspects which affect the detection
efficiency of the detector and thus impact the amount of signal
available. Combined they yield a detection efficiency as shown in
fig. [[fig:limitCalculation:combined_detection_eff]]. As can be seen, the
combined detection efficiency maxes out at about 40% around 1.5 keV
(*CHECK NUMBERS*). Note that this does not include the effect of the
window strongback, which is separately taken into account for the
exact position dependent points (for the signal contributions).

*TODO*: Also include the version that is split up into the individual
pieces somewhere!

#+ATTR_LATEX: :width 0.8\textwidth
#+CAPTION: The combined detection efficiency of the detector, taking into account the
#+CAPTION: telescope efficiency via the effective area, the window absorption probability
#+CAPTION: and the absorption probability in the detector gas.
#+CAPTION: 
#+CAPTION: *TODO:* REPLACE THE PLOT! ONLY DET EFF
#+NAME: fig:limitCalculation:combined_detection_eff
[[~/org/Figs/statusAndProgress/limitSanityChecks/sanity_detection_eff.pdf]]

*** Average absorption depth of X-rays

In order to compute a realistic axion image based on raytracing the
plane at which to compute the image needs to be known, as the focal
spot size changes significantly depending on the distance to the focal
point of the X-ray optics.

This is of particular importance for a gaseous detector, as the
raytracing only makes sense up to the generation of a photoelectron,
after which the electrons undergo diffusion. Therefore, one needs to
compute the average absorption depth of X-rays in the relevant energy
ranges for the used gas mixture of the detector.

*INSERT COMPUTATION OR REFERENCE IT BEFORE*

As it is, the average depth is computed to be $\langle d \rangle =
\SI{1.22}{cm}$ behind the detector window.

*** Raytracing axion image

The axion image computed according to the description in
sec. [[#sec:raytracing]] is shown in fig. [[fig:limitCalculation:axion_image]]

#+ATTR_LATEX: :width 0.8\textwidth
#+CAPTION: Axion image as computed using raytracing for the AGSS09 solar model
#+CAPTION: and under the assumption that the axion-electron coupling constant
#+CAPTION: $g_{ae}$ (*GIVE NUMBER*) dominates over the axion-photon coupling $g_{aγ}$.
#+CAPTION: The left image shows the raw axion image whereas the right one includes
#+CAPTION: the window strongback
#+CAPTION: *NOTE: EXTEND TO RIGHT W/ STRONGBACK*
#+NAME: fig:limitCalculation:axion_image
[[~/org/Figs/statusAndProgress/limitSanityChecks/axion_image_limit_calc_no_window_no_theta.pdf]]

*** Background [0/6]

The background must be evaluated at the position and energy of each
cluster candidate. As the background is not constant in energy or
position on the chip, we need a continuous description in those
dimensions of the background rate.

In order to obtain such a thing, we start from all X-ray like clusters
remaining after background rejection, see
fig. [[fig:limit:background_clusters]] where each point is a cluster
center with the color indicating its energy (similar to the candidates
plot further up).

Figures:
1. background clusters
2. (optional) plot showing "selection" of clusters based on
   =queryBallPoint=? I.e. show all clusters in grey, radius & then in
   color those that are in the radius?
3. background "interpolation" based purely on query ball point of raw
   data, at a slice of energy.
4. in a facet with 3 show same after normalization?
5. show effect of area cutoff correction. Also results in a "final"
   background rate interpolated.


Highlight:
So what? This allows us to evaluate the background rate correctly on
the full chip! Generic ALPs can be studied this way, as we don't have
to manually define regions on the chip with specific backgrounds etc.!
One of the fundamental points about making this whole procedure generic.

- [ ] explain using k-d tree to efficiently look up "neighbors" at any
  point (x, y, E). In particular explain how energy works. Not taken
  into account in distance aside from whether inside. So gaussian
  weighting only in x/y.
  
- [ ] use number & distance to these points to compute a weighted
  number of elements in desired "radius"
- [ ] potentially rescale number based on area cut off due to edges of
  the chip. how does this work.
- [ ] renormalize from an effective "number" of clusters to a rate. . how does rescaling work.

- [ ] explain how the integration works etc, copy from sections
  [[sec:correct_inter_cutoff]] and [[sec:limit:gaussian_weight_normalization]]
  in status.

- [ ] *TODO*: check the integration of the gaussian weight again. Is
  that really correct??!! Ahh, it might be correct. What we try to do
  is not to compute anything related to the actual neighbors found in
  the radius, but rather to get the "equivalent area" of the weighted
  data!


**** Sampling of background interpolation

Take interpolation. For sampling purposes we need to sample from
background according to rate. How?
Take a grid in x, y, E of N grid cells. Take background in those
volumes & normalize to # counts in tracking time. Then Poisson sample
from that as mean. Sample an (x, y, E) "position" in that cube.

10x10x20 ? cells used. Plot of the cells, normalized to counts.

*** Systematics

Talk about the systematics. The different systematics used, the table
of systematics.



**** Derivation of the systematics                              :noexport:

Copy over from =[status]=. 

*** Putting it all together

First: show the basic algorithm in pseudo code to compute a likelihood
value for a set of parameters ($g_{ae}²$, and the $θ$ values).

- expected rate,
- nuisance parameter penalty terms
- loop over candidates, for each candidate
  - compute signal
  - compute background
  -> combine

From here either integrate out $θ$ manually, or sample via MCMC. Goes
straight to next section.  

*** MCMC to sample the distribution

*** Expected limit, MC toy sampling



** Axions

*** Axion-electron coupling

**** The candidates

Unblinding the data, the solar tracking candidates left after
application of the likelihood cut method and vetoes, are shown in
fig. [[fig:limit:solar_track_candidates]].

All other inputs for the limit calculation remains the same as
presented in the previous section sec. [[#sec:limit:limit_method]].

- [ ] insert plot of solar tracking candidates!

*** Axion-photon coupling

*** Chameleon coupling

** Compute limit w/ our method (whatever that will finally be)

** Comparison to 2013 limit (using their method)

** Limit calculation using neural networks                         :PENDING:

** TODO Chameleons ?


* Outlook                                                             :Part5:

Timepix3 based detector will be big improvement, as long readout times
without time information are probably the biggest issue (and partially
biggest mistake) in the data taking campaign.

* Summary & conclusion                                                :Part5:



# Use biblatex for the bibliography
# Add bibliography to Table of Contents
# Comment out this command if your references are printed for each chapter.
#+LATEX: \printbibliography[heading=bibintoc]


\appendix
# * Appendix                                                         :Appendix:
# #+LATEX: \minitoc

* ~TimepixAnalysis~ [/]                                            :Appendix:
:PROPERTIES:
:CUSTOM_ID: sec:appendix:software
:END:


Essentially we aim to move the chapter [[Software]] here and extend it to:
- give an overview of all tools we use in this thesis behind the
  scenes (means what they do, what their CLI looks like and how to use
  them in the context of generating the limit starting from raw data)
-

** ~InGridDatabase~
:PROPERTIES:
:CUSTOM_ID: sec:appendix:software:ingrid_database
:END:

- explain database
- explain data structure needed to add to DB
- show how to add    

* Configurations                                                   :Appendix:

*** TOS configuration file [/]

This is the configuration file as it was used at CAST during the data
taking periods.

- [ ] *ALSO LINK AN ONLINE VERSION?*

#+begin_src toml
[General]
sAddress_fadc = 1
baseAddress_hv = 0x4000

[HvModule]
setKillEnable                   = true
# Voltage and Current RampSped currently set to arbitrary value
# in percent / second
moduleVoltageRampSpeed          = 0.1
moduleCurrentRampSpeed          = 50
# checkModuleTimeInterval       = 60, checks the status of the
# module every 60 seconds during a Run, between two events
checkModuleTimeInterval         = 60

# if this flag is set to true, anode and grid
# will be coupled to one group
[HvGroups]
anodeGridGroupFlag              = true
# grid is master channel of set on group
anodeGridGroupMasterChannel     = 5
anodeGridGroupNumber            = 0
monitorTripGroupFlag            = true
monitorTripGroupNumber          = 1
rampingGroupFlag                = true
rampingGroupNumber              = 2                          
gridChannelNumber               = 5
anodeChannelNumber              = 6
cathodeChannelNumber            = 9

[HvChannels]
# grid, anode and cathode settings
# all currents given in A (vmecontrol shows mA)
0_Name                          = grid
0_Number                        = 5
0_VoltageSet                    = 300
0_VoltageNominal                = 500
0_VoltageBound                  = 10
0_CurrentSet                    = 0.000050
0_CurrentNominal                = 0.000500 
0_CurrentBound                  = 0
                                
1_Name                          = anode
1_Number                        = 6
1_VoltageSet                    = 375
1_VoltageNominal                = 500
1_VoltageBound                  = 10
1_CurrentSet                    = 0.000050
1_CurrentNominal                = 0.000500
1_CurrentBound                  = 0
                                
2_Name                          = cathode
2_Number                        = 9
2_VoltageSet                    = 1875
2_VoltageNominal                = 2500
2_VoltageBound                  = 15
2_CurrentSet                    = 0.000050
2_CurrentNominal                = 0.000500
2_CurrentBound                  = 0
                                
3_Name                          = Ring1
3_Number                        = 7
3_VoltageSet                    = 415
3_VoltageNominal                = 500
3_VoltageBound                  = 15
3_CurrentSet                    = 0.000100
3_CurrentNominal                = 0.000500
3_CurrentBound                  = 0
                                
4_Name                          = Ring29
4_Number                        = 8
4_VoltageSet                    = 1830
4_VoltageNominal                = 2500
4_VoltageBound                  = 15
4_CurrentSet                    = 0.000100
4_CurrentNominal                = 0.000500
4_CurrentBound                  = 0
                                
6_Name                          = sipm
6_Number                        = 4
6_VoltageSet                    = 65.6
6_VoltageNominal                = 100
6_VoltageBound                  = 5
6_CurrentSet                    = 0.0005
6_CurrentNominal                = 0.0005
6_CurrentBound                  = 0
                                
# The veto paddle scintillator is commented out, as it was supplied
# with HV by an external CAEN HV power supply.
# 5_Name                        = szintillator
# 5_Number                      = 11
# #5_VoltageSet                 = 1300
# 5_VoltageSet                  = 0
# 5_VoltageNominal              = 2500
# 5_VoltageBound                = 5
# 5_CurrentSet                  = 0.002
# 5_CurrentNominal              = 0.002
# 5_CurrentBound                = 0

[Fadc] # FADC Settings
fadcTriggerType                 = 3 
fadcFrequency                   = 2
fadcPosttrig                    = 80
fadcPretrig                     = 15000
# was 2033 before, 1966 corresponds to -40 mV
fadcTriggerThresholdRegisterAll = 1966 
# run time of a single pedestal run for the FADC in ms
fadcPedestalRunTime             = 100
# number of acquisition runs done for each pedestal calibration
fadcPedestalNumRuns             = 10
# using channel 0 on FADC as trigger source, thus bit 0  1!
fadcChannelSource               = 1
# set FADC mode register (mainly to enable 14-bit readout)
fadcModeRegister                = 0b000

[Temperature] # temperature related parameters
safeUpperTempIMB                = 61
safeUpperTempSeptem             = 61
safeLowerTempIMB                = 0
safeLowerTempSeptem             = 0
#+end_src



* Calibrations                                                     :Appendix:

** Septemboard calibration
:PROPERTIES:
:CUSTOM_ID: sec:appendix:septemboard_calibrations
:END:

Show all calibrations for each of the runs.

That means, for all chips:
- THS optimization & equalization bits
- equalized matrix of all pixels  
- ToT calibration
- S-curves
- fit to 50% point of S-curves to get #electrons / THL DAC value    

** Calibration measurements of the veto scintillator paddle
:PROPERTIES:
:CUSTOM_ID: sec:appendix:scintillator_calibration_notes
:END:

The following is a set of notes taken when calibrating the
scintillator paddle in the laboratory of the RD51 group at CERN. It is
reproduced here for transparency and completeness.

*** Scintillator paddle calibrations [0/2]

This document contains the data for the calibration of the MM veto
scintillator. It is a 'report' created while data taking and thus may
contain conflicting information. Not to be understood as a simple
reference protocol.

The scintillator has a Canberra 2007 base, which accepts positive
HV. The PMT is a Bicron Corp. 31.49x15.74M2BC408/2-X, where the first
two numbers are the scintillators dimensions in inch.

=For calibration we're using $\SI{1400}{\volt}$, while Juanan
mentioned in his mail to use $\SI{1200}{\volt}$ during data taking.=

For calibration we're using an Ortec 9302 amplifier after the PMT with
a gain of 20. This is fed into an LRS 621CL discriminator. The PMT and
base are used at a HV of $+\SI{1200}{\volt}$.

Scintillator is of size $\SI{42}{\cm}$ times $\SI{82}{\cm}$. Which is
an area of
#+BEGIN_SRC nim
let x = 0.42
let y = 0.82
echo x * y 
#+END_SRC

#+RESULTS:
: 0.3444

- [ ] *TODO: CROSS CHECK THESE NUMBERS HERE*

At a cosmic muon rate of $\sim\SI{100}{\hertz \per \meter \squared
\steradian}$, the expected signal rate of munons is thus $\sim
\SI{33}{\hertz}$.

#+BEGIN_SRC nim
let area = 0.34
let total_muons = 60000.0
echo area * total_muons
#+END_SRC

#+RESULTS:
: 20400.0

- [ ] *UPDATE*: Muon rate about $\SI{1}{cm^{-2}.min^{-1}} \approx \SI{166.67}{m^{-2}.s^{-1}}$

**** Calibration
:PROPERTIES:
:ORDERED:  t
:END:

Threshold values are scaled by a factor of 10. Coincidence using
Theodoros 2 scintillator paddles in RD51 lab. 
- upper scinti: $\SI{-2070}{\volt}$
- lower scinti: $\SI{-2050}{\volt}$

Measurement time for each value: $\SI{10}{\minute}$

Note: The reason the coincidences are much lower than the single
scintillator counts is of course due to the much smaller coincidence
area of the small scintillators used for the measurement.

| Threshold / mV | Counts Szinti | Counts Coincidence |
|----------------+---------------+--------------------|
|         -301.9 |         24062 |                760 |
|           -399 |         13332 |                496 |
|           -498 |          6584 |                300 |
|           -603 |          3363 |                167 |
|           -699 |          1900 |                104 |
|           -802 |          1087 |                 83 |
|           -901 |           651 |                 54 |
|          -1005 |           523 |                 50 |
|          -1104 |           361 |                 32 |
|          -1203 |           231 |                 32 |
|          -1305 |           189 |                 38 |
|          -1400 |           151 |                 23 |
|          -1502 |            96 |                 14 |
|          -1602 |            78 |                 15 |
|          -1703 |            72 |                 10 |
|          -1802 |            58 |                 11 |
|                |               |                    |

Second set of measurements around interesting point of
$\SI{1000}{\milli\volt}$

| Threshold / mV | Counts Szinti | Counts Coincidence |
|----------------+---------------+--------------------|
|          -1200 |           259 |                 35 |
|          -1100 |           350 |                 34 |
|          -1000 |           456 |                 48 |
|           -900 |           774 |                 42 |

A third measurement using an amplifier after the PMT, since the output
signal of the PMT is so small (see mail of JuanAn). Now the HV was
lowered to $\SI{1200}{\volt}$ again, since it is not necessary.

#+NAME: tab-test
| Threshold / mV | Counts Szinti | Counts Coincidence |
|----------------+---------------+--------------------|
|           -598 |         31221 |                634 |
|           -700 |         30132 |                674 |
|           -804 |         28893 |                635 |
|           -903 |         28076 |                644 |
|          -1005 |         27012 |                684 |
|          -1103 |         25259 |                566 |
|          -1200 |         22483 |                495 |
|          -1303 |         19314 |                437 |
|          -1403 |         16392 |                356 |
|          -1505 |         13677 |                312 |
|          -1600 |         11866 |                267 |
|          -1701 |         10008 |                243 |
|                |               |                    |

|           -900 |         28263 |                892 |
|          -1000 |         26789 |                991 |


#+begin_src nim :var tbl=tab-test 
import ggplotnim, sequtils
proc parse(s: openArray[string]): seq[float] = s.filterIt(it.len > 0).mapIt(it.parseFloat)
let df = toDf({ "Thr" : tbl["Threshold / mV"].parse,
                "Szinti" : tbl["Counts Szinti"].parse,
                "Coinc" : tbl["Counts Coincidence"].parse })
ggplot(df, aes("Thr", "Szinti")) +
  geom_point() + geom_line() +
  ggsave("/t/test.pdf")
#+end_src

Export this table using org-table-export to
[[file:data/veto_szinti_counts.txt]]. Then remove unnecessary last line
and add # to beginning of first line.

- [ ] *REWRITE TO USE AN INLINE GGPLOTNIM PLOTTING AND SHOW DATA*

Then use [[file:PyS_mm_veto_szinti_calib.py]] to plot the data.

A threshold of $\SI{-110}{\milli\volt}$ was selected, after analysis.


* CAST data taking run list
:PROPERTIES:
:CUSTOM_ID: sec:appendix:cast_run_list
:END:


\scriptsize
#+CAPTION: List of all runs recorded with the Septemboard detector during Run-2 and Run-3 at CAST.
#+CAPTION: The run type is listed as ~b~: background with possible tracking and ~c~: calibration with
#+CAPTION: the $\ce{^{55}Fe}$ source.
#+NAME: tab:appendix:cast_run_list
#+ATTR_LATEX: :environment longtable :width \textwidth :spread
| Run # | Type | Start                  | End                    | Length        | # trackings | # frames | # FADC |
|-------+------+------------------------+------------------------+---------------+-------------+----------+--------|
| Run-2 |      |                        |                        |               |             |          |        |
|-------+------+------------------------+------------------------+---------------+-------------+----------+--------|
|    76 | b    | <2017-10-30 Mon 18:39> | <2017-11-02 Thu 5:24>  | 2 days 10:44  |           1 |    88249 |  19856 |
|    77 | b    | <2017-11-02 Thu 5:24>  | <2017-11-03 Fri 5:28>  | 1 days 00:03  |           1 |    36074 |   8016 |
|    78 | b    | <2017-11-03 Fri 5:28>  | <2017-11-03 Fri 20:45> | 0 days 15:17  |           1 |    23506 |   5988 |
|    79 | b    | <2017-11-03 Fri 20:46> | <2017-11-05 Sun 0:09>  | 1 days 03:22  |           1 |    40634 |   8102 |
|    80 | b    | <2017-11-05 Sun 0:09>  | <2017-11-05 Sun 23:50> | 0 days 23:40  |           1 |    35147 |   6880 |
|    81 | b    | <2017-11-05 Sun 23:54> | <2017-11-07 Tue 0:00>  | 1 days 00:06  |           1 |    35856 |   7283 |
|    82 | b    | <2017-11-07 Tue 0:01>  | <2017-11-08 Wed 15:58> | 1 days 15:56  |           2 |    59502 |  12272 |
|    83 | c    | <2017-11-08 Wed 16:27> | <2017-11-08 Wed 17:27> | 0 days 00:59  |           0 |     4915 |   4897 |
|    84 | b    | <2017-11-08 Wed 17:49> | <2017-11-09 Thu 19:01> | 1 days 01:11  |           1 |    37391 |   7551 |
|    85 | b    | <2017-11-09 Thu 19:01> | <2017-11-09 Thu 21:46> | 0 days 02:45  |           0 |     4104 |    899 |
|    86 | b    | <2017-11-09 Thu 21:47> | <2017-11-11 Sat 2:17>  | 1 days 04:29  |           1 |    42396 |   9656 |
|    87 | b    | <2017-11-11 Sat 2:17>  | <2017-11-12 Sun 14:29> | 1 days 12:11  |           2 |    54786 |  15123 |
|    88 | c    | <2017-11-12 Sun 14:30> | <2017-11-12 Sun 15:30> | 0 days 00:59  |           0 |     4943 |   4934 |
|    89 | b    | <2017-11-12 Sun 15:30> | <2017-11-13 Mon 18:27> | 1 days 02:57  |           1 |    25209 |   6210 |
|    90 | b    | <2017-11-13 Mon 19:14> | <2017-11-14 Tue 20:24> | 1 days 01:09  |           1 |    37497 |   8122 |
|    91 | b    | <2017-11-14 Tue 20:24> | <2017-11-15 Wed 21:44> | 1 days 01:20  |           1 |    37732 |   8108 |
|    92 | b    | <2017-11-15 Wed 21:45> | <2017-11-17 Fri 19:18> | 1 days 21:32  |           1 |    67946 |  14730 |
|    93 | c    | <2017-11-17 Fri 19:18> | <2017-11-17 Fri 20:18> | 0 days 01:00  |           0 |     4977 |   4968 |
|    94 | b    | <2017-11-17 Fri 20:48> | <2017-11-19 Sun 2:34>  | 1 days 05:46  |           1 |    44344 |   9422 |
|    95 | b    | <2017-11-19 Sun 2:35>  | <2017-11-23 Thu 10:41> | 4 days 08:06  |           1 |   154959 |  33112 |
|    96 | c    | <2017-11-23 Thu 10:42> | <2017-11-23 Thu 17:43> | 0 days 07:01  |           0 |    34586 |  34496 |
|    97 | b    | <2017-11-23 Thu 17:43> | <2017-11-26 Sun 1:41>  | 2 days 07:57  |           1 |    83404 |  18277 |
|    98 | b    | <2017-11-26 Sun 1:42>  | <2017-11-26 Sun 21:18> | 0 days 19:36  |           1 |    29202 |   6285 |
|    99 | b    | <2017-11-26 Sun 21:18> | <2017-11-28 Tue 6:46>  | 1 days 09:27  |           1 |    49921 |  10895 |
|   100 | b    | <2017-11-28 Tue 6:46>  | <2017-11-29 Wed 6:40>  | 0 days 23:53  |           1 |    35658 |   7841 |
|   101 | b    | <2017-11-29 Wed 6:40>  | <2017-11-29 Wed 20:18> | 0 days 13:37  |           1 |    20326 |   4203 |
|   102 | c    | <2017-11-29 Wed 20:19> | <2017-11-29 Wed 22:19> | 0 days 02:00  |           0 |     9919 |   9898 |
|   103 | b    | <2017-11-29 Wed 22:26> | <2017-12-01 Fri 6:46>  | 1 days 08:19  |           1 |    47381 |   7867 |
|   104 | b    | <2017-12-01 Fri 6:47>  | <2017-12-02 Sat 6:48>  | 1 days 00:00  |           1 |    35220 |   5866 |
|   105 | b    | <2017-12-02 Sat 6:48>  | <2017-12-03 Sun 6:39>  | 0 days 23:51  |           1 |    34918 |   5794 |
|   106 | b    | <2017-12-03 Sun 6:40>  | <2017-12-04 Mon 6:54>  | 1 days 00:14  |           1 |    35576 |   6018 |
|   107 | b    | <2017-12-04 Mon 6:54>  | <2017-12-04 Mon 13:38> | 0 days 06:44  |           1 |     9883 |   1641 |
|   108 | c    | <2017-12-04 Mon 13:39> | <2017-12-04 Mon 17:39> | 0 days 04:00  |           0 |    19503 |  19448 |
|   109 | b    | <2017-12-04 Mon 17:47> | <2017-12-05 Tue 11:20> | 0 days 17:32  |           1 |    28402 |   8217 |
|   110 | c    | <2017-12-05 Tue 11:20> | <2017-12-05 Tue 13:20> | 0 days 01:59  |           0 |     9804 |   9786 |
|   111 | b    | <2017-12-05 Tue 13:23> | <2017-12-05 Tue 16:17> | 0 days 02:53  |           0 |     4244 |    644 |
|   112 | b    | <2017-12-06 Wed 14:50> | <2017-12-10 Sun 6:46>  | 3 days 15:55  |           2 |   128931 |  19607 |
|   113 | b    | <2017-12-10 Sun 6:46>  | <2017-12-11 Mon 6:49>  | 1 days 00:03  |           1 |    35100 |   5174 |
|   114 | b    | <2017-12-11 Mon 6:50>  | <2017-12-11 Mon 18:33> | 0 days 11:43  |           1 |    17111 |   2542 |
|   115 | b    | <2017-12-11 Mon 18:36> | <2017-12-12 Tue 20:58> | 1 days 02:21  |           1 |    40574 |   9409 |
|   116 | c    | <2017-12-12 Tue 20:59> | <2017-12-12 Tue 22:59> | 0 days 02:00  |           0 |     9741 |   9724 |
|   117 | b    | <2017-12-12 Tue 23:56> | <2017-12-13 Wed 21:29> | 0 days 21:33  |           1 |    31885 |   5599 |
|   118 | c    | <2017-12-13 Wed 21:30> | <2017-12-13 Wed 23:30> | 0 days 02:00  |           0 |     9771 |   9748 |
|   119 | b    | <2017-12-14 Thu 0:07>  | <2017-12-14 Thu 17:04> | 0 days 16:57  |           1 |    25434 |   4903 |
|   120 | c    | <2017-12-14 Thu 17:04> | <2017-12-14 Thu 21:04> | 0 days 04:00  |           0 |    19308 |  19261 |
|   121 | b    | <2017-12-14 Thu 21:07> | <2017-12-15 Fri 19:22> | 0 days 22:14  |           1 |    33901 |   6947 |
|   122 | c    | <2017-12-15 Fri 19:22> | <2017-12-16 Sat 1:20>  | 0 days 05:57  |           0 |    29279 |  29208 |
|   123 | b    | <2017-12-16 Sat 1:21>  | <2017-12-17 Sun 1:06>  | 0 days 23:45  |           1 |    34107 |   3380 |
|   124 | b    | <2017-12-17 Sun 1:06>  | <2017-12-19 Tue 2:57>  | 2 days 01:50  |           2 |    71703 |   7504 |
|   125 | b    | <2017-12-19 Tue 2:57>  | <2017-12-19 Tue 16:20> | 0 days 13:22  |           1 |    19262 |   1991 |
|   126 | c    | <2017-12-19 Tue 16:21> | <2017-12-19 Tue 19:21> | 0 days 02:59  |           0 |    14729 |  14689 |
|   127 | b    | <2017-12-19 Tue 19:27> | <2017-12-22 Fri 0:17>  | 2 days 04:50  |           1 |    75907 |   7663 |
|   128 | c    | <2017-12-22 Fri 0:18>  | <2017-12-22 Fri 9:23>  | 0 days 09:05  |           0 |    44806 |  44709 |
|   145 | c    | <2018-02-17 Sat 17:18> | <2018-02-17 Sat 20:40> | 0 days 03:22  |           0 |    16797 |  16796 |
|   146 | b    | <2018-02-17 Sat 20:41> | <2018-02-18 Sun 18:12> | 0 days 21:30  |           1 |    32705 |   3054 |
|   147 | c    | <2018-02-18 Sun 18:12> | <2018-02-18 Sun 20:12> | 0 days 01:59  |           0 |    10102 |  10102 |
|   148 | b    | <2018-02-18 Sun 20:46> | <2018-02-19 Mon 17:24> | 0 days 20:37  |           1 |    31433 |   3120 |
|   149 | c    | <2018-02-19 Mon 17:25> | <2018-02-19 Mon 19:25> | 0 days 02:00  |           0 |     9975 |   9975 |
|   150 | b    | <2018-02-19 Mon 19:53> | <2018-02-20 Tue 17:36> | 0 days 21:42  |           1 |    33192 |   3546 |
|   151 | c    | <2018-02-20 Tue 17:36> | <2018-02-20 Tue 19:36> | 0 days 01:59  |           0 |     9907 |   9907 |
|   152 | b    | <2018-02-20 Tue 21:54> | <2018-02-21 Wed 18:05> | 0 days 20:10  |           1 |    30809 |   3319 |
|   153 | c    | <2018-02-21 Wed 18:05> | <2018-02-21 Wed 20:05> | 0 days 01:59  |           0 |    10103 |  10102 |
|   154 | b    | <2018-02-21 Wed 21:10> | <2018-02-22 Thu 17:23> | 0 days 20:12  |           1 |    30891 |   3426 |
|   155 | c    | <2018-02-22 Thu 17:23> | <2018-02-22 Thu 19:23> | 0 days 02:00  |           0 |     9861 |   9861 |
|   156 | b    | <2018-02-23 Fri 6:06>  | <2018-02-23 Fri 17:41> | 0 days 11:35  |           1 |    17686 |   1866 |
|   157 | c    | <2018-02-23 Fri 17:41> | <2018-02-23 Fri 19:41> | 0 days 01:59  |           0 |     9962 |   9962 |
|   158 | b    | <2018-02-23 Fri 19:42> | <2018-02-26 Mon 8:46>  | 2 days 13:03  |           1 |    93205 |   9893 |
|   159 | c    | <2018-02-26 Mon 8:46>  | <2018-02-26 Mon 12:46> | 0 days 04:00  |           0 |    19879 |  19878 |
|   160 | b    | <2018-02-26 Mon 14:56> | <2018-03-01 Thu 10:24> | 2 days 19:28  |           1 |   103145 |  11415 |
|   161 | c    | <2018-03-01 Thu 10:26> | <2018-03-01 Thu 14:26> | 0 days 04:00  |           0 |    19944 |  19943 |
|   162 | b    | <2018-03-01 Thu 17:07> | <2018-03-04 Sun 20:16> | 3 days 03:08  |           3 |   114590 |  11897 |
|   163 | c    | <2018-03-04 Sun 20:17> | <2018-03-04 Sun 22:17> | 0 days 02:00  |           0 |    10093 |  10093 |
|   164 | b    | <2018-03-04 Sun 22:57> | <2018-03-06 Tue 19:15> | 1 days 20:18  |           2 |    67456 |   6488 |
|   165 | c    | <2018-03-06 Tue 19:15> | <2018-03-06 Tue 23:15> | 0 days 04:00  |           0 |    19882 |  19879 |
|   166 | b    | <2018-03-07 Wed 0:50>  | <2018-03-07 Wed 18:28> | 0 days 17:38  |           1 |    26859 |   2565 |
|   167 | c    | <2018-03-07 Wed 18:29> | <2018-03-07 Wed 20:29> | 0 days 02:00  |           0 |     9938 |   9938 |
|   168 | b    | <2018-03-07 Wed 20:37> | <2018-03-13 Tue 16:54> | 5 days 20:16  |           0 |   213545 |  20669 |
|   169 | c    | <2018-03-13 Tue 16:55> | <2018-03-13 Tue 22:55> | 0 days 06:00  |           0 |    29874 |  29874 |
|   170 | b    | <2018-03-13 Tue 23:19> | <2018-03-14 Wed 21:01> | 0 days 21:42  |           1 |    33098 |   3269 |
|   171 | c    | <2018-03-14 Wed 21:01> | <2018-03-14 Wed 23:01> | 0 days 02:00  |           0 |     9999 |   9999 |
|   172 | b    | <2018-03-14 Wed 23:06> | <2018-03-15 Thu 17:57> | 0 days 18:50  |           1 |    28649 |   2773 |
|   173 | c    | <2018-03-15 Thu 17:59> | <2018-03-15 Thu 19:59> | 0 days 01:59  |           0 |     9898 |   9897 |
|   174 | b    | <2018-03-15 Thu 20:39> | <2018-03-16 Fri 16:27> | 0 days 19:48  |           1 |    30163 |   2961 |
|   175 | c    | <2018-03-16 Fri 16:28> | <2018-03-16 Fri 18:28> | 0 days 01:59  |           0 |    10075 |  10075 |
|   176 | b    | <2018-03-16 Fri 18:35> | <2018-03-17 Sat 20:55> | 1 days 02:19  |           1 |    40084 |   3815 |
|   177 | c    | <2018-03-17 Sat 20:55> | <2018-03-17 Sat 22:55> | 0 days 01:59  |           0 |     9967 |   9966 |
|   178 | b    | <2018-03-17 Sat 23:31> | <2018-03-22 Thu 17:40> | 4 days 18:09  |           5 |   174074 |  17949 |
|   179 | c    | <2018-03-22 Thu 17:41> | <2018-03-22 Thu 19:41> | 0 days 01:59  |           0 |     9887 |   9887 |
|   180 | b    | <2018-03-22 Thu 20:47> | <2018-03-24 Sat 18:10> | 1 days 21:22  |           1 |    69224 |   7423 |
|   181 | c    | <2018-03-24 Sat 18:10> | <2018-03-24 Sat 22:10> | 0 days 04:00  |           0 |    20037 |  20036 |
|   182 | b    | <2018-03-24 Sat 23:32> | <2018-03-26 Mon 19:46> | 1 days 19:14  |           2 |    65888 |   6694 |
|   183 | c    | <2018-03-26 Mon 19:47> | <2018-03-26 Mon 23:47> | 0 days 03:59  |           0 |    20026 |  20026 |
|   184 | b    | <2018-03-27 Tue 0:32>  | <2018-03-30 Fri 14:18> | 3 days 13:45  |           0 |   130576 |  12883 |
|   185 | c    | <2018-03-30 Fri 14:18> | <2018-03-30 Fri 18:18> | 0 days 03:59  |           0 |    19901 |  19901 |
|   186 | b    | <2018-03-30 Fri 19:03> | <2018-04-11 Wed 16:03> | 11 days 21:00 |           0 |   434087 |  42830 |
|   187 | c    | <2018-04-11 Wed 16:04> | <2018-04-11 Wed 20:04> | 0 days 04:00  |           0 |    19667 |  19665 |
|   188 | b    | <2018-04-11 Wed 20:53> | <2018-04-17 Tue 10:53> | 5 days 14:00  |           0 |   204281 |  20781 |
|-------+------+------------------------+------------------------+---------------+-------------+----------+--------|
| Run-3 |      |                        |                        |               |             |          |        |
|-------+------+------------------------+------------------------+---------------+-------------+----------+--------|
|   239 | c    | <2018-10-20 Sat 18:31> | <2018-10-20 Sat 20:31> | 0 days 02:00  |           0 |     9565 |   9518 |
|   240 | b    | <2018-10-21 Sun 14:54> | <2018-10-22 Mon 16:15> | 1 days 01:21  |           1 |    38753 |   4203 |
|   241 | c    | <2018-10-22 Mon 16:16> | <2018-10-22 Mon 18:16> | 0 days 02:00  |           0 |     9480 |   9426 |
|   242 | b    | <2018-10-22 Mon 18:44> | <2018-10-23 Tue 22:08> | 1 days 03:24  |           1 |    41933 |   4843 |
|   243 | c    | <2018-10-23 Tue 22:09> | <2018-10-24 Wed 0:09>  | 0 days 01:59  |           0 |     9488 |   9429 |
|   244 | b    | <2018-10-24 Wed 0:32>  | <2018-10-24 Wed 19:24> | 0 days 18:52  |           1 |    28870 |   3317 |
|   245 | c    | <2018-10-24 Wed 19:25> | <2018-10-24 Wed 21:25> | 0 days 01:59  |           0 |     9573 |   9530 |
|   246 | b    | <2018-10-24 Wed 21:59> | <2018-10-25 Thu 16:18> | 0 days 18:18  |           1 |    27970 |   2987 |
|   247 | c    | <2018-10-25 Thu 16:19> | <2018-10-25 Thu 18:19> | 0 days 01:59  |           0 |     9389 |   9334 |
|   248 | b    | <2018-10-25 Thu 18:25> | <2018-10-26 Fri 22:29> | 1 days 04:04  |           1 |    42871 |   4544 |
|   249 | c    | <2018-10-26 Fri 22:30> | <2018-10-27 Sat 0:30>  | 0 days 02:00  |           0 |     9473 |   9431 |
|   250 | b    | <2018-10-27 Sat 1:31>  | <2018-10-27 Sat 22:26> | 0 days 20:54  |           1 |    31961 |   3552 |
|   251 | c    | <2018-10-27 Sat 22:26> | <2018-10-28 Sun 0:26>  | 0 days 01:59  |           0 |     9551 |   9503 |
|   253 | c    | <2018-10-28 Sun 19:18> | <2018-10-28 Sun 21:39> | 0 days 02:20  |           0 |    11095 |  11028 |
|   254 | b    | <2018-10-28 Sun 21:40> | <2018-10-29 Mon 23:03> | 1 days 01:23  |           1 |    38991 |   4990 |
|   255 | c    | <2018-10-29 Mon 23:03> | <2018-10-30 Tue 1:03>  | 0 days 02:00  |           0 |     9378 |   9330 |
|   256 | b    | <2018-10-30 Tue 1:49>  | <2018-10-31 Wed 22:18> | 1 days 20:29  |           1 |    68315 |   8769 |
|   257 | c    | <2018-10-31 Wed 22:19> | <2018-11-01 Thu 0:19>  | 0 days 01:59  |           0 |     9648 |   9592 |
|   258 | b    | <2018-11-01 Thu 0:20>  | <2018-11-01 Thu 16:15> | 0 days 15:55  |           1 |    24454 |   3103 |
|   259 | c    | <2018-11-01 Thu 16:16> | <2018-11-01 Thu 17:31> | 0 days 01:14  |           0 |     5900 |   5864 |
|   260 | c    | <2018-11-01 Thu 17:39> | <2018-11-01 Thu 19:09> | 0 days 01:30  |           0 |     7281 |   7251 |
|   261 | b    | <2018-11-01 Thu 19:39> | <2018-11-04 Sun 15:23> | 2 days 19:43  |           3 |   103658 |  12126 |
|   262 | c    | <2018-11-04 Sun 15:24> | <2018-11-04 Sun 21:24> | 0 days 05:59  |           0 |    28810 |  28681 |
|   263 | b    | <2018-11-05 Mon 0:35>  | <2018-11-05 Mon 20:28> | 0 days 19:52  |           1 |    30428 |   3610 |
|   264 | c    | <2018-11-05 Mon 20:28> | <2018-11-05 Mon 22:28> | 0 days 01:59  |           0 |     9595 |   9544 |
|   265 | b    | <2018-11-05 Mon 22:52> | <2018-11-07 Wed 22:14> | 1 days 23:21  |           1 |    72514 |   8429 |
|   266 | c    | <2018-11-07 Wed 22:14> | <2018-11-08 Thu 0:14>  | 0 days 01:59  |           0 |     9555 |   9506 |
|   267 | b    | <2018-11-08 Thu 2:05>  | <2018-11-08 Thu 6:54>  | 0 days 04:48  |           0 |     7393 |    929 |
|   268 | b    | <2018-11-09 Fri 6:15>  | <2018-11-09 Fri 17:20> | 0 days 11:04  |           1 |    16947 |   1974 |
|   269 | c    | <2018-11-09 Fri 17:20> | <2018-11-09 Fri 21:20> | 0 days 04:00  |           0 |    19382 |  19302 |
|   270 | b    | <2018-11-09 Fri 21:27> | <2018-11-11 Sun 21:02> | 1 days 23:34  |           2 |    72756 |   8078 |
|   271 | c    | <2018-11-11 Sun 21:03> | <2018-11-11 Sun 23:46> | 0 days 02:43  |           0 |    13015 |  12944 |
|   272 | b    | <2018-11-12 Mon 0:09>  | <2018-11-14 Wed 19:07> | 2 days 18:58  |           3 |   102360 |  11336 |
|   273 | c    | <2018-11-14 Wed 19:08> | <2018-11-14 Wed 21:08> | 0 days 01:59  |           0 |     9535 |   9471 |
|   274 | b    | <2018-11-14 Wed 21:28> | <2018-11-17 Sat 18:14> | 2 days 20:45  |           3 |   105187 |  12101 |
|   275 | c    | <2018-11-17 Sat 18:14> | <2018-11-17 Sat 20:57> | 0 days 02:43  |           0 |    13179 |  13116 |
|   276 | b    | <2018-11-17 Sat 22:08> | <2018-11-22 Thu 2:26>  | 4 days 04:17  |           2 |   153954 |  19640 |
|   277 | c    | <2018-11-22 Thu 2:26>  | <2018-11-22 Thu 16:14> | 0 days 13:48  |           0 |    66052 |  65749 |
|   278 | b    | <2018-11-22 Thu 16:14> | <2018-11-23 Fri 10:51> | 0 days 18:36  |           0 |    28164 |   3535 |
|   279 | b    | <2018-11-24 Sat 10:51> | <2018-11-26 Mon 14:58> | 2 days 04:07  |           2 |    79848 |   9677 |
|   280 | c    | <2018-11-26 Mon 14:59> | <2018-11-26 Mon 18:59> | 0 days 04:00  |           0 |    19189 |  19112 |
|   281 | b    | <2018-11-26 Mon 19:02> | <2018-11-28 Wed 18:07> | 1 days 23:04  |           1 |    72230 |   8860 |
|   282 | c    | <2018-11-28 Wed 18:07> | <2018-11-28 Wed 20:51> | 0 days 02:43  |           0 |    12924 |  12860 |
|   283 | b    | <2018-11-28 Wed 22:31> | <2018-12-01 Sat 14:38> | 2 days 16:07  |           3 |    98246 |  11965 |
|   284 | c    | <2018-12-01 Sat 14:39> | <2018-12-01 Sat 18:39> | 0 days 03:59  |           0 |    19017 |  18904 |
|   285 | b    | <2018-12-01 Sat 19:06> | <2018-12-03 Mon 19:39> | 2 days 00:33  |           2 |    74405 |   8887 |
|   286 | c    | <2018-12-04 Tue 15:57> | <2018-12-04 Tue 17:57> | 0 days 02:00  |           0 |     9766 |   9715 |
|   287 | b    | <2018-12-04 Tue 19:07> | <2018-12-05 Wed 15:08> | 0 days 20:01  |           1 |    30598 |   3393 |
|   288 | c    | <2018-12-05 Wed 17:28> | <2018-12-05 Wed 19:28> | 0 days 02:00  |           0 |     9495 |   9443 |
|   289 | b    | <2018-12-05 Wed 23:07> | <2018-12-06 Thu 19:11> | 0 days 20:03  |           1 |    30629 |   3269 |
|   290 | c    | <2018-12-06 Thu 19:11> | <2018-12-06 Thu 21:11> | 0 days 02:00  |           0 |     9457 |   9394 |
|   291 | b    | <2018-12-06 Thu 23:14> | <2018-12-08 Sat 13:39> | 1 days 14:24  |           2 |    58602 |   6133 |
|   292 | c    | <2018-12-08 Sat 13:39> | <2018-12-08 Sat 15:39> | 0 days 02:00  |           0 |     9475 |   9426 |
|   293 | b    | <2018-12-08 Sat 17:42> | <2018-12-10 Mon 21:50> | 2 days 04:07  |           1 |    79677 |   8850 |
|   294 | c    | <2018-12-10 Mon 21:50> | <2018-12-10 Mon 23:50> | 0 days 02:00  |           0 |     9514 |   9467 |
|   295 | b    | <2018-12-11 Tue 0:54>  | <2018-12-11 Tue 20:31> | 0 days 19:37  |           1 |    29981 |   3271 |
|   296 | c    | <2018-12-11 Tue 20:31> | <2018-12-11 Tue 22:31> | 0 days 02:00  |           0 |     9565 |   9517 |
|   297 | b    | <2018-12-12 Wed 0:14>  | <2018-12-13 Thu 18:30> | 1 days 18:15  |           2 |    68124 |  12530 |
|   298 | b    | <2018-12-13 Thu 18:39> | <2018-12-15 Sat 6:41>  | 1 days 12:01  |           1 |    53497 |      0 |
|   299 | b    | <2018-12-15 Sat 6:43>  | <2018-12-15 Sat 18:13> | 0 days 11:29  |           1 |    17061 |      0 |
|   300 | c    | <2018-12-15 Sat 18:38> | <2018-12-15 Sat 20:38> | 0 days 02:00  |           0 |     9466 |   9415 |
|   301 | b    | <2018-12-15 Sat 21:34> | <2018-12-17 Mon 14:17> | 1 days 16:43  |           2 |    62454 |   7751 |
|   302 | c    | <2018-12-17 Mon 14:18> | <2018-12-17 Mon 16:18> | 0 days 01:59  |           0 |     9616 |   9577 |
|   303 | b    | <2018-12-17 Mon 16:52> | <2018-12-18 Tue 16:41> | 0 days 23:48  |           1 |    36583 |   4571 |
|   304 | c    | <2018-12-19 Wed 9:33>  | <2018-12-19 Wed 11:33> | 0 days 01:59  |           0 |     9531 |   9465 |
|   306 | b    | <2018-12-20 Thu 6:55>  | <2018-12-20 Thu 11:53> | 0 days 04:58  |           1 |     7546 |    495 |

\normalsize

* CAST data taking notes [0/1]                            :Appendix:noexport:

*NOTE*: This can't be properly exported to the full thesis in a
PDF. The layout is all sorts of broken.

This file contains a run list of all runs taken during the data taking
period starting in October 2017.

It lists each run, separated as data or calibration run and includes
notes about chip settings etc. (in case there were changes).

- [ ] *HAVE A NOEXPORT SECTION EACH ABOUT:*
  - CAST detector documentation
  - Shifter documentation
  - ..?


** Run table

This section contains a table of the different runs, which identifies
what type each run is, when it started and ended.

The type column describes the run as either
- 'd' == data runs
- 'c' == calibration run
- 'x' == experimental, related to development, problems etc

*** Run in 2017

| Run # | Type {d, c} | Start                  | End                    | Length       | Backup? | Notes                                      |
|-------+-------------+------------------------+------------------------+--------------+---------+--------------------------------------------|
|    76 | d           | <2017-10-30 Mon 18:39> | <2017-11-02 Thu 5:24>  | 2 days 10:44 | y       |                                            |
|    77 | d           | <2017-11-02 Thu 05:24> | <2017-11-03 Fri 5:28>  | 1 days 00:03 | y       |                                            |
|    78 | d           | <2017-11-03 Fri 05:28> | <2017-11-03 Fri 20:45> | 0 days 15:17 | y       |                                            |
|    79 | d           | <2017-11-03 Fri 20:46> | <2017-11-05 Sun 0:09>  | 1 days 03:22 | y       |                                            |
|    80 | d           | <2017-11-05 Sun 00:09> | <2017-11-05 Sun 23:50> | 0 days 23:40 | y       |                                            |
|    81 | d           | <2017-11-05 Sun 23:54> | <2017-11-07 Tue 0:00>  | 1 days 00:06 | y       |                                            |
|    82 | d           | <2017-11-07 Thu 00:01> | <2017-11-08 Wed 15:58> | 1 days 15:56 | y       |                                            |
|    83 | c           | <2017-11-08 Wed 16:27> | <2017-11-08 Wed 17:27> | 0 days 00:59 | y       |                                            |
|    84 | d           | <2017-11-08 Wed 17:49> | <2017-11-09 Thu 19:01> | 1 days 01:11 | y       |                                            |
|    85 | d           | <2017-11-09 Thu 19:01> | <2017-11-09 Thu 21:46> | 0 days 02:45 | y       |                                            |
|    86 | d           | <2017-11-09 Thu 21:47> | <2017-11-11 Sat 2:17>  | 1 days 04:29 | y       |                                            |
|    87 | d           | <2017-11-11 Sat 2:17>  | <2017-11-12 Sun 14:29> | 1 days 12:11 | y       |                                            |
|    88 | c           | <2017-11-12 Sun 14:30> | <2017-11-12 Sun 15:30> | 0 days 0:59  | y       |                                            |
|    89 | d           | <2017-11-12 Sun 15:30> | <2017-11-13 Mon 18:27> | 1 days 2:57  | y       | See note below about length                |
|    90 | d           | <2017-11-13 Mon 19:14> | <2017-11-14 Tue 20:24> | 1 days 1:09  | y       |                                            |
|    91 | d           | <2017-11-14 Tue 20:24> | <2017-11-15 Wed 21:44> | 1 days 1:20  | y       |                                            |
|    92 | d           | <2017-11-15 Wed 21:45> | <2017-11-17 Fri 19:18> | 1 days 21:32 | y       | No Run on <2017-11-16 Th>                  |
|    93 | c           | <2017-11-17 Fri 19:18> | <2017-11-17 Fri 20:18> | 0 days 1:00  | y       |                                            |
|    94 | d           | <2017-11-17 Fri 20:48> | <2017-11-19 Sun 2:34>  | 1 days 5:46  | y       |                                            |
|    95 | d           | <2017-11-19 Sun 2:35>  | <2017-11-23 Thu 10:41> | 4 days 8:06  | y       | Beginning of GRID                          |
|    96 | c           | <2017-11-23 Thu 10:42> | <2017-11-23 Thu 17:43> | 0 days 7:01  | y       | Long calibration for statistics            |
|    97 | d           | <2017-11-23 Thu 17:43> | <2017-11-26 Sun 1:41>  | 2 days 7:57  | y       | ~4 min of tracking lost on 25/11, see note |
|    98 | d           | <2017-11-26 Sun 1:42>  | <2017-11-26 Sun 21:18> | 0 days 19:36 | y       |                                            |
|    99 | d           | <2017-11-26 Sun 21:18> | <2017-11-28 Tue 6:46>  | 1 days 9:27  | y       |                                            |
|   100 | d           | <2017-11-28 Tue 6:46>  | <2017-11-29 Wed 6:40>  | 0 days 23:53 | y       |                                            |
|   101 | d           | <2017-11-29 Wed 6:40>  | <2017-11-29 Wed 20:18> | 0 days 13:37 | y       | FADC amp settings changed, see below       |
|   102 | c           | <2017-11-29 Wed 20:19> | <2017-11-29 Wed 22:19> | 0 days 2:00  | y       |                                            |
|   103 | d           | <2017-11-29 Wed 22:26> | <2017-12-01 Fri 6:46>  | 1 days 8:19  | y       |                                            |
|   104 | d           | <2017-12-01 Fri 6:47>  | <2017-12-02 Sat 6:48>  | 1 days 0:00  | y       |                                            |
|   105 | d           | <2017-12-02 Sat 6:48>  | <2017-12-03 Sun 6:39>  | 0 days 23:51 | y       |                                            |
|   106 | d           | <2017-12-03 Sun 6:40>  | <2017-12-04 Mon 6:54>  | 1 days 0:14  | y       |                                            |
|   107 | d           | <2017-12-04 Mon 6:54>  | <2017-12-04 Mon 13:38> | 0 days 6:44  | y       |                                            |
|   108 | c           | <2017-12-04 Mon 13:39> | <2017-12-04 Mon 17:39> | 0 days 4:00  | y       |                                            |
|   109 | d           | <2017-12-04 Mon 17:47> | <2017-12-05 Tue 11:20> | 0 days 17:32 | y       | A lot of noise during this shift           |
|   110 | c           | <2017-12-05 Tue 11:20> | <2017-12-05 Tue 13:20> | 0 days 1:59  | y       |                                            |
|   111 | d           | <2017-12-05 Tue 13:23> | <2017-12-05 Tue 16:17> | 0 days 2:53  | y       | gas interlock box fuse burned, early stop  |
|   112 | d           | <2017-12-06 Wed 14:50> | <2017-12-10 Sun 6:46>  | 3 days 15:55 | y       | FADC: int. time: 50->100->50ns + quench    |
|   113 | d           | <2017-12-10 Sun 6:46>  | <2017-12-11 Mon 6:49>  | 1 days 0:03  | y       |                                            |
|   114 | d           | <2017-12-11 Mon 6:50>  | <2017-12-11 Mon 18:33> | 0 days 11:43 | y       |                                            |
|   115 | d           | <2017-12-11 Mon 18:36> | <2017-12-12 Tue 20:58> | 1 days 2:21  | y       |                                            |
|   116 | c           | <2017-12-12 Tue 20:59> | <2017-12-12 Tue 22:59> | 0 days 2:00  | y       |                                            |
|   117 | d           | <2017-12-12 Tue 23:56> | <2017-12-13 Wed 21:29> | 0 days 21:33 | y       |                                            |
|   118 | c           | <2017-12-13 Wed 21:30> | <2017-12-13 Wed 23:30> | 0 days 2:00  | y       |                                            |
|   119 | d           | <2017-12-14 Thu 0:07>  | <2017-12-14 Thu 17:04> | 0 days 16:57 | y       |                                            |
|   120 | c           | <2017-12-14 Thu 17:04> | <2017-12-14 Thu 21:04> | 0 days 4:00  | y       |                                            |
|   121 | d           | <2017-12-14 Thu 21:07> | <2017-12-15 Fri 19:22> | 0 days 22:14 | y       | Jochen: FADC int. time: 50->100ns, c note  |
|   122 | c           | <2017-12-15 Fri 19:22> | <2017-12-16 Sat 1:20>  | 0 days 5:57  | y       |                                            |
|   123 | d           | <2017-12-16 Sat 1:21>  | <2017-12-17 Sun 1:06>  | 0 days 23:45 | y       |                                            |
|   124 | d           | <2017-12-17 Sun 1:06>  | <2017-12-19 Tue 2:57>  | 2 days 1:50  | y       |                                            |
|   125 | d           | <2017-12-19 Tue 2:57>  | <2017-12-19 Tue 16:20> | 0 days 13:22 | y       |                                            |
|   126 | c           | <2017-12-19 Tue 16:21> | <2017-12-19 Tue 19:21> | 0 days 2:59  | y       |                                            |
|   127 | d           | <2017-12-19 Tue 19:27> | <2017-12-22 Fri 0:17>  | 2 days 4:50  | y       |                                            |
|   128 | c           | <2017-12-22 Fri 0:18>  | <2017-12-22 Fri 9:23>  | 0 days 9:05  | y       | Final run of 2017                          |

*** Run 1 in 2018

| Run # | Type {d, c} | Start                  | End                    | Length        | # trackings | Backup? | Notes                                                             |
|-------+-------------+------------------------+------------------------+---------------+-------------+---------+-------------------------------------------------------------------|
|   137 | d           | <2018-02-15 Thu 5:34>  | <2018-02-15 Thu 17:08> | 0 days 11:34  |             | y*      | WARNING: do not use, THL problems, see note!                      |
|   138 | c           | <2018-02-15 Thu 17:09> | <2018-02-15 Thu 19:34> | 0 days 2:24   |             | y*      | Seems like gas amplification down by factor 2!                    |
|   139 | c           | <2018-02-15 Thu 20:31> | <2018-02-15 Thu 21:53> | 0 days 1:22   |             | y*      | Central THL 450 -> 400 from here on! (if result good)             |
|   140 | d           | <2018-02-15 Thu 21:53> | <2018-02-16 Fri 17:59> | 0 days 20:05  |             | y*      | Running THL from Run 139.                                         |
|   141 | x (c)       | <2018-02-16 Fri 18:00> | <2018-02-17 Sat 13:28> | 0 days 19:28  |             | y*      | Calibration run over night, showcasing increasing [Power Problem] |
|   142 | x (d)       | <2018-02-17 Sat 14:04> | <2018-02-17 Sat 16:17> | 0 days 2:12   |             | y*      | Background data run w/ THL 400 and problems, see [Power Problem]  |
|   143 | x (c)       | <2018-02-17 Sat 16:18> | <2018-02-17 Sat 16:26> | 0 days 0:07   |             | y*      | More calibration for testing                                      |
|   144 | x (c)       | <2018-02-17 Sat 16:32> | <2018-02-17 Sat 17:18> | 0 days 0:45   |             | y*      | Calibration run in which [Power Problem] was fixed                |
|   145 | c           | <2018-02-17 Sat 17:18> | <2018-02-17 Sat 20:40> | 0 days 3:22   |             | y       | Proper calibration run w/ THL = 450 and fixed [Power Problem]     |
|   146 | d           | <2018-02-17 Sat 20:41> | <2018-02-18 Sun 18:12> | 0 days 21:30  |             | y       | First good shift after power supply problem                       |
|   147 | c           | <2018-02-18 Sun 18:12> | <2018-02-18 Sun 20:12> | 0 days 1:59   |             | y       | Calibration run                                                   |
|   148 | d           | <2018-02-18 Sun 20:46> | <2018-02-19 Mon 17:24> | 0 days 20:37  |             | y       |                                                                   |
|   149 | c           | <2018-02-19 Mon 17:25> | <2018-02-19 Mon 19:25> | 0 days 2:00   |             | y       |                                                                   |
|   150 | d           | <2018-02-19 Mon 19:53> | <2018-02-20 Tue 17:36> | 0 days 21:42  |             | y       |                                                                   |
|   151 | c           | <2018-02-20 Tue 17:36> | <2018-02-20 Tue 19:36> | 0 days 1:59   |             | y       |                                                                   |
|   152 | d           | <2018-02-20 Tue 21:54> | <2018-02-21 Wed 18:05> | 0 days 20:10  |             | y       |                                                                   |
|   153 | c           | <2018-02-21 Wed 18:05> | <2018-02-21 Wed 20:05> | 0 days 1:59   |             | y       |                                                                   |
|   154 | d           | <2018-02-21 Wed 21:10> | <2018-02-22 Thu 17:23> | 0 days 20:12  |             | y       |                                                                   |
|   155 | c           | <2018-02-22 Thu 17:23> | <2018-02-22 Thu 19:23> | 0 days 1:59   |             | y       |                                                                   |
|   156 | d           | <2018-02-23 Fri 6:06>  | <2018-02-23 Fri 17:41> | 0 days 11:35  |             | y       |                                                                   |
|   157 | c           | <2018-02-23 Fri 17:41> | <2018-02-23 Fri 19:41> | 0 days 1:59   |             | y       |                                                                   |
|   158 | d           | <2018-02-23 Fri 19:42> | <2018-02-26 Mon 8:46>  | 2 days 13:03  |             | y       |                                                                   |
|   159 | c           | <2018-02-26 Mon 8:46>  | <2018-02-26 Mon 12:46> | 0 days 4:00   |             | y       |                                                                   |
|   160 | d           | <2018-02-26 Mon 14:56> | <2018-03-01 Thu 10:24> | 2 days 19:28  |             | y       |                                                                   |
|   161 | c           | <2018-03-01 Thu 10:26> | <2018-03-01 Thu 14:26> | 0 days 4:00   |             | y       |                                                                   |
|   162 | d           | <2018-03-01 Thu 17:07> | <2018-03-04 Sun 20:16> | 3 days 3:08   |             | y       |                                                                   |
|   163 | c           | <2018-03-04 Sun 20:17> | <2018-03-04 Sun 22:17> | 0 days 2:00   |             | y       |                                                                   |
|   164 | d           | <2018-03-04 Sun 22:57> | <2018-03-06 Tue 19:15> | 1 days 20:18  |             | y       |                                                                   |
|   165 | c           | <2018-03-06 Tue 19:15> | <2018-03-06 Tue 23:15> | 0 days 4:00   |             | y       |                                                                   |
|   166 | d           | <2018-03-07 Wed 0:50>  | <2018-03-07 Wed 18:28> | 0 days 17:38  |             | y       |                                                                   |
|   167 | c           | <2018-03-07 Wed 18:29> | <2018-03-07 Wed 20:29> | 0 days 2:00   |             | y       |                                                                   |
|   168 | d           | <2018-03-07 Wed 20:37> | <2018-03-13 Tue 16:54> | 5 days 20:16  |             | y       |                                                                   |
|   169 | c           | <2018-03-13 Tue 16:55> | <2018-03-13 Tue 22:55> | 0 days 6:00   |             | y       |                                                                   |
|   170 | d           | <2018-03-13 Tue 23:19> | <2018-03-14 Wed 21:01> | 0 days 21:42  |           1 | y       | First shift including sun tracking                                |
|   171 | c           | <2018-03-14 Wed 21:01> | <2018-03-14 Wed 23:01> | 0 days 2:00   |             | y       |                                                                   |
|   172 | d           | <2018-03-14 Wed 23:06> | <2018-03-15 Thu 17:57> | 0 days 18:50  |           1 | y       |                                                                   |
|   173 | c           | <2018-03-15 Thu 17:59> | <2018-03-15 Thu 19:59> | 0 days 1:59   |             | y       |                                                                   |
|   174 | d           | <2018-03-15 Thu 20:39> | <2018-03-16 Fri 16:27> | 0 days 19:48  |           1 | y       |                                                                   |
|   175 | c           | <2018-03-16 Fri 16:28> | <2018-03-16 Fri 18:28> | 0 days 1:59   |             | y       |                                                                   |
|   176 | d           | <2018-03-16 Fri 18:35> | <2018-03-17 Sat 20:55> | 1 days 2:19   |           1 | y       |                                                                   |
|   177 | c           | <2018-03-17 Sat 20:55> | <2018-03-17 Sat 22:55> | 0 days 1:59   |             | y       |                                                                   |
|   178 | d           | <2018-03-17 Sat 23:31> | <2018-03-22 Thu 17:40> | 4 days 18:09  |           5 | y       |                                                                   |
|   179 | c           | <2018-03-22 Thu 17:41> | <2018-03-22 Thu 19:41> | 0 days 1:59   |             | y       |                                                                   |
|   180 | d           | <2018-03-22 Thu 20:47> | <2018-03-24 Sat 18:10> | 1 days 21:22  |           2 | y       |                                                                   |
|   181 | c           | <2018-03-24 Sat 18:10> | <2018-03-24 Sat 22:10> | 0 days 4:00   |             | y       |                                                                   |
|   182 | d           | <2018-03-24 Sat 23:32> | <2018-03-26 Mon 19:46> | 1 days 19:14  |           2 | y       | Last run including tracking                                       |
|   183 | c           | <2018-03-26 Mon 19:47> | <2018-03-26 Mon 23:47> | 0 days 3:59   |             | y       |                                                                   |
|   184 | d           | <2018-03-27 Tue 0:32>  | <2018-03-30 Fri 14:18> | 3 days 13:45  |             | y       |                                                                   |
|   185 | c           | <2018-03-30 Fri 14:18> | <2018-03-30 Fri 18:18> | 0 days 3:59   |             | y       |                                                                   |
|   186 | d           | <2018-03-30 Fri 19:03> | <2018-04-11 Wed 16:03> | 11 days 21:00 |             | y       |                                                                   |
|   187 | c           | <2018-04-11 Wed 16:04> | <2018-04-11 Wed 20:04> | 0 days 4:00   |             | y       |                                                                   |
|   188 | d           | <2018-04-11 Wed 20:53> | <2018-04-17 Tue 10:53> | 5 days 14:00  |             | y       | Last background data run of 2017/18                               |
|   189 | X*          | <2018-04-20 Fri 9:53>  | <2018-04-21 Sat 18:39> | 1 days 08:45  |             | y       | X-ray finger run <2018-04-20 Fri>                                 |

y* == located in 2018/BadRuns folder to not mix up with 'good' data
X* == X-ray finger run

*** Run 2 in 2018

Data taking for the second data taking period starts on
<2018-10-20 Sat 18:33> with a 2h calibration run after the detector
was finally fixed on <2018-10-19 Fri>. The issue was a bad soldering
joint on the Phoenix connector on the intermediate board.

| Run # | Type {d, c} | Start | End | Length       | # trackings | Backup? | Notes                  |
|-------+-------------+-------+-----+--------------+-------------+---------+------------------------|
|   239 | c           |       |     | 0 days 02:00 |             |         |                        |
|   240 | d           |       |     |              |           1 |         | no B field!            |
|   297 | d           |       |     |              |             |         | crazy noise at the end |
|   298 | d           |       |     |              |             |         | run without FADC       |


| Run # | Type          | DataType | Start                  | End                    | Length       | # trackings | # frames | # FADC Backup? | Backup? | Notes |
|-------+---------------+----------+------------------------+------------------------+--------------+-------------+----------+----------------+---------+-------|
|   239 | rtCalibration | rfNewTos | <1970-01-01 Thu 1:00>  | <1970-01-01 Thu 1:00>  | 0 days 02:00 |             |        0 |              0 | y       |       |
|   240 | rtBackground  | rfNewTos | <2018-10-21 Sun 14:54> | <2018-10-22 Mon 16:15> | 1 days 01:21 |             |    38753 |           4203 | y       |       |
|   239 | rtCalibration | rfNewTos | <2018-10-20 Sat 18:31> | <2018-10-20 Sat 20:31> | 0 days 02:00 |             |     9565 |           9518 | y       |       |
|   240 | rtBackground  | rfNewTos | <2018-10-21 Sun 14:54> | <2018-10-22 Mon 16:15> | 1 days 01:21 |             |    38753 |           4203 | y       |       |
|   239 | rtCalibration | rfNewTos | <2018-10-20 Sat 18:31> | <2018-10-20 Sat 20:31> | 0 days 02:00 |             |     9565 |           9518 | y       |       |
|   240 | rtBackground  | rfNewTos | <2018-10-21 Sun 14:54> | <2018-10-22 Mon 16:15> | 1 days 01:21 |             |    38753 |           4203 | y       |       |
|   239 | rtCalibration | rfNewTos | <2018-10-20 Sat 18:31> | <2018-10-20 Sat 20:31> | 0 days 02:00 |             |     9565 |           9518 | y       |       |
|   240 | rtBackground  | rfNewTos | <2018-10-21 Sun 14:54> | <2018-10-22 Mon 16:15> | 1 days 01:21 |             |    38753 |           4203 | y       |       |
|   241 | rtCalibration | rfNewTos | <2018-10-22 Mon 16:16> | <2018-10-22 Mon 18:16> | 0 days 02:00 |             |     9480 |           9426 | y       |       |
|   242 | rtBackground  | rfNewTos | <2018-10-22 Mon 18:44> | <2018-10-23 Tue 22:08> | 1 days 03:24 |             |    41933 |           4843 | y       |       |
|   243 | rtCalibration | rfNewTos | <2018-10-23 Tue 22:09> | <2018-10-24 Wed 0:09>  | 0 days 01:59 |             |     9488 |           9429 | y       |       |
|   244 | rtBackground  | rfNewTos | <2018-10-24 Wed 0:32>  | <2018-10-24 Wed 19:24> | 0 days 18:52 |             |    28870 |           3317 | y       |       |
|   245 | rtCalibration | rfNewTos | <2018-10-24 Wed 19:25> | <2018-10-24 Wed 21:25> | 0 days 01:59 |             |     9573 |           9530 | y       |       |
|   246 | rtBackground  | rfNewTos | <2018-10-24 Wed 21:59> | <2018-10-25 Thu 16:18> | 0 days 18:18 |             |    27970 |           2987 | y       |       |
|   247 | rtCalibration | rfNewTos | <2018-10-25 Thu 16:19> | <2018-10-25 Thu 18:19> | 0 days 01:59 |             |     9389 |           9334 | y       |       |
|   248 | rtBackground  | rfNewTos | <2018-10-25 Thu 18:25> | <2018-10-26 Fri 22:29> | 1 days 04:04 |             |    42871 |           4544 | y       |       |
|   249 | rtCalibration | rfNewTos | <2018-10-26 Fri 22:30> | <2018-10-27 Sat 0:30>  | 0 days 02:00 |             |     9473 |           9431 | y       |       |
|   250 | rtBackground  | rfNewTos | <2018-10-27 Sat 1:31>  | <2018-10-27 Sat 22:26> | 0 days 20:54 |             |    31961 |           3552 | y       |       |
|   251 | rtCalibration | rfNewTos | <2018-10-27 Sat 22:26> | <2018-10-28 Sun 0:26>  | 0 days 01:59 |             |     9551 |           9503 | y       |       |
|   252 | rtNone        | rfNewTos | <2018-10-28 Sun 0:59>  | <2018-10-28 Sun 2:20>  | 0 days 01:20 |             |     2060 |            214 | y       |       |
|   253 | rtCalibration | rfNewTos | <2018-10-28 Sun 19:18> | <2018-10-28 Sun 21:39> | 0 days 02:20 |             |    11095 |          11028 | y       |       |
|   254 | rtBackground  | rfNewTos | <2018-10-28 Sun 21:40> | <2018-10-29 Mon 23:03> | 1 days 01:23 |             |    38991 |           4990 | y       |       |
|   255 | rtCalibration | rfNewTos | <2018-10-29 Mon 23:03> | <2018-10-30 Tue 1:03>  | 0 days 02:00 |             |     9378 |           9330 | y       |       |
|   256 | rtBackground  | rfNewTos | <2018-10-30 Tue 1:49>  | <2018-10-31 Wed 22:18> | 1 days 20:29 |             |    68315 |           8769 | y       |       |
|   257 | rtCalibration | rfNewTos | <2018-10-31 Wed 22:19> | <2018-11-01 Thu 0:19>  | 0 days 01:59 |             |     9648 |           9592 | y       |       |
|   258 | rtBackground  | rfNewTos | <2018-11-01 Thu 0:20>  | <2018-11-01 Thu 16:15> | 0 days 15:55 |             |    24454 |           3103 | y       |       |
|   259 | rtCalibration | rfNewTos | <2018-11-01 Thu 16:16> | <2018-11-01 Thu 17:31> | 0 days 01:14 |             |     5900 |           5864 | y       |       |
|   260 | rtCalibration | rfNewTos | <2018-11-01 Thu 17:39> | <2018-11-01 Thu 19:09> | 0 days 01:30 |             |     7281 |           7251 | y       |       |
|   261 | rtBackground  | rfNewTos | <2018-11-01 Thu 19:39> | <2018-11-04 Sun 15:23> | 2 days 19:43 |             |   103658 |          12126 | y       |       |
|   262 | rtCalibration | rfNewTos | <2018-11-04 Sun 15:24> | <2018-11-04 Sun 21:24> | 0 days 05:59 |             |    28810 |          28681 | y       |       |
|   263 | rtBackground  | rfNewTos | <2018-11-05 Mon 0:35>  | <2018-11-05 Mon 20:28> | 0 days 19:52 |             |    30428 |           3610 | y       |       |
|   264 | rtCalibration | rfNewTos | <2018-11-05 Mon 20:28> | <2018-11-05 Mon 22:28> | 0 days 01:59 |             |     9595 |           9544 | y       |       |
|   265 | rtBackground  | rfNewTos | <2018-11-05 Mon 22:52> | <2018-11-07 Wed 22:14> | 1 days 23:21 |             |    72514 |           8429 | y       |       |
|   266 | rtCalibration | rfNewTos | <2018-11-07 Wed 22:14> | <2018-11-08 Thu 0:14>  | 0 days 01:59 |             |     9555 |           9506 | y       |       |
|   267 | rtBackground  | rfNewTos | <2018-11-08 Thu 2:05>  | <2018-11-08 Thu 6:54>  | 0 days 04:48 |             |     7405 |            930 | y       |       |
|   268 | rtBackground  | rfNewTos | <2018-11-09 Fri 6:15>  | <2018-11-09 Fri 17:20> | 0 days 11:04 |             |    16947 |           1974 | y       |       |
|   269 | rtCalibration | rfNewTos | <2018-11-09 Fri 17:20> | <2018-11-09 Fri 21:20> | 0 days 04:00 |             |    19382 |          19302 | y       |       |
|   270 | rtBackground  | rfNewTos | <2018-11-09 Fri 21:27> | <2018-11-11 Sun 21:02> | 1 days 23:34 |             |    72756 |           8078 | y       |       |
|   271 | rtCalibration | rfNewTos | <2018-11-11 Sun 21:03> | <2018-11-11 Sun 23:46> | 0 days 02:43 |             |    13015 |          12944 | y       |       |
|   272 | rtBackground  | rfNewTos | <2018-11-12 Mon 0:09>  | <2018-11-14 Wed 19:07> | 2 days 18:58 |             |   102360 |          11336 | y       |       |
|   273 | rtCalibration | rfNewTos | <2018-11-14 Wed 19:08> | <2018-11-14 Wed 21:08> | 0 days 01:59 |             |     9535 |           9471 | y       |       |
|   274 | rtBackground  | rfNewTos | <2018-11-14 Wed 21:28> | <2018-11-17 Sat 18:14> | 2 days 20:45 |             |   105187 |          12101 | y       |       |
|   275 | rtCalibration | rfNewTos | <2018-11-17 Sat 18:14> | <2018-11-17 Sat 20:57> | 0 days 02:43 |             |    13179 |          13116 | y       |       |
|   276 | rtBackground  | rfNewTos | <2018-11-17 Sat 22:08> | <2018-11-22 Thu 2:26>  | 4 days 04:17 |             |   153954 |          19640 | y       |       |
|   277 | rtCalibration | rfNewTos | <2018-11-22 Thu 2:26>  | <2018-11-22 Thu 16:14> | 0 days 13:48 |             |    66052 |          65749 | y       |       |
|   278 | rtBackground  | rfNewTos | <2018-11-22 Thu 16:14> | <2018-11-23 Fri 10:51> | 0 days 18:36 |             |    28899 |           3581 | y       |       |
|   279 | rtBackground  | rfNewTos | <2018-11-24 Sat 10:51> | <2018-11-26 Mon 14:58> | 2 days 04:07 |             |    79848 |           9677 | y       |       |
|   280 | rtCalibration | rfNewTos | <2018-11-26 Mon 14:59> | <2018-11-26 Mon 18:59> | 0 days 04:00 |             |    19189 |          19112 | y       |       |
|   281 | rtBackground  | rfNewTos | <2018-11-26 Mon 19:02> | <2018-11-28 Wed 18:07> | 1 days 23:04 |             |    72230 |           8860 | y       |       |
|   282 | rtCalibration | rfNewTos | <2018-11-28 Wed 18:07> | <2018-11-28 Wed 20:51> | 0 days 02:43 |             |    12924 |          12860 | y       |       |
|   283 | rtBackground  | rfNewTos | <2018-11-28 Wed 22:31> | <2018-12-01 Sat 14:38> | 2 days 16:07 |             |    98246 |          11965 | y       |       |
|   284 | rtCalibration | rfNewTos | <2018-12-01 Sat 14:39> | <2018-12-01 Sat 18:39> | 0 days 03:59 |             |    19017 |          18904 | y       |       |
|   285 | rtBackground  | rfNewTos | <2018-12-01 Sat 19:06> | <2018-12-03 Mon 19:39> | 2 days 00:33 |             |    74431 |           8888 | y       |       |
|   286 | rtCalibration | rfNewTos | <2018-12-04 Tue 15:57> | <2018-12-04 Tue 17:57> | 0 days 02:00 |             |     9766 |           9715 | y       |       |
|   287 | rtBackground  | rfNewTos | <2018-12-04 Tue 19:07> | <2018-12-05 Wed 15:08> | 0 days 20:01 |             |    30622 |           3395 | y       |       |
|   288 | rtCalibration | rfNewTos | <2018-12-05 Wed 17:28> | <2018-12-05 Wed 19:28> | 0 days 02:00 |             |     9495 |           9443 | y       |       |
|   289 | rtBackground  | rfNewTos | <2018-12-05 Wed 23:07> | <2018-12-06 Thu 19:11> | 0 days 20:03 |             |    30629 |           3269 | y       |       |
|   290 | rtCalibration | rfNewTos | <2018-12-06 Thu 19:11> | <2018-12-06 Thu 21:11> | 0 days 02:00 |             |     9457 |           9394 | y       |       |
|   291 | rtBackground  | rfNewTos | <2018-12-06 Thu 23:14> | <2018-12-08 Sat 13:39> | 1 days 14:24 |             |    58602 |           6133 | y       |       |
|   292 | rtCalibration | rfNewTos | <2018-12-08 Sat 13:39> | <2018-12-08 Sat 15:39> | 0 days 02:00 |             |     9475 |           9426 | y       |       |
|   293 | rtBackground  | rfNewTos | <2018-12-08 Sat 17:42> | <2018-12-10 Mon 21:50> | 2 days 04:07 |             |    79677 |           8850 | y       |       |
|   294 | rtCalibration | rfNewTos | <2018-12-10 Mon 21:50> | <2018-12-10 Mon 23:50> | 0 days 02:00 |             |     9514 |           9467 | y       |       |
|   295 | rtBackground  | rfNewTos | <2018-12-11 Tue 0:54>  | <2018-12-11 Tue 20:31> | 0 days 19:37 |             |    29981 |           3271 | y       |       |
|   296 | rtCalibration | rfNewTos | <2018-12-11 Tue 20:31> | <2018-12-11 Tue 22:31> | 0 days 02:00 |             |     9565 |           9517 | y       |       |
|   297 | rtBackground  | rfNewTos | <2018-12-12 Wed 0:14>  | <2018-12-13 Thu 18:30> | 1 days 18:15 |             |    68124 |          12530 | y       |       |
|   298 | rtBackground  | rfNewTos | <2018-12-13 Thu 18:39> | <2018-12-15 Sat 6:41>  | 1 days 12:01 |             |    53497 |              0 | y       |       |
|   299 | rtBackground  | rfNewTos | <2018-12-15 Sat 6:43>  | <2018-12-15 Sat 18:13> | 0 days 11:29 |             |    17061 |              0 | y       |       |
|   300 | rtCalibration | rfNewTos | <2018-12-15 Sat 18:38> | <2018-12-15 Sat 20:38> | 0 days 02:00 |             |     9466 |           9415 | y       |       |
|   301 | rtBackground  | rfNewTos | <2018-12-15 Sat 21:34> | <2018-12-17 Mon 14:17> | 1 days 16:43 |             |    62454 |           7751 | y       |       |
|   302 | rtCalibration | rfNewTos | <2018-12-17 Mon 14:18> | <2018-12-17 Mon 16:18> | 0 days 01:59 |             |     9616 |           9577 | y       |       |
|   303 | rtBackground  | rfNewTos | <2018-12-17 Mon 16:52> | <2018-12-18 Tue 16:41> | 0 days 23:48 |             |    36583 |           4571 | y       |       |
|   304 | rtCalibration | rfNewTos | <2018-12-19 Wed 9:33>  | <2018-12-19 Wed 11:33> | 0 days 01:59 |             |     9531 |           9465 | y       |       |
|   305 | rtCalibration | rfNewTos | <2018-12-19 Wed 13:24> | <2018-12-20 Thu 3:23>  | 0 days 13:58 |             |    32655 |          25702 | y*      |       |
|   306 | rtBackground  | rfNewTos | <2018-12-20 Thu 6:55>  | <2018-12-20 Thu 11:53> | 0 days 04:58 |             |     7574 |            496 | y       |       |


NOTE: Run 305 is considered a *bad* run now! 
See [[docs/statusAndProgress.org]] for more information. It is *not* a
calibration run. Probably it's just a background run, but the
confusion makes me not want to trust it!

y* == located in 2018/BadRuns folder to not mix up with 'good' data
X* == X-ray finger run


X-ray finger runs are apparently number 21 (old before data taking??)
and then 189 at the end of the 2017/18 data taking in Apr 2018. See
[[file:analysis.org]] for reference to run 21.


*** Total run time

After Run 96:
- Currently 23.85625 days (552.5 hours) of data taking (raw, beginning to end)
  - of that were 10 hours calibration
  - 17 shifts a 90 minutes => 25.5 hours
  => - 517 hours background
     - 10 hours calibration
     - 25.5 hours tracking

After Run 116 (since excl. 96):
- another 449.95 hours of data taking
  - of that were 16 shifts => ~24 hours tracking
  - 10 hours of calibration
=> - 417.95 hours of background
   - 24 hours of tracking
   - 10 hours of calibration

Combined so far:
- background: 934.95 h
- tracking: 49.5 h
- calibration: 20 h

Up to incl. 128 (since excl. 116):
- 4 days, 100 hours, 271 minutes background
- 200.5 hours of background + tracking
- 8 shifts since run 117 incl = 12 hours
- calibration: 22 hours
=> - 188 h background
   - 12 h tracking
   - 22 h calibration

Combined Runs 2017:
- background: 1123 h
- tracking: 61.5 h
- calibration: 42 h


Run time 2018 from run 145 to run 167:
- total time: 8 days + 211 hours + 578 minutes = 17 days +
  4 hours + 38 minutes
- background + tracking: 15 days + 5 hours + 3.5 minutes ~ 365 h
- background (90 minutes tracking): 342.5 h
- tracking: 22.5 h
- calibration: 31 hours + 17 minutes ~ 31.5 h

Run time 2018 from run 168 to Run 187:
- background + tracking: 26 days + 172 hours + 265 minutes = 33 days + 8 hours +
  25 minutes ~ 800.5 h
- # trackings: 13
- background: 781 h
- tracking: 19.5 h
- calibration: 32 hours


Total time of Run 2017 / 2018:
background: 2288 h
tracking: 103.5 h
calibration: 105.5 h



** Data runs

This section covers the data runs, which took place.

The runs, unless otherwise stated, are using the FSR files as in the
Septem H calibration Git repo in the folder fsr_in_use. These are the
THL values, which were obtained during calibration, but have THL+50
for chips 1, 2, 5 and 6.
The HV values are the ones documented in the detector documentation
[[file:Doc/Detector/CastDetectorDocumentation.org]]
(as of <2017-11-09 Do 19:05>).

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_76_171030-18-39.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_77_171102-05-24.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_78_171103-05-28.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_79_171103-20-46.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_80_171105-00-09.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_81_171105-23-54.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_82_171107-00-01.tar.gz]]

*NOTE:* this was the first run with the correct SiPM HV setting of $\SI{65.6}{\volt}$
[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_84_171108-17-49.tar.gz]]

*NOTE*: this run was stopped early to fix the src/waitconditions.cpp
bug, mentioned in the note below.
[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_85_171109-19-01.tar.gz]]

*NOTE: VERY IMPORTANT*
In all runs above, there was a bug in src/waitconditions.cpp, which
cause the FADC and scintillator values to be written the all
subsequent files, from an event in which the FADC triggered until the
next (in case of non-subsequent FADC events).
Therefore: for analysis, we need to take into account
- fadcReadout == 1.
Otherwise we read random scintillator trigger values as well as FADC
trigger clock cycles.

All runs below are without the aforementioned error.

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_86_171109-21-47.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_87_171111-02-17.tar.gz]]

*NOTE:* During Run 89 the byobu buffer containing TOS got stuck on
<2017-11-12 So 19:35> due to <F7> being pressed (which eventually
pauses the thread). Was called by Cristian at <2017-11-13 Mo 5:55>
roughly. I fixed the issue. Therefore the length given in the table is
misleading, as it does not show the actual time of data taking of that
run.

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_89_171112-15-30.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_90_171113-19-14.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_91_171114-20-24.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_92_171115-21-45.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_94_171117-20-48.tar.gz]]

*NOTE:* The following run contains the beginning (and most of it) of
the GRID measurement. It only contains a single tracking, that's why
the run is so long.

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/DataRuns/Run_95_171119-02-35.tar.gz]]

*NOTE:* Regarding Run 97, morning shift on 25/11/17, from the elog:
#+BEGIN_SRC
Remarks: At approx. 7:02 there was an error message in the Slow
Control program indicating that some file could not be saved because
there was not enough memory. After about a minute, the Slow Control PC
restarted by itself. At about the same time, an error message appeared
in the Tracking program, probably related to the fact that it could
not communicate with the Slow Control program in order to read
proximity sensor data. After the restart of the Slow control PC and
Slow control program, things went back to normal. Because of all that,
we lost first 3-4 minutes of tracking
#+END_SRC

*NOTE: Still need to add links to previous runs (97, 98, 99)*

*NOTE:* Regarding Run 101: Because of pretty bad noise during the run,
I decided to play around with the main amplifier of the analogue
signal. I changed the settings as followed:
- Diff: 50 ns -> 20 ns (one to left)
- Coarse gain: 6x -> 10x (one to right)
this got rid of (almost ?) all of the noise. However, obviously this
changes the FADC data completely. The shapes are slightly altered (a
little steeper)

*NOTE:* Regarding Run 109: CRAZY amounts of noise during that
run. Interestingly, the only difference between the previous runs from
what I can tell (although I wasn't present in the shift), was that the
main light in the LHCb part of the hall was turned on. Maybe this
causes the electricity circuit to be working under high load,
producing a lot more noise? Will keep an eye on this.

*NOTE:* Regarding Run 111: Was stopped early, because I tried to debug
the noise and in doing so burned a fuse in the gas interlock box by
connecting the NIM crate to a wrong power cable.
-> no shift on 6/12/17, background data being taken again since <2017-12-06 Wed 14:55>.

*NOTE:* Regarding Run 112: Another change of FADC settings due to crazy amounts of
noise. Changed integration time from:
- 50ns -> 100ns
gets rid of all noise for now. However, shapes are much smoother than
before, might make differentiation much harder later.
This was done at around <2017-12-07 Thu 8:00>
*Also:* The power cable from the main amplifier to the pre amplifier
was not properly inserted. Did that before changing the settings,
seeemed to help, but noise eventually returned.

*NOTE:* Regarding Run 112 and previous note: Turned down integration
time from 100ns to 50ns again at around <2017-12-08 Fri 17:50>.

*NOTE:* Regarding Run 112: Run is so long, because after problems with
fuse, had quench on <2017-12-07 Thu 18:31:53>.

*NOTE:* Regarding Run 121: Jochen set the FADC main amplifier
integration time from 50 to 100 ns again. Happened at around
<2017-12-15 Fri 10:20>. Maybe 5 min later.

*** Notes 2018

After Run 137 (first run of 2018) I did a calibration run only to
notice that we didn't recover 220 electrons anymore, but
rather 110. THLscan revealed that indeed the THL values of the central
chips (and potentially all others) changed.

Previously we used:
Chip #: 3
THL: 450

Now a value of:
THL: 400

produces no noise, if run without source on 2.4s frames, and recovers
all electrons again, it seems.

- Calibration Run 138 uses THL 450
- Calibration Run 139 uses THL 400

Change is reflected in CAST calibration Git repository, in fsr_as_used
folder!

**** Power Problem

Problem due to power supply, causing what looked like changes to the
thresholds of all chips.

See the following mail for a short explanation:
[[file:Mails/cast_power_supply_problem_thlshift/power_supply_problem.org]]

**** Run 297 and 298
There was some pretty crazy noise in run 297 (see Sergios video on
WhatsApp), so I disabled the FADC on <2018-12-13 Thu 18:40> for Run
298, since I'm heading down to CERN on <2018-12-14 Fri>.


** Calibration runs

This scetion covers the calibration runs, which took place.

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/CalibrationRuns/Run_83_171108-16-27.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/CalibrationRuns/Run_88_171112-14-30.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/CalibrationRuns/Run_93_171117-19-18.tar.gz]]

[[file:/ssh:tpc@tpc00:/volume1/cast/data/2017_CAST-Run/CalibrationRuns/Run_96_171123-10-42.tar.gz]]



** Automatically generated run list

The following run list is created by the =writeRunList= tool:
 [[file:~/CastData/ExternCode/TimepixAnalysis/Tools/writeRunList/writeRunList.nim]]
based on the tracking logs.

 | Run # | Type          | DataType | Start                  | End                    | Length        | # trackings | # frames | # FADC | Backup? | Notes |
 |-------+---------------+----------+------------------------+------------------------+---------------+-------------+----------+--------+---------+-------|
 |    76 | rtBackground  | rfNewTos | <2017-10-30 Mon 18:39> | <2017-11-02 Thu 5:24>  | 2 days 10:44  |           1 |    88249 |  19856 | y       |       |
 |    77 | rtBackground  | rfNewTos | <2017-11-02 Thu 5:24>  | <2017-11-03 Fri 5:28>  | 1 days 00:03  |           1 |    36074 |   8016 | y       |       |
 |    78 | rtBackground  | rfNewTos | <2017-11-03 Fri 5:28>  | <2017-11-03 Fri 20:45> | 0 days 15:17  |           1 |    23506 |   5988 | y       |       |
 |    79 | rtBackground  | rfNewTos | <2017-11-03 Fri 20:46> | <2017-11-05 Sun 0:09>  | 1 days 03:22  |           1 |    40634 |   8102 | y       |       |
 |    80 | rtBackground  | rfNewTos | <2017-11-05 Sun 0:09>  | <2017-11-05 Sun 23:50> | 0 days 23:40  |           1 |    35147 |   6880 | y       |       |
 |    81 | rtBackground  | rfNewTos | <2017-11-05 Sun 23:54> | <2017-11-07 Tue 0:00>  | 1 days 00:06  |           1 |    35856 |   7283 | y       |       |
 |    82 | rtBackground  | rfNewTos | <2017-11-07 Tue 0:01>  | <2017-11-08 Wed 15:58> | 1 days 15:56  |           2 |    59502 |  12272 | y       |       |
 |    83 | rtCalibration | rfNewTos | <2017-11-08 Wed 16:27> | <2017-11-08 Wed 17:27> | 0 days 00:59  |           0 |     4915 |   4897 | y       |       |
 |    84 | rtBackground  | rfNewTos | <2017-11-08 Wed 17:49> | <2017-11-09 Thu 19:01> | 1 days 01:11  |           1 |    37391 |   7551 | y       |       |
 |    85 | rtBackground  | rfNewTos | <2017-11-09 Thu 19:01> | <2017-11-09 Thu 21:46> | 0 days 02:45  |           0 |     4104 |    899 | y       |       |
 |    86 | rtBackground  | rfNewTos | <2017-11-09 Thu 21:47> | <2017-11-11 Sat 2:17>  | 1 days 04:29  |           1 |    42396 |   9656 | y       |       |
 |    87 | rtBackground  | rfNewTos | <2017-11-11 Sat 2:17>  | <2017-11-12 Sun 14:29> | 1 days 12:11  |           2 |    54786 |  15123 | y       |       |
 |    88 | rtCalibration | rfNewTos | <2017-11-12 Sun 14:30> | <2017-11-12 Sun 15:30> | 0 days 00:59  |           0 |     4943 |   4934 | y       |       |
 |    89 | rtBackground  | rfNewTos | <2017-11-12 Sun 15:30> | <2017-11-13 Mon 18:27> | 1 days 02:57  |           1 |    25209 |   6210 | y       |       |
 |    90 | rtBackground  | rfNewTos | <2017-11-13 Mon 19:14> | <2017-11-14 Tue 20:24> | 1 days 01:09  |           1 |    37497 |   8122 | y       |       |
 |    91 | rtBackground  | rfNewTos | <2017-11-14 Tue 20:24> | <2017-11-15 Wed 21:44> | 1 days 01:20  |           1 |    37732 |   8108 | y       |       |
 |    92 | rtBackground  | rfNewTos | <2017-11-15 Wed 21:45> | <2017-11-17 Fri 19:18> | 1 days 21:32  |           1 |    67946 |  14730 | y       |       |
 |    93 | rtCalibration | rfNewTos | <2017-11-17 Fri 19:18> | <2017-11-17 Fri 20:18> | 0 days 01:00  |           0 |     4977 |   4968 | y       |       |
 |    94 | rtBackground  | rfNewTos | <2017-11-17 Fri 20:48> | <2017-11-19 Sun 2:34>  | 1 days 05:46  |           1 |    44344 |   9422 | y       |       |
 |    95 | rtBackground  | rfNewTos | <2017-11-19 Sun 2:35>  | <2017-11-23 Thu 10:41> | 4 days 08:06  |           1 |   154959 |  33112 | y       |       |
 |    96 | rtCalibration | rfNewTos | <2017-11-23 Thu 10:42> | <2017-11-23 Thu 17:43> | 0 days 07:01  |           0 |    34586 |  34496 | y       |       |
 |    97 | rtBackground  | rfNewTos | <2017-11-23 Thu 17:43> | <2017-11-26 Sun 1:41>  | 2 days 07:57  |           1 |    83404 |  18277 | y       |       |
 |    98 | rtBackground  | rfNewTos | <2017-11-26 Sun 1:42>  | <2017-11-26 Sun 21:18> | 0 days 19:36  |           1 |    29202 |   6285 | y       |       |
 |    99 | rtBackground  | rfNewTos | <2017-11-26 Sun 21:18> | <2017-11-28 Tue 6:46>  | 1 days 09:27  |           1 |    49921 |  10895 | y       |       |
 |   100 | rtBackground  | rfNewTos | <2017-11-28 Tue 6:46>  | <2017-11-29 Wed 6:40>  | 0 days 23:53  |           1 |    35658 |   7841 | y       |       |
 |   101 | rtBackground  | rfNewTos | <2017-11-29 Wed 6:40>  | <2017-11-29 Wed 20:18> | 0 days 13:37  |           1 |    20326 |   4203 | y       |       |
 |   102 | rtCalibration | rfNewTos | <2017-11-29 Wed 20:19> | <2017-11-29 Wed 22:19> | 0 days 02:00  |           0 |     9919 |   9898 | y       |       |
 |   103 | rtBackground  | rfNewTos | <2017-11-29 Wed 22:26> | <2017-12-01 Fri 6:46>  | 1 days 08:19  |           1 |    47381 |   7867 | y       |       |
 |   104 | rtBackground  | rfNewTos | <2017-12-01 Fri 6:47>  | <2017-12-02 Sat 6:48>  | 1 days 00:00  |           1 |    35220 |   5866 | y       |       |
 |   105 | rtBackground  | rfNewTos | <2017-12-02 Sat 6:48>  | <2017-12-03 Sun 6:39>  | 0 days 23:51  |           1 |    34918 |   5794 | y       |       |
 |   106 | rtBackground  | rfNewTos | <2017-12-03 Sun 6:40>  | <2017-12-04 Mon 6:54>  | 1 days 00:14  |           1 |    35576 |   6018 | y       |       |
 |   107 | rtBackground  | rfNewTos | <2017-12-04 Mon 6:54>  | <2017-12-04 Mon 13:38> | 0 days 06:44  |           1 |     9883 |   1641 | y       |       |
 |   108 | rtCalibration | rfNewTos | <2017-12-04 Mon 13:39> | <2017-12-04 Mon 17:39> | 0 days 04:00  |           0 |    19503 |  19448 | y       |       |
 |   109 | rtBackground  | rfNewTos | <2017-12-04 Mon 17:47> | <2017-12-05 Tue 11:20> | 0 days 17:32  |           1 |    28402 |   8217 | y       |       |
 |   110 | rtCalibration | rfNewTos | <2017-12-05 Tue 11:20> | <2017-12-05 Tue 13:20> | 0 days 01:59  |           0 |     9804 |   9786 | y       |       |
 |   111 | rtBackground  | rfNewTos | <2017-12-05 Tue 13:23> | <2017-12-05 Tue 16:17> | 0 days 02:53  |           0 |     4244 |    644 | y       |       |
 |   112 | rtBackground  | rfNewTos | <2017-12-06 Wed 14:50> | <2017-12-10 Sun 6:46>  | 3 days 15:55  |           2 |   128931 |  19607 | y       |       |
 |   113 | rtBackground  | rfNewTos | <2017-12-10 Sun 6:46>  | <2017-12-11 Mon 6:49>  | 1 days 00:03  |           1 |    35100 |   5174 | y       |       |
 |   114 | rtBackground  | rfNewTos | <2017-12-11 Mon 6:50>  | <2017-12-11 Mon 18:33> | 0 days 11:43  |           1 |    17111 |   2542 | y       |       |
 |   115 | rtBackground  | rfNewTos | <2017-12-11 Mon 18:36> | <2017-12-12 Tue 20:58> | 1 days 02:21  |           1 |    40574 |   9409 | y       |       |
 |   116 | rtCalibration | rfNewTos | <2017-12-12 Tue 20:59> | <2017-12-12 Tue 22:59> | 0 days 02:00  |           0 |     9741 |   9724 | y       |       |
 |   117 | rtBackground  | rfNewTos | <2017-12-12 Tue 23:56> | <2017-12-13 Wed 21:29> | 0 days 21:33  |           1 |    31885 |   5599 | y       |       |
 |   118 | rtCalibration | rfNewTos | <2017-12-13 Wed 21:30> | <2017-12-13 Wed 23:30> | 0 days 02:00  |           0 |     9771 |   9748 | y       |       |
 |   119 | rtBackground  | rfNewTos | <2017-12-14 Thu 0:07>  | <2017-12-14 Thu 17:04> | 0 days 16:57  |           1 |    25434 |   4903 | y       |       |
 |   120 | rtCalibration | rfNewTos | <2017-12-14 Thu 17:04> | <2017-12-14 Thu 21:04> | 0 days 04:00  |           0 |    19308 |  19261 | y       |       |
 |   121 | rtBackground  | rfNewTos | <2017-12-14 Thu 21:07> | <2017-12-15 Fri 19:22> | 0 days 22:14  |           1 |    33901 |   6947 | y       |       |
 |   122 | rtCalibration | rfNewTos | <2017-12-15 Fri 19:22> | <2017-12-16 Sat 1:20>  | 0 days 05:57  |           0 |    29279 |  29208 | y       |       |
 |   123 | rtBackground  | rfNewTos | <2017-12-16 Sat 1:21>  | <2017-12-17 Sun 1:06>  | 0 days 23:45  |           1 |    34107 |   3380 | y       |       |
 |   124 | rtBackground  | rfNewTos | <2017-12-17 Sun 1:06>  | <2017-12-19 Tue 2:57>  | 2 days 01:50  |           2 |    71703 |   7504 | y       |       |
 |   125 | rtBackground  | rfNewTos | <2017-12-19 Tue 2:57>  | <2017-12-19 Tue 16:20> | 0 days 13:22  |           1 |    19262 |   1991 | y       |       |
 |   126 | rtCalibration | rfNewTos | <2017-12-19 Tue 16:21> | <2017-12-19 Tue 19:21> | 0 days 02:59  |           0 |    14729 |  14689 | y       |       |
 |   127 | rtBackground  | rfNewTos | <2017-12-19 Tue 19:27> | <2017-12-22 Fri 0:17>  | 2 days 04:50  |           1 |    75907 |   7663 | y       |       |
 |   128 | rtCalibration | rfNewTos | <2017-12-22 Fri 0:18>  | <2017-12-22 Fri 9:23>  | 0 days 09:05  |           0 |    44806 |  44709 | y       |       |
 |   145 | rtCalibration | rfNewTos | <2018-02-17 Sat 17:18> | <2018-02-17 Sat 20:40> | 0 days 03:22  |           0 |    16797 |  16796 | y       |       |
 |   146 | rtBackground  | rfNewTos | <2018-02-17 Sat 20:41> | <2018-02-18 Sun 18:12> | 0 days 21:30  |           1 |    32705 |   3054 | y       |       |
 |   147 | rtCalibration | rfNewTos | <2018-02-18 Sun 18:12> | <2018-02-18 Sun 20:12> | 0 days 01:59  |           0 |    10102 |  10102 | y       |       |
 |   148 | rtBackground  | rfNewTos | <2018-02-18 Sun 20:46> | <2018-02-19 Mon 17:24> | 0 days 20:37  |           1 |    31433 |   3120 | y       |       |
 |   149 | rtCalibration | rfNewTos | <2018-02-19 Mon 17:25> | <2018-02-19 Mon 19:25> | 0 days 02:00  |           0 |     9975 |   9975 | y       |       |
 |   150 | rtBackground  | rfNewTos | <2018-02-19 Mon 19:53> | <2018-02-20 Tue 17:36> | 0 days 21:42  |           1 |    33192 |   3546 | y       |       |
 |   151 | rtCalibration | rfNewTos | <2018-02-20 Tue 17:36> | <2018-02-20 Tue 19:36> | 0 days 01:59  |           0 |     9907 |   9907 | y       |       |
 |   152 | rtBackground  | rfNewTos | <2018-02-20 Tue 21:54> | <2018-02-21 Wed 18:05> | 0 days 20:10  |           1 |    30809 |   3319 | y       |       |
 |   153 | rtCalibration | rfNewTos | <2018-02-21 Wed 18:05> | <2018-02-21 Wed 20:05> | 0 days 01:59  |           0 |    10103 |  10102 | y       |       |
 |   154 | rtBackground  | rfNewTos | <2018-02-21 Wed 21:10> | <2018-02-22 Thu 17:23> | 0 days 20:12  |           1 |    30891 |   3426 | y       |       |
 |   155 | rtCalibration | rfNewTos | <2018-02-22 Thu 17:23> | <2018-02-22 Thu 19:23> | 0 days 02:00  |           0 |     9861 |   9861 | y       |       |
 |   156 | rtBackground  | rfNewTos | <2018-02-23 Fri 6:06>  | <2018-02-23 Fri 17:41> | 0 days 11:35  |           1 |    17686 |   1866 | y       |       |
 |   157 | rtCalibration | rfNewTos | <2018-02-23 Fri 17:41> | <2018-02-23 Fri 19:41> | 0 days 01:59  |           0 |     9962 |   9962 | y       |       |
 |   158 | rtBackground  | rfNewTos | <2018-02-23 Fri 19:42> | <2018-02-26 Mon 8:46>  | 2 days 13:03  |           1 |    93205 |   9893 | y       |       |
 |   159 | rtCalibration | rfNewTos | <2018-02-26 Mon 8:46>  | <2018-02-26 Mon 12:46> | 0 days 04:00  |           0 |    19879 |  19878 | y       |       |
 |   160 | rtBackground  | rfNewTos | <2018-02-26 Mon 14:56> | <2018-03-01 Thu 10:24> | 2 days 19:28  |           1 |   103145 |  11415 | y       |       |
 |   161 | rtCalibration | rfNewTos | <2018-03-01 Thu 10:26> | <2018-03-01 Thu 14:26> | 0 days 04:00  |           0 |    19944 |  19943 | y       |       |
 |   162 | rtBackground  | rfNewTos | <2018-03-01 Thu 17:07> | <2018-03-04 Sun 20:16> | 3 days 03:08  |           3 |   114590 |  11897 | y       |       |
 |   163 | rtCalibration | rfNewTos | <2018-03-04 Sun 20:17> | <2018-03-04 Sun 22:17> | 0 days 02:00  |           0 |    10093 |  10093 | y       |       |
 |   164 | rtBackground  | rfNewTos | <2018-03-04 Sun 22:57> | <2018-03-06 Tue 19:15> | 1 days 20:18  |           2 |    67456 |   6488 | y       |       |
 |   165 | rtCalibration | rfNewTos | <2018-03-06 Tue 19:15> | <2018-03-06 Tue 23:15> | 0 days 04:00  |           0 |    19882 |  19879 | y       |       |
 |   166 | rtBackground  | rfNewTos | <2018-03-07 Wed 0:50>  | <2018-03-07 Wed 18:28> | 0 days 17:38  |           1 |    26859 |   2565 | y       |       |
 |   167 | rtCalibration | rfNewTos | <2018-03-07 Wed 18:29> | <2018-03-07 Wed 20:29> | 0 days 02:00  |           0 |     9938 |   9938 | y       |       |
 |   168 | rtBackground  | rfNewTos | <2018-03-07 Wed 20:37> | <2018-03-13 Tue 16:54> | 5 days 20:16  |           0 |   213545 |  20669 | y       |       |
 |   169 | rtCalibration | rfNewTos | <2018-03-13 Tue 16:55> | <2018-03-13 Tue 22:55> | 0 days 06:00  |           0 |    29874 |  29874 | y       |       |
 |   170 | rtBackground  | rfNewTos | <2018-03-13 Tue 23:19> | <2018-03-14 Wed 21:01> | 0 days 21:42  |           1 |    33098 |   3269 | y       |       |
 |   171 | rtCalibration | rfNewTos | <2018-03-14 Wed 21:01> | <2018-03-14 Wed 23:01> | 0 days 02:00  |           0 |     9999 |   9999 | y       |       |
 |   172 | rtBackground  | rfNewTos | <2018-03-14 Wed 23:06> | <2018-03-15 Thu 17:57> | 0 days 18:50  |           1 |    28649 |   2773 | y       |       |
 |   173 | rtCalibration | rfNewTos | <2018-03-15 Thu 17:59> | <2018-03-15 Thu 19:59> | 0 days 01:59  |           0 |     9898 |   9897 | y       |       |
 |   174 | rtBackground  | rfNewTos | <2018-03-15 Thu 20:39> | <2018-03-16 Fri 16:27> | 0 days 19:48  |           1 |    30163 |   2961 | y       |       |
 |   175 | rtCalibration | rfNewTos | <2018-03-16 Fri 16:28> | <2018-03-16 Fri 18:28> | 0 days 01:59  |           0 |    10075 |  10075 | y       |       |
 |   176 | rtBackground  | rfNewTos | <2018-03-16 Fri 18:35> | <2018-03-17 Sat 20:55> | 1 days 02:19  |           1 |    40084 |   3815 | y       |       |
 |   177 | rtCalibration | rfNewTos | <2018-03-17 Sat 20:55> | <2018-03-17 Sat 22:55> | 0 days 01:59  |           0 |     9967 |   9966 | y       |       |
 |   178 | rtBackground  | rfNewTos | <2018-03-17 Sat 23:31> | <2018-03-22 Thu 17:40> | 4 days 18:09  |           5 |   174074 |  17949 | y       |       |
 |   179 | rtCalibration | rfNewTos | <2018-03-22 Thu 17:41> | <2018-03-22 Thu 19:41> | 0 days 01:59  |           0 |     9887 |   9887 | y       |       |
 |   180 | rtBackground  | rfNewTos | <2018-03-22 Thu 20:47> | <2018-03-24 Sat 18:10> | 1 days 21:22  |           1 |    69224 |   7423 | y       |       |
 |   181 | rtCalibration | rfNewTos | <2018-03-24 Sat 18:10> | <2018-03-24 Sat 22:10> | 0 days 04:00  |           0 |    20037 |  20036 | y       |       |
 |   182 | rtBackground  | rfNewTos | <2018-03-24 Sat 23:32> | <2018-03-26 Mon 19:46> | 1 days 19:14  |           2 |    65888 |   6694 | y       |       |
 |   183 | rtCalibration | rfNewTos | <2018-03-26 Mon 19:47> | <2018-03-26 Mon 23:47> | 0 days 03:59  |           0 |    20026 |  20026 | y       |       |
 |   184 | rtBackground  | rfNewTos | <2018-03-27 Tue 0:32>  | <2018-03-30 Fri 14:18> | 3 days 13:45  |           0 |   130576 |  12883 | y       |       |
 |   185 | rtCalibration | rfNewTos | <2018-03-30 Fri 14:18> | <2018-03-30 Fri 18:18> | 0 days 03:59  |           0 |    19901 |  19901 | y       |       |
 |   186 | rtBackground  | rfNewTos | <2018-03-30 Fri 19:03> | <2018-04-11 Wed 16:03> | 11 days 21:00 |           0 |   434087 |  42830 | y       |       |
 |   187 | rtCalibration | rfNewTos | <2018-04-11 Wed 16:04> | <2018-04-11 Wed 20:04> | 0 days 04:00  |           0 |    19667 |  19665 | y       |       |
 |   188 | rtBackground  | rfNewTos | <2018-04-11 Wed 20:53> | <2018-04-17 Tue 10:53> | 5 days 14:00  |           0 |   204281 |  20781 | y       |       |
 |   239 | rtCalibration | rfNewTos | <2018-10-20 Sat 18:31> | <2018-10-20 Sat 20:31> | 0 days 02:00  |           0 |     9565 |   9518 | y       |       |
 |   240 | rtBackground  | rfNewTos | <2018-10-21 Sun 14:54> | <2018-10-22 Mon 16:15> | 1 days 01:21  |           1 |    38753 |   4203 | y       |       |
 |   241 | rtCalibration | rfNewTos | <2018-10-22 Mon 16:16> | <2018-10-22 Mon 18:16> | 0 days 02:00  |           0 |     9480 |   9426 | y       |       |
 |   242 | rtBackground  | rfNewTos | <2018-10-22 Mon 18:44> | <2018-10-23 Tue 22:08> | 1 days 03:24  |           1 |    41933 |   4843 | y       |       |
 |   243 | rtCalibration | rfNewTos | <2018-10-23 Tue 22:09> | <2018-10-24 Wed 0:09>  | 0 days 01:59  |           0 |     9488 |   9429 | y       |       |
 |   244 | rtBackground  | rfNewTos | <2018-10-24 Wed 0:32>  | <2018-10-24 Wed 19:24> | 0 days 18:52  |           1 |    28870 |   3317 | y       |       |
 |   245 | rtCalibration | rfNewTos | <2018-10-24 Wed 19:25> | <2018-10-24 Wed 21:25> | 0 days 01:59  |           0 |     9573 |   9530 | y       |       |
 |   246 | rtBackground  | rfNewTos | <2018-10-24 Wed 21:59> | <2018-10-25 Thu 16:18> | 0 days 18:18  |           1 |    27970 |   2987 | y       |       |
 |   247 | rtCalibration | rfNewTos | <2018-10-25 Thu 16:19> | <2018-10-25 Thu 18:19> | 0 days 01:59  |           0 |     9389 |   9334 | y       |       |
 |   248 | rtBackground  | rfNewTos | <2018-10-25 Thu 18:25> | <2018-10-26 Fri 22:29> | 1 days 04:04  |           1 |    42871 |   4544 | y       |       |
 |   249 | rtCalibration | rfNewTos | <2018-10-26 Fri 22:30> | <2018-10-27 Sat 0:30>  | 0 days 02:00  |           0 |     9473 |   9431 | y       |       |
 |   250 | rtBackground  | rfNewTos | <2018-10-27 Sat 1:31>  | <2018-10-27 Sat 22:26> | 0 days 20:54  |           1 |    31961 |   3552 | y       |       |
 |   251 | rtCalibration | rfNewTos | <2018-10-27 Sat 22:26> | <2018-10-28 Sun 0:26>  | 0 days 01:59  |           0 |     9551 |   9503 | y       |       |
 |   253 | rtCalibration | rfNewTos | <2018-10-28 Sun 19:18> | <2018-10-28 Sun 21:39> | 0 days 02:20  |           0 |    11095 |  11028 | y       |       |
 |   254 | rtBackground  | rfNewTos | <2018-10-28 Sun 21:40> | <2018-10-29 Mon 23:03> | 1 days 01:23  |           1 |    38991 |   4990 | y       |       |
 |   255 | rtCalibration | rfNewTos | <2018-10-29 Mon 23:03> | <2018-10-30 Tue 1:03>  | 0 days 02:00  |           0 |     9378 |   9330 | y       |       |
 |   256 | rtBackground  | rfNewTos | <2018-10-30 Tue 1:49>  | <2018-10-31 Wed 22:18> | 1 days 20:29  |           1 |    68315 |   8769 | y       |       |
 |   257 | rtCalibration | rfNewTos | <2018-10-31 Wed 22:19> | <2018-11-01 Thu 0:19>  | 0 days 01:59  |           0 |     9648 |   9592 | y       |       |
 |   258 | rtBackground  | rfNewTos | <2018-11-01 Thu 0:20>  | <2018-11-01 Thu 16:15> | 0 days 15:55  |           1 |    24454 |   3103 | y       |       |
 |   259 | rtCalibration | rfNewTos | <2018-11-01 Thu 16:16> | <2018-11-01 Thu 17:31> | 0 days 01:14  |           0 |     5900 |   5864 | y       |       |
 |   260 | rtCalibration | rfNewTos | <2018-11-01 Thu 17:39> | <2018-11-01 Thu 19:09> | 0 days 01:30  |           0 |     7281 |   7251 | y       |       |
 |   261 | rtBackground  | rfNewTos | <2018-11-01 Thu 19:39> | <2018-11-04 Sun 15:23> | 2 days 19:43  |           3 |   103658 |  12126 | y       |       |
 |   262 | rtCalibration | rfNewTos | <2018-11-04 Sun 15:24> | <2018-11-04 Sun 21:24> | 0 days 05:59  |           0 |    28810 |  28681 | y       |       |
 |   263 | rtBackground  | rfNewTos | <2018-11-05 Mon 0:35>  | <2018-11-05 Mon 20:28> | 0 days 19:52  |           1 |    30428 |   3610 | y       |       |
 |   264 | rtCalibration | rfNewTos | <2018-11-05 Mon 20:28> | <2018-11-05 Mon 22:28> | 0 days 01:59  |           0 |     9595 |   9544 | y       |       |
 |   265 | rtBackground  | rfNewTos | <2018-11-05 Mon 22:52> | <2018-11-07 Wed 22:14> | 1 days 23:21  |           1 |    72514 |   8429 | y       |       |
 |   266 | rtCalibration | rfNewTos | <2018-11-07 Wed 22:14> | <2018-11-08 Thu 0:14>  | 0 days 01:59  |           0 |     9555 |   9506 | y       |       |
 |   267 | rtBackground  | rfNewTos | <2018-11-08 Thu 2:05>  | <2018-11-08 Thu 6:54>  | 0 days 04:48  |           0 |     7393 |    929 | y       |       |
 |   268 | rtBackground  | rfNewTos | <2018-11-09 Fri 6:15>  | <2018-11-09 Fri 17:20> | 0 days 11:04  |           1 |    16947 |   1974 | y       |       |
 |   269 | rtCalibration | rfNewTos | <2018-11-09 Fri 17:20> | <2018-11-09 Fri 21:20> | 0 days 04:00  |           0 |    19382 |  19302 | y       |       |
 |   270 | rtBackground  | rfNewTos | <2018-11-09 Fri 21:27> | <2018-11-11 Sun 21:02> | 1 days 23:34  |           2 |    72756 |   8078 | y       |       |
 |   271 | rtCalibration | rfNewTos | <2018-11-11 Sun 21:03> | <2018-11-11 Sun 23:46> | 0 days 02:43  |           0 |    13015 |  12944 | y       |       |
 |   272 | rtBackground  | rfNewTos | <2018-11-12 Mon 0:09>  | <2018-11-14 Wed 19:07> | 2 days 18:58  |           3 |   102360 |  11336 | y       |       |
 |   273 | rtCalibration | rfNewTos | <2018-11-14 Wed 19:08> | <2018-11-14 Wed 21:08> | 0 days 01:59  |           0 |     9535 |   9471 | y       |       |
 |   274 | rtBackground  | rfNewTos | <2018-11-14 Wed 21:28> | <2018-11-17 Sat 18:14> | 2 days 20:45  |           3 |   105187 |  12101 | y       |       |
 |   275 | rtCalibration | rfNewTos | <2018-11-17 Sat 18:14> | <2018-11-17 Sat 20:57> | 0 days 02:43  |           0 |    13179 |  13116 | y       |       |
 |   276 | rtBackground  | rfNewTos | <2018-11-17 Sat 22:08> | <2018-11-22 Thu 2:26>  | 4 days 04:17  |           2 |   153954 |  19640 | y       |       |
 |   277 | rtCalibration | rfNewTos | <2018-11-22 Thu 2:26>  | <2018-11-22 Thu 16:14> | 0 days 13:48  |           0 |    66052 |  65749 | y       |       |
 |   278 | rtBackground  | rfNewTos | <2018-11-22 Thu 16:14> | <2018-11-23 Fri 10:51> | 0 days 18:36  |           0 |    28164 |   3535 | y       |       |
 |   279 | rtBackground  | rfNewTos | <2018-11-24 Sat 10:51> | <2018-11-26 Mon 14:58> | 2 days 04:07  |           2 |    79848 |   9677 | y       |       |
 |   280 | rtCalibration | rfNewTos | <2018-11-26 Mon 14:59> | <2018-11-26 Mon 18:59> | 0 days 04:00  |           0 |    19189 |  19112 | y       |       |
 |   281 | rtBackground  | rfNewTos | <2018-11-26 Mon 19:02> | <2018-11-28 Wed 18:07> | 1 days 23:04  |           1 |    72230 |   8860 | y       |       |
 |   282 | rtCalibration | rfNewTos | <2018-11-28 Wed 18:07> | <2018-11-28 Wed 20:51> | 0 days 02:43  |           0 |    12924 |  12860 | y       |       |
 |   283 | rtBackground  | rfNewTos | <2018-11-28 Wed 22:31> | <2018-12-01 Sat 14:38> | 2 days 16:07  |           3 |    98246 |  11965 | y       |       |
 |   284 | rtCalibration | rfNewTos | <2018-12-01 Sat 14:39> | <2018-12-01 Sat 18:39> | 0 days 03:59  |           0 |    19017 |  18904 | y       |       |
 |   285 | rtBackground  | rfNewTos | <2018-12-01 Sat 19:06> | <2018-12-03 Mon 19:39> | 2 days 00:33  |           2 |    74405 |   8887 | y       |       |
 |   286 | rtCalibration | rfNewTos | <2018-12-04 Tue 15:57> | <2018-12-04 Tue 17:57> | 0 days 02:00  |           0 |     9766 |   9715 | y       |       |
 |   287 | rtBackground  | rfNewTos | <2018-12-04 Tue 19:07> | <2018-12-05 Wed 15:08> | 0 days 20:01  |           1 |    30598 |   3393 | y       |       |
 |   288 | rtCalibration | rfNewTos | <2018-12-05 Wed 17:28> | <2018-12-05 Wed 19:28> | 0 days 02:00  |           0 |     9495 |   9443 | y       |       |
 |   289 | rtBackground  | rfNewTos | <2018-12-05 Wed 23:07> | <2018-12-06 Thu 19:11> | 0 days 20:03  |           1 |    30629 |   3269 | y       |       |
 |   290 | rtCalibration | rfNewTos | <2018-12-06 Thu 19:11> | <2018-12-06 Thu 21:11> | 0 days 02:00  |           0 |     9457 |   9394 | y       |       |
 |   291 | rtBackground  | rfNewTos | <2018-12-06 Thu 23:14> | <2018-12-08 Sat 13:39> | 1 days 14:24  |           2 |    58602 |   6133 | y       |       |
 |   292 | rtCalibration | rfNewTos | <2018-12-08 Sat 13:39> | <2018-12-08 Sat 15:39> | 0 days 02:00  |           0 |     9475 |   9426 | y       |       |
 |   293 | rtBackground  | rfNewTos | <2018-12-08 Sat 17:42> | <2018-12-10 Mon 21:50> | 2 days 04:07  |           1 |    79677 |   8850 | y       |       |
 |   294 | rtCalibration | rfNewTos | <2018-12-10 Mon 21:50> | <2018-12-10 Mon 23:50> | 0 days 02:00  |           0 |     9514 |   9467 | y       |       |
 |   295 | rtBackground  | rfNewTos | <2018-12-11 Tue 0:54>  | <2018-12-11 Tue 20:31> | 0 days 19:37  |           1 |    29981 |   3271 | y       |       |
 |   296 | rtCalibration | rfNewTos | <2018-12-11 Tue 20:31> | <2018-12-11 Tue 22:31> | 0 days 02:00  |           0 |     9565 |   9517 | y       |       |
 |   297 | rtBackground  | rfNewTos | <2018-12-12 Wed 0:14>  | <2018-12-13 Thu 18:30> | 1 days 18:15  |           2 |    68124 |  12530 | y       |       |
 |   298 | rtBackground  | rfNewTos | <2018-12-13 Thu 18:39> | <2018-12-15 Sat 6:41>  | 1 days 12:01  |           1 |    53497 |      0 | y       |       |
 |   299 | rtBackground  | rfNewTos | <2018-12-15 Sat 6:43>  | <2018-12-15 Sat 18:13> | 0 days 11:29  |           1 |    17061 |      0 | y       |       |
 |   300 | rtCalibration | rfNewTos | <2018-12-15 Sat 18:38> | <2018-12-15 Sat 20:38> | 0 days 02:00  |           0 |     9466 |   9415 | y       |       |
 |   301 | rtBackground  | rfNewTos | <2018-12-15 Sat 21:34> | <2018-12-17 Mon 14:17> | 1 days 16:43  |           2 |    62454 |   7751 | y       |       |
 |   302 | rtCalibration | rfNewTos | <2018-12-17 Mon 14:18> | <2018-12-17 Mon 16:18> | 0 days 01:59  |           0 |     9616 |   9577 | y       |       |
 |   303 | rtBackground  | rfNewTos | <2018-12-17 Mon 16:52> | <2018-12-18 Tue 16:41> | 0 days 23:48  |           1 |    36583 |   4571 | y       |       |
 |   304 | rtCalibration | rfNewTos | <2018-12-19 Wed 9:33>  | <2018-12-19 Wed 11:33> | 0 days 01:59  |           0 |     9531 |   9465 | y       |       |
 |   306 | rtBackground  | rfNewTos | <2018-12-20 Thu 6:55>  | <2018-12-20 Thu 11:53> | 0 days 04:58  |           1 |     7546 |    495 | y       |       |

** Automatically calculated total run times

Run period 2 (= 2017/18): 
#+BEGIN_SRC 
Type: rtBackground
         trackingDuration: 4 days, 10 hours, and 20 seconds
         nonTrackingDuration: 14 weeks, 2 days, 1 hour, 23 minutes, and 18 seconds
Type: rtCalibration
         trackingDuration: 0 nanoseconds
         nonTrackingDuration: 4 days, 11 hours, 25 minutes, and 20 seconds
#+END_SRC

Which amounts to:
Calibration data: 107.42 h
Background data: 2401.40 h
Tracking data: 106 h

Run period 3 (= Oct-Dec 2018):
#+BEGIN_SRC
Type: rtBackground
         trackingDuration: 3 days, 2 hours, 17 minutes, and 53 seconds
         nonTrackingDuration: 6 weeks, 4 days, 20 hours, 54 minutes, and 29 seconds
Type: rtCalibration
         trackingDuration: 0 nanoseconds
         nonTrackingDuration: 3 days, 15 hours, 3 minutes, and 45 seconds
#+END_SRC

Which amounts to:
Calibration data: 87.05 h
Background data: 1124.9 h
Tracking data: 74.29 h

So in total:
Calibration data: 194.47 h
Background data: 3526.3 h
Tracking data: 180.29 h

** InGrid temperature from shift forms

Due to the bug in TOS that caused the temperature log files to be
placed in =./TOS/log/= instead of the respective run folders, the
files were overwritten periodically it seems.

The only temperature information we still have from it thus is the
shift forms.

There are also pictures of every shift form in my googlo photos.

| Run number | Date                   | Temp / ° | Notes                                          |
|------------+------------------------+----------+------------------------------------------------|
|         76 | <2017-10-17 Tue 05:00> |        - | Not written down yet                           |
|         77 | <2017-11-02 Thu 05:25> |    40.50 |                                                |
|         78 | <2017-11-03 Fri 05:25> |    40.30 |                                                |
|         79 | <2017-11-04 Sat 05:30> |    40.63 |                                                |
|         80 | <2017-11-05 Sun 05:30> |    40.80 |                                                |
|         81 | <2017-11-06 Mon 06:07> |    40.27 |                                                |
|         82 | <2017-11-07 Tue 06:00> |    40.10 |                                                |
|         82 | <2017-11-08 Wed 05:32> |        - | Wrote 2nd val: 22.73                           |
|         84 | <2017-11-09 Thu 05:33> |    40.22 |                                                |
|         86 | <2017-11-10 Fri 05:32> |    40.13 |                                                |
|         87 | <2017-11-11 Sat 05:36> |    40.00 |                                                |
|         87 | <2017-11-12 Sun 06:07> |    40.31 |                                                |
|         89 | <2017-11-13 Mon 05:40> |    39.87 |                                                |
|         90 | <2017-11-14 Tue 05:40> |    39.74 |                                                |
|         91 | <2017-11-15 Wed 05:35> |    39.68 |                                                |
|         92 | <2017-11-17 Fri 05:36> |    39.72 |                                                |
|         94 | <2017-11-18 Sat 05:38> |    39.72 |                                                |
|         95 | <2017-11-19 Sun 05:44> |    39.70 |                                                |
|         97 | <2017-11-25 Sat 05:52> |    40.35 |                                                |
|         98 | <2017-11-26 Sun 06:28> |    39.70 |                                                |
|         99 | <2017-11-27 Mon 06:25> |    39.61 |                                                |
|        100 | <2017-11-28 Tue 06:35> |    38.93 |                                                |
|        101 | <2017-11-29 Wed 06:35> |    38.72 |                                                |
|        103 | <2017-11-30 Thu 06:32> |    39.70 |                                                |
|        104 | <2017-12-01 Fri 06:42> |    38.68 |                                                |
|        105 | <2017-12-02 Sat 06:40> |    39.46 |                                                |
|        106 | <2017-12-03 Sun 06:36> |    39.46 |                                                |
|        107 | <2017-12-04 Mon 06:50> |    38.67 |                                                |
|        109 | <2017-12-05 Tue 06:35> |    38.31 |                                                |
|        112 | <2017-12-07 Thu 06:45> |    38.46 |                                                |
|        112 | <2017-12-09 Sat 06:38> |    39.79 |                                                |
|        113 | <2017-12-10 Sun 06:37> |    38.56 |                                                |
|        114 | <2017-12-11 Mon 06:45> |    38.86 |                                                |
|        115 | <2017-12-12 Tue 06:45> |    39.86 |                                                |
|        117 | <2017-12-13 Wed 06:41> |    39.71 |                                                |
|        119 | <2017-12-14 Thu 06:42> |    40.32 |                                                |
|        121 | <2017-12-15 Fri 06:45> |    39.95 |                                                |
|        123 | <2017-12-16 Sat 06:42> |    40.03 |                                                |
|        124 | <2017-12-17 Sun 06:47> |    39.96 |                                                |
|        124 | <2017-12-18 Mon 06:45> |    40.07 |                                                |
|        125 | <2017-12-19 Tue 06:44> |    40.61 |                                                |
|        127 | <2017-12-20 Wed 06:46> |    40.75 |                                                |
|        137 | <2018-02-15 Thu 05:48> |        - | Start of 2018 data taking, temp readout broken |
|        140 | <2018-02-16 Fri 05:44> |        - |                                                |
|        146 | <2018-02-18 Sun 06:15> |        - |                                                |
|        148 | <2018-02-19 Sun 06:12> |        - |                                                |
|        150 | <2018-02-20 Tue 06:00> |        - |                                                |
|        152 | <2018-02-21 Wed 06:12> |        - |                                                |
|        154 | <2018-02-22 Thu 06:14> |        - |                                                |
|        156 | <2018-02-23 Fri 05:58> |        - |                                                |
|        158 | <2018-02-24 Sat 06:15> |        - |                                                |
|        160 | <2018-02-28 Wed 06:01> |        - |                                                |
|        162 | <2018-03-02 Fri 05:58> |        - |                                                |
|        162 | <2018-03-03 Tue 06:03> |        - |                                                |
|        162 | <2018-03-04 Sun 05:57> |        - |                                                |
|        164 | <2018-03-05 Mon 06:00> |        - |                                                |
|        164 | <2018-03-06 Tue 06:00> |        - |                                                |
|        166 | <2018-03-07 Wed 05:44> |        - |                                                |
|        170 | <2018-03-14 Wed 05:35> |        - |                                                |
|        172 | <2018-03-15 Thu 05:29> |        - |                                                |
|        174 | <2018-03-16 Fri 05:30> |        - |                                                |
|        176 | <2018-03-17 Sat 05:25> |        - |                                                |
|        178 | <2018-03-18 Sun 05:24> |        - |                                                |
|        178 | <2018-03-19 Mon 05:22> |        - |                                                |
|        178 | <2018-03-20 Tue 05:16> |        - |                                                |
|        178 | <2018-03-21 Wed 05:15> |        - |                                                |
|        178 | <2018-03-22 Thu 05:12> |        - |                                                |
|        180 | <2018-03-23 Fri 05:12> |        - |                                                |
|        180 | <2018-03-24 Sat 05:17> |        - |                                                |
|        182 | <2018-03-25 Sun 06:07> |        - |                                                |
|        182 | <2018-03-26 Mon 06:07> |        - |                                                |
|        240 | <2018-10-22 Mon 06:38> |    48.27 | Begin of Run 3 period                          |
|        242 | <2018-10-23 Tue 06:38> |    48.61 |                                                |
|        244 | <2018-10-24 Wed 06:45> |    48.70 |                                                |
|        246 | <2018-10-25 Thu 06:47> |    49.83 |                                                |
|        248 | <2018-10-26 Fri 06:47> |    49.37 |                                                |
|        250 | <2018-10-27 Sat 06:46> |    47.55 |                                                |
|        252 | <2018-10-28 Sun 05:40> |    47.16 |                                                |
|        254 | <2018-10-29 Mon 05:55> |    45.77 |                                                |
|        256 | <2018-10-30 Tue 05:33> |    45.56 |                                                |
|        258 | <2018-11-01 Thu 05:50> |    46.15 |                                                |
|        261 | <2018-11-02 Fri 06:10> |    46.65 |                                                |
|        261 | <2018-11-03 Sat 05:53> |    47.02 |                                                |
|        261 | <2018-11-04 Sun 06:14> |    47.97 |                                                |
|        263 | <2018-11-05 Mon 06:14> |    47.94 |                                                |
|        265 | <2018-11-06 Tue 05:53> |    47.27 |                                                |
|        268 | <2018-11-09 Fri 06:00> |    47.66 |                                                |
|        270 | <2018-11-10 Sat 06:04> |    48.39 |                                                |
|        270 | <2018-11-11 Sun 06:11> |    48.43 |                                                |
|        272 | <2018-11-12 Mon 06:10> |    48.69 |                                                |
|        272 | <2018-11-13 Tue 06:04> |    48.59 |                                                |
|        272 | <2018-11-14 Wed 06:10> |    48.96 |                                                |
|        274 | <2018-11-15 Thu 06:10> |    48.57 |                                                |
|        274 | <2018-11-16 Fri 06:07> |    48.60 |                                                |
|        274 | <2018-11-17 Sat 06:03> |    47.98 |                                                |
|        276 | <2018-11-18 Sun 06:05> |    47.70 |                                                |
|        276 | <2018-11-19 Mon 06:10> |    47.36 |                                                |
|        278 | <2018-11-24 Sat 06:22> |    46.60 |                                                |
|        279 | <2018-11-25 Sun 06:29> |    46.74 |                                                |
|        279 | <2018-11-26 Mon 06:26> |    46.67 |                                                |
|        281 | <2018-11-27 Tue 06:20> |    46.57 |                                                |
|        283 | <2018-11-29 Thu 06:22> |    46.31 |                                                |
|        283 | <2018-11-30 Fri 06:26> |    46.76 |                                                |
|        283 | <2018-12-01 Sat 06:29> |    46.83 |                                                |
|        285 | <2018-12-02 Sun 06:26> |    46.75 |                                                |
|        285 | <2018-12-03 Mon 06:28> |    46.62 |                                                |
|        287 | <2018-12-05 Wed 06:28> |    47.10 |                                                |
|        289 | <2018-12-06 Thu 06:29> |    47.44 |                                                |
|        291 | <2018-12-07 Fri 06:31> |    46.23 |                                                |
|        291 | <2018-12-08 Sat 06:35> |    46.13 |                                                |
|        293 | <2018-12-09 Sun 06:32> |    46.02 |                                                |
|        293 | <2018-12-10 Mon 06:32> |    45.78 |                                                |
|        295 | <2018-12-11 Tue 06:33> |    45.41 |                                                |
|        297 | <2018-12-12 Wed 06:37> |    44.38 |                                                |
|        297 | <2018-12-13 Thu 06:35> |    44.50 |                                                |
|        298 | <2018-12-14 Fri 06:40> |    44.74 |                                                |
|        299 | <2018-12-15 Sat 06:43> |    44.50 |                                                |
|        301 | <2018-12-16 Sun 06:41> |    44.44 |                                                |
|        301 | <2018-12-17 Mon 06:26> |    45.03 |                                                |
|        303 | <2018-12-18 Tue 06:52> |    44.69 |                                                |
|        306 | <2018-12-20 Thu 06:30> |    40.04 |                                                |


* CAST operation procedures                                        :Appendix:
:PROPERTIES:
:CUSTOM_ID: sec:appendix:cast_operations
:END:

This chapter provides some guidance about typical operations necessary
during maintenance or installation of the detector / vacuum system.

** Ramping the HV

The high voltage supply can be controlled in two different
ways. Besides differing in usability terms (one is manual, the other
automatic), the main difference between the two is the HV interlock,
which is only partially usable in case of the manual HV control.
1. in the manual way using the Linux software supplied by iseg. On the
   InGrid-DAQ computer it is located in
   [[file:/home/ingrid/src/isegControl/isegControl][~/src/isegControl/isegControl]]. Depending on the setup of the
   machine, the software may need superuser rights to access the USB
   connection. With the software the given channel as shown in
   tab. [[tab:hv]] can be set up and the HV can be ramped up. Note: one
   needs to activate SetKillEnable such that the HV is shut down in
   case of a current trip (exceeding of specified current). One should
   then set 'groups' of different channels, so that grid, anode and
   ring 1 are shut down at the same time, in case of a current trip,
   as well as ring 29 and the cathode! In addition the trip current
   needs to be manually set about a factor 5 higher during ramping,
   because of capacitors, which need to be charged first. Otherwise
   the channels trip immediately. In this case the HV interlock is
   restricted to basic current restrictions. Anything detector related
   is not included!
2. in the automatic way via the TOS. The TOS takes care of everything
   mentioned above. To use the TOS for the HV control (and thus also
   use the complete HV interlock, as it exists at the moment), perform
   the following steps:
   1. check [[file:~/TOS/config/HFM_settings.ini][~/TOS/config/HFM_settings.ini]] and compare with tab. [[tab:hv]]
      whether settings seem reasonable
   2. after starting TOS and setting up the chips, call
      #+BEGIN_SRC sh
      > ActivateHFM
      #+END_SRC
      which will set up TOS to use the combined HV and FADC (due to
      both inside the same VME crate, they are intertwined). This
      configures the FADC and reads the desired HV settings, but does
      not set the HV settings on the module yet.
   3. to write the HV to the HV module, call
      #+BEGIN_SRC sh
      > InitHV
      #+END_SRC
      which will write the HV settings from HFM_settings.ini to the HV
      module. At the end it will ask the user, whether the HV should
      be ramped up:
      #+BEGIN_SRC sh
      Do you wish to ramp up the channels now? (Y / n)
      #+END_SRC
      If yes, the ramping progress will be shown via calls to the
      CheckModuleIsRamping() function (which can also be called
      manually in TOS). 
   This should properly ramp up all channels. It is possible that TOS
   fails to connect to the VME crate and hence is not able to ramp up
   the channels. The most likely reason for this is that the
   isegControl software is still open, since only one application can
   access a single USB interface at the same time.

** Vacuum

The vacuum system as described in sec. [[#sec:cast:vacuum_system]] usually does not
require manual intervention during normal operation.

For maintenance the following two sections describe how to pump the
system safely as well as how to flush it with nitrogen. Both processes
are rather delicate due to the sensitive $\ce{Si_x N_y}$
window. Pumping needs to be done slowly, $O(\SI{1}{\milli\bar \per
\second})$. To be able to do this, the needle valve
$V_{\text{Needle}}$ (cf. fig. [[fig:cast:vacuum-schematic]]) is installed. One
may separate the vacuum volume into two separate vacua. A bad vacuum
before the primary pump and after the turbo pumps T1 and T2 and a good
vacuum before the turbo pump T2. There are three connections from the
good vacuum to the bad one. 
1. through T2, closable via $V_{\text{T2}}$, $\SI{40}{\mm}$ tubing
2. through the needle valve $V_{\text{needle}}$, $\SI{16}{\mm}$ tubing
3. through T1 via the manipulator interstage, normally closed (see the
  note below), $\SI{25}{\mm}$ tubing
3 is mainly irrelevant for pumping purposes, since there is no valve
to open or close; it is always closed by a 2-O-ring seal to the good
vacuum. While 1 is the main path for pumping during operation, it is 2
which is used during a pumping down or flushing of the system, since
it can be controlled very granularly. 

For both explanations below, it is very important to always think
about each step (are the correct valves open / closed? etc.). A small
mistake can lead to severe damage of the hardware (turbo pumps can
break, the window can rupture).

_Note_: There is a third very small vacuum volume before T1, which is
the volume up to the manipulator interstage. This volume is separate
from the main good vacuum chamber, due to a 2-O-ring seal on both ends
of the manipulator. Compare with fig. [[fig:cast:vacuum-schematic]] at the
location of the two clamped flanges 'above' the manipulator. One
2-O-ring seal is at the upper flange and one at the lower. This is
because the manipulator part furthest from the beampipe is under
air. In order to seal the air and the vacuum especially during
movement of the source, these seals are in place. However, while the
2-O-ring seals provide decent sealing, it is not perfect. This is why
the small turbo pump T1 is in place at all, to reduce the amount of
air, which might enter the system during source manipulation. Another
aspect to keep in mind is potential air, which can get trapped in
between the two O-rings. This air will be released during movement of
the seals. Especially after the system was open to air, it is expected
that a small pressure increase on $P_{\text{MM}}$ can be seen during
operation, despite T1 being in place. After several movement cycles,
$O(10)$, these peaks should be negligible.

*** Pumping the vacuum

Before pumping it is a good idea to connect two linear gauges to the
two $P_{\text{Linear}}$ pressure sensors.
To pump the system safely, perform the following steps:
1. Make sure every pump is turned off.
2. Make sure every valve in the system is closed:
   1. $V_{\text{Primary}}$
   2. $V_{\text{Leak}}$
   3. $V_{\text{T2}}$
   4. $V_{\text{Needle}}$
3. Connect a linear gauge to $P_{\text{P, Linear}}$ on the primary pump line.
4. Start the primary pump. Tubing up to $V_{\text{Primary}}$ will be
   pumped, visible on linear gauge connected to
   $P_{\text{P, Linear}}$. Check that the second linear gauge remains
   unchanged, if not $V_{\text{Primary}}$ and $V_{\text{Needle}}$ is
   open!
5. Once $P_{\text{P, Linear}}$ shows $\leq \SI{10}{\milli bar}$,
   slowly open $V_{\text{Primary}}$, again checking $P_{\text{N,
   Linear}}$ remains unchanged. This will increase the pressure on
   $P_{\text{P, Linear}}$ again until the volume is pumped.
6. This step is the most crucial. With $V_{\text{T2}}$ still closed,
   very carefully open $V_{\text{Needle}}$, while keeping an eye on
   $P_{\text{N, Linear}}$. Note that $V_{\text{Needle}}$ has two
   locking mechanisms. The knob at the end with the analog indicator
   and a general lock in front of that. While the analog indicator
   shows =000=, open the general lock. Then slowly start turning the
   knob. At around =300= the pressure on $P_{\text{N, Linear}}$ should
   slowly start to decrease. Keep turning the knob until you reach a
   pump rate of $O(\SI{1}{\milli \bar \per \second})$. You will have
   to keep opening the needle valve further, the lower the pressure is
   to keep the pump rate constant.
7. Once both linear gauges have equalized (up to different offsets),
   close the needle valve again.
8. Open $V_{\text{T2}}$.
9. Start T2 by turning on the power and pressing the right most
   button. Use the arrow buttons to select the 'actual RPM' setting to
   see that the turbo is spinning up. Final speed should be set to
   $\SI{1500}{\Hz}$.
10. While T2 is spinning up, start T1 by turning on the power at the
    back. There is no additional button to be pressed.

The system should now be in the following state:
- $V_{\text{Leak}}$ closed
- $V_{\text{Needle}}$ closed
- $V_{\text{T2}}$ open
- $V_{\text{Primary}}$ open
- T2 & T1 running
- Primary pump running
If so, the system is now pumping. Note that it may take several days
to reach a vacuum good enough to satisfy the interlock.

*** Flushing the system

Flushing the system is somewhat of a reverse of pumping the
system. Follow these steps to safely flush the system with
nitrogen. See section [[Nitrogen supply]] for an explanation of which
valves need to be operated to open the nitrogen line.
Before flushing the system connect two linear gauges to both
$P_{\text{Linear}}$ sensors.
1. Make sure the turbo pumps are turned off, if not yet turn both off
   and wait for them to have come to a halt.
2. Turn off the primary pump.
3. Close $V_{\text{T2}}$. $V_{\text{Leak}}$ and $V_{\text{Needle}}$
   should already be closed, while $V_{\text{T2}}$ and
   $V_{\text{Primary}}$ should still be open.
4. Connect the nitrogen line to the blind flange before
   $V_{\text{Leak}}$. 
5. Slowly open $V_{\text{Leak}}$, while checking both linear
   gauges. Make sure only the pressure on $P_{\text{P, Linear}}$
   increases, while $P_{\text{N, Linear}}$ remains under vacuum. If
   not, another valve is still open. Close $V_{\text{Leak}}$
   immediately again!
6. Keep flushing nitrogen, until $P_{\text{P, Linear}}$ gets close to
   $\SI{1000}{\milli\bar}$ (the sensors will never actually reach
   that value).
7. Close $V_{\text{Leak}}$ again to make sure you do not put the
   system over one atmosphere of pressure.
8. This step is the most crucial. With $V_{\text{T2}}$ still closed,
   very carefully open $V_{\text{Needle}}$, while keeping an eye on
   $P_{\text{N, Linear}}$. Note that $V_{\text{Needle}}$ has two
   locking mechanisms. The knob at the end with the analog indicator
   and a general lock in front of that. While the analog indicator
   shows =000=, open the general lock. Then slowly start turning the
   knob. At around =300= the pressure on $P_{\text{N, Linear}}$ should
   slowly start to increase. Keep turning the knob until you reach a
   pump rate of $O(\SI{1}{\milli \bar \per \second})$.
9. You will notice that the pressure on $P_{\text{P, Linear}}$ will
   start to decrease, since the air will distribute in a larger
   volume. Open $V_{\text{Leak}}$ again slightly to keep $P_{\text{P,
   Linear}}$ roughly constant.
10. Keep flushing with $\SI{1}{\milli\bar\per\second}$ until both
    sensors read $O(\SI{1000}{\milli\bar})$.
11. Close all valves in the system again.

This way the system is safely flushed with nitrogen. This helps to
pump faster after a short maintenance, because less humidity can enter
the system.

** COMMENT Gas supply

If the requirements of the gas supply interlock are satisfied
(cf. sec. [[Gas supply interlock]]), it is possible to flush the detector
with gas. For that, follow these steps:
1. Make sure the pressure controller is connected and running. Check
   InGrid-PLC computer in control room and see if pressure control
   software is running. If gas supply is currently closed, reported
   pressure inside the detector is usually reported to
   $\SIrange{960}{980}{\milli\bar}$.
2. Outside the building, open the main valve of the currently active
   gas bottle (check the arrow on the bottle selector mechanism). See
   fig. [[fig:gas-bottle-outside]].
3. Open the second valve near the bottle.
4. Pressure values should be:
   - gas bottle: $\sim\SIrange{30}{100}{\bar}$
   - pre-line pressure: $\sim\SI{7}{\bar}$
   - line pressure: $\sim\SI{0.45}{\bar}$
5. Activate the gas supply at the interlock box by turning the key to
   =Security on= and pressing the large button. See
   fig. [[fig:interlock-box]].
6. Go to the airport side of the magnet. Open the valve on the InGrid
   gas panel below the telescope platform. See
   fig. [[fig:ingrid-gas-panel]].
7. Slowly open the needle valve on the flow meter on the previous
   panel. Increase gas flow up to $\sim\SI{2}{\liter\per\hour}$.
8. Open the needle valve on the gas supply line on the side of the
   platform (see fig. [[fig:gas-needle-valve]]).
9. After $\SIrange{5}{10}{\minute}$ the pressure controller on the
   InGrid-PLC computer should report $\SI{1050}{\milli\bar}$.
# 7. Make sure the electrovalves on the second gas panel (see
#    fig. NOT HERE. NO PANEL) are open. THESE VALVES CANNOT BE CHECKED
#    EXPLICITLY. IF INTERLOCK BOX IS ACTIVE, WILL BE OPEN?! MAYBE CHECK
#    BOX POWER SUPPLY? NO LED I THINK.


Now the detector should be flushed with $\ce{Ar} /
\ce{iC_4H_{10}}$. Before turning on the HV, make sure to flush for at
least $\SI{12}{\hour}$ to be on the safe side.

#+CAPTION: Location of the Argon-Isobutane bottle and the main valves outside the building.
#+NAME: fig:gas-bottle-outside
[[file:~/org/Doc/Detector/figs/gas_bottles_outside.jpg]]


#+CAPTION: Location of the gas interlock box
#+NAME: fig:interlock-box
[[file:~/org/Doc/Detector/figs/gas_interlock_box.jpg]]

#+CAPTION: Location of the InGrid gas panel below the telescope platform on the airport side.
#+NAME: fig:ingrid-gas-panel
[[file:~/org/Doc/Detector/figs/gas_panel.jpg]]

#+CAPTION: Location of the needle valve on the gas supply line
#+NAME: fig:gas-needle-valve
<file to be inserted>

** Nitrogen supply

Nitrogen is supplied by a nitrogen bottle outside the building. To
open the nitrogen line, 5 valves need to be opened. The line ends in a
copper pipe on the airport side, which is usually there rolled up (the
copper is somewhat flexible).
1. Open the lever on the nitrogen bottle outside the building (see
   fig. [[fig:nitrogen-bottle-outside]]).
2. Open the valve next to the bottle.
3. Go to the gas lines next to the control room. The right most line
   (see fig. [[fig:valves-control-room]] and
   fig. [[fig:nitrogen-valve-control-room]]) is the nitrogen line. Open
   the valve.
4. Open the needle valve on the flow meter to the right of the
   previous valve.
5. Open the needle valve on the airport side of the magnet (see
   fig. [[fig:nitrogen-airport-side]]).
This should be all to open the nitrogen line. The flow through the
pipe is not too large, but it should be large enough to feel it on the
back of the hand.

#+CAPTION: Location of the Nitrogen bottle and the main valves outside the building.
#+NAME: fig:nitrogen-bottle-outside
[[file:~/org/Doc/Detector/figs/nitrogen_bottle.jpg]]

#+CAPTION: Location of the valves next to the control room
#+NAME: fig:valves-control-room
[[file:~/org/Doc/Detector/figs/nitrogen_valve_location.jpg]]

#+CAPTION: The actual nitrogen valve on the set of valves near the control room.
#+NAME: fig:nitrogen-valve-control-room
[[file:~/org/Doc/Detector/figs/nitrogen_valve.jpg]]


#+CAPTION: Location of the flow meter near the valve next to the control room
#+NAME: fig:nitrogen-flow-meter-control-room
[[file:~/org/Doc/Detector/figs/nitrogen_flow_meter.jpg]]

#+CAPTION: Location of the needle valve on the airport side
#+NAME: fig:nitrogen-airport-side
<file to be inserted>


#+BEGIN_EXPORT latex
\newpage
#+END_EXPORT

* Cabling & software setup [/]                                     :Appendix:
:PROPERTIES:
:CUSTOM_ID: sec:appendix:cabling_and_softwar_setup
:END:

- [ ] *CLEAN THIS UP TO MAKE IT STAND ON ITS OWN OR MERGE INTO ABOVE
  CAST OPERATION?*

The requires:
- Virtex:
  - power
  - 2 HDMI to intermediate board
  - mini USB into JTAG port on backside
  - RJ45 from ethernet port into 2nd ethernet card on DAQ PC

The RJ45 connection is only required to flash the firmware onto the
Virtex.

For the flashing of the firmware, take into account the USB driver
setup described in =void_settings.org=.

** Detector cabling [/]

- [ ] *CLEAN THIS UP*

The following is the cabling for the FADC and the scintillators to the
intermediate board. It's a useful reference when connecting the
cabling!

FADC Trig out:
- trig out -> level adapter (NIM module) into NIM IN, set to +NORM+ /
  *COMPL* (*this is active*)
  TTL out -> TTL signal clipper (TTL 5V -> 2.4V) into port marked =I=
  TTL signal clipper -> adapter board into *left LEMO at back* (viewed
  from behind the crate; cable still at CAST)

FPGA to FADC (shutter signal)
- Adapter board *right LEMO at back* (viewed from behind crate) ->
  level adapter (NIM module), set to *NORM* / +COMPL+ into TTL IN
  NIM out -> FADC EXT EN TRIG

Veto scintillator (*NOTE* this may be *WRONG*; input to adapter board
that is); signal order is reversed!
- Adapter board *left LEMO on top* (viewed from behind the crate,
  input number *1* on adapter board) -> discriminator OUT (top discriminator in NIM module)
  discriminator IN -> back of Amplifier Discriminator NIM module
  amplifier input -> veto scintillator signal
  The signal is needs to be *2.4 V TTL signal!*


** Ethernet connection with Virtex

The ethernet connection with the Virtex needs to be set up
manually.

On the one hand it is required to use a static IP address for the
secondary ethernet device and in addition we need to set an ARP entry
(note: the =arp= program is part of the =net-tools= package, name same
in ubuntu & void linux).

Under Ubuntu said setup can be done using the network manager. In Void
we need to use =ip= from the terminal.

The settings are as follows:
- IP address: 10.1.2.3
- Subnet: 24

Setup of the device can be done according to the example here:
https://docs.voidlinux.org/config/network/index.html
namely (with superuser rights):
#+begin_src sh
ip addr show
# check the name of the correct, secondary device
ip link set dev enp4s0 up # name on tpc19
ip addr add 10.1.2.3/24 brd + dev enp4s0
#+end_src
afterwards we can set the ARP entries (ref: https://confluence.team.uni-bonn.de/display/PHYGASDET/How+to+automatically+set+ARP+entries):
#+begin_src sh
arp -i enp4s0 -s 10.1.2.2 AA:BA:DD:EC:AD:E2
#+end_src

*** Make these two steps automatic under void

In principle it should be enough to set the above steps into =/etc/rc.local=.

** Setting up the chips in TOS

This section is specific to the Septemboard used at CAST.

Following the steps described in the shifter documentation
[[file:~/org/Doc/ShiftDocumentation/shifter_documentation.org]]
#+begin_src sh
#+BEGIN_SRC python
7 # number of chips
4 # preload
SetChipIDOffset
190
lf
# 7 times enter to load default paths
uma
1 # Matrix settings
0
1
1
0
LoadThreshold # load threshold equalisation files
4 # write matrix
3 # read out
3
ActivateHFM
SetFadcSettings
Run
1 # run time via # frames
0
0
0
2 # shutter range select
30 # shutter time select
0 # zero suppression
1 # FADC usage
0 # accept FADC settings
#+end_src

The above would launch a full background run.



* Window rupture and vacuum contamination                 :Appendix:noexport:
:PROPERTIES:
:CUSTOM_ID: sec:appendix:vacuum_contamination
:END:

*NOTE*: This section is a direct copy of my notes about the calculation of the
possible contamination of the LLNL telescope.



This file is a simple readme about the calculation of the potential
vacuum contamination of the system. The rough ideas are stated here.

** Calculation of vacuum volume
In order to calculate the total amount of gas, which entered the
vacuum volume, we first need to calculate the total volume of the
vacuum system. 

The calculation of the volume will be done in the Nim calculation
[[file:~/CAST/VacuumContamination/vacuum_contamination.nim][vacuum_contamination.nim]].

*** Tubing
The following lists the different pieces of vacuum piping, tubes etc.:
**** Static tubing:
This table lists the static tubes used in the vacuum system:

Table A:
| Diameter / mm | Length / cm | Index | Notes                                  |
|---------------+-------------+-------+----------------------------------------|
|            63 |          10 |     1 | telescope to gate valve                |
|            63 |          51 |     2 | telescope to detector, stainless steel |
|            63 |        21.5 |     3 | between st. steel tube & copper tube   |
|            25 |        33.7 |     4 | copper tube                            |
|            63 |          20 |     5 | bellow in front of telescope           |
|             ? |          50 |     6 | telescope                              |
|            40 |        15.5 |     7 | piece needle valve connects to         |
|            16 |          13 |     8 | Pirani <-> Mini turbo                  |
|            40 |          10 |    10 | 90 deg next to cross for needle valve  |


**** Flexible tubing:

Table B:
| Diameter / mm | Length / cm | Index | Notes                                         |
|---------------+-------------+-------+-----------------------------------------------|
|            16 |          25 |     1 | connection from needle valve to primary 1 / 4 |
|            16 |          25 |     2 | 2 / 4                                         |
|            16 |          25 |     3 | 3 / 4                                         |
|            16 |          25 |     4 | 4 / 4                                         |
|            16 |          40 |     5 | to needle valve                               |
|            25 |          90 |     6 | Pirani <-> Mini turbo                         |
|            25 |          80 |     7 | Mini turbo <-> T piece towards primary        |
|            40 |          50 |     8 | before turbo pump                             |
|            16 |         150 |     9 | connection to primary                         |
|            40 |          80 |    10 | needle valve to turbo, before index C3        |
|            40 |          80 |    11 | to turbo pump, after index C3                 |


**** T-pieces:

Table C:
| Diameter / mm | Length / cm | Index | Notes                                        |
|---------------+-------------+-------+----------------------------------------------|
|            40 | 18 x 21     |     1 | orthogonal to 3A                             |
|            16 | 7 x 4.5     |     2 | in between mini turbo, needle valve, primary |
|            40 | 10          |     3 | T-piece connection of P-MM                   |


**** Crosses:

Table D:
| Diameter / mm | Length / cm | Index | Notes                           |
|---------------+-------------+-------+---------------------------------|
|            16 | 10 x 10     |     1 | before primary                  |
|            40 | 14 x 14     |     2 | before turbo, behind gate valve |
|            40 | 14 x 14     |     3 | same as above                   |
|            40 | 14 x 14     |     4 | cross at needle valve           |




*** Implementation of tubing and calculation of volume
Given the tubing data as above, the nim module defines a TubesMap
datastructure, which is simply an object, with 4 different fields. One
for each type of vacuum tubing:
- static
- flexible
- T-pieces
- crosses
where for each a sequence of tuples is created given (diameter / mm,
length / cm).
This is defined in [[file:~/CAST/VacuumContamination/tubing.nim][tubing.nim]], which also offers a function to get
such a TubesMap for the data.

This tubing object is taken in the main() and handed to the
calcTotalVacuumVolume(), which uses the helper volume functions to
calculate the total vacuum volume.

In a functional style using map, we iterate over each of the fields ot
TubesMap one after another. For each item (a tuple of floats), an
anonymous function is used to calculate the volume of that specific
part. 

Finally, each volume element, which is added to the new sequence, is
summed after map is completed to give the total volume.

This amounts to 
#+BEGIN_LaTeX
$V_{\text{vacuum}} \approx 10.88 \, \mathrm{l}$.
#+END_LaTeX

** Calculation of potential influx of gas

Once we have the total volume of the vacuum system, we still need to
potential amount of gas, which entered the system. 

This can be separated into two parts. 
1. An static initial state given by the detector volume under the pressure at
   which the window burst:
#+BEGIN_LaTeX
$n_{\text{inital}} = \frac{p_{\text{burst}} V_{\text{det}}}{R T_{\text{amb}}}$.
#+END_LaTeX
2. And afterwards a dynamical flow, given by the compressed air tube,
   inserting gas until it was shut off, after
   $\SIrange{2}{5}{\second}$. For this one needs to consider the
   following. The compressed air tries to supply 6 bar. Assuming the
   last gauge sees $\SI{6}{\bar}$ the whole time. From there
   $\SI{2}{\meter}$ of tubing with about $\SI{3}{\milli \meter}$ inner
   diameter, results in a pressure of
   #+BEGIN_LaTeX
   $p_{\text{exit}} = p_i - z L \frac{\partial V}{\partial t}$
   #+END_LaTeX
   (or something like this?). $p_{\text{exit}}$ is the pressure at the
   end of the tube, i.e. inside the detector. $p_i$ the initial
   $\SI{6}{\bar}$, while $z$ is the specific impedance (per length) of
   the tube for the compressed air. The partial derivative should
   describe the flow of the gas. Analogous to currents, an impedance
   should drop the pressure inside the tube depending on the length
   $L$ due to the flow of gas inside it. Problematic to estimate
   impedance of the tubes. Look into Demtröder etc.
   
Given this, one can calculate the flow into the detector for the
time gas was still flowing. 
#+BEGIN_LaTeX
$n_{\text{total}} = n_{\text{initial}} + \frac{p_{\text{exit}}}{R T_{\text{amb}}}\frac{\mathrm{d}V}{\mathrm{d}t} t$
#+END_LaTeX
Or something similar...   

Alternative way to estimate total gas is to consider increase of
pressure inside of the $\sim \SI{11}{\liter}$ of vacuum volume while
the turbopumps and primary were still running. However, this is
probably less accurate, because this should be highly non-linear,
since the turbos shut off immediately (ramping down slowly,
i.e. pumping less and less). Primary kept pumping for about
$\SI{2}{\minute}$. 

Note: Upper parts remain for now, change approach of 2. point above.
We calculate the flow rate of the compressed air inside the tube using
the Poiseuille equation
#+BEGIN_LaTeX
$Q = \frac{\pi D^4 \Delta P}{128 \mu \Delta x}$,
#+END_LaTeX
where $Q$ is the flow rate in $\si{\liter\per\second}$, $D$ the
diameter of the tube, $\Delta P$ the pressure difference between both
ends of the tube, $\mu$ the dyanmic viscosity of air and $\Delta x$
the length of the tube. Regarding the dynamic viscosity, we use 
https://www.lmnoeng.com/Flow/GasViscosity.php
to calculate the viscosity of the compressed air. As a good
approximation, the dynamic viscosity is unchanged under pressure
changes
(https://www.quora.com/What-is-the-effect-of-pressure-on-viscosity-of-gases-and-liquids),
which means we can use the above calculator for air at
$\SI{20}{\celsius}$ to get a value of 
#+BEGIN_LaTeX
$\mu = \SI{1.8369247E-5}{\pascal \second}$.
#+END_LaTeX
In principle we need to check, whether the tube still contains laminar
flow, which we can do following:
https://engineering.stackexchange.com/questions/8004/how-to-calculate-flow-rate-of-water-through-a-pipe.
This calculation results in a value of
#+BEGIN_LaTeX
$Q_{\text{air, laminar}} = \SI{3.246}{\liter \per \second}$, 
#+END_LaTeX
which should be a good upper bound, since the equation is only valid
for laminar, incompressible fluids with a small pressure
gradient. Especially the last is definitely not valid, while the first
two are at least questionable.

Quick calculation of the Reynold's factor (to determine laminar or
turbulent flow), shows that (using velocity of flow $v$):
#+BEGIN_LaTeX
\[
v = \frac{Q}{A}
\]
\[
\mathrm{Re} = \frac{\rho d v}{\mu}
\]
#+END_LaTeX

#+BEGIN_SRC nim :exports both
import math
let v = 3.246e-3 / (PI * pow(1.5e-3, 2))
echo v
let Re = 1.225 * 1.5e-3 * v / (1.8369e-5)
echo Re
#+END_SRC

#+RESULTS:
| 459.2150624678154 |
| 45936.50592218471 | 
which shows that this calculation is wrong on several levels. The
speed of the flow is much too high I would assume. Although one thing
is to be noted: given a flow of compressed air into a vacuum, one
might expect a speed similar to the speed of sound of the inlet
pressure?!

At the same time, if one were to trust this, it suggests the flow to
be in the turbulent range (cp. laminar is $Re < \num{2300}$).

Maximal bound given by Bernouilli's principle
#+BEGIN_SRC nim :exports both
import math
let v = sqrt(2 * 6e5 / 1.2)
let Q = PI * pow(1.5e-3, 2) * v
echo v
echo Q * 1000
#+END_SRC

#+RESULTS:
|            1000.0 |
| 7.068583470577035 |
meaning a speed of $\SI{1000}{\meter \per \second}$ and a maximal flow
of $\SI{7.07}{\liter\per\second}$. 

On the other hand for a more practical value (ignoring more complex
calculations including turbulent, incompressible gases), see the
following plot from
http://www.engineeringtoolbox.com/air-flow-compressed-air-pipe-line-d_1280.html:

#+CAPTION: Compressed air capacities for different inner sizes. 1/8" roughly 3mm inner tube
#+NAME: fig::comp-air-capacity
[[file:~/org/Figs/compressed-air-pipeline-capacity-liter.png]]

shows a capacity of the compressed air line of
$\sim\SI{2}{\liter\per\second}$.

Thus, we can safely assume the calculated
$\SI{3.25}{\liter\per\second}$ to be a worst case scenario.

Hence, the total amount of air introduced into the system is:
#+BEGIN_LaTeX
$n_{\text{total}} = n_{\text{initial}} + \frac{Q_{\text{comp. air}} \cdot \SI{5}{\second} \cdot p_{\text{atm}}}{R T_{\text{amb}}}$,
where 
$Q_{\text{comp. air}} = \SI{3.246}{\liter\per\second}$
#+END_LaTeX
Ends up to be:
#+BEGIN_LaTeX
$n_{\text{total}} = n_{\text{initial}} + n_{\text{flow}} = \SI{0.0069}{\mol} + \SI{0.666}{\mol} = \SI{0.673}{\mol}$
#+END_LaTeX
Given in volume at normal conditions, this results in a gas volume of
#+BEGIN_LaTeX
$V_{\text{gas}} = \SI{16.4}{\liter}$
#+END_LaTeX

** Consider pumping of pumps

Since the pumps were still running during this period, they would have
extracted most of the gas immediately again. See last point in
previous section.

** Calculation of possible contamination

Finally, given the total vacuum volume and the amount of gas, which
entered the system, we can estimate the potential contamination. 

With the vacuum volume and the gas flowing into the system, the
maximum possible contamination can be estimated. The upper limit is of
course all contaminations in the gas forming a monolayer in the whole
vacuum system. Assuming a certain ppm contamination in the gas, the
maximum contamination is simply
#+BEGIN_LaTeX
$d_{\text{cont}} = \frac{n_{\text{total}} R T_{\text{amb}} \cdot q_{\text{cont}}}{A_{\text{vacuum}}}$
#+END_LaTeX
where $q_{\text{cont}}$ is the ppm contaminiation in the total gas
volume $nRT$, which enterd, while $A_{\text{vacuum}}$ is the total
surface area of all vacuum tubing. 

#+BEGIN_COMMENT 
However, first of all calculate the total amount of oil, which entered
the system assuming a (very high) 1 ppm, based on the calculated total
moles entering the vacuum of $n_{\text{total}} =
\SI{0.673}{\mol}$. This means a total of $\SI{6.73e-7}{\mol}$ of oil
entered the vacuum. 
#+END_COMMENT

However, first we estimate the amount of oil, which entered the system
from a typical oil contamination in compressed air. The ISO standard
ISO 8573-1:2010 defines different classes for compressed air in
different applications. Classes regarding oil contamination range from
0 to 4, with class 4 being the worst. Class 4 calls for
$\text{ppmv}_{\text{oil}} \leq \SI{5}{\milli
\gram\per\meter\cubed.}$. Thus, even if CERN's compressed air is a lot
worse than this, $\text{ppmv}_{\text{oil}} \approx
\SI{10}{\milli\gram\per\meter\cubed.}$ should be sufficient as a
baseline.

This means the entered air will contain about
#+BEGIN_SRC nim :exports both
import math
let air_vol = 16.4
let ppmv = 10e-3
echo ppmv * air_vol
#+END_SRC

#+RESULTS:
: 0.164

which is $\SI{0.164}{\mg}$ of oil. 

The telescope surface is not known exactly. No time to find out until
this needs to be done. Can be checked again later with Jaime / find
slides, paper about LLNL telescope, to get better numbers. Assuming 10
quarter shells of a radius of $\SI{5}{\centi\meter}$ (some larger,
some smaller radius), the telescope has an area of:
#+BEGIN_SRC nim :exports both nim
import math
let A = 10.0 * 0.5 * PI * 0.05 * 0.5
echo A
#+END_SRC

#+RESULTS:
: 0.3926990816987241
, i.e. an area of $A_{\text{telescope}} =
\SI{0.393}{\meter\squared}$. If all of the oil was placed on the
telescope, this would result in
#+BEGIN_SRC nim :exports both nim
import math
let A = 0.393
let oil_mg = 0.164
let ratio = oil_mg / A * 1e-4
echo ratio
#+END_SRC

#+RESULTS:
: 4.173027989821883e-05
A contamination of $d_{\text{max, cont}} =
\SI{41.73}{\nano\gram\per\cm\squared}$ is an upper bound on oil on the
telescope. Realistically, the telescope only has $< \frac{1}{10}$ of
the total vacuum surface area, while probably $> \SI{90}{\percent}$ of
the oil will have left the system via the pumps, pushing the
contamination as low as $d_{\text{cont}} <
\SI{0.4173}{\nano\gram\per\cm\squared}$. 

This may still sounds like quite a bit, but the assumptions made here
are all extremely conservative:
- 5 seconds with an open valve. More likely it was about
  \SI{3}{\second} => factor of $3/5$.
- flow of compressed air of $\SI{3.25}{\liter\per\second}$, more
  likely about $\SI{2}{\liter\per\second}$ => factor of another
  $2/3.25$.
- area of telescope vs total area of gas volume (hard to calculate due
  to flexible tubing) probably quite a bit less than 1 / 10 ?
- $\SI{10}{\percent}$ of oils sticking to surface probably also
  extremely unlikely. Maybe 2 orders of magnitude less?

#+BEGIN_SRC nim :exports both
let factors = (3.0 / 5.0) * (2.0 / 3.25) * 0.5 * 1e-2
echo factors
echo factors * 0.4173
#+END_SRC

#+RESULTS:
|  0.001846153846153846 |
| 0.0007704000000000001 | 
Meaning values as low as $d_{\text{cont}} <
\SI{0.7704}{\pico \gram\per\cm\squared}$ may even be more
reasonable. It is probably safe to say that this level is easily
reached if the telescope sits open during installation etc.



# A contamination of $d_{\text{max, cont}} =
# \SI{1.715e-10}{\mol\per\cm\squared}$. Realistically, the telescope only
# has $< \frac{1}{10}$ of the total vacuum surface area, while probably
# $> \SI{90}{\percent}$ of the oil will have left the system via the
# pumps, pushing the contamination as low as $d_{\text{cont}} <
# \SI{1.74e-12}{\mol\per\cm\squared}$.  Still a lot of particles, but
# probably much less than contaminating the telescope due to exposure to
# air.

# #+BEGIN_SRC nim :exports both nim
# let saw = 500.0
# echo 1.74e-12 * saw
# #+END_SRC

# #+RESULTS:
# : 8.7e-10

# This is about $\SI{8.7e-10}{\milli \gram \per \cm\squared}$ of oil. This
# still sounds like quite a bit, but the assumptions made here are all
# extremely conservative:
# - 5 seconds with an open valve. More likely it was about
#   \SI{3}{\second} => factor of $3/5$.
# - flow of compressed air of $\SI{3.25}{\liter\per\second}$, more
#   likely about $\SI{2}{\liter\per\second}$ => factor of another
#   $2/3.25$.
# - area of telescope vs total area of gas volume (hard to calculate due
#   to flexible tubing) probably quite a bit less than 1 / 10.
# - $\SI{10}{\percent}$ of oils sticking to surface probably also
#   extremely unlikely. Maybe 2 orders of magnitude less.

# #+BEGIN_SRC nim
# let factors = (3.0 / 5.0) * (2.0 / 3.25) * 0.5 * 1e-2
# echo factors
# echo factors * 2.6
# #+END_SRC

# #+RESULTS:
# | 0.001846153846153846 |
# |               0.0048 |
# => Would result in about $\SI{5}{\micro \gram \per \cm \squared}$.




# #+BEGIN_SRC nim :exports both
# import math
# let oil_g = 16.4e-3
# let g_per_mol = 500.0
# echo oil_g / g_per_mol

# echo 6.73e-7 * 500.0

# echo oil_g / 0.8

# #+END_SRC

# #+RESULTS:
# |  3.28e-05 |
# | 0.0003365 |
# |    0.0205 |

* 
Read up on =ox-extra= and the :ignore: tag that it includes to only
export this, but not the actual header.

#+LATEX: \listoffigures{}
#+LATEX: \listoftables{}

* Acknowledgments                                                     :Part5:

Thanks to Klaus & group.

Thanks to Araq for building Nim.

Thanks to Nim community, and especially:
Mamy (@mratsim), Hugo (@hugogranstrom), Clonkk, Chuck (@cblake), Andrea Ferreti (alea among others), @brentp
(plotly was a *huge* help in the beginning), @Bluenote10 (NimData was
great), @yglukhov (nimpy in particular!!)

Also thanks to Theodoros (and maybe Giovanni / Konstantin / Horst ?
maybe not...)
