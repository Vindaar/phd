#+LATEX_CLASS: book-noparts
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage{booktabs}
#+LaTeX_HEADER: \usepackage{pdfpages}
#+LaTeX_HEADER: \usepackage{tikz}

# 'externalize' all TikZ plots, i.e. cache them
#+LaTeX_HEADER: \usepackage{pgfplots}
#+LaTeX_HEADER: \usepgfplotslibrary{external} 
#+LaTeX_HEADER: \tikzexternalize


# for mini table of contents for each chapter
#+LATEX_HEADER: \usepackage{minitoc}

#+LATEX_HEADER: \usepackage{siunitx}
#+LATEX_HEADER: \sisetup{mode=text,range-phrase = {\text{~to~}}}

# font handling

# font handling
#+LATEX_HEADER: \usepackage{fontspec,minted}
#+LATEX_HEADER: \setmonofont{Fira Code} % suports all unicode we care about in code
#+LATEX_HEADER: \setmainfont{DejaVu Serif} % supports all unicode we care about as serif font

# The following is the approach using `ucharclasses` but that ruins
# code blocks of minted...
#   #+LATEX_HEADER: \usepackage{fontspec}
#   #+LATEX_HEADER: \usepackage[Latin,Mathematics,Punctuation,Symbols]{ucharclasses}
#
#   #+LATEX_HEADER: \newfontfamily{\mydefaultfont}{DejaVuSans}
#   #+LATEX_HEADER: \newfontfamily{\mymainfont}{CMU Serif}
#
#   #+LATEX_HEADER: \setTransitionsForPunctuation{\mymainfont}{\mydefaultfont}
#   #+LATEX_HEADER: \setTransitionsForLatin{\mymainfont}{\mydefaultfont}
#   #+LATEX_HEADER: \setTransitionsForSymbols{\mydefaultfont}{\mymainfont}
#   #+LATEX_HEADER: \setTransitionsForMathematics{\mydefaultfont}{\mymainfont}

# package that allows inserting unicode characters in math environment
#+LATEX_HEADER: \usepackage{unicode-math}

#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{mhchem}

# make the margin on the sides smaller
#+LATEX_HEADER: \usepackage[margin=2.5cm]{geometry}

# ##############################
# change output of code blocks to use monokai
# ##############################
#+LaTeX_HEADER: \usemintedstyle{monokai}

#+LATEX_HEADER: \definecolor{monokai_bg}{RGB}{39, 40, 34}
#+LATEX_HEADER: \definecolor{monokai_fg}{RGB}{241, 235, 235}
#+LATEX_HEADER: \definecolor{monokai_0}{RGB}{72,72,62}
#+LATEX_HEADER: \definecolor{monokai_1}{RGB}{220,37,102}
#+LATEX_HEADER: \definecolor{monokai_3}{RGB}{212,201,110}
#+LATEX_HEADER: \definecolor{monokai_4}{RGB}{85,188,206}

# color commands
#+LATEX_HEADER: \definecolor{monokai_orange}{RGB}{253, 151, 31}
#+LATEX_HEADER: \newcommand{\orange}{\textcolor{monokai_orange}}
#+LATEX_HEADER: \newcommand{\green}{\textcolor{green}}
#+LATEX_HEADER: \newcommand{\red}{\textcolor{red}}
#+LATEX_HEADER: \DeclareSIUnit\year{yr}

#+LATEX_HEADER: \usepackage{biblatex}
#+LATEX_HEADER: \addbibresource{references.bib}

#+LATEX_HEADER: \linespread{1.2} % change line spacing to be a bit larger. TODO: find good value!

# HTML Export
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="nimdoc.css" />
#+OPTIONS: html-style:nil

#+OPTIONS: toc:nil # turn off Table of Contents here and place it elsewhere

#+LATEX: \dominitoc % initialize the package


\begin{titlepage}

\begin{center}
  \huge Search for solar axions using a 7-GridPix IAXO prototype detector at CAST

  \vspace{2cm}
  \Large Sebastian Michael Schmidt
\end{center}

place funny logos and stuff

Doktorgrad
erworben 2021
Solingen


\end{titlepage}

#+TOC: headlines 2


# Part 0: Introduction

* Compile                                                          :noexport:

Compilation at the moment is still a bit broken due to =biber=.

We need to generate the TeX file from Org =C-c C-e l l= to generate
the TeX file.

Then in terminal:
#+begin_src sh
xelatex --shell-escape thesis.tex
biber thesis
xelatex --shell-escape thesis.tex
#+end_src

* Start me                                                         :noexport:

#+begin_src emacs-lisp
(add-to-list 'org-latex-classes
             '("book-noparts"
               "\\documentclass{book}"
               ("\\chapter{%s}" . "\\chapter*{%s}")
               ("\\section{%s}" . "\\section*{%s}")
               ("\\subsection{%s}" . "\\subsection*{%s}")
               ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
               ("\\paragraph{%s}" . "\\paragraph*{%s}")
               ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+end_src


* Introduction                                                        :Intro:

Bla.


After a short side note about this thesis as a document in chapter
[[About this thesis (structure)]], we introduce the theoretical foundation
of axion physics in chapter [[Theory of axions]]. From a historical
standpoint as to why axions were invented in the first place to the
avenues of detection and related the expected solar axion fluxes.

This leads to chapter [[Axion helioscopes]], which introduces the concept
of an axion helioscope as a way to potentially detect axions of a
solar origin. Other possible approaches will be shortly mentioned.

With an understanding of possible detection mechanisms for axions, we
will focus next on the required hardware to actually measure axions
indirectly, i.e. via gaseous detectors for X-ray detection in chapter
[[Gaseous detectors principles]].

As we finally wish to compute a limit on different axion coupling
constants, an understanding of basic statistics for limit calculations
is required. This we will cover in chapter [[Statistics & limit
calculations]].

Next we introduce our detector, the Septemboard based GridPix
detector, in chapter [[Septemboard detector]]. Here we will discuss both
the motivation behind why such a detector was built, the different
features of the detector and basic calibration principles as well as
covering the setup and software used to run the detector.

Stopping at the software running the detector, we will then transfer
over to the software suite built to analyze the data in chapter
[[Software]].

A further chapter about the analysis principles follows, which
explains the ideas of how the data reconstruction works, what kind of
calibrations are applied to the data and how it all fits together to
compute a background rate and limit. This is chapter [[Chapter about
analysis principle]].

Raytracing chapter will be moved somehow.

What follows in chapter [[Detector preparation / study /
characterization etc.]] is the explanation of all characterization
measurements, an introduction to the $^55\text{Fe}$ calibration
measurements and how the energy calibration works.

From there we go to the actual deployment of the detector at CAST in
chapter [[Detector installation at CAST & data taking]], in which we
describe the physical setup and give an overview over the different
data taking periods.

With the description of the data periods out of the way, we can make
use of the data to compute the background rate of the detector for
different cases in chapter [[Background rate computation]].

These background rates are combined with the expected signals from
chapter *TODO which one Raytracing + theory?* and the measured
candidates during tracking time to compute a limit in chapter [[Limit
calculation]].

As a final part we will give an outlook of what a future Timepix3
based detector might achieve in chapter [[Outlook]].

Afterwards we finally conclude in chapter [[Summary & conclusion]].

* About this thesis (structure)                                       :Intro:

Explanation about the thesis structure and introduction of the "full
thesis document".

The thesis you are reading right now is a shortened version of the
full document it is part of. To conform to the expectations of a PhD
thesis many parts are removed that are irrelevant for the basic
presentation of the work done during the thesis.

However, a fellow researcher who wishes to understand all the details,
in particular in terms of reproducibility of the results, the full
document should be read instead.

The full document is found at:

*TODO*: insert link, probably to GitHub as well as some other source

The main difference between the regular thesis document and the
extended version are the following. The extended version contains:
- either inline code or links to the code that produces *every plot*
  (that is created by me); inline code is used if the required code to
  generate the plot is less than a certain amount of lines.
  For non-inlined code the used code is referenced (link to the code +
  correct git commit)
- access to *all* raw and reconstructed data to reproduce the results
- additional chapters that were not relevant enough / polished enough
  for inclusion into the thesis. This includes additional plots,
  investigations of detector behavior etc., theoretical calculations
  and more.

In essence the idea is to provide a fully reproducible thesis. The
extended version should ideally be read as a mix of the generated PDF
and the real Org file behind it.

The extended version includes many source code blocks that can be
extracted using [[https://github.com/OrgTangle/ntangle][ntangle]]:
#+begin_src sh
ntangle thesis.org
#+end_src

Ideally, all results can be reproduced with a single:
#+begin_src sh
./generateResults.sh
#+end_src
call (we'll see how that will work out).

The package versions for the code used in the extended version will be
frozen at a specific time. The list of version numbers will be found
below.

*TODO*: Add version numbers of all packages used for final plots.

*TODO*: Have specific marking in (sub)sections if they contain more
information in extended version?

*TODO*: It would be sick if we could do something like
#+begin_src sh
curl -s <backblaze link> | sh foo.sh
#+end_src
to download and generate everything in one go. Seems a bit insane
though. But who knows.

*TODO*: In =noexport= sections, possibly have a "Skip this section
if:" introduction? So that readers know exactly why a certain section
might be of interest to them.


Further, this thesis does not attempt to cover *every* aspect of the
theoretical foundation required to understand every part. For example
we will not introduce the Standard Model or explain certain detector
features, if they are not of importance for the understanding of our
data.
Good references, if available, will however be given for an interested
reader / a reader attempting to fill in gaps in knowledge.

* TODO List of todos [0/9]                                   :Intro:noexport:

** TODO Have reference to Firmware used at CAST in each run

** TODO Run list (appendix)

** TODO Include exact results from Geometer measurements

Find in EDH and include, even if we don't use it. Referenced in X-ray
finger measurements.


** TODO fix up schematic of V6 Septemboard connections
** TODO fix up schematic of MM working principle

The existing schematic is not very clear. Change the drift gap
behavior and amplification gap one by reversing their drawing
style. Add some alpha to different regions to highlight amount of
electrons drifting. Add a text label with O(magnitude)

** TODO insert the first LaTeX + Vega-lite based plot

This gives us an idea of how this will work. For a start I'd say base
the Vega-lite plots on Github gists. That allows for easy replacement
for the time being.

** TODO implement nothing ⇒ background rate as reproducible build

This one will be a bit ambitious, but maybe it's a day of work.

*If* we get this working we're at a point where generating other plots
is just a simple shell command (call script X with args Y), as we will
have all =Calibration/DataRunsX_Y.h5= files ready somewhere.

Steps:
*** Setup Nim + all packages of fixed versions (take versions from a TOML file)
*** Have config file storing paths of raw data + output paths
*** run raw data, reco, ...
*** generate CDL datasets
*** compute logL files
*** plot background

** TODO find way to host the raw data

We could start by a simple Backblaze B2 hosting.

Pricing is competitive:
Hosting: 0.005 $/Month/GB
Download: 0.01 $/GB
https://www.backblaze.com/b2/cloud-storage-pricing.html

Which is 1.5$ for 300 GB and 3$ to download it. Certainly cheap enough
to try!

Data to store
*** All 2017/18 data runs
**** Run 2
**** Run 3
*** Detector calibration files for Run 2, Run 3
*** FADC pedestal run
*** X-ray finger runs
*** All our notes + thesis
*** Nim code?                                                     :pending:

** TODO use some package for abbreviations

** Points of contention

At the moment <2021-07-31 Sat 11:36> my biggest point of uncertainty
is the whole detector calibration part + how this plays into a
software framework.

Difficult to come up with good layout at this point. Will be easier
once more notes are added in each part I think.

* Theory of axions                                                   :Theory:

From a historical standpoint including the strong CP problem, we go
over to the Peccei-Quinn solution. Another way to look at it is from a
modern standpoint asking why does the neutron not have a dipole
moment?

*Take a look at lectures for Axion School*
*QCD AXION LANDSCAPE PAPER*
*PAPER RINGWALD LIKED SO MUCH*

** Historical origins

From electroweak theory we know about CP violation. Standard model for
strong force is just SU(3) vs. SU(2) for electroweak.

Lagrangian allows mostly the same terms for both forces. This implies
there should be a strong CP violation. This isn't observed and even
today theh neutron electric dipole moment is restricted to values
smaller $d_N \leq 1e-26 \text{? some units}$.

Merge the next section into this one and change title?

** Strong CP problem

Use the schematic I created for Hendrik's presentation?

** Peccei-Quinn solution

Main Peccei-Quinn paper citation.

Solution by introducing another global U(1) symmetry that is
spontaneously broken below some energy scale. 

** The axion

Leads to a pseudo Nambu-Goldstone boson that Wilzcek named the Axion
(ref a pic of axion detergent), as it washes the standard model clean
of an ugly stain.

** DFSZ & KSVZ axion models

Further developments lead to more complex axion models that better fit
with our understanding.

Two main types of models emerged.

** Implications for axion interactions

Axions are apparently not interacting a whole lot, otherwise we'd know
about them already. Very weak interaction

Main interaction arises due to anomalies in standard model that allow
for a Fermion loop diagram. That allows for coupling to
gluons. Effective photon coupling is the result, equivalent to
Primakoff effect for pions (also an effective coupling!).

Write down effective Lagrangian.

*COHERENCE CONDITION*
*VACUMM VS GAS*

** Solar axion flux

Important for us? How do we detect them.

Have a simple derivation from KG equation? Take a look at Biljana &
Kreso for simple overview and simplify.

Take KG equation and derive interaction.

Interaction tells us conversion is proportional to B and L. Where are
strong Bs for long Ls? Solar core.
Take modern solar model to plot the density profile & especially
temperature. Density + temperature allows us to compute:
- number of photons
- at various photon energies

By wrapping blackbody radiation (ref, 3 sentences about it) present in
solar core with Primakoff coupling, we get an effective axion flux
equivalent to:

$dΦ/dE ∝ g_{aγ}² · \text{black body radiation}$

*CHECK CAST PHASE I RESULT PAPER FOR OVERVIEW* (contains physics +
integration over solar model!)
Refer to that paper in particular to answer the question: "do axions
escape from the sun?"

*** Primakoff flux

Including analytical equation for flux... :)

#+begin_src nim :tangle /tmp/solar_axion_flux.nim :results silent
import unchained, ggplotnim, math, chroma, ginger
defUnit(keV⁻¹•m⁻²•yr⁻¹)
defUnit(keV⁻¹•cm⁻²•s⁻¹)
defUnit(GeV⁻¹)

proc axionFluxPrimakoff(E_a: keV, g_aγ: GeV⁻¹): keV⁻¹•cm⁻²•s⁻¹ =
  ## dΦ_a/dE taken from paper about first CAST results \cite{PhysRevLett.94.121301}
  let g₁₀ = g_aγ / 1e-10.GeV⁻¹ # * 10e10.GeV¹ #
  result = g₁₀^2 * 3.821e10.cm⁻²•s⁻¹•keV⁻¹ * (E_a / 1.keV)^3 / (exp(E_a / (1.103.keV)) - 1)

proc axFluxPerYear(E_a: keV, g_aγ: GeV⁻¹): keV⁻¹•m⁻²•yr⁻¹ =
  result = axionFluxPrimakoff(E_a, g_aγ).to(keV⁻¹•m⁻²•yr⁻¹)

proc axionFluxPrimakoffMasterThesis(ω: keV, g_ay: GeV⁻¹): keV⁻¹•m⁻²•yr⁻¹ =
  # axion flux produced by the Primakoff effect
  # in units of m^(-2) year^(-1) keV^(-1)
  result = 2.0 * 1e18.keV⁻¹•m⁻²•yr⁻¹ * (g_ay / 1e-12.GeV⁻¹)^2 * pow(ω / 1.keV, 2.450) * exp(-0.829 * ω / 1.keV)

let E = linspace(1e-3, 14.0, 1000)
let df = seqsToDf(E)
  .mutate(f{float: "Flux" ~ axionFluxPrimakoff(`E`.keV, 1e-10.GeV⁻¹).float})
  .mutate(f{float: "FluxYr" ~ axFluxPerYear(`E`.keV, 1e-11.GeV⁻¹).float})
  .mutate(f{float: "FluxMSc" ~ axionFluxPrimakoffMasterThesis(`E`.keV, 1e-11.GeV⁻¹).float})    
ggplot(df, aes("E", "Flux")) +
  geom_line() +
  geom_line(aes = aes(y = "FluxMSc"), color = some(parseHex("0000FF"))) + 
  ggtitle("Solar axion flux due to Primakoff production, g_aγ = 10⁻¹⁰·GeV⁻¹") +
  xlab("Energy [keV]") +
  #ylab("Axion flux [keV⁻¹·cm⁻²·s⁻¹]") +
  ylab("Axion flux [keV⁻¹·m⁻²·yr⁻¹]") +  
  ggsave("/tmp/primakoff_axion_flux.pdf")

ggplot(df.mutate(f{"Flux" ~ `Flux` / 1e10}), aes("E", "Flux")) +
  geom_line() +
  #xlab("Energy [keV]", tickFont = font(12.0), margin = 1.5) +
  xlab(r"\fontfamily{lmss}\selectfont Energy [$\si{\keV}$]", margin = 2.0, font = font(16.0),
       tickFont = font(16.0)) +
  xlim(0, 14) + 
  #ylab("Axion flux [10¹⁰ keV⁻¹·cm⁻²·s⁻¹]", margin = 1.5) +
  ylab(r"\fontfamily{lmss}\selectfont Axion flux [\SI[print-unity-mantissa=false]{1e10}{\keV^{-1} \cm^{-2} \second^{-1}}]",
       margin = 2.0,
       font = font(16.0)) + 
  #     tickFont = font(12.0)) +
  #ggtitle(r"Expected solar axion flux, g_aγ = 10⁻¹⁰ GeV⁻¹", titleFont = font(12.0)) +
  annotate(r"\fontfamily{lmss}\selectfont Expected solar axion flux" &
    r"\\$g_{aγ} = \SI[print-unity-mantissa=false]{1e-10}{\GeV^{-1}}$", #10⁻¹⁰ GeV⁻¹",
           x = 6.2, y = 6.2, 
           font = font(16.0),
           backgroundColor = transparent) +
  #ggtitle(r"Expected solar axion flux, $g_{aγ} = \SI{1e-11}{\GeV^{-1}}$", titleFont = font(12.0)) + 
  #ggsave("/tmp/cristina_primakoff_axion_flux.pdf", width = 400, height = 300) #, useTeX = true, standalone = true)
  ggsave("/tmp/cristina_primakoff_axion_flux.pdf", useTeX = true, standalone = true)
  

defUnit(m⁻²•yr⁻¹)  
echo 1.cm⁻²•s⁻¹.to(m⁻²•yr⁻¹)
#+end_src

There are different analytical expressions for the solar axion flux
for Primakoff production. These stem from the fact that a solar model
is used to model the internal density, temperature, etc. in the Sun to
compute the photon distribution (essentially the blackbody radiation)
near the core. From it (after converting via the Primakoff effect) we
get the axion flux.

Different solar models result in different expressions for the
flux. The first one uses an older model, while the latter ones use
newer models.

*** Axion-electron flux

*citations*: Redondo 2013, maybe (Johanna + Sebastian Hoof something?)
*Keep in mind errors in Redondo 2013*! *possibly write a mail to Sebastian Hoof*

Expected axion flux combined.

Reference to file storing the results for specific coupling constants.

Much more complicated.

ABC components.

B and C can be expressed analytically.

A cannot, needs opacity project.

Show plot of differential axion flux.

For a derivation of this, consider section about ray tracing. Custom
computation of A done by Johanna in code developed by her & me in
*LINK*.

** TODO possibly add chameleons?

?? will depend on whether we do a chameleon limit (which we should, as
our detector is much better here!)

Should be easy after all, as everything is the same as for axions,
except different flux, raytracing and thus limit calc (from a number
perspective; concept is the same).

** Current bounds on axion couplings

Astronomical axion bounds.

Cavity bounds.

Helioscope bounds.

(what else?)

*TODO*: include newest Chandra results for coupling constant

*TODO*: include Xenon-1T results 

* Axion helioscopes                                                  :Theory:

Introduce axion helioscopes as one of the types of experiments
proposed by Sikivie in his paper. *CITE SIKIVIE*

Maybe shortly mention other experiments.

As discussed in the previous chapter in section [[Solar axion flux]],
stars are expected to produce significant excess of axions. In 1983
Pierre Sikivie proposed multiple methods to potentially detect
axions, one of these making use of this solar axion production. 

From the theory on axions (ref. section [[Implications for axion
interactions]]) we know there is an effective coupling to the photon
$g_{aγ}$. This coupling is an equivalent to the Primakoff effect,
which describes a resonant production of mesons via a Fermion loop in
strong electromagnetic fields when interacting with a nucleus. In the
Primakoff effect two photons are present, an incoming real photon and
a virtual photon of the electromagnetic interaction of the
nucleus. Axions can take the place of the physical photon, either in
the initial state or in the final state. In the former case we have an
axion to photon conversion and in the latter a photon to axion
conversion.

*DIFFERENTIATE BETWEEN PRIMAKOFF AND INVERSE PRIMAKOFF*

*PUT PRIMAKOFF FEYNMAN DIAGRAM*
*POSSIBLY MOVE TO THEORY ITSELF AND REFERENCE*

As it turns out, the relevant aspect for the Primakoff effect is not
the presence of a nucleus, but simply the fact that the nucleus
provides an electromagnetic field. This means the nucleus can also be
replaced by - for example - a transverse, constant magnetic field.

*EXPLAIN WHY TRANSVERSE MAGNETIC FIELD IN THEORY*

This fact is the foundation of the helioscope idea. By pointing a
magnet at the Sun one expects a small fraction of the axions produced
in the Sun to reconvert to photons in the presence of the magnetic
field via the inverse Primakoff effect. These photons will carry the
energy of the original photons that produced the axions, namely the
energy of photons in the solar core. Essentially black body radiation
of $\sim\mathcal{O}(\SI{15}{\mega\kelvin}$.

*INSERT FIG BLACKBODY HERE OR IN SOLAR AXION FLUX SECTION*

This means the reconverted photons are mostly in the soft X-ray range
between \SIrange{1}{7}{\keV}. The first implementation of the
helioscope idea was the Rochester-Brookhaven-Florida experment *CITE
2*. It was followed by the SUMICO experiment in Tokyo *CITE 3*. The
third and only still running helioscope is the CERN Axion Solar
Telescope (CAST), which we will present in more detail in section [[CERN
Axion Solar Telescope (CAST)]]. In the final section we will introduce
the next generation of axion helioscopes, the International AXion
Observatory (IAXO), section [[International AXion Observatory (IAXO)]].

** Black body radiation in solar core                             :noexport:

Let's compute the black body radiation for the solar core and see if
it matches the energy spectrum we expect for axions.

Planck's law is defined as *CITE SOMETHING*:

\[
B_ν(ν, T) = \frac{2hν³}{c²} \frac{1}{e^{hν/kT} - 1}
\]

where $ν$ is the frequency of the photon and $T$ the temperature in
Kelvin. $k$ is of course the Boltzmann constant and $h$ the Planck
constant. Let's see what this looks like for $T =
\SI{15}{\mega\kelvin}$.

#+begin_src nim
import ggplotnim, unchained, sequtils

defUnit(s⁻¹)
defUnit(μs⁻¹)
defUnit(Watt•Steradian⁻¹•Meter⁻²•NanoMeter⁻¹)
defUnit(Joule•Meter⁻²•Steradian⁻¹)

let T_sun = 15.MegaKelvin.to(Kelvin)

proc blackBody(ν: s⁻¹, T: Kelvin): Joule•Meter⁻²•Steradian⁻¹ =
  result = (2 * hp * ν^3 / c^2 / (exp(hp * ν / (k * T)) - 1)).to(Joule•Meter⁻²•Steradian⁻¹)

proc xrayEnergyToFreq(E: keV): s⁻¹ = 
  ## converts the input energy in keV to a correct frequency
  result = E.to(Joule) / hp
echo 1.keV.xrayEnergyToFreq

echo blackBody(1.μs⁻¹.to(s⁻¹), T_sun)
echo blackBody(1.keV.xrayEnergyToFreq, T_sun)

let energies = linspace(0.01, 16.0, 1000)
let radiance = energies.mapIt(blackBody(it.keV.xrayEnergyToFreq, T_sun).float)
let df = seqsToDf(energies, radiance)
ggplot(df, aes("energies", "radiance")) + 
  geom_line() + 
  ggtitle("Black body radiation @ T = 15 Mio. K") +
  xlab("Energy [keV]") + ylab("Radiance [J•m⁻²•sr⁻¹]") + 
  ggsave("/tmp/blackbody_sun.pdf")

#+end_src

#+RESULTS:
| 2.41799e+17 | Second⁻¹                  |
| 4.60862e-21 | Joule•Meter⁻²•Steradian⁻¹ |
|     178.526 | Joule•Meter⁻²•Steradian⁻¹ |


** TODO small section about other kinds of experiment?

** CERN Axion Solar Telescope (CAST)

The CERN Axion Solar Telescope (CAST) was proposed in 1999
\cite{ZIOUTAS1999480} and started data taking in 2003
\cite{PhysRevLett.94.121301}. 

*PICTURE OF CAST*

Using a \SI{9.26}{m} long LHC dipole magnet that was available from
the developments for the LHC, CAST features a \SI{9}{\tesla} strong
transverse magnetic field for axion-photon conversion produced by a
current of \SI{13}{\kilo\ampere} in the superconducting wires
*MATERIAL EXPLICIT* at \SI{1.8}{\kelvin}. It is placed on a movable
platform that allows for solar tracking both during sunrise as well as
sunset. The vertical range of movement is in principle
$\sim\pm\ang{8}$, but is slightly reduced in the last years of data
taking since 2019 (*CHECK NUMBER ASK THEODOROS*). This range of motion
allows for solar tracking of approximately \SI{90}{\minute} each day,
the exact duration depending on time of the year. Due to their
incredibly feeble interactions solar tracking can already start before
sunrise / stop after sunset as axions easily traverse through large
distances of Earth's mantle.

*NAME SUPERCONDUCTING MATERIAL OF THESE MAGNETS*

*CROSS SECTION OF LHC DIPOLE MAGNET*

An LHC dipole magnet has two bores for the two proton beams running in
reverse order. Being a prototype magnet it is *not* bent to the
curvature required by the LHC. A cross section can be seen in
fig. *INSERT ME*. These two bores have a diameter of \SI{4.3}{cm}
*CITE NUMBER* \cite{ZIOUTAS1999480} *SAYS 42.5mm*. In total then two
bores on each side allow for 4 experiments to be installed at CAST,
two for data taking during sunrise and two during sunset. 
#+begin_export latex
\footnote{There is some confusion about the diameter and length of the
magnet. The original CAST proposal \cite{ZIOUTAS1999480} talks about
the prototype dipole magnets as having a bore diameter of
\SI{42.5}{mm} and a length of \SI{9.25}{m}. However, ever CAST
publication afterwards uses the numbers \SI{43}{mm} and
\SI{9.26}{m}. Digging into references about the prototype dipole
magnets is inconclusive. For better compatibility with all other CAST
related publications, we will use the same \SI{43}{mm} and
\SI{9.26}{m} values in this thesis.}
#+end_export

The first data taking period (often referred to as 'phase I') took
place in 2003 for 6 months between May and November and was a pure
vacuum run with 3 different detectors. On the side observing during
sunset was a Time Projection Chamber (TPC) that covered both bores. On
the 'sunrise' side a Micromegas (Micromesh Gaseous Detector) detector
and a Charged Coupled Device (CCD) detector were installed. The CCD
was further behind a still in place X-ray telescope originally
designed for the ABRIXAS X-ray space telescope
\cite{ABRIXAS}. \cite{PhysRevLett.94.121301}

The full first phase I data taking period comprises of data taken in
2003 and 2004 and achieved a best limit of $g_{aγ} <
\SI{8.8e-11}{\GeV^{-1}}$ \cite{Andriamonje_2007}.

In what is typically referred to as 'phase II' of the CAST data
taking, the magnet was filled with helium as a buffer gas. First
between late 2005 and early 2007 with $^4\text{He}$. From March 2008 a
run with $^3\text{He}$ was started, which ran until 2011
\cite{Arik_2009, PhysRevD.92.021101}. In 2012 another $^4\text{He}$
data run took place \cite{PhysRevD.92.021101}. 

From 2013 on the CAST experiment has only taken data using vacuum
\cite{cast_nature}. Further, the physics scope has been extended
to include searches for chameleons *CITE CHRISTOPH, SDD, KWISP*, and
axions in the galactic halo via cavity experiments *CITE SERGIO,
CAPP*. 

In addition, with the MicroMegas dataset taken in *CHECK EXACT* phase I a
limit on the axion electron coupling was computed *CITE 2013*.

*160 STEPS WERE PERFORMED WITH BUFFER GAS* \cite{Arik_2009}

*BETTER SEPARATE X-ray OPTICS*

*MENTION COHERENCE CONDITION* (here or in theory?)

*2 ANNOTATED PICTURES OF CAST W/ HIGHLIGHT OF SUNRISE, SUNSET,
AIRPORT, JURA* 
*INTRODUCE THESE IN TEXT*

*CAST PROPOSAL MENTIONS 9.25m and 42.5mm DIAMETER!! CHECK*

Basic data.

Data taking periods.

*INSERT VIDEO IN FOOTNOTE*

*** CAST X-ray optics

The first X-ray telescope used at CAST as a focusing optics for the
expected axion induced X-ray flux was a Wolter I type X-ray telescope
\cite{wolter_1_type} originally built for a proposed German space
based X-ray telescope mission, ABRIXAS \cite{ABRIXAS}. The telescope
consists of 27 gold coated parabolic and hyperbolic shells and has a
focal length of \SI{1.6}{m}. Due to the small size of the dipole
magnet's bores of only \SI{42.5}{mm} only a single section of the
telescope can be exposed. The telescope is thus placed off-axis from
the magnet bore to expose a single mirror section. An image of the
mirror system with a rough indication of the exposed section is shown
in fig. [[CAST_abrixas_mirror_system]]. 

The telescope is owned by the Max Planck Institut für
extraterrestrische Physik in Garching. For that reason it will often
be referred to as the 'MPE telescope' in the rest of the thesis.

The efficiency of the telescope reaches about \SI{48}{\%} as the peak
at around \SI{1.5}{\keV}, drops sharply at around \SI{2.3}{\keV} to
only about \SI{30}{\%} up to about \SI{7}{\keV}. From there it
continues to drop until about \SI{5}{\%} efficiency at
\SI{10}{\keV}. The efficiency is shown in a comparison with the LLNL
telescope in the next section [[Lawrence Livermore National Laboratory
(LLNL) telescope]] in fig. [[telescope_efficiency_comparison_mpe_llnl]].

A picture of the telescope installed at CAST behind the magnet on the
'sunrise' side of the magnet is shown in fig. [[CAST_abrixas_telescope_installed]]. 

This telescope was used for the data taking campaign in 2014 and 2015 using a GridPix
based detector discussed in \cite{krieger2018search} and serves as a
comparison for certain aspects in this thesis.

#+begin_center
#+CAPTION: Image of the CAST Abrixas installed at CAST on the sunrise side.
#+CAPTION: The image is taken from \cite{CAST_telescope_ccd} as it provides a 
#+CAPTION: relatively clear image of the telescope, which is hard to take nowadays.
#+NAME: CAST_abrixas_telescope_installed
[[~/org/Figs/thesis/CAST/cast_abrixas_telescope_image_clear.png]]
#+end_center

#+begin_center
#+CAPTION: Image of the CAST Abrixas telescope mirror system. The different shells of the 
#+CAPTION: Wolter I type telescope system are visible. One section is exposed to the 
#+CAPTION: magnet bore, the white line indicating roughly the extent of the bore. The 
#+CAPTION: sproke like structure is the support for the mirror shells.
#+CAPTION: Image taken from \cite{CAST_telescope_ccd}.
#+NAME: CAST_abrixas_mirror_system
[[~/org/Figs/thesis/CAST/abrixas_cast_telescope_system.png]]
#+end_center

*** Lawrence Livermore National Laboratory (LLNL) telescope

Up to 2014 there was only a single X-ray telescope in use at CAST. In
August 2014 a second X-ray optics was installed on the second bore
next to the ABRIXAS telescope. This telescope using technologies
originally developed for the space based NuSTAR telescope by NASA
\cite{Harrison_2013, Harrison2006, nustar_design_performance, nustar_fabrication, nustar_overview_status}, 
but purpose built for
axion searches and in particular the CAST experiment. Contrary to the
ABRIXAS telescope only a single telescope section of the Wolter I type
geometry was built as the small bore cannot expose more area. It
consists of 13 platinum / carbon coated glass shells in sections for a
total of 26 mirrors. Further the focal length was shortened to
\SI{1.5}{m} and the focal point is slightly angled away from the
straight continuation of the bore to make more room for the
installation of the detectors. This can be seen in the render of the
2017/18 detector setup in
fig. [[llnl_telescope_setup_2017_render]]. \cite{llnl_telescope_first_cast_results}

*BETTER INTRODUCE 2 LENGTH WISE SECTION THING OF WOLTER TELESCOPES*

#+begin_center
#+CAPTION: Render of the setup of the GridPix septemboard detector in 2017/18 showing the 
#+CAPTION: LLNL telescope on the left side. The diversion away from the extension of the
#+CAPTION: bore is visible, to have more space for detector installation, in particular the
#+CAPTION: lead shielding that is not shown in the render.
#+CAPTION: *ANNOTATE THE RENDER*
#+NAME: llnl_telescope_setup_2017_render
[[~/org/Figs/rayTracing/llnl_cast_gridpix_render_small.png]]
#+end_center

Part of the master thesis of Johanna von Oy in this group was a ray
tracing simulation for this optics. A comparison of the ray tracing
simulation is part of a more detailed introduction to the ray tracing
in chapter [[Raytracing - where does this belong?]]. *CITE JOHANNA*

#+begin_center
#+CAPTION: Comparison of the efficiency between the two telescopes, the MPE (ABRIXAS) as the 
#+CAPTION: original CAST telescope and the LLNL telescope purpose built for axion searches.
#+CAPTION: The LLNL telescope has superior efficiency in the energy range where the axion
#+CAPTION: flux is assumed to dominate, but falls off sharper at high energies.
#+CAPTION: The data for the LLNL telescope is extracted from fig. 3 in \cite{llnl_telescope_first_cast_results},
#+CAPTION: whereas for the ABRIXAS telescope it is extracted from the red line in fig. 4
#+CAPTION: of \cite{CAST_telescope_ccd}.
#+CAPTION: *FIX ME AND THINK ABOUT TRANSMISSION VS EFFICIENCY*
#+NAME: telescope_efficiency_comparison_mpe_llnl
[[~/org/Figs/statusAndProgress/llnl_mpe_transmission_comparison.pdf]]
#+end_center

*** Best limits

In the many years of data taking and countless detectors taking data
at the CAST experiment, it has put the most stringent limits on
different coupling constants over the years.

Specifically, CAST sets the current best limits on the:
- Axion-photon coupling $g_{aγ}$
- Axion-electron coupling $g_{ae}$
- Chameleon-photon coupling $β_γ$

For the axion-photon coupling the best limit is from
\cite{cast_nature} in 2017 based on the full MicroMegas dataset
including the data behind the LLNL telescope and constricts the coupling to $g_{aγ} <
\SI{6.6e-11}{\GeV^{-1}}$. 

For the axion-photon coupling the best limit is still from 2013 in
\cite{Barth_2013} using the theoretical calculations for an expected
solar axion flux done by J. Redondo in \cite{Redondo_2013} for a limit
on the product of the axion-electron and axion-photon coupling of
$g_{ae} g_{aγ} < \SI{8.1e-23}{\GeV^{-1}}$. The limit calculation was
based on data taken in CAST phase I in 2003 - 2005 with a pn-CCD
detector behind the MPE telescope.

For the chameleon search the best current limit on the
chameleon-photon coupling is based on a single GridPix based detector
with data taken in 2014 and 2015 by C. Krieger in
\cite{krieger2018search}, limiting the coupling to $β_γ <
\num{5.74e10}$, which is the first limit below the solar luminosity
bound. *CHECK CORRECT TERM*.

*Mention the limit method with foreshadowing to statistics chapter
that we will use the same?*

*** Subsection about gaseous phase, affecting conversion :noexport:

Extract parts of the axionMass.org file and place it here. Essentially
the:
- conversion probability in gas
- how to compute that
- one step showing conversion prob outside coherent condition

** International AXion Observatory (IAXO)

Barring a revolution in detector development or a lucky find of a non
QCD axion, the CAST experiment was unlikely to detect any signals. A
fourth generation axion helioscope to possibly reach towards the QCD
band in the mass-coupling constant phase space is a natural idea.

The first proposal for a next generation axion helioscope was
published in 2011 \cite{Irastorza_2011}, with the name International AXion
Observatory (IAXO) first appearing in 2013 \cite{vogel2013iaxo}. A
conceptual design report was further published in 2014
\cite{Armengaud_2014}. 

The proposed experiment is supposed to have a total magnet length of \SI{25}{m}
length with \num{8} \SI{60}{\cm} bores with an average transverse
magnetic field of \SI{2.5}{\tesla}. With a cryostat and magnet design
specifically built for the experiment, much larger tilting angles of
the magnet of about $\pm\ang{25}$ are proposed to allow for solar
tracking for \SI{12}{\hour} per day for a 1:1 data split between
tracking and background data. \cite{Armengaud_2014}

A schematic of the proposed design can be seen in fig. *IAXO FIG*.

Given the comparatively large budget requirements for such an
experiment, a compromise was envisioned to prove the required
technologies. This intermediate experiment called BabyIAXO will be
discussed in the next section, [[BabyIAXO]].

Make use of PRC (?) mainly for data, citation both that and first
proposal.

*MAYBE PICTURE OF IAXO LEFT, BABYIAXO RIGHT*

*** BabyIAXO

The major difference between full grown IAXO and BabyIAXO is
restricting the setup to 2 bores instead of 8 with a magnet length of
only \SI{10}{\m} to prove the magnet design works, before building a
larger version of said design.

Since the first conceptual design of IAXO \cite{Armengaud_2014} the
bore diameter for the two bores of BabyIAXO has increased from
\SI{60}{\cm} to \SI{70}{\cm}. \cite{abeln2021conceptual}

The BabyIAXO design was approved by the Deutsches
Elektronen-Synchrotron (DESY) for construction onsite, possibly
starting 2022 *CHECK*. As of writing the thesis the final construction
site is still undecided.
*WHEN CONSTRUCTION START UNCLEAR, WHAT TO WRITE HERE*

A schematic of the BabyIAXO design can be seen in fig. *BABYIAXO*.

*FIGURE OF MERIT*

*EXPECTED LIMIT for IAXO / BabyIAXO*


* Gaseous detectors principles                                       :Theory:

#+LATEX: \minitoc

Gaseous detectors, keep a bit short. Before writing properly read
Lucian. Best if read Lucian and then write a couple of weeks later.

This chapter will be kept reasonably short. Instead of introducing all
physics relevant for gaseous detectors, we will focus on the things
that are relevant for the understanding in the context of the
thesis. For better general overview of the physics of gaseous
detectors, read some of the following references: *Lucian, Markus MSc;
Lupberger, Krieger PhD, Elisa PhD, PDG, some book?...*

*Highlight which reference for what*

The theory sections covered in the following parts all have in common
that their understanding is required to make certain assumptions in
the data analysis or *???* 

It should be noted though that no part will be thorough enough to
stand on its own. Further reading is required in many places. This
theory section is supposed to serve as a reference for the later parts
of the thesis.

Of particular interest are all sections that give the theoretical
foundation for different kinds of background we might measure or the
understanding of our calibration data.

** TODO cosmic background?
:PROPERTIES:
:CUSTOM_ID: sec:cosmic_radiation
:END:

In a paragraph or two introduce cosmic radiation as a source of
background? I mean it's pretty essential.

*PLOT OF PRIMARY RADIATION*

*SECONDARY MUON PRODUCTION*

*MUON FLUX AT ZENITH*, *MUON FLUX UNDER ANGLE* (cos²)

** Particle interactions with matter

*** X-rays through matter & gases

Lambert-Beer's law

\[
I(z) = I_0 e^{-μz}
\]

gives the intensity of radiation $I(z)$ after traversing through a
medium with attenuation $μ$ of length $z$, given a starting intensity
of $I_0$. 

This law is of vital importance for the behavior of X-rays traversing
through matter, which is needed to compute the detector efficiency.

In addition it is also related to the mean free path of X-rays in a
gas, which is an important parameter in gaseous detectors to
understand the absorption efficiency of X-rays of different energies
and the expected diffusion.

Talk about attenuation length for photons in gases.

Absorption based on density etc. (for our windows)

Mean free path of photons in gas. (for point of absorption in
detector + diffusion distance)

*EXAMPLE of ?*

*** Bethe-Bloch equation

Another relevant aspect for gaseous detectors is the energy deposition
of charged particles. In particular for experiments that sit near the
surface, a major source of background is due to cosmic radiation,
with cosmic muons making up *HOW MUCH* the largest fraction of
radiation at the surface. 

These muons lose energy according to the Bethe-Bloch equation *CITE
WHAT*, which describes the average energy loss per distance for a
charged particle with charge $Ne$ in a homogeneous medium with charge
carriers $Z$. *FIX ME* \cite{Zyla:2020zbs}

\begin{equation}
  \left\langle -\frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle = 
    K z² \frac{Z}{A} \frac{1}{β²} \left[ 
      \frac{1}{2} \ln\frac{2m_e c² β² γ² W_{\text{max}}}{I²} - β² - \frac{δ(βγ)}{2} 
    \right]
\end{equation}
where the different variables are as follows: 
*TURN INTO TABLE*
- $K = 4π N_A r_e² m_e c² = \SI{0.307075}{\MeV \mol^{-1} \cm²}$
- $N_A = \SI{6.022 140 857(74)e23}{\mol^{-1}}$: Avogadro's number
- $r_e = e² / 4π ε_0 m_e c² = \SI{2.817 940 3227(19)}{fm}$: classical
  electron radius
- $m_e = \SI{9.1093837015(28)e-31}{\kg}$: electron mass
- $c = \SI{299792458}{\meter\per\second}$: speed of light in vacuum
- $z$: charge number of incident particle
- $Z$: atomic number of absorber material
- $A$: atomic mass of absorber material
- $β = \frac{v}{c}$: speed of incident particle
- $γ = \frac{1}{\sqrt{1 - β²}}$: Lorentz factor
- $W_{\text{max}}$: Maximum possible energy transfer to an electron in
  a single interaction
- $I$: mean excitation energy of the absorber material in \si{\eV}
- $δ(βγ)$: density-effect correction to energy loss

This interaction behavior of muons leads to a specific, expected
energy loss per distance. For argon gas at normal conditions (1 bar,
20°C, ...) this is shown in fig. *ARGON BETHE*.

*CITE PDG*
There are multiple different representations of the Bethe-Bloch
equation mention multiple different ways to write formula.

As the Bethe formula was derived from quantum mechanical perturbation
theory, higher order corrections can be computed. For our purposes
here the leading order is enough. The next corrections proportional to
$Z³$ and $Z⁴$ are called /??/ and /shell correction/ respectively. 
At higher energies also the density correction by Fermi *CITE* needs
to be accounted for.
*SHOW WITH OR WITHOUT. EQUATION WITH, BUT DROP IN CALCS*

Muons arriving at the surface have energies typically above
\SI{100}{\MeV}. For that reason the higher order corrections are not
of importance for the study of muons in gaseous detectors.

At each point the formula gives the *expectation value* for the energy
loss after a distance large enough to include many interactions. In
each interaction the particle loses energy according to a Landau
distribution *CITE WHAT*, shown in fig. *LANDAU PLOT*. 
*EXPLANATION NOT QUITE CORRECT*

*MOVE FOLLOWING TO SEPARATE SECTION LATER (noexport about muon studies?)*
By taking into account the Bethe formula and a Landau distribution for
each point, we can compute an expectation for the energy loss for
muons under typical conditions met in a gaseous detector.

Introduce bethe equation, add a plot we did for our gas. (for muons in particular)

Landau distribution!

Also check out this $f$ function that is mentioned here:
https://doi.org/10.1016/j.nima.2006.03.009

as a better way to compute the actual energy loss per distance?

Also: read again PDG part about PDG and later in chapter the average
energy loss. Of course cannot take the mean of the Landau distribution
due to the long tail. We don't really do that in our muon simulation
though. 

\input{~/phd/Figs/muonStudies/ar_energy_loss_cast.tex}

**** Bethe equation for muons traversing \SI{3}{\cm} of argon gas 

We will now compute the energy loss for muons traversing the
\SI{3}{\cm} of argon gas that are seen by a muon traversing
orthogonally to the readout plane (i.e. such that it may look like a
photon).

#+begin_src nim :results silent
import math, macros, unchained, ggplotnim, sequtils, strformat, strutils
import thesisHelpers
import ggplotnim / ggplot_vegatex

let K = 4 * π * N_A * r_e^2 * m_e * c^2 # usually in: [MeV mol⁻¹ cm²]

defUnit(cm³•g⁻¹)
defUnit(J•m⁻¹)
defUnit(cm⁻³)
defUnit(g•mol⁻¹)
defUnit(MeV•g⁻¹•cm²)
defUnit(mol⁻¹)
defUnit(keV•cm⁻¹)

proc I[T](z: float): T =
  ## use Bloch approximation for all but Argon (better use tabulated values!)
  result = if z == 18.0: 188.0.eV.to(T) 
           else: (10.eV * z).to(T)

proc calcβ(γ: UnitLess): UnitLess =
  result = sqrt(1.0 - 1.0 / (γ^2))

proc betheBlochPDG(z, Z: UnitLess, A: g•mol⁻¹, γ: UnitLess, M: kg): MeV•g⁻¹•cm² =
  ## result in MeV cm² g⁻¹ (normalized by density)
  ## z: charge of particle
  ## Z: charge of particles making up medium
  ## A: atomic mass of particles making up medium
  ## γ: Lorentz factor of particle
  ## M: mass of particle in MeV (or same mass as `m_e` defined as)
  let β = calcβ(γ)
  let W_max = 2 * m_e * c^2 * β^2 * γ^2 / (1 + 2 * γ * m_e / M + (m_e / M)^2)
  let lnArg = 2 * m_e * c^2 * β^2 * γ^2 * W_max / (I[Joule](Z)^2)
  result = (K * z^2 * Z / A * 1.0 / (β^2) * (
   0.5 * ln(lnArg) - β^2
  )).to(MeV•g⁻¹•cm²)

proc density(p: mbar, M: g•mol⁻¹, temp: Kelvin): g•cm⁻³ =
  ## returns the density of the gas for the given pressure.
  ## The pressure is assumed in `mbar` and the temperature (in `K`).
  ## The default temperature corresponds to BabyIAXO aim.
  ## Returns the density in `g / cm^3`
  let gasConstant = 8.314.J•K⁻¹•mol⁻¹ # joule K^-1 mol^-1
  let pressure = p.to(Pa) # pressure in Pa
  result = (pressure * M / (gasConstant * temp)).to(g•cm⁻³)

proc E_to_γ(E: GeV): UnitLess =
  result = E.to(Joule) / (m_μ * c^2) + 1

type
  Element = object
    name: string
    Z: UnitLess
    M: g•mol⁻¹
    A: UnitLess # numerically same as `M`
    ρ: g•cm⁻³

proc initElement(name: string, Z: UnitLess, M: g•mol⁻¹, ρ: g•cm⁻³): Element =
  Element(name: name, Z: Z, M: M, A: M.UnitLess, ρ: ρ)

let M_Ar = 39.95.g•mol⁻¹ # molar mass. Numerically same as relative atomic mass
let ρAr = density(1050.mbar, M_Ar, temp = 293.15.K)
let Argon = initElement("ar", 18.0.UnitLess, 39.95.g•mol⁻¹, ρAr)

proc intBethe(e: Element, d_total: cm, E0: eV, dx = 1.μm): eV =
  ## integrated energy loss of bethe formula after `d` cm of matter
  ## and returns the energy remaining
  var γ: UnitLess = E_to_γ(E0.to(GeV))
  var d: cm
  result = E0
  var totalLoss = 0.eV
  while d < d_total and result > 0.eV:
    let E_loss: MeV = betheBlochPDG(-1, e.Z, e.M, γ, m_μ) * e.ρ * dx
    result = result - E_loss.to(eV)
    γ = E_to_γ(result.to(GeV))
    d = d + dx.to(cm)
    totalLoss = totalLoss + E_loss.to(eV)
  result = max(0.float, result.float).eV

func argonLabel(): string = "muon_argon_3cm_bethe_loss"

func argonCaption(): string = 
  result = r"Mean energy loss of muons in \SI{3}{\cm} of argon at conditions in use in " &
    r"GridPix detector at CAST. \SI{1050}{mbar} of chamber pressure at room temperature." &
    interactiveVega(argonLabel())

proc plotDetectorAbsorption(element: Element) =
  let E_float = logspace(-2, 2, 1000)
  let energies = E_float.mapIt(it.GeV)
  let E_loss = energies.mapIt((it.to(eV) - intBethe(element, 3.cm, it.to(eV))).to(keV).float)
  let df = seqsToDf(E_float, E_loss)
  ggplot(df, aes("E_float", "E_loss")) +
    geom_line() +
    xlab(r"μ Energy [\si{\GeV}]") + ylab(r"$-\left\langle \frac{\mathrm{d}E}{\mathrm{d}x}\right\rangle$ [\si{\keV}]") +
    scale_x_log10() + scale_y_log10() +
    theme_latex() + 
    ggtitle(r"Energy loss of Muons in \SI{3}{\cm} " & &"{element.name.capitalizeAscii} at CAST conditions") +
    #ggsave(&"/home/basti/phd/Figs/muonStudies/{element.name}_energy_loss_cast.pdf", useTeX = true, standalone = true)
    ggvegatex(&"/home/basti/phd/Figs/muonStudies/{element.name}_energy_loss_cast",
              caption = argonCaption(),
              label = argonLabel())
plotDetectorAbsorption(Argon)
#+end_src

*** X-ray fluorescence

Important for our 3 keV Argon line + 8 keV copper line mainly.

Cosmic muons in their interactions with matter can ionize atoms,
leading to the possible emission of X-rays if the removed electron is
part on an inner shell, mostly K (and some L) shell electrons. This
leads to a form of background based on real X-rays and thus represents
a kind of background that is impossible to distinguish from any kind
of axion signal unless external scintillator based vetoes are used.
*TOO MUCH DETAIL HERE?* *CHECK THE SHELL STUFF, GIVE A MINI TABLE OF
IMPORTANT ATOMIC LINES!* 

Different lines of different materials are listed in
tab. [[tab_all_xray_fluorescence]], with a focus on elements that are
likely to be present in or around a detector.


*TODO: REMOVE UNNECESSARY LINES*
#+NAME: tab_all_xray_fluorescence
#+CAPTION: Photon energies of K, L and M emission lines for different elements in \si{eV}. 
#+CAPTION: Taken from \cite{williams2001x}, specifically https://xdb.lbl.gov/Section1/Table_1-2.pdf.
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  3 | Li      | 54.3      |           |          |          |           |          |          |          |         |
|  4 | Be      | 108.5     |           |          |          |           |          |          |          |         |
|  5 | B       | 183.3     |           |          |          |           |          |          |          |         |
|  6 | C       | 277       |           |          |          |           |          |          |          |         |
|  7 | N       | 392.4     |           |          |          |           |          |          |          |         |
|  8 | O       | 524.9     |           |          |          |           |          |          |          |         |
|  9 | F       | 676.8     |           |          |          |           |          |          |          |         |
| 10 | Ne      | 848.6     | 848.6     |          |          |           |          |          |          |         |
| 11 | Na      | 1,040.98  | 1,040.98  | 1,071.1  |          |           |          |          |          |         |
| 12 | Mg      | 1,253.60  | 1,253.60  | 1,302.2  |          |           |          |          |          |         |
| 13 | Al      | 1,486.70  | 1,486.27  | 1,557.45 |          |           |          |          |          |         |
| 14 | Si      | 1,739.98  | 1,739.38  | 1,835.94 |          |           |          |          |          |         |
| 15 | P       | 2,013.7   | 2,012.7   | 2,139.1  |          |           |          |          |          |         |
| 16 | S       | 2,307.84  | 2,306.64  | 2,464.04 |          |           |          |          |          |         |
| 17 | Cl      | 2,622.39  | 2,620.78  | 2,815.6  |          |           |          |          |          |         |
| 18 | Ar      | 2,957.70  | 2,955.63  | 3,190.5  |          |           |          |          |          |         |
| 19 | K       | 3,313.8   | 3,311.1   | 3,589.6  |          |           |          |          |          |         |
| 20 | Ca      | 3,691.68  | 3,688.09  | 4,012.7  | 341.3    | 341.3     | 344.9    |          |          |         |
| 21 | Sc      | 4,090.6   | 4,086.1   | 4,460.5  | 395.4    | 395.4     | 399.6    |          |          |         |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
| 22 | Ti      | 4,510.84  | 4,504.86  | 4,931.81 | 452.2    | 452.2     | 458.4    |          |          |         |
| 23 | V       | 4,952.20  | 4,944.64  | 5,427.29 | 511.3    | 511.3     | 519.2    |          |          |         |
| 24 | Cr      | 5,414.72  | 5,405.509 | 5,946.71 | 572.8    | 572.8     | 582.8    |          |          |         |
| 25 | Mn      | 5,898.75  | 5,887.65  | 6,490.45 | 637.4    | 637.4     | 648.8    |          |          |         |
| 26 | Fe      | 6,403.84  | 6,390.84  | 7,057.98 | 705.0    | 705.0     | 718.5    |          |          |         |
| 27 | Co      | 6,930.32  | 6,915.30  | 7,649.43 | 776.2    | 776.2     | 791.4    |          |          |         |
| 28 | Ni      | 7,478.15  | 7,460.89  | 8,264.66 | 851.5    | 851.5     | 868.8    |          |          |         |
| 29 | Cu      | 8,047.78  | 8,027.83  | 8,905.29 | 929.7    | 929.7     | 949.8    |          |          |         |
| 30 | Zn      | 8,638.86  | 8,615.78  | 9,572.0  | 1,011.7  | 1,011.7   | 1,034.7  |          |          |         |
| 31 | Ga      | 9,251.74  | 9,224.82  | 10,264.2 | 1,097.92 | 1,097.92  | 1,124.8  |          |          |         |
| 32 | Ge      | 9,886.42  | 9,855.32  | 10,982.1 | 1,188.00 | 1,188.00  | 1,218.5  |          |          |         |
| 33 | As      | 10,543.72 | 10,507.99 | 11,726.2 | 1,282.0  | 1,282.0   | 1,317.0  |          |          |         |
| 34 | Se      | 11,222.4  | 11,181.4  | 12,495.9 | 1,379.10 | 1,379.10  | 1,419.23 |          |          |         |
| 35 | Br      | 11,924.2  | 11,877.6  | 13,291.4 | 1,480.43 | 1,480.43  | 1,525.90 |          |          |         |
| 36 | Kr      | 12,649    | 12,598    | 14,112   | 1,586.0  | 1,586.0   | 1,636.6  |          |          |         |
| 37 | Rb      | 13,395.3  | 13,335.8  | 14,961.3 | 1,694.13 | 1,692.56  | 1,752.17 |          |          |         |
| 38 | Sr      | 14,165    | 14,097.9  | 15,835.7 | 1,806.56 | 1,804.74  | 1,871.72 |          |          |         |
| 39 | Y       | 14,958.4  | 14,882.9  | 16,737.8 | 1,922.56 | 1,920.47  | 1,995.84 |          |          |         |
| 40 | Zr      | 15,775.1  | 15,690.9  | 17,667.8 | 2,042.36 | 2,039.9   | 2,124.4  | 2,219.4  | 2,302.7  |         |
| 41 | Nb      | 16,615.1  | 16,521.0  | 18,622.5 | 2,165.89 | 2,163.0   | 2,257.4  | 2,367.0  | 2,461.8  |         |
| 42 | Mo      | 17,479.34 | 17,374.3  | 19,608.3 | 2,293.16 | 2,289.85  | 2,394.81 | 2,518.3  | 2,623.5  |         |
| 43 | Tc      | 18,367.1  | 18,250.8  | 20,619   | 2,424    | 2,420     | 2,538    | 2,674    | 2,792    |         |
| 44 | Ru      | 19,279.2  | 19,150.4  | 21,656.8 | 2,558.55 | 2,554.31  | 2,683.23 | 2,836.0  | 2,964.5  |         |
| 45 | Rh      | 20,216.1  | 20,073.7  | 22,723.6 | 2,696.74 | 2,692.05  | 2,834.41 | 3,001.3  | 3,143.8  |         |
| 46 | Pd      | 21,177.1  | 21,020.1  | 23,818.7 | 2,838.61 | 2,833.29  | 2,990.22 | 3,171.79 | 3,328.7  |         |
| 47 | Ag      | 22,162.92 | 21,990.3  | 24,942.4 | 2,984.31 | 2,978.21  | 3,150.94 | 3,347.81 | 3,519.59 |         |
| 48 | Cd      | 23,173.6  | 22,984.1  | 26,095.5 | 3,133.73 | 3,126.91  | 3,316.57 | 3,528.12 | 3,716.86 |         |
| 49 | In      | 24,209.7  | 24,002.0  | 27,275.9 | 3,286.94 | 3,279.29  | 3,487.21 | 3,713.81 | 3,920.81 |         |
| 50 | Sn      | 25,271.3  | 25,044.0  | 28,486.0 | 3,443.98 | 3,435.42  | 3,662.80 | 3,904.86 | 4,131.12 |         |
| 51 | Sb      | 26,359.1  | 26,110.8  | 29,725.6 | 3,604.72 | 3,595.32  | 3,843.57 | 4,100.78 | 4,347.79 |         |
| 52 | Te      | 27,472.3  | 27,201.7  | 30,995.7 | 3,769.33 | 3,758.8   | 4,029.58 | 4,301.7  | 4,570.9  |         |
| 53 | I       | 28,612.0  | 28,317.2  | 32,294.7 | 3,937.65 | 3,926.04  | 4,220.72 | 4,507.5  | 4,800.9  |         |
| 54 | Xe      | 29,779    | 29,458    | 33,624   | 4,109.9  | —         | —        | —        | —        |         |
| 55 | Cs      | 30,972.8  | 30,625.1  | 34,986.9 | 4,286.5  | 4,272.2   | 4,619.8  | 4,935.9  | 5,280.4  |         |
| 56 | Ba      | 32,193.6  | 31,817.1  | 36,378.2 | 4,466.26 | 4,450.90  | 4,827.53 | 5,156.5  | 5,531.1  |         |
| 57 | La      | 33,441.8  | 33,034.1  | 37,801.0 | 4,650.97 | 4,634.23  | 5,042.1  | 5,383.5  | 5,788.5  | 833     |
| 58 | Ce      | 34,719.7  | 34,278.9  | 39,257.3 | 4,840.2  | 4,823.0   | 5,262.2  | 5,613.4  | 6,052    | 883     |
| 59 | Pr      | 36,026.3  | 35,550.2  | 40,748.2 | 5,033.7  | 5,013.5   | 5,488.9  | 5,850    | 6,322.1  | 929     |
| 60 | Nd      | 37,361.0  | 36,847.4  | 42,271.3 | 5,230.4  | 5,207.7   | 5,721.6  | 6,089.4  | 6,602.1  | 978     |
| 61 | Pm      | 38,724.7  | 38,171.2  | 43,826   | 5,432.5  | 5,407.8   | 5,961    | 6,339    | 6,892    | —       |
| 62 | Sm      | 40,118.1  | 39,522.4  | 45,413   | 5,636.1  | 5,609.0   | 6,205.1  | 6,586    | 7,178    | 1,081   |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
|  Z | Element | Kα1       | Kα2       | Kβ1      | Lα1      | Lα2       | Lβ1      | Lβ2      | Lγ1      | Mα1     |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|
| 63 | Eu      | 41,542.2  | 40,901.9  | 47,037.9 | 5,845.7  | 5,816.6   | 6,456.4  | 6,843.2  | 7,480.3  | 1,131   |
| 64 | Gd      | 42,996.2  | 42,308.9  | 48,697   | 6,057.2  | 6,025.0   | 6,713.2  | 7,102.8  | 7,785.8  | 1,185   |
| 65 | Tb      | 44,481.6  | 43,744.1  | 50,382   | 6,272.8  | 6,238.0   | 6,978    | 7,366.7  | 8,102    | 1,240   |
| 66 | Dy      | 45,998.4  | 45,207.8  | 52,119   | 6,495.2  | 6,457.7   | 7,247.7  | 7,635.7  | 8,418.8  | 1,293   |
| 67 | Ho      | 47,546.7  | 46,699.7  | 53,877   | 6,719.8  | 6,679.5   | 7,525.3  | 7,911    | 8,747    | 1,348   |
| 68 | Er      | 49,127.7  | 48,221.1  | 55,681   | 6,948.7  | 6,905.0   | 7,810.9  | 8,189.0  | 9,089    | 1,406   |
| 69 | Tm      | 50,741.6  | 49,772.6  | 57,517   | 7,179.9  | 7,133.1   | 8,101    | 8,468    | 9,426    | 1,462   |
| 70 | Yb      | 52,388.9  | 51,354.0  | 59,370   | 7,415.6  | 7,367.3   | 8,401.8  | 8,758.8  | 9,780.1  | 1,521.4 |
| 71 | Lu      | 54,069.8  | 52,965.0  | 61,283   | 7,655.5  | 7,604.9   | 8,709.0  | 9,048.9  | 10,143.4 | 1,581.3 |
| 72 | Hf      | 55,790.2  | 54,611.4  | 63,234   | 7,899.0  | 7,844.6   | 9,022.7  | 9,347.3  | 10,515.8 | 1,644.6 |
| 73 | Ta      | 57,532    | 56,277    | 65,223   | 8,146.1  | 8,087.9   | 9,343.1  | 9,651.8  | 10,895.2 | 1,710   |
| 74 | W       | 59,318.24 | 57,981.7  | 67,244.3 | 8,397.6  | 8,335.2   | 9,672.35 | 9,961.5  | 11,285.9 | 1,775.4 |
| 75 | Re      | 61,140.3  | 59,717.9  | 69,310   | 8,652.5  | 8,586.2   | 10,010.0 | 10,275.2 | 11,685.4 | 1,842.5 |
| 76 | Os      | 63,000.5  | 61,486.7  | 71,413   | 8,911.7  | 8,841.0   | 10,355.3 | 10,598.5 | 12,095.3 | 1,910.2 |
| 77 | Ir      | 64,895.6  | 63,286.7  | 73,560.8 | 9,175.1  | 9,099.5   | 10,708.3 | 10,920.3 | 12,512.6 | 1,979.9 |
| 78 | Pt      | 66,832    | 65,112    | 75,748   | 9,442.3  | 9,361.8   | 11,070.7 | 11,250.5 | 12,942.0 | 2,050.5 |
| 79 | Au      | 68,803.7  | 66,989.5  | 77,984   | 9,713.3  | 9,628.0   | 11,442.3 | 11,584.7 | 13,381.7 | 2,122.9 |
| 80 | Hg      | 70,819    | 68,895    | 80,253   | 9,988.8  | 9,897.6   | 11,822.6 | 11,924.1 | 13,830.1 | 2,195.3 |
| 81 | Tl      | 72,871.5  | 70,831.9  | 82,576   | 10,268.5 | 10,172.8  | 12,213.3 | 12,271.5 | 14,291.5 | 2,270.6 |
| 82 | Pb      | 74,969.4  | 72,804.2  | 84,936   | 10,551.5 | 10,449.5  | 12,613.7 | 12,622.6 | 14,764.4 | 2,345.5 |
| 83 | Bi      | 77,107.9  | 74,814.8  | 87,343   | 10,838.8 | 10,730.91 | 13,023.5 | 12,979.9 | 15,247.7 | 2,422.6 |
| 84 | Po      | 79,290    | 76,862    | 89,800   | 11,130.8 | 11,015.8  | 13,447   | 13,340.4 | 15,744   | —       |
| 85 | At      | 81,520    | 78,950    | 92,300   | 11,426.8 | 11,304.8  | 13,876   | —        | 16,251   | —       |
| 86 | Rn      | 83,780    | 81,070    | 94,870   | 11,727.0 | 11,597.9  | 14,316   | —        | 16,770   | —       |
| 87 | Fr      | 86,100    | 83,230    | 97,470   | 12,031.3 | 11,895.0  | 14,770   | 14,450   | 17,303   | —       |
| 88 | Ra      | 88,470    | 85,430    | 100,130  | 12,339.7 | 12,196.2  | 15,235.8 | 14,841.4 | 17,849   | —       |
| 89 | Ac      | 90,884    | 87,670    | 102,850  | 12,652.0 | 12,500.8  | 15,713   | —        | 18,408   | —       |
| 90 | Th      | 93,350    | 89,953    | 105,609  | 12,968.7 | 12,809.6  | 16,202.2 | 15,623.7 | 18,982.5 | 2,996.1 |
| 91 | Pa      | 95,868    | 92,287    | 108,427  | 13,290.7 | 13,122.2  | 16,702   | 16,024   | 19,568   | 3,082.3 |
| 92 | U       | 98,439    | 94,665    | 111,300  | 13,614.7 | 13,438.8  | 17,220.0 | 16,428.3 | 20,167.1 | 3,170.8 |
| 93 | Np      | —         | —         | —        | 13,944.1 | 13,759.7  | 17,750.2 | 16,840.0 | 20,784.8 | —       |
| 94 | Pu      | —         | —         | —        | 14,278.6 | 14,084.2  | 18,293.7 | 17,255.3 | 21,417.3 | —       |
| 95 | Am      | —         | —         | —        | 14,617.2 | 14,411.9  | 18,852.0 | 17,676.5 | 22,065.2 | —       |
|----+---------+-----------+-----------+----------+----------+-----------+----------+----------+----------+---------|


Of course to be relevant as a form of detector background the material
must be close to the detector, as the X-rays will otherwise be
absorbed. This makes the detector material, the gas itself and all
material in the direction of the detectors' sensitivity a candidate
for X-ray fluorescence background.

Tab. *TABLE INSERT* contains the different lines of plausible
materials used for detector construction / etc. *...*
*ASK TOBI IF TO ADD SOME MATERIAL*

*HOW DOES THIS CORRESPOND TO AUGER ELECTRONS?*

*** Bremsstrahlung

Talk about Bremsstrahlung as a requirement for the CDL data?



** Gaseous detector fundamentals

*** Mean free path

See photons above.

Of major importance for the detection of particles in a gaseous
detector is of course the mean free path. This is the mean length a
particle traverses in a medium before interactions. For charged
particles it yields the mean distance between individual interaction
points, whereas for a photon it gives the mean length the photon
traverses through the detector before interaction. 

Especially for photons this value is of crucial importance, as it
tells us at what distance photons will likely convert depending on
their energy. This is important as it directly affects the possible
drift distance and thus diffusion available to the generated
electrons.
*TOO MUCH DETAIL, AS WE HAVE NOT INTRODUCED DETECTORS YET!!*

*** Diffusion

Describe diffusion based on gas. Needed to get expected photon size
based on conversion at specific height.

What effects affect diffusion?

Random walk + a force acting on particles.

*COMPUTE USING PYBOLTZ: https://github.com/UTA-REST/PyBoltz*

*** Drift velocity

Talk about drift velocity of electrons for a given electric
field. Required to know time scales associated with e.g. muons + FADC,
time it takes for X-rays to drift (for random coincidences in long
frames etc.)

*USE FORMULA PDG*

The detector used in this thesis does not make use of magnetic
fields. Thus, all terms but the first are zero. Further, the electric
field is constant, leading to the following simplification:


Based on the so called 'friction force model' an analytical expression
for the drift velocity in an electromagnetic field can be written to:
\[
\vec{v} = \frac{e}{m_e} \frac{τ}{1 + ω²τ²}\left( \vec{E} + \frac{ωτ}{B}
(\vec{E} × \vec{B}) + \frac{ω²τ²}{B²}(\vec{E} · \vec{B}) \vec{B} \right)
\]
with the electron charge $e$ and mass $m_e$, in an electric field
$\vec{E}$ and magnetic field $\vec{B}$, given the Lamor frequency 
$ω = eB / m_e$ and the mean collision time $τ$. \cite{Zyla:2020zbs}

For the typical case in Micromegas detectors without a magnetic field
$B = 0, ω = 0$ and a constant, homogeneous electric field $E$, this
reduces to the Townsend expression:

\[
v = \frac{e E τ}{m_e}
\]

These can be computed using software packages like MAGBOLTZ (or its
Python port PyBoltz) that solve the underlying transport equation, the
Boltzmann equation:

\begin{align}
  \frac{∂f}{∂t} + \vec{v} \frac{∂}{∂\vec{r}}f + \frac{∂}{∂\vec{v}}\vec{g} &= Q(t) \\
  \vec{g} &= \left(\frac{e\vec{E}}{m} + \vec{ω} × \vec{v}\right) f
\end{align}
*FIX THIS*

*BOLTZMANN EQUATION: https://en.wikipedia.org/wiki/Boltzmann_equation*

*COMPUTE USING PYBOLTZ: https://github.com/UTA-REST/PyBoltz*

*** Escape photons / peaks | 55Fe as a typical calibration source

Explain escape photons, escape peaks, how that gives us an escape peak
in the 55Fe spectra as well as a line at 3 keV in our background data.

Explain Fe ↦ Mn excited ↦ Mn + γ and what spectrum looks like


*** Why expect ~26 eV for argon

Talk about ionization energy vs. the actual mean energy loss for a
single ionization. Argon ionization energy is only like 15 eV or so,
but effective one is 26.

Leads to our 226 or so primary electrons for our 55Fe spectra.


*** Energy resolution

What is energy resolution, definition.

E / σ_E or something like this.

Why important for our detector.

Fano factors are related to this! Theory and observation
disagree. Fano factor fixes this by doing a scaling. Related to the
fact that theory assumes a perfectly statistical process, but reality
has fixed number of possible interactions, hence not really perfect statistics.

*** Gas amplification, avalanche effect

If it fits here, Polya distribution to describe avalanche effect.

What gas properties affect the gas gain? Temperature, density etc.

Gas gain.

** Micromegas working principle

\textbf{Micro} \textbf{Me}sh \textbf{Ga}seous \textbf{S}tructures
(Micromegas) are a kind of \textbf{M}icro\textbf{p}attern
\textbf{G}aseous \textbf{D}etectors (MPGDs) first introduced in 1996
\cite{GIOMATARIS199629, GIOMATARIS1998239}. The modern Micromegas is
the Microbulk Micromegas \cite{Andriamonje_2010}.

Interestingly, the name Micromegas is based on the novella Micromégas
by Voltaire published in 1752 \cite{voltaire1752micromegas}, an early
example of a science fiction story. \cite{GIOMATARIS199629}

These detectors are - as the name implies - gaseous detectors
containing a 'micro mesh'. In the most basic form they are a made of a
closed detector volume that is filled with a suitable gas (often Argon
based gas mixtures are used; Xenon based detectors are in development
for certain applications) allowing ionization. The volume is split
into two different sections, a large drift volume typically
$\mathcal{O}(\text{few }\si{cm})$ and an amplification region, sized
$\mathcal{O}(\SIrange{50}{100}{μm})$. 

At the top of the volume is a cathode to apply an electric
field. Below the mesh is the readout area at the bottom of the
volume. In standard Micromegas detectors strips or pads are used as a
readout.

The electric field in the drift region is strong enough to avoid
recombination of the created electron-ion pairs and to provide
reasonably fast drift velocities $\mathcal{O}(\si{cm.μs⁻¹})$. 

The amplification gap on the other hand is precisely used to multiply
the primary electrons using an avalanche effect. Thus, the electric
field reaches values of $\mathcal{O}(\SI{50}{kV.cm⁻¹})$.

These drift and amplification volumes are achieved by an electric
field between a cathode and the mesh as well as the mesh and the
readout area. 

For a more detailed overview of Micromegas detectors and their
history, see *CITE WHAT?* 
# \cite{} 


#+begin_center
#+CAPTION: Working principle of a general Micromegas detector. An ionizing photon enters through the
#+CAPTION: detector window into the gas-filled detector body. After a certain distance it produces
#+CAPTION: a photo electron, which ionizes further gas molecules for a specific number of primary
#+CAPTION: electrons (depending on the incoming photon's energy) and gas mixture. The primary electrons
#+CAPTION: drift towards the micromesh due to the drift voltage, thereby experiencing diffusion. 
#+CAPTION: In the much higher voltage in the amplification gap an avalanche of electrons is produced, 
#+CAPTION: enough to trigger the readout electronics (strips or pads).
#+CAPTION: Note that the numbers shown in the figure are exemplary and vary between individual
#+CAPTION: detectors.
#+NAME: micromegas_schematic
[[~/org/Figs/thesis/detectors/micromegas_schematic.pdf]]
#+end_center


** Timepix ASIC

The Timepix ASIC (Application Specific Integrated Circuit) is a $256 ×
256$ pixel ASIC (\SI{50}{\micro\meter} pitch)

Introduce Timepix. Short introduction to how they are built?

Different modes to work with, we use ToT (Time over Threshold). Also:
ToA (Time of Arrival).

Works at \SI{40}{\mega\Hz}. 

Check Lucian's master thesis for information about Timepix & gaseous
detector physics. :)

*TALK HERE ABOUT DIFFERENT TOS CALIBRATIONS?*

*ADD ALL USED DETECTOR CALIBRATIONS IN FULL TO APPENDIX. INCLUDE THE
PLOTS FOR TOT. TABLE OF TOT FIT PARAMETERS ETC*

*** Timepix3

Introduce as something for which readout etc. is currently in
development. Mention improvements so that we can refer back to them in
our conclusion that having time information would be great.

** GridPix

Build GridPix on top of Timepix. Nikhef paper CITE.

Production nowadays in Berlin IZM. Show sketch of production process?
Imo should be enough to refer to Lucian's thesis for production
process. Is there a paper about IZM process? Ask Yevgen & Lucian.

\SI{50}{\micro\meter} pillars (amplification gap). Typical gas gains
of 2000-5000. 

Polya plot.

Important: single electron detection efficiency. 

*** Caveats

E.g. things like charge up effects etc. discussed in other theses.

** 2014 / 2015 GridPix detector

In the course of CITE THESIS a first GridPix based detector for axion
search was developed.

As an example and a reference shown here. The foundation of what is
done in this thesis.

Not sure if this section is the right place. But: Could add background
rate achieved by that detector here?
*YES*
- background rate
- background over chip (latter comes later??)




* Statistics & limit calculations

In a physics experiment after performing all measurements there comes
the question of "did I measures something and do I want to compute
some confidence interval on an observable or did I measure nothing and
want to set a limit on the observable?"

These questions can be answered in a variety of different ways. 

In the end it is highly dependent on a Frequentist vs. Bayesian
approach to statistics.

** Limit computation methods

Describe log L and χ² distribution and how to compute limit.

Unphysicality, fix by rescaling, χ² min + 4 thing
*UPDATE*: good that we now understand how this actually works,
i.e. integrate the posterior probability (likelihood * prior / normalization)

* Septemboard detector                                             :Detector:

The first section introduces the reasoning behind building a more
complicated detector. Existing detector has multiple downsides, seen
in background rate & detector efficiency.

In the further sections we discuss each additional detector feature in
detail and explain why it was added / what drawback of the previous
detector should be improved on.

After we have introduced the detector as a whole we talk about the
calibrations that are necessary to perform sensible measurements.

** The why (make this the introduction to the chapter?)

*IN EACH SUBSECTION START WITH WHAT IT'S SUPPOSED TO HELP WITH?*

The detector in use in the 2014 / 2015 data taking campaign, presented
in section [[2014 / 2015 GridPix detector]] had a few significant
drawbacks for more sensitive searches, in particular for searches at
low energies $\lesssim\SI{2}{\keV}$ and/or searches requiring low
backgrounds over larger areas on the chip (for example the chameleon
search done in \cite{krieger2018search}). 

All detector upgrades were done to alleviate one or more of these
drawbacks. We will now go through each of the new detector features
and highlight the aspects it is intended to improve on.

Section [[#sec:scintillators]] introduces two new scintillators as
vetoes. These require the addition of an external shutter for the
Timepix, which is realized by usage of a flash ADC (FADC), see section
[[#sec:fadc]]. Further, an independent but extremely important addition is
the replacement of the Mylar window by a silicon nitride window,
section [[#sec:sin_window]]. Another aspect is the addition of another 6
GridPixes around the central GridPix, the 'Septemboard' introduced in
section [[#sec:septemboard]]. 

The full detector is presented in section [[#sec:full_septemboard_detector]].

Why do we build such a 'complicated' detector?

Background increases to edges, esp. corners.

Background rate has known peaks. 3 keV for the Argon escape
peak. Can't do anything about that in current iteration.

Peak at 8-9 keV. A mix of a copper peak and orthogonal muons, which
are expected to emit about 8 keV through 3 cm. More on this later in
[[Background rate]].

Window doesn't transmit at < 2 keV

** Scintillator vetoes
:PROPERTIES:
:CUSTOM_ID: sec:scintillators
:END:

The first general improvement is the addition of two scintillators for
veto purposes. While both have slightly different goals, each is there
to help with the removal of muon signals in the detector or muon
induced events (for example X-ray fluorescence). Given that cosmic
muons (ref. section [[#sec:cosmic_radiation]]) dominate the background by
flux, statistically there is a high chance of muons creating X-ray
like signatures in the detector (more on that below). By tagging muons
before they interact near the detector, these can be correlated with
events seen on the Timepix and thus possibly be vetoed if precise time
information is available.

The first scintillator is a large *CHECK SIZES* \SI{1}{\m} by
\SI{40}{\cm} paddle installed above the detector installation, aiming
to tag a large fraction of cosmic muons traversing in the area around
the detector. Muons which traverse through this scintillator and the gaseous
detector volume are not the use case, as they can be easily
identified by the geometric properties of the induced tracks (their
zenith angles are relatively small, resulting in track like signatures
as the GridPix readout is orthogonal to the zenith angle). There is a
small chance however that a muon can excite an atom of the detector
material, which may emit an X-ray upon deexcitation. One particular
source of background can be attributed to the presence of copper whose
Kα lines are at $\sim\SI{8.04}{\keV} *CITE X-ray LBL GOV* (for an
overview of X-ray fluorescence lines see tab. *TABLE OF FLUORESCENCE*).

The second scintillator is a small silicon photomultiplier (SiPM)
installed on the underside of the PCB on which the septemboard is
installed. With this scintillator we are interested in tagging
precisely those muons, which enter the detector orthogonally to the
readout plane. This implies zenith angles of almost \SI{90}{\degree}
such that the elongation in the transverse direction of the muon track
is small enough to result in a small eccentricity. From the Bethe
equation we expect muons to deposit about \SI{8}{\keV} along the
\SI{3}{\cm} of drift volume in the detector, assuming the conditions
as used in the detector at CAST (see fig. [[muon_argon_3cm_bethe_loss]]
for the energy loss). This coincides with the copper Kα lines and
should lead to another source of background in this energy
range. Although the muon background will have a much wider
distribution than the copper lines.

*ADD NOEXPORT OF CALCULATIONS OF MUON ANGLES POSSIBLE*

*SCHEMATIC OF MUON IONIZATION*

*** Aim

Scintillators: remove muons / muon induced X-rays

SiPM: remove orthogonal muons, expected energy ~8 keV.

*** Description

** FADC
:PROPERTIES:
:CUSTOM_ID: sec:fadc
:END:

As the Timepix is read out in a shutter based fashion and typical
shutter lengths for low rate experiments are long compared to the rate
of cosmic muons, the scintillators introduced in previous section
require an external trigger to close the Timepix shutter early if a
signal is measured on the Timepix. This is one the main purposes of
the \text{f}lash \textbf{a}nalog to \textbf{d}igital
\textbf{c}onverter (FADC) that is part of the detector.

The specific FADC used for the detector is an Caen V1792a *WHICH
REVISION?*. It runs at a frequency of \SI{1}{\GHz} and has a cyclic
register with \num{10240} channels. This means it covers the last
$\sim\SI{10}{\micro\second}$ at any time. The raw signal decoupled from
the grid is first fed into an Ortec pre-amplifier, which slightly
integrates and shapes the signal as well as amplifies it. For a
detailed introduction to this FADC system, see the thesis of
A. Deisting *CITE DEISTING*.

*HAVE PRE AMPLIFIER BEFORE FADC. ORTEC*

The analogue signal measured by the FADC is the induced signal on the
grid of the central GridPix (introduced in detail in section
[[#sec:septemboard]]) via a small capacitor in parallel to the high
voltage line. For a schematic of the circuit see fig. *CIRCUIT FIGURE*
When a primary electron traverses through a hole in the grid and
is amplified, the back flowing ions induce a small voltage spike on
top of the constant high voltage applied to the grid. This signal -
the envelope of possibly many primary electrons - is measured by the
FADC.

This signal can be used for two distinct things:
1. it may be used as a trigger to close the shutter of the ongoing
   event. Ideally, we want to only measure a single physical event
   within one shutter window. A long shutter time can statistically
   result in multiple events happening, which the FADC trigger helps
   to alleviate.
2. By nature of the signal production & drift properties of the
   primary electrons before they reach the grid, the signal shape can
   theoretically be used to determine a rough longitudinal shape of
   the event. The length of the FADC event should be proportional to
   the size of the primary electron cloud distribution along the
   'vertical' detector axis. 

The former allows us to reduce the number of events with multiple
physical events and acts as a trigger for the scintillators. This in
turn means possible muon induced X-ray fluorescence can be vetoed. The
latter potentially allows to differentiate between a muon traversing
orthogonally through the readout plane and an X-ray due to their
longitudinal shape difference.

*** Aim

Show what hardware. V1792. Picture etc.

*SCHEMATIC OF FADC CLOSING TIMEPIX SHUTTER*

FADC: required for trigger + some time information of events.

Flash ADC. Fast ADC. 1024 channels, cyclic register.

Used at 1 GHz, i.e. covering ~1 μs?

Explain shortly how the raw data is converted to something useful.

*** Description

*** Pedestals & signal reconstruction

Yes, this needs to be about essentially a FADC calibration.

Before the FADC data can be used, the raw data needs to be converted
from the internal, cyclic representation into a 10240 long array.

...

By default each channel of the FADC has an arbitrary value in the
range between \num{0} to \num{10000}. This needs to be corrected for
by taking a so called 'pedestal run'. It is simply a readout of the
FADC in the absence of any signal. This pedestal run then is
subtracted from each actual FADC event to remove the pedestal
baseline. 

*** Noise sensitive

Because of the small amplitude of the associated signals induced on
the grid, electromagnetic interference is a serious issue with this
FADC setup. Ideally, the detector should be installed in a Faraday
cage and a short, shielded LEMO cable should be used to connect it to
the 

** SiN window
:PROPERTIES:
:CUSTOM_ID: sec:sin_window
:END:


*** Aim

Much better sensitivity, especially at low energies, important in
particular for axion electron & chameleon, not so much Primakoff.

Comparison of different window setups.

*** Description

** Septemboard - 6 GridPixes around a center one
:PROPERTIES:
:CUSTOM_ID: sec:septemboard
:END:

The main motivation for extending the readout area from a single chip
to a 7 chip readout is to reduce background towards the outer sides of
the chip, in particular in the corners. Against common intuition
however, it also plays a role for events, which have cluster centers
near the center of the readout. The latter is due to gas ionization
being a statistical process. In particular in lower energy events,
tracks may have gaps in them large enough to avoid being detected as a
single cluster.
*THE LATTER NEEDS MORE WORDING ELSEWHERE / CLUSTERING ALGORITHM EXPL /
SEPTEM VETO*

Fig. [[cluster_centers_likelihood]] shows a heatmap of all cluster centers
during roughly \SI{2000}{\hour} of background data after passing these
clusters through a likelihood based cut method aiming to filter out
X-ray like clusters. It is clearly visible that the further a cluster
center is towards the chip edges, and especially the corners, the more
likely it is to be considered an X-ray like cluster. This has an easy
geometric explanation. Consider a perfect track traversing over the
whole chip. In this case it is clearly eccentric. Move the same track
such that its center is in one of the corners and rotate it by
\SI{45}{\degree} and suddenly the majority of the track won't be
detected on the chip anymore. Instead something roughly circular
remains visible, 'fooling' the likelihood method. For a schematic
illustrating this, see fig *SHOW CUT OFF FROM ONE OF MY TALKS* .

\input{~/phd/Figs/backgroundClusters/background_cluster_centers.tex}
*TODO: NEED CAPTION AND LABEL FOR BACKGROUND CLUSTERS*

*** Compute the cluster backgrounds                              :noexport:

To compute these cluster backgrounds, we need the following
ingredients:
- the fully reconstructed data files =DataRuns201*_Reco.h5= 
- the prepared CDL data from the 2019 dataset
  =calibration-cdl_2019.h5= and the X-ray reference datasets that
  define the X-ray like properties.
- apply the likelihood method to all background events in one of the
  files (gives enough statistics) to get a resulting file containing
  only passed clusters *over the whole chip*.

With the resulting file we can then use
[[file:~/CastData/ExternCode/TimepixAnalysis/Plotting/plotBackgroundClusters/plotBackgroundClusters.nim]]
to plot these cluster centers.

Assuming the reconstructed data files are found in *...* and the CDL
data files in *...*, let's generate the data after likelihood method:
#+begin_src sh
~/CastData/ExternCode/TimepixAnalysis/Analysis/ingrid/likelihood ~/CastData/data/DataRuns2017_Reco.h5 --h5out /tmp/lhood_2017_full_chip.h5 \
  --altCdlFile ~/CastData/data/CDL_2019/calibration-cdl-2018.h5 \
  --altRefFile ~/CastData/data/CDL_2019/XrayReferenceFile2018.h5 \
  --cdlYear=2018 --region=crAll 
#+end_src

Now we can create the plot:
#+begin_src sh
cd ~/CastData/ExternCode/TimepixAnalysis/Plotting/plotBackgroundClusters
nim c -d:danger --threads:on plotBackgroundClusters.nim
./plotBackgroundClusters -f /tmp/lhood_2017_full_chip.h5 --useTikZ
#+end_src


** TODO Render done by Tobi. Exploded view.
:PROPERTIES:
:CUSTOM_ID: sec:full_septemboard_detector
:END:

*AS LAST SECTION?*
*** Cooling system, small motivation?

Show funny occupancy plot of the horrible sparking behavior.

Flow rate!

** TOS

*THIS NEEDS TO BE MOVED ELSEWHERE*

The \textbf{T}imepix \textbf{O}perating \textbf{S}ystem (TOS) is the
computer-side data acquisition software to read out Timepix based
detectors. It is an object oriented C++ project, available at *PUSH TO
GITHUB*. [fn:TOS_versions] 
*ACCORDING TO WIENER VME MANUAL ALL FILES ARE OPEN SOURCE*
https://wikihost.nscl.msu.edu/S800Doc/lib/exe/fetch.php?media=wiki:manual_vm-usb_9_01_1.pdf
The project needs to be used in conjunction with the \textbf{T}imepix
\textbf{O}perating \textbf{F}irmware (TOF), which is a firmware for a
Xilinx Virtex6 FPGA. The latter controls one or more Timepix ASICs via
HDMI and communicates with the TOS via Ethernet.

[fn:TOS_versions] There are unfortunately 2 different versions of TOS, as
development diverged for different readout systems. One version is for
the Xylinx Virtex 6 (V6) ML 605 evaluation board and the other for the
\textbf{S}calable \textbf{R}eadout \textbf{S}ystem (SRS). The V6
version can read out only a single detector (with up to 8 Timepix
ASICs), but supports readout of an Ortec FADC and controlling of a
Wiener HV module via VME. The SRS version instead supports neither of
these additional features, but supports multiple detectors at the same
time. The detector used in this thesis is read out using the Virtex 6
board.


*ADD FULL NAME OF V6 BOARD*

The fully object oriented nature of the project means that there are
different classes for the different software pieces:
- =Console=: A class representing the user facing REPL to control the
  software
- =PC=: A class representing the network layer and communication side
  of the software, sitting between the console and lower layers.
- =FPGA=: A class representing the functionality required to control
  the FPGA on the Virtex 6 evaluation board.
- =Chip=: A class representing each Timepix ASIC and its
  functionality.
- =HFManager=: A class unifying the FADC & Wiener HV controls as they are
  both controlled via USB, installed in a VME crate. This class
  contains individual attributes that contain explicit classes for
  these two devices. The name is shortened for 'High Voltage and FADC Manager'.
  - =V1729=: A class representing the Ortec Flash ADC.
  - =HV*=: Multiple classes representing HV channels, groups and more.
- =MCP2210=: A class representing the PT1000 temperature sensors
  installed on the detector via a MCP2210 micro controller.

In general TOS is a fully command line driven software package, with
its own REPL (Return, Evaluate, Print, Loop; the name for an
interactive terminal process, which takes commands that are evaluated
and returns to the terminal). It brings all the expected features one
might wish from a REPL, including auto completion, history lookup,
emacs style keybindings and more.

The aforementioned =HFManager= and the temperature sensors are
optional pieces that are not required for basic Timepix
operation. Their functionality has to be activated via a manual
command, =ActivateHFM=. This triggers the USB connection to the VME
crate and tries to find the Wiener HV module as well as the Ortec FADC
in the crate. Additionally, the temperature sensors are attempted to
be found (via a secondary, optional USB connection). If the latter are
found a continuous temperature logging begins. Outside of actual data
taking the temperature is logged into the internal =log= directory of
the TOS directory as =temp_log.txt=. [fn:temp_logs_lost]

[fn:temp_logs_lost] This default temperature logging location was also
used as an unintended fallback mechanism during data taking, if the HV
of the detector was considered out of certain bounds. Unfortunately,
the bounds checking was faulty which is why it was disabled manually
during data taking at CAST, as it triggered data taking aborts. This
however triggered a secondary code path for the temperature logging,
storing it in that default location. As an effect the majority of CAST
temperature logging data has been lost, as most of it was overwritten
several times. About daily manual temperature measurements are still
left and show acceptable temperature values. Precise correlations with
certain detector behaviors are unfortunately impossible. The two
different code paths for the temperature logging are essentially a bug
in the code that was never intended, stemming from the fact that
temperature logging must be done to a 'global' location outside of
data taking (as no data taking specific directory exists). Due to how
the temperature logging and HV & FADC controls were added to TOS,
these things were more entangled than necessary. A more thorough
testing period of the detector and software package should have been
performed, but was not in scope.


The HV controls are specific to Wiener HV power supplies. In principle
the implemented functionality is a fully featured HV controller that
supports all Wiener functionality like grouping different channels to
ramp up together, trip together etc.

An example of a typical startup procedure is shown in listing
[[TOS_startup_commands]]. Note that most essential commands in TOS also
have shortened names via numbers, due to historic reasons (TOS
originally did not have autocompletion or allowed moving the cursor in
text input, making typing complex names cumbersome and error prone),
which is why many of the inputs are simple numbers.

#+CAPTION: An example of the typical startup routine of TOS for a background data taking measurement at CAST
#+CAPTION: for the Septemboard based GridPix detector.
#+LABEL: TOS_startup_commands
#+begin_src sh
user@ingrid-DAQ~/ ./TOS
> 7 # number of chips
> 4 # preload
> SetChipIDOffset
> 190
> lf # load FSR values for the chips
> # 7 times enter to load default paths
> uma # create a uniform matrix for all chips
> 1 # Matrix settings
> 0
> 1
> 1
> 0
> LoadThreshold # load threshold equalisation files
> 4 # write matrix
> 3 # read out
> 3 # 2nd readout to make sure pixels are 'empty'
> ActivateHFM # startup HV & FADC controls
> SetFadcSettings # load the FADC settings
> Run # start a data taking run
> 1 # run time via # frames
> 0
> 0
> 0
> 2 # shutter range select
> 30 # shutter time select
> 0 # zero suppression
> 1 # FADC usage
> 0 # accept FADC settings
#+end_src

Data taken with TOS is stored - for historic reasons - in pure ASCII
files. Two different readout modes (with different output formats) are
supported. For the following explanation it is assumed the Timepix is
used in the ToT mode.
1. full matrix readout: reads out the whole Timepix ASIC and writes a
   single 256x256 pixel matrix as an ASCII file. 256 lines, each
   containing space separated ToT values for each pixel.
2. zero suppressed readout: reads out only those pixels that have ToT
   values larger than 0. Stores the data in TSV files (tab separated
   values) =X Y ToT= with an additional header. The header contains a
   global "run" and "event" header, which contains information about
   the run the event is taken from and a "chip" header, which contains
   information about the specific Timepix ASIC being read out (up to 8
   can be read out at the same time using TOS).

The Timepix is only capable of shutter based readouts. Typically, a
fixed shutter is used. The readout is complicated for the case of
using an FADC, in which case an FADC signal can be used as an external
trigger to close the shutter early. This will be further explained in
the FADC section, [[FADC]].
*REWRITE THIS PART, REFER TO SCHEMATIC ABOUT TIMEPIX*

As for our purposes most events are extremely sparse (< 500 pixels
active) the zero suppressed readout is the only relevant readout
mode. An example of the file type produced in this mode is in listing
[[zero_suppressed_readout]].

#+CAPTION: Example of an event read out in zero suppressed readout mode. The ASCII output data
#+CAPTION: consists of a global run and event header (indicated by =##=), a chip header (indicated by 
#+CAPTION: =#= and actual data in format =X Y ToT= values. Each chip header is followed by
#+CAPTION: by all active pixels on that chip in the event.
#+NAME: zero_suppressed_readout
#+begin_src sh
## [General]
## runNumber:        339
## runTime:       	 7200
## runTimeFrames: 	 0
## pathName:         data/runs/Run_339_190218-10-36
## dateTime:         2019-02-18.10:36:34
## numChips:         7
## shutterTime:      2
## shutterMode:      verylong
## runMode:          0
## fastClock:        0
## externalTrigger:  0
## [Event]
## eventNumber:      2
## useHvFadc:    	 1
## fadcReadout:    	 1
## szint1ClockInt:	 0
## szint2ClockInt:	 0
## fadcTriggerClock: 647246
# chipNumber: 0
# chipName:   E 6 W69
# numHits:    0
# chipNumber: 1
# chipName:   K 6 W69
# numHits:    0
# chipNumber: 2
# chipName:   H 9 W69
# numHits:    2
106	160	75
211	142	2
# chipNumber: 3
# chipName:   H 10 W69
# numHits:    23
238	154	51
242	153	18
...
# chipNumber: 4
# chipName:   G 10 W69
# numHits:    0
# chipNumber: 5
# chipName:   D 9 W69
# numHits:    0
# chipNumber: 6
# chipName:   L 8 W69
# numHits:    4
139	254	146
166	233	11810
234	203	11810
70	57	315
#+end_src

Working principle of TOS.

User facing REPL.

Different classes for PC, Timepix, chip, fpga stuff.

VME USB module.

Communication with HV & FADC via.

TOS. TOF.

Link to repositories (maybe we can make the Virtex TOS public?) 

Link to TOF firmware.


Septem event display example.


*** TOS output data format
:PROPERTIES:
:CUSTOM_ID: sec:tos_output_format
:END:

TOS needs to talk about data format that was used in V6 TOS. Stupid
ASCII files. Mention that in hindsight the time should have been
invested to either use a really dumb binary format (like NIO) or HDF5
(even if painful from C++).


Already shown an example above in the section. Move this into this section?


*** TOS development                                              :noexport:

As mentioned in one of the footnotes in the previous section, there
are nowadays 2 independent versions of TOS.

The detector used for CAST in 2014/15 (and thus its successor used in
this thesis) was based on a readout using the Virtex 6 FPGA. This
system was, at the point I started on my master thesis in 2015,
already quite diverged from the SRS based system, which was mainly
developed for multi chip detectors that were initially planned for a
large GridPix based TPC to be used for the ILD (the detector planned
for the ILC, the International Linear Collider to be built in Japan).

In addition there was recent a master thesis (by Alexander Deisting, ref
*CITE DEISTING*), which included work on using an FADC to read out the
induced charges on the grid of the InGrid by decoupling the signal
using a capacitor.
The software library to interact with the used FADC had partially been
implemented into the Virtex 6 TOS. 

As the FADC was an integral part in the new detector design, it was
natural to start with the Virtex 6 version.

At the same time the SRS TOS version at the time was even more
ugly than the same code paths in the Virtex 6 TOS.

... 

A large amount of time spent

*what else*


** TODO schematic of whole readout chain

*ELSEWHERE AS WELL?*

Create a full flow chart of how everything is connected.

We have our notes about where each cable goes etc.

We have a schematic in the master thesis. That can be modified a bit
for the PhD thesis.

** Detector calibrations etc.

*ELSEWHERE AS WELL*

What kind of calibrations exist. How do they work, what do they do
etc.

From a purely detector standpoint.

Polya distribution goes here somewhere. Related to gaseous detector
physics & our detector in particular.

Before a Timepix based detector can be used for data taking, different
calibrations have to be performed.

We will discuss the main calibrations that are performed, starting
with a =THS= optimization (sec. [[=THS= optimization]]) , followed by the threshold
equalization (sec [[Threshold equalization]]). Third is an S-Curve scan
(sec. [[S-Curve scan]]) and finally the ToT calibration, section [[ToT
calibration]]. In these the first 3 are calibrations that are used to
set different DACs on the Timepix to 'good' values. The last
calibration on the other hand is one to *interpret* the ToT values in
amounts of charge.

In principle there are many other calibrations one could perform, as
the Timepix has *CHECK NUMBER* 10 different DACs. Most are used with
default values that are seen in *TABLE OF CALIBRATION*.

These calibrations are mainly explained to give context for the used
detector calibrations at CAST. All calibrations can be found in appendix *APPEND CALIBRATIONS*.

*** =THS= optimization

The =THS= DAC is one of the available DACs on the Timepix ASIC. It's
purpose is to change the behavior of another DAC, the *WHAT IS THIS
CALLED* which is present on each pixel. A change in the =THS= DAC
yields a change in the relative range of the *PIXEL THR DAC*. 

If the =THS= DAC is set too low *CHECK*, the 4 bit DAC on each pixel
will be too coarse for a fine adjustment. If it is too high, not
enough range will be available to adjust each pixel to an equal noise
/ sensitivity level.

The calibration works by scanning a range of =THL= values (the global
threshold DAC) through a subset of 4096 pixels on the given chip using
pixel DAC values of 0 for all these pixels and doing the same at the
maximum value of 15 for each pixel. For each of these two cases we can
compute a histogram of the number of active pixels given different
=THL= values. The resulting histogram will be a Gaussian around a
specific =THL= value. An ideal =THS= value is such that these two
Gaussians overlap at the 3σ level (*OR RMS?*), as it means the range
of the 4 bit DAC is large enough to adjust all pixels to be at the
same level in the threshold equalization (next calibration).

*INSERT SOMEWHERE* For each =THL= value the shutter is opened
shortly. If a pixel has a too low threshold, it will register random
noise as a ToT signal. After closing the shutter the pixels will be
read out and the resulting values are used. *bla*

The actual calibration starts from a user given =THS= value and
computes the two mentioned histograms. Then the =THS= value is halved
and the same histograms are computed again. As the =THS= DAC is
linear, the distance between the two histograms is computed for the
first and second =THS= value. Then using a linear interpolation the
ideal 3σ is computed and set.

_Note:_ for this calibration the =THL= range to scan is another user given
input. All that matters for this range is to make sure the real
threshold of the pixels lies within that range (such that the two
Gaussians are fully within that range).

*PSEUDO CODE ALGORITHM?*

*PLOT OF THESE TWO HISTOGRAMS. SHOW MAYBE IDEALIZED EXAMPLE OF BAD THS
AND GOOD THS VALUE*

*LOOK AT TOS CODE AGAIN*

*CROSS CHECK THE NAMES ETC*

*** Threshold equalization

The threshold equalization requires the =THS= optimization to be done
correctly. Its goal is to set each pixel DAC such that, in theory,
each pixel has exactly the same =THL= threshold value.

Essentially, the algorithm walks over all pixels and scans a user
given =THL= range while changing the pixel DACs for each pixel to move
the threshold to the same value.

After equalization each pixel should in theory have the same threshold.

*UNDERSTAND THIS ALGORITHM*

*** S-Curve scan

The S-Curve scan is one of 2 different ways to determine the optimal
=THL= value. 

It works by injecting charges onto each pixel and checking the pixel
response of each pixel at different =THL= values. Below a certain
=THL= value all pixels will respond to the injected charge. At some
point certain pixels will be insensitive to the induced charge and a
90° rotated "S" will form. By fitting an error function to this S an
ideal =THL= value can be deduced. 

An alternative to this method is to simply scan all =THL= values by
hand and look at the number of pixels active. For a correctly
equalized chip a sharp drop off of noisy pixels should be visible at a
certain threshold. In principle the =THL= value at which no more
pixels are noisy is the ideal =THL= value.

However, one major issue of determining the threshold is one of
shutter lengths, which complicates this idealized view. Each Timepix
pixel has an electronic noise charge (ENC) of *CHECK THIS*
electrons. Of course the behavior of the charges on the pixels are
statistically distributed. For the different calibrations typically
very short shutter opening times are used to get fast
calibrations. For practical data takings at experiments like CAST,
very long shutter times on the order of $\mathcal{O}(> \SI{1}{\s})$ are
used however. Due to the statistical nature of noise, a =THL= value
that is noise less may not be fully noise free for long
shutters. Therefore, one often uses =THL= values that are slightly
larger (i.e. ~5 values larger of the 10 bit DAC). 

In this sense the S-Curve scan is a good cross check for whether the
=THL= value seems sensible, but in practice a =THL= scan with a longer
shutter time is more useful. 

*PLOT OF SCURVE SCANS*

*APPENDIX ALL SCURVE SCANS FOR CAST DATA TAKING*

*** ToT calibration
:PROPERTIES:
:CUSTOM_ID: sec:tot_calibration
:END:


The final calibration that is crucial to interpret the data received
from each Timepix ASIC is the ToT (\textbf{T}ime \textbf{o}ver
\textbf{T}hreshold) calibration. It is needed to interpret the ToT
values recorded by each pixel as a charge, i.e. a number of recorded
electrons.

This is done by injecting charges onto the individual
pixels. Capacitors are present to inject very precise voltage bursts
onto the pixels. By knowing the capacitance and the voltage induced on
them, the number of injected electrons can be easily calculated from

\[
Q = C U.
\]

By varying the injected charge and recording the resulting ToT values
of the pixels a relation between electrons and ToT values is
determined.

The resulting relationship is a $\mathrm{sqrt}$ function:

\[
f(ToT) = \sqrt{x} ... stuff
\]

An example of a ToT calibration of one chip is shown in fig. *ToT CALIB*.

Required understanding for our charge calibration.

Show function that is being fitted to it.

*** Pólya distribution & gas gain
:PROPERTIES:
:CUSTOM_ID: sec:polya_distribution
:END:

Explain how all charge values combined as a histogram generate a
~Pólya distribution from which we can deduce the gas gain.


* Software                                                         :Software:

Introduce used software for analysis.

Previous code used MarlinTPC (already extended a framework for use for
gaseous detectors, focus on strips). Additional extension to use our
new detector features would be beyond the scope of the framework. 

** Nim

Shortly introduce Nim & why it was chosen.

Efficient, productive, gets out of my way.

** TimepixAnalysis

Framework written for data analysis.

Rewrites Timepix / InGrid related code from MarlinTPC in Nim and
extends it (e.g. supports Timepix3).

[[https://github.com/Vindaar/TimepixAnalysis]]

After the thesis is published it is possible that this repository will
become the de facto repository for the thesis and the actual analysis
code will become its own repository. We'll see.

*THESE SECTIONS MUST BE MERGED WITH THE ANALYSIS BELOW*. Maybe let
this chapter simply be a high level overview: introduce Nim and the
why. Mention the TimepixAnalysis repo only as a "this is the code for
the analysis, the details of which will be explained in the next
section? In that case one might merge the whole chapter with the next
one and simply have these as the introductory part of the chapter.

*** =raw_data_manipulation=

*LINK TO HDF5 FORMAT IF FIRST TIME MENTIONING*

The first step of the analysis pipeline is essentially just a parsing
stage of the data generated by TOS (see section [[sec:tos_output_format]]
for an explanation of it) and storing it in a compressed HDF5 data
file.

The program is fed with a directory containing a TOS run, i.e. a
single data taking period ranging typically from minutes to days in
length, or a directory that itself contains multiple TOS run directories.

All data files contained in a run directory will then be parsed in a
multithreaded way. The files are memory mapped and parsed in parallel
into a =Run= data structure, which itself contains =Event= structures.

Depending on the designated run type of a file, some slight
processing steps are performed. *WHAT?*

If FADC files are present in a directory, these will also be parsed
into =FadcEvent= structures in a similar fashion.

Each run is then written into the output HDF5 file as a group. The
meta data about each run and event are stored as attributes and
additional datasets, respectively.

An example structure of a resulting HDF5 file is shown in:
*EXAMPLE LAYOUT WITH EXAMPLE ATTRIBUTES AND DATASETS?*

In addition the tool also supports input from HDF5 files containing
the raw data from a Timepix3 detector. That data is parsed and
reprocessed into the same kind of file structure.

#+CAPTION: Usage of the =raw_data_manipulation= tool. Input is in the form of a run directory / a directory
#+CAPTION: containing multiple run directories. The parsed output is stored in compressed HDF5 files.
#+NAME: list:raw_data_manipulation_help
#+begin_src shell-session
Version: 13809be built on: 2021-05-07 at 00:53:39
  InGrid raw data manipulation.

Usage:
  raw_data_manipulation <folder> [options]
  raw_data_manipulation <folder> --runType <type> [options]
  raw_data_manipulation <folder> --out=<name> [--nofadc] \
    [--runType=<type>] [--ignoreRunList] [options]
  raw_data_manipulation <folder> --nofadc [options]
  raw_data_manipulation --tpx3 <H5File> [options]
  raw_data_manipulation --tpx3 <H5File> --runType <type> [options]
  raw_data_manipulation --tpx3 <H5File> --runType <type> --out=<name> \
    [options]
  raw_data_manipulation -h | --help
  raw_data_manipulation --version

Options:
  --tpx3 <H5File>     Convert data from a Timepix3 H5 file to TPA format
  --runType=<type>    Select run type (Calib | Back | Xray)
                      The following are parsed case insensetive:
                      Calib = {"calib", "calibration", "c"}
                      Back = {"back", "background", "b"}
                      Xray = {"xray", "xrayfinger", "x"}
  --out=<name>        Filename of output file
  --nofadc            Do not read FADC files
  --ignoreRunList     If set ignores the run list 2014/15 to indicate
                      using any rfOldTos run
  --overwrite         If set will overwrite runs already existing in the
                      file. By default runs found in the file will be skipped.
                      HOWEVER: overwriting is assumed, if you only hand a
                      run folder!
  -h --help           Show this help
  --version           Show version.
#+end_src

*** =reconstruction=
:PROPERTIES:
:CUSTOM_ID: sec:reconstruction
:END:

After the raw data has been converted to storage in HDF5, the
=reconstruction= tool is used to start the actual analysis of the
data.

As the name implies, the first stage of data analysis is in the form
of reconstructing the basic properties of each event. In this stage
all events are processed in a multithreaded way. A cluster finding
algorithm is applied to each event on each chip separately, splitting
a single event into possibly multiple clusters. Clusters are defined
based on a certain notion of distance (the details depend on the
clustering algorithm used). The multiple clusters from a single event
are then treated fully equally for the rest of the analysis. The fact
that they originate from the same event has no further relevance (with
a slight exception for one veto technique, which utilizes clustering
over multiple chips, more on that in section [[sec:septem_veto]]).

For the individual clusters geometric properties will be
computed. These are the long and short axis, the eccentricity as well
as the statistical moments up to kurtosis along the long and short
axis. The full list is shown in tab. [[tab:geometric_properties]].

#+CAPTION: Table of all the (mostly) geometric properties of a single cluster computed during the
#+CAPTION: =reconstruction= tool. All but the likelihood, charge and energy properties are computed
#+CAPTION: during the first pass of the tool.
#+NAME: tab:geometric_properties
| Property                  | Meaning                                                          |
|---------------------------+------------------------------------------------------------------|
| igCenterX                 | =x= position of cluster center                                   |
| igCenterY                 | =y= position of cluster center                                   |
| igHits                    | number of pixels in cluster                                      |
| igEventNumber             | event number cluster is from                                     |
| igEccentricity            | eccentricity of the cluster                                      |
| igSkewnessLongitudinal    | skewness along long axis                                         |
| igSkewnessTransverse      | skewness along short axis                                        |
| igKurtosisLongitudinal    | kurtosis along long axis                                         |
| igKurtosisTransverse      | kurtosis along short axis                                        |
| igLength                  | size along long axis                                             |
| igWidth                   | size along short axis                                            |
| igRmsLongitudinal         | RMS along long axis                                              |
| igRmsTransverse           | RMS along short axis                                             |
| igLengthDivRmsTrans       | length divided by transverse RMS                                 |
| igRotationAngle           | rotation angle of long axis over chip coordinate system          |
| igEnergyFromCharge        | energy of cluster computed from its charge                       |
| igLikelihood              | likelihood value for cluster                                     |
| igFractionInTransverseRms | fraction of pixels within radius of transverse RMS around center |
| igTotalCharge             | integrated charge of total cluster in electrons                  |
| igNumClusters             |                                                                  |
| igFractionInHalfRadius    | fraction of pixels in half radius around center                  |
| igRadiusDivRmsTrans       | radius divided by transverse RMS                                 |
| igRadius                  | radius of cluster                                                |
| igLengthDivRadius         | length divided by radius                                         |

The properties are computed here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L308-L366
and here:
https://github.com/Vindaar/TimepixAnalysis/blob/master/Analysis/ingrid/private/geometry.nim#L517-L569

*NOTE:* How should we take care of linking to our code? Of course need
tagged version that corresponds to stuff in the thesis, but beyond
that?


After all geometrical properties have been computed, the next step is
to apply the ToT calibration (sec. [[sec:tot_calibration]]) to the ToT
values of all clusters, resulting in the equivalent charge in
electrons. The charge values for all recorded pixels are then used to
compute a histogram, which roughly follows a Pólya distribution
(sec. [[sec:polya_distribution]]). From the mean value of that
distribution a value for the gas gain is obtained, which is a
necessary input to perform an energy calibration for each cluster.

Second step of analysis, performs most of the major steps.

- cluster finding
- calculation of geometric properties
- charge calibration
- gas gain computation
- energy calibration
- ...



*** =likelihood=

Apply likelihood method for background suppression.

*** =computeLimit=

Computes the limit *NOT THE ONE USED*

*** Other

**** =cdl_spectrum_creation=

Generates the data from the CDL data that is used as X-ray reference
data for the likelihood method.

**** ...

Many other tools are present. Mainly different plotting tools and
tools dealing with other data, e.g. log files of the CAST experiment.


* Chapter about analysis principle                                 :Software:

*NOTE:* We need to better understand how to:
- explain the theoretical foundations of what we do, e.g. cluster
  finding algorithms. Certain things, e.g. cluster finding algos could
  also just go to the appendix. Interesting, but technically just a detail.
- introduce the software stack we use
- introduce the physics for the calibration (e.g. ToT calib, ...)
- explain the algorithms used in the software

Can we disentangle this from the purely detector focused things? I'm
not so sure.

After introducing detector specific calibrations etc. we can go on to
what the steps are that are required to turn a calibrated detector
(one that is sensitive to N electrons essentially) into something that
can do physics.

Need some chapter that talks about the detector specific details that
explain how a limit / physics result is obtained.

** Take data. Output data is ASCII files

Parsing of data in format.

Present format.
#+begin_quote
Generic header.

Data.
#+end_quote

Store data in HDF5 files. Not much going on here aside from making it
fast.

** Reconstruct & calibrate data

Read data from HDF5 files. 

What does reconstruction mean?

Multiple things.

*** 1. perform cluster finding

Present our current two clustering algorithms. 

- dumb search in radius around each pixel (add foot note that the
  implementation in MarlinTPC had a bug)
- optional: DBSCAN, short introduction give full reference to
  implementation.

**** Investigation of buggy clustering in MarlinTPC             :noexport:

*** 2. for each cluster, compute geometric properties

Table of the computed properties.

As they are geometric easy to explain.

Highlight the ones used for likelihood. Done here? 

Show our sketch explaining what each property means from one of the
talks. Maybe need to fix the radius variable?



*** 3. (optional / required for analysis) charge calibration

Use Timepix ToT calibration (ref theory section before where we
explain how it works).

Given ToT calibration apply function to get number of electrons (given
that we ran in ToT mode).

*** 4. (optional / required for analysis) compute gas gain

Computing gas gain. Polya fit. Explain not fit parameter used, but
mean of data.

Heavy gas gain variation over time. 

Explain that thus behavior chosen that minimizes effect by binning in
time.

90 minutes.

Show plot with old way (full runs) vs. new length.

Results in stable operation. This section probably belongs somewhere
else? 

**** Study for optimal gas gain time length                     :noexport:



*** 5. (optional / required for analysis) energy computation

Requires: charge calibration, gas gain

Very easy in theory. In practice complicated.

Theoretically, two ways:

1. pixel counting. Due to single electron detection efficiency (or a
   slight correction for under/overcounting) can just multiply hits by
   eV per hit
2. charge calibration plus reference spectrum of 55Fe runs. 

Both cases are very simple *iff* the detector is stable over
time. Then just take closest 55Fe run and compute correction factor
for hits / conversion factor from peak in charge values.

But: instability means we need to average over more data.

Compute for all runs.

Fit.

Apply fit.

*** 6. (optional) FADC reconstruction

Apply pedestals.

Determine lowest point. Determine rising / falling times in ns.

Compute other properties.

** Compute reference spectra 

Possibly explain in chapter about CDL? Or talk there only about the
*data* we took there, but not in detail about *what* this data is *for*?

If so explain here.

** Log file reader to get tracking (maybe no export)

Talk about log file reader (full section definitely :noexport:), used
to mark times in runs that correspond to tracking.

** Likelihood method

Explain likelihood method in theory (maybe do in section before).

Explain our methods for linear interpolation between the reference
spectra.

Apply reference data for limit at specific custom software efficiency.

Started at 80% reference and then tweaked for optimal ε = S/√B (or
something). 

Likelihood method gives us everything we need for background
rate. Whatever comes out gives us left over clusters.

*** Septem veto
:PROPERTIES:
:CUSTOM_ID: sec:septem_veto
:END:

Talk about the septem veto we finally use.

In the septem veto the main idea is to go back to the raw data for any
event, which contains a cluster on the central chip, which is
signal-like based on the likelihood method presented above. For these,
a so called 'septem event' is built based on the raw pixel data of all
chips. This is simply an 'event' in the same notion as understood by
the =reconstruction= tool (c/f [[sec:reconstruction]]), i.e. a two
dimensional array of the ToT values. Except in this case it is not a
$256 \times 256$ array, but rather a $3 \cdot 256 \times 3 \cdot 256$
array, where the full septemboard detector is merged into a single
event without any spacing between the chips (more on that below). 

These septem events are then pushed through the whole reconstruction
and calibration pipeline. Thanks to starting from an event that now
includes information that was previously not taken into account (pixel
activity outside the center chip), the cluster finding algorithm can
detect larger clusters than previously. This can change the shape of
the cluster that was previously considered signal like. In the case
that this cluster now looks more like background, it will be vetoed by
this technique.

The decision to merge the different chips into a single event
*without* any spacing between the chips is made to ensure good cluster
finding. The spacing between chips is of course a dead zone where no
activity can be measured. For a cluster finding algorithm this may
cause a cutoff that should not happen, as the information is simply
not *available*. Ideally, one could imagine an algorithm that
interpolates data between the chips based on the information on the
two neighboring chips. But this is too experimental. 

If there is data on the neighboring chip, it is extremely likely there
was ionization between the chips as well, meaning the merging of the
chips "only" makes the event less eccentric than the physical
event. If there is no data on the neighboring chip, the merging has no
effect, the cluster will simply look the same as in the original
single chip event. 

This excludes two possibilities:
1. a physical event may have no active pixels between the chips, despite
   having active pixels on both chip borders. This is extremely
   unlikely, if the events are significantly close to the border. The
   main case of this would be two real X-rays (extremely low
   probability) or either of the clusters is a track parallel to
   border of the chip. 
2. a more likely loss information for events without information on
   the neighboring chips, despite the physical event being more
   eccentric than the recorded one. This is a real limitation that
   cannot be worked around.

**** Explain why no spacing between chips

**** Hough transformation experiments                           :noexport:



*** Scintillator veto

Talk about scintillator veto. Main ideas of course.

*** FADC veto

Explain the veto we use based on FADC.



*** Comparison with other attempts                               :noexport:

Show the other attempts we did about the different ways to
interpolate.

** Compute limit

Limit computation done. Needs to be after ray tracing introduction I'd
say. Input for theory is required.

Perform signal / background rejection.

Get background rate + signals in tracking.

Get expected flux from theory.

Get detector efficiencies.

Combine efficiencies & theory flux in raytracing simulation.

Compute 'real' expected signal.

Use suitable limit calculation method to compute a limit.

We can split this into two pieces?:

** How to compute background rate

** How to compute a limit

For =mclimit= use the notes in StatusAndProgress about how limit
calculation works. Might be good in general, because a lot of it
applies elsewhere anyway.

Describe unbinned likelihood method from Nature paper adapted to our
work. We can plot some funny plots explaining how it works.

* Raytracing - where does this belong?                             :Software:

Ray tracing through the detector. Put this before limit calculation stuff?

The whole theoretical side needs to be described in the theory chapter
in [[Axion-electron flux]]. Then here we can just describe how one
implements this (in particular in the noexport section). 

*PLOT OF MIRROR SHELLS*

*AXION ELECTRON IMAGE*

*PRIMAKOFF IMAGE*

*CHAMELEON IMAGE*

*NUMBERS FOR FLUX FRACTION ENCOUNTERED WHERE*

** TODO Can we finish our interactive ray tracer?

Need:
- light sources (4h of work at most)
- cylinders, hyperboloids, paraboloids as objects (once we figure out
  one, the rest should be relatively easy)
- placing different telescope layers etc. (2h)

In theory this *should* be possible as an extensive weekend project!
I'd say this is definitely worth it.


** Computation of atomic processes :noexport:

Computation of atomic processes done in *CODE*. 




* Detector preparation / study / characterization etc.                :Part3:

** CAST Detector Lab

Measurements for X-ray reference data

Detector lab measurements were only performed after the data taking
period at CAST was over. From a logical standpoint it makes more sense
to talk about it before though.

Everything required in StatusAndProgress. Will need to redo all plots
of course.

** Detector calibrations + characterization plots

*** FADC spectrum & threshold

** 55Fe spectra

Example spectrum. What's the point of these spectra.

** Energy calibration, how done?


* Detector installation at CAST & data taking                         :Part3:

** Installation & setup

Use detector documentation written for CERN (Thank fucking god I had
to write this back then).

** Lead shielding at CAST 

PDF of lead shielding. Extract one image as reference, refer to full
one in appendix.

** X-ray finger runs

2 X-ray finger runs were made. One near beginning, one near end.

Plot of X-ray finger centers.

Mention how this plays into the analysis side, that it means we need
to adjust the ray tracing.

** CAST log files, data format bla

** Issues etc. during data taking period

Noise issues, scintillators not working in Run 2 due to firmware bug.

** Detector behavior over time

Plot of the (known) temperature at PCB from shift forms.
Unfortunately, most of the high resolution temperature logs were lost due to a
software bug.
Cooling power varied over time, probably due to slight clogging.

Plot of the peak position of the 55Fe calibration runs.

** Run 2 and Run 3

Different detector calibrations in each run.

Amount of data in each. Take table from StatusAndProgress.

Run table somewhere in appendix, link to online version.


* Background rate computation                                      :Analysis:

Mitigation strategies for detector behavior, e.g. gain variation over time.

** Understanding background rate

3 keV is easy to understand.

8-9 keV is more difficult. 

** Muon calculations :noexport:

Probably not going to make it into final thesis? We'll see, take from
StatusAndProgress. Maybe shortened version will make it.

* Limit calculation                                                :Analysis:

If we decide to present different limits, we should have one section
(maybe in theory) where we present our methodology and then compute
the limits based on that method for each of the different cases:
- chameleon
- axion photon
- axion electron

Using background rate & methods to determine it.

*Need* to show the log L phase space according to Igor. Well, that
seems useful anyway.

** Axions

*** Axion-electron coupling

*** Axion-photon coupling

** Compute limit w/ our method (whatever that will finally be)

** Comparison to 2013 limit (using their method)

** Limit calculation using neural networks :PENDING:

** TODO Chameleons ?

* Outlook                                                             :Part5:

Timepix3 based detector will be big improvement, as long readout times
without time information are probably the biggest issue (and partially
biggest mistake) in the data taking campaign.

* Summary & conclusion                                                :Part5:



* Acknowledgments                                                     :Part5:

Thanks to Klaus & group.

Thanks to Araq for building Nim.

Thanks to Nim community, and especially:
mratsim, Hugo, Clonkk, Andrea Ferreti (alea among others), brentp
(plotly was a *huge* help in the beginning), Bluenote10 (NimData was
great), yglukhov (nimpy in particular!!)


# Use biblatex for the bibliography
# Add bibliography to Table of Contents
# Comment out this command if your references are printed for each chapter.
#+LATEX: \printbibliography[heading=bibintoc]

* Appendix                                                         :Appendix:

#+LATEX: \listoffigures{}

#+LATEX: \listoftables{}


